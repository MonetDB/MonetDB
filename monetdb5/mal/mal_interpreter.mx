@/
The contents of this file are subject to the MonetDB Public License
Version 1.1 (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html

Software distributed under the License is distributed on an "AS IS"
basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
License for the specific language governing rights and limitations
under the License.

The Original Code is the MonetDB Database System.

The Initial Developer of the Original Code is CWI.
Portions created by CWI are Copyright (C) 1997-July 2008 CWI.
Copyright August 2008-2011 MonetDB B.V.
All Rights Reserved.
@

@a M. Kersten
@v 0.0
@* The MAL Interpreter
The MAL interpreter always works in the context of a single user session,
which provides for storage access to global variables and modules.
@menu
* MAL API::
* Exception Handling::
* Garbage Collection::
* Stack Management::
@end menu

@{
@h
#ifndef _MAL_INTERPRET_H
#define _MAL_INTERPRET_H

#include "mal_client.h"
#include "mal_factory.h"
#include "mal_profiler.h"

@-
Activation of a thread requires construction of the argument list
to be passed by a handle.
@h

/*#define DEBUG_MAL_INTERPRETER*/
/* #define DEBUG_FLOW */
/* #define DEBUG_FLOW2 */
/* #define STACKTRACE*/
/* #define DEBUG_GC*/
/* #define DEBUG_MEMORY_CLAIM*/

mal_export void showErrors(Client cntxt);
mal_export MalStkPtr prepareMALstack(MalBlkPtr mb, int size);
mal_export str runMAL(Client c, MalBlkPtr mb, int startpc,
			MalBlkPtr mbcaller, MalStkPtr env, InstrPtr pcicaller);
mal_export str runMALdataflow( Client cntxt, MalBlkPtr mb, int startpc,
		int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller);
mal_export str reenterMAL(Client cntxt, MalBlkPtr mb, int startpc,
	int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller);
mal_export str callMAL(Client cntxt, MalBlkPtr mb, MalStkPtr *glb,
	ValPtr argv[], char debug);
mal_export void garbageElement(Client cntxt, ValPtr v);
mal_export void garbageCollector(Client cntxt, MalBlkPtr mb, MalStkPtr stk, int flag);
mal_export void releaseBAT(MalBlkPtr mb, MalStkPtr stk, int bid);
mal_export lng getVolume(MalStkPtr stk, InstrPtr pci, int rd);
mal_export void getMemoryClaim(MalStkPtr stk, InstrPtr pci, lng *argclaim, lng *retclaim, lng *hotclaim);

mal_export ptr getArgReference(MalStkPtr stk, InstrPtr pci, int k);

@c
#include "monetdb_config.h"
#include "mal_interpreter.h"
#include "mal_debugger.h"   /* for mdbStep() */
#include "mal_recycle.h"
#include "mal_type.h"

#define SLOW 1
#define FAST 0

static str runMALsequence( Client cntxt, MalBlkPtr mb, int startpc,
		int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller);
static void displayVolume(Client cntxt, lng vol);

#define MEMORY_THRESHOLD  0.8
#define MAXHOT 16

static lng memorypool;		/* memory claimed by concurrent threads */
static lng memoryused;		/* memory used for intermediates */
static int memoryclaims = 0;	/* number of threads active with expensive operations */
static struct{
	lng claim;	/* actual claim on memory*/
	int bid;
} hotpotatoes[MAXHOT];
static int hottop = 0;

#define heapinfo(X) if((X) && (X)->base) vol = (X)->free; else vol = 0;
#define hashinfo(X) if((X) && (X)->mask) vol = ((X)->mask+(X)->lim+1)*sizeof(int) + sizeof(*(X)); else vol = 0;

#define FREE_EXCEPTION(p) { if (p && p != M5OutOfMemory) GDKfree(p); }

@-
The struct alignment leads to 40% gain in simple instructions when set.
@c
inline
ptr getArgReference(MalStkPtr stk, InstrPtr pci, int k)
{
#ifdef STRUCT_ALIGNED
	return (ptr) & stk->stk[pci->argv[k]].val.ival;
#else
	int j=0;
	ValRecord *v=0;
	ptr ret = NULL;

	j = pci->argv[k];
	v= &stk->stk[j];

	switch(ATOMstorage(v->vtype)){
	case TYPE_void: ret= (ptr) & v->val.ival; break;
	case TYPE_bit: ret= (ptr) & v->val.cval[0]; break;
	case TYPE_chr: ret= (ptr) & v->val.cval[0]; break;
	case TYPE_sht: ret= (ptr) & v->val.shval; break;
	case TYPE_bat: ret= (ptr) & v->val.bval; break;
	case TYPE_int: ret= (ptr) & v->val.ival; break;
	case TYPE_wrd: ret= (ptr) & v->val.wval; break;
	case TYPE_bte: ret= (ptr) & v->val.btval; break;
	case TYPE_oid: ret= (ptr) & v->val.oval; break;
	case TYPE_ptr: ret= (ptr) & v->val.pval; break;
	case TYPE_flt: ret= (ptr) & v->val.fval; break;
	case TYPE_dbl: ret= (ptr) & v->val.dval; break;
	case TYPE_lng: ret= (ptr) & v->val.lval; break;
	case TYPE_str: ret= (ptr) & v->val.sval; break;
	default:
		ret= (ptr) & v->val.pval;
	}
	return ret;
#endif
}

/* code is obsolete, because all should be handled as exceptions */
void showErrors(Client cntxt) {
	int i;
	if (cntxt->errbuf && *cntxt->errbuf) {
		i = (int)strlen(cntxt->errbuf);
		mnstr_printf(cntxt->fdout, "%s", cntxt->errbuf);
		if (cntxt->errbuf[i - 1] != '\n')
			mnstr_printf(cntxt->fdout, "\n");
		cntxt->errbuf[0] = '\0';
	}
}
@-
The bigfoot memory tracker keeps track on the space occupancy of BATs.
The property 'memory' illustrates the total amount of memory claimed.
It ignores for the time being the heaps for the variable sized atoms.
Moreover, it is not thread safe and it can not correctly handle
aliases embedded in MAL assignments.
This means that the footprint is only to be used as indicative.
@c
static inline void
updateBigFoot(Client cntxt, int bid, int add)
{
	BAT *b;
	lng total = 0,vol = 0;

	if (bid != bat_nil ){
		BUN cnt = 0;
		b= BBPquickdesc(ABS(bid),TRUE);
		if (b == NULL)
			return;
		if ( isVIEW(b) )
			return;
		/* count it once ! */
		cntxt->cnt = cnt = BATcount(b);
		@:calcFootprint@
		if ( b->H->hash )
			total +=  cnt * sizeof(int);
		if ( b->T->hash )
			total +=  cnt * sizeof(int);

		if (add) {
			cntxt->vmfoot += total;
			cntxt->memory += total;
		} else
			cntxt->vmfoot -= total;
		/* correct for limitations by resetting */
		if (cntxt->vmfoot < 0)
			cntxt->vmfoot = 0;
		if (cntxt->vmfoot > cntxt->bigfoot)
			cntxt->bigfoot = cntxt->vmfoot;
	}
}
@-
Copy the constant values onto the stack frame
Also we cannot overwrite values on the stack as this maybe part of a
sequence of factory calls.
BEWARE WE ASSUME THAT FIRST VARIABLES ON THE STACK ALIGN WITH THE SIGNATURE.
@= initStack
	for(i= @1; i< mb->vtop; i++) {
		lhs = &stk->stk[i];
		if( isVarConstant(mb,i) > 0 ){
			if( !isVarDisabled(mb,i)){
				rhs = &getVarConstant(mb,i);
				VALcopy(lhs,rhs);
			}
		} else{
			lhs->vtype = getVarGDKType(mb,i);
			lhs->val.pval = 0;
			lhs->len = 0;
		}
	}
@c
static int
isNotUsedIn(InstrPtr p, int start, int a)
{
	int k;
	for (k=start; k<p->argc; k++)
		if( getArg(p,k)== a)
			return 0;
	return 1;
}

MalStkPtr
prepareMALstack(MalBlkPtr mb, int size){
	MalStkPtr stk= NULL;
	int i;
	ValPtr lhs,rhs;

	assert(size >= mb->vsize);
	stk= newGlobalStack(size);
	memset((char *) stk, 0, stackSize(size));
	stk->stktop= mb->vtop;
	stk->stksize= size;
	stk->blk= mb;

	@:initStack(1)@
	return stk;
}

str runMAL(Client cntxt, MalBlkPtr mb, int startpc, MalBlkPtr mbcaller,
	   MalStkPtr env, InstrPtr pcicaller){
	MalStkPtr stk= NULL;
	int i;
	ValPtr lhs,rhs;
	InstrPtr pci=getInstrPtr(mb,0);
	str ret;
	@:performanceVariables@

	if (mb->errors) {
		showErrors(cntxt);
		if (cntxt->itrace == 0) /* permit debugger analysis */
			return createScriptException(mb, 0, MAL, NULL, "Syntax error in script");
	}
@-
Prepare a new interpreter call. This involves two steps, (1) allocate
the minimum amount of stack space needed, some slack resources
are included to permit code optimizers to add a few variables at run time,
(2) copying the arguments into the new stack frame.
Notice that arguments are always the first entries on the stack.

The env stackframe is set when a MAL function is called recursively.
Alternatively, there is no caller but a stk to be re-used for interpretation.
We assume here that it aligns with the variable table of the routine
being called.
@c
	/* allocate space for value stack */
	/* the global stack should be large enough */
	if( mbcaller== NULL && env != NULL){
		stk = env;
		if( mb != stk->blk)
			showScriptException(mb,0,MAL,"runMAL:misalignment of symbols\n");
		if( mb->vtop > stk->stksize)
			showScriptException(mb,0,MAL,"stack too small\n");
		pci= pcicaller;
	} else {
		newStack(stk,mb->vsize);
		stk->stktop= mb->vtop;
		stk->stksize= mb->vsize;
		stk->blk= mb;
		stk->cmd= cntxt->itrace; /* set debug mode */
		if( env) {
			/*safeguardStack*/
			stk->stkdepth= stk->stksize + env->stkdepth;
			stk->calldepth= env->calldepth + 1;
			if ( stk->calldepth > 256 )
				throw(MAL, "mal.interpreter", MAL_CALLDEPTH_FAIL);
			if ( (unsigned) stk->stkdepth > THREAD_STACK_SIZE/ sizeof(mb->var[0]) / 4 && THRhighwater())
				/* we are running low on stack space */
				throw(MAL, "mal.interpreter", MAL_STACK_FAIL);
		}
	}

	if( env && mbcaller){
		InstrPtr pp;
		int k;
@-
Beware, a function signature f(a1..an):(b1..bn) is parsed in such a way that
the symbol table and stackframe contains the sequence
f,a1..an,b1..bn. This slightly complicates the implementation
of the return statement.
@c
		pci= pcicaller;
		pp = getInstrPtr(mb, 0);
		/* set return types */
		for(i=0; i< pci->retc; i++){
			lhs = &stk->stk[i];
			lhs->vtype =getVarGDKType(mb,i);
		}
		for(k=pp->retc; i<pci->argc; i++,k++){
			lhs = &stk->stk[pp->argv[k]];
			/* variable arguments ? */
			if( k== pp->argc-1) k--;

			rhs = &env->stk[pci->argv[i]];
			VALcopy(lhs,rhs);
			if( lhs->vtype == TYPE_bat)
				BBPincref(lhs->val.bval, TRUE);
		}
		stk->up = env;
	}
@-
An optimization is to copy all constant variables used in functions immediately
onto the value stack. Then we do not have to check for their location
later on any more. At some point, the effect is optimal, if at least several
constants are referenced in a function (a gain on tst400a of 20% has been
observed due the small size of the function).

Moreover, we have to copy the result types to the stack for later
use. The stack value is cleared to avoid misinterpretation of left-over
information. Since a stack frame may contain values of a previous call,
we should first remove garbage.
@c
	if (env && mbcaller) {
		@:initStack(pci->argc)@
	} else if ( env && env->stkbot) {
		@:initStack(env->stkbot)@
	} else {
		@:initStack(mbcaller? pci->argc:1)@
	}

	if(stk->cmd  && env && stk->cmd!='f') stk->cmd = env->cmd ;
	ret = runMALsequence(cntxt, mb, startpc,  0, stk, env, pcicaller);

	/* pass the new debug mode to the caller */
	if (stk->cmd  && env && stk->cmd!='f') env->cmd = stk->cmd;
	if ( !stk->keepAlive && garbageControl(getInstrPtr(mb,0)) )
		garbageCollector(cntxt, mb,stk, env != stk);
	@:endProfile(stk)@
	if (stk && stk != env)
		GDKfree(stk);
	return ret;
}
@-

@+ Single instruction
It is possible to re-enter the interpreter at a specific place.
This is used in the area where we need to support co-routines.

A special case for MAL interpretation is to execute just one instruction.
This is typically used by optimizers and schedulers that need part of the
answer to direct their actions. Or, a dataflow scheduler could step in
to enforce a completely different execution order.
@c
str reenterMAL(Client cntxt, MalBlkPtr mb, int startpc, int stoppc,
	MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller)
{
	str ret;
	int keepAlive;

	if (stk == NULL)
		throw(MAL, "mal.interpreter", MAL_STACK_FAIL);
	keepAlive = stk->keepAlive;
	if(env && stk && stk->cmd!='f') stk->cmd = env->cmd ;

	ret = runMALsequence(cntxt, mb, startpc,  stoppc, stk, env, pcicaller);

	/* pass the new debug mode to the caller */
	if (env && stk->cmd!='f') env->cmd = stk->cmd;
	if ( keepAlive == 0 && garbageControl(getInstrPtr(mb,0)) )
		garbageCollector(cntxt, mb,stk,env!=stk);
	return ret;
}
@-
Front ends may benefit from a more direct call to any of the MAL
procedural abstractions. The argument list points to the arguments
for the block to be executed. An old stack frame may be re-used,
but it is then up to the caller to ensure it is properly
initialized.
The call does not return values, they are ignored.
@c
str
callMAL(Client cntxt, MalBlkPtr mb, MalStkPtr *env, ValPtr argv[], char debug){
	MalStkPtr stk= NULL;
	str ret= MAL_SUCCEED;
	int i;
	ValPtr lhs,rhs;
	InstrPtr pci= getInstrPtr(mb,0);
	@:performanceVariables@

#ifdef DEBUG_CALLMAL
	mnstr_printf(cntxt->fdout,"callMAL\n");
	printInstruction(cntxt->fdout,mb,0,pci,LIST_MAL_ALL);
#endif
	switch( pci->token){
	case FUNCTIONsymbol:
	case FCNcall:
@-
Prepare the stack frame for this operation. Copy all the arguments
in place. We assume that the caller has supplied pointers for
all arguments and return values.
@c
		if( *env==NULL){
			stk=newGlobalStack(mb->vsize);
			memset((char *) stk, 0, stackSize(mb->vtop));
			stk->stktop= mb->vtop;
			stk->stksize= mb->vsize;
			stk->blk= mb;
			stk->up = 0;
			@:initStack(pci->argc)@
			*env= stk;
		} else stk = *env;
		assert(stk);
		for(i=pci->retc; i<pci->argc; i++){
			lhs= &stk->stk[pci->argv[i]];
			VALcopy(lhs, argv[i]);
			if( lhs->vtype == TYPE_bat)
				BBPincref(lhs->val.bval,TRUE);
		}
		stk->cmd = debug;
		ret = runMALsequence(cntxt, mb, 1,  0, stk, 0, 0);
		break;
	case FACTORYsymbol:
	case FACcall:
		ret= callFactory(cntxt, mb, argv,debug);
		break;
	case PATcall:
	case CMDcall:
	default:
		throw(MAL, "mal.interpreter", RUNTIME_UNKNOWN_INSTRUCTION);
	}
	@:endProfile(stk)@
	return ret;
}
@-
The core of the interpreter is presented next. It takes the context information
and starts the interpretation at the designated instruction.
Note that the stack frame is aligned and initialized in the enclosing routine.
@c
str runMALsequence( Client cntxt, MalBlkPtr mb, int startpc,
		int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller)
{
	ValPtr lhs,rhs,v;
	int i,k;
	InstrPtr pci=0;
	int exceptionVar,prevpc=0;
	str ret=0;
#if FAST
	int stamp= -1;
#endif
	bat *backup= (bat*) alloca(mb->maxarg * sizeof(bat));
	str *sbackup= (str*) alloca(mb->maxarg * sizeof(str));
	int *garbage= (int*) alloca(mb->maxarg * sizeof(int));
	lng oldtimer=0;
	struct Mallinfo oldMemory;
	int stkpc = 0;
	MT_Lock *lock = NULL;
	int tid = 0;

#ifdef HAVE_SYS_RESOURCE_H
	int oldinblock=0;
	int oldoublock=0;
	struct rusage oldResource;
#endif
	@:performanceVariables@

	if (stk == NULL)
		throw(MAL, "mal.interpreter", MAL_STACK_FAIL);
	if( cntxt->flags & timerFlag)
		oldtimer= cntxt->timer= GDKusec();
	oldMemory.arena= 0;

	stkpc = startpc;
	exceptionVar = -1;
@-
From this point onwards we should differentiate fast processing
against monitored processing. Fast processing is possible if there is
no call to the debugger statically/dynamically set. Same holds for
performance control statements.
The code currently does not statically checks the mode change.
Preferrably we should introduce a itrace flag PROFILE
We rely on optimizing compilers to remove the redundant code.
@c
	if (mb->recycle ==  TRUE && malProfileMode == 0 &&
		cntxt->itrace==0 && cntxt->flags == 0 && GDKdebug == 0) {
		while(stkpc < mb->stop && stkpc != stoppc ){
			pci = getInstrPtr(mb,stkpc);
			if (malProfileMode + cntxt->itrace)
				goto workslow;

				@:MALrecycleStart(stk)@ {
				@:MALinterpret(FAST)@
			}
			@:MALflowofcontrol(FAST,continue)@
		}
	} else
	if (malProfileMode == 0 && cntxt->itrace==0 && cntxt->flags == 0 && GDKdebug == 0) {
		while(stkpc < mb->stop && stkpc != stoppc ){
			pci = getInstrPtr(mb,stkpc);
			if (malProfileMode + cntxt->itrace + mb->trap)
				goto workslow;

				@:MALinterpret(FAST)@
			@:MALflowofcontrol(FAST,continue)@
		}
	} else
	while(stkpc < mb->stop && stkpc != stoppc ){
		pci = getInstrPtr(mb,stkpc);
workslow:
		if( cntxt->itrace || mb->trap  ) {
			lng t=0;

			if( stk->cmd== 0)
				stk->cmd= cntxt->itrace;
			if( oldtimer)
				t= GDKusec();
			if( cntxt->flags & bbpFlag)
				BBPTraceCall(cntxt,mb,stk,prevpc);
			prevpc = stkpc;
			mdbStep(cntxt,mb,stk,stkpc);
			if( stk->cmd == 'x' || cntxt->mode == FINISHING) {
				stk->cmd = 0;
				stkpc = mb->stop;
				continue;
			}
			if( oldtimer ) {
				/* ignore debugger waiting time*/
				t= GDKusec()-t;
				oldtimer += t;
#ifdef HAVE_SYS_RESOURCE_H
				getrusage(RUSAGE_SELF, &oldResource);
#endif
				if (cntxt->flags & memoryFlag)
					oldMemory= MT_mallinfo();
			}
		}

		@:beginProfile(stk,1)@
		@:MALrecycleStart(stk)@ {
			@:MALinterpret(FAST)@
		}
		@:MALflowofcontrol(FAST,continue)@
		@:endProfile(stk)@
	}
	@:MALwrapup@
	return ret;
}
@- Out of order execution
The alternative is to execute the instructions out of order
using dataflow dependencies and as an independent process.
Dataflow processing only works on a code
sequence that does not include additional (implicit) flow of control
statements and, ideally, consist of expensive BAT operations.
The dataflow interpreter selects cheap instructions
using a simple costfunction based on the size of the BATs involved.

The dataflow portion is identified as a guarded block,
whose entry is controlled by the function language.dataflow();
This way the function can inform the caller to skip the block
when dataflow execution was performed.
@h
mal_export str runMALdataflow( Client cntxt, MalBlkPtr mb, int startpc,
		int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller);
@-
The flow graphs should be organized such that parallel threads can
access it mostly without expensive locking.
Furthermore, per flow block we keep an administration when
variables are blocked or not. An instruction can fire if all
its input variables are not blocked.
@c
#define DFLOWpending 0		/* runnable */
#define DFLOWrunning 1		/* currently in progress */
#define DFLOWwrapup  2		/* done! */
#define DFLOWretry   3		/* reschedule */

typedef struct queue {
	int size;	/* size of queue */
	int last;	/* last element in the queue */
	void **data;
	MT_Lock l;	/* its a shared resource, ie we need locks */
	MT_Sema s;	/* threads wait on empty queues */
} queue;


typedef struct {
	MT_Id tid;
	int id;
	queue *todo;		/* pending actions for this client */
	lng clk;
} FlowTask;

typedef struct DataFlow {
	Client cntxt;		/* for debugging and client resolution */
	MalBlkPtr mb;		/* carry the context */
	MalStkPtr stk;
	int start, stop;	/* guarded block under consideration*/
	char *status;		/* statements can be blocked on other statements */
	char *blocked;		/* blocked, should be created first */
	int *assign;		/* first assignment of variable */
	int *inuse;		/* inuse in parallel threads reference count */
	queue *done;		/* work finished */
	queue *todo;		/* pending actions for this client */
	int    nway;		/* number of workers */
	FlowTask *worker;	/* worker threads for the client */
	struct DataFlow *free;	/* free list */
} *DataFlow, DataFlowRec;

typedef struct {
	int pc;	/* pc in underlying malblock */
	sht status;
	sht cost;
	str error;
	DataFlow flow;
} *FlowStep, FlowStepRec;

@-
Running all eligible instructions in parallel creates
resource contention. This means we should implement
an admission control scheme where threads are temporarily
postponed if the claim for memory exceeds a threshold
In general such contentions will be hard to predict,
because they depend on the algorithm, the input sizes,
and the output produced.

The heuristic is based on calculating the storage footprint
of the operands and assuming it preferrably should fit in memory.
Ofcourse, there may be intermediate structures being
used and the size of the result is not a priori known.
For this, we use a high watermark on the amount of
physical memory we pre-allocate for the claims.

Instructions are eligible to be executed when the
total footprint of all concurrent executions stays below
the high-watermark or it is the single expensive
instruction being started.

When we run out of memory, the instruction is delayed.
How long depends on the other instructions to free up
resources. The current policy simple takes a local
decision by delaying the instruction based on its
past and the size of the memory pool size.
The waiting penalty decreases with each step to ensure
it will ultimately taken into execution, with possibly
all resource contention effects.

Another option would be to maintain a priority queue of
suspended instructions.
@= calcFootprint
	heapinfo(&b->H->heap); total += vol;
	heapinfo(b->H->vheap); total += vol;
	hashinfo(b->H->hash); total += vol;

	heapinfo(&b->T->heap); total += vol;
	heapinfo(b->T->vheap); total += vol;
	hashinfo(b->T->hash); total += vol;
@= calcclaim
t = total;
if (stk->stk[getArg(pci,i)].vtype == TYPE_bat){
	b = BATdescriptor(stk->stk[getArg(pci,i)].val.bval);
	if (b==NULL)
		continue;
	@:calcFootprint@
	/* prepare for hashes */
	if ( b->H->hash == NULL && b->hsorted == 0  &&
		 b->T->hash == NULL && b->tsorted == 0 ){
		if ( BATcount(b)  > cnt)
			cnt = BATcount(b);
	}
	if ( (b->ttype == TYPE_oid && !BATtordered(b) && !BATtdense(b)) ||
	   ( b->htype == TYPE_oid && !BAThordered(b) && !BAThdense(b)) ){
		/* assume we may have to do random IO, punish it by increasing the claim  with hash elem size*/
		total += 4 * BATcount(b) ;
		total = total >(lng) (MEMORY_THRESHOLD * monet_memory)? (lng) (MEMORY_THRESHOLD * monet_memory):total;
	}
	BBPunfix( h = b->batCacheid);
}
@c
static lng
getHotClaim()
{
	lng total = 0;
	int i;
	for ( i = 0; i < hottop; i++)
		total += hotpotatoes[i].claim;
	return total;
}

@-
Calculate the memory need of a single instruction and also determine how much of the
hot potatoes it will eat.
@c
void
getMemoryClaim(MalStkPtr stk, InstrPtr pci, lng *argclaim, lng *retclaim, lng *hotclaim)
{
	int i, h = int_nil;
	lng guess=0, t=0, total = 0, vol=0;
	BUN cnt = 0;
	BAT *b;

	total = 0;
	if (retclaim)
		*retclaim =0;
	if (hotclaim)
		*hotclaim =0;
	if (argclaim){
		for(i=  pci->retc; i< pci->argc; i++) {
			h = int_nil;
			@:calcclaim@
			if ( guess == 0)
				guess = total -t;
			/* claims on hotpotatoes are not counted */
			if (hotclaim)
			for (t =0; t< hottop; t++)
			if (hotpotatoes[t].bid == h)
				*hotclaim += hotpotatoes[t].claim;
		}
		/* make sure you can afford one hash when you have propCheck enabled */
		if ( GDKdebug & 10 ){
			total += cnt * sizeof(BUN);
		}
		*argclaim = total;
	}
	if ( retclaim  && *retclaim == 0)
		*retclaim = guess * pci->retc;
#ifdef DEBUG_MEMORY_CLAIM
	if ( total )
		mnstr_printf(GDKout,"#DFLOWgetMemoryClaim   pool " LLFMT " claims " LLFMT "," LLFMT "," LLFMT"\n", memorypool,total,(retclaim?*retclaim:0),(hotclaim?*hotclaim:0));
#endif
}
@-
After we have executed the instruction, we should release any hotpotatoe claim (it is hot only once)
and make more precise claims for the return arguments. Moreover, we should reduce the hot potatoe set,
due to other arguments being loaded.
@c
void
updMemoryUsedPart(MalStkPtr stk, InstrPtr pci, int start, int stop, lng argclaim)
{
	/* remove the result arguments from the hot set */
	int i,j,h,bid;

	if ( hottop >= MAXHOT || memoryused > (lng) (MEMORY_THRESHOLD * monet_memory) ){
		/* forget everything returning memory to pool */
		mal_set_lock(mal_contextLock, "DFLOWdelay");
		for ( i =0; i< MAXHOT; i++){
			hotpotatoes[i].claim=0;
			hotpotatoes[i].bid=0;
		}
		memoryused = 0;
		hottop = 0;
		mal_unset_lock(mal_contextLock, "DFLOWdelay");
#ifdef DEBUG_MEMORY_CLAIM
		mnstr_printf(GDKout,"#DFLOWhotpotatoes reset\n");
#endif
	}

	if (memorypool == 0 ){
		/* not initialized */
		return;
	}
	mal_set_lock(mal_contextLock, "DFLOWdelay");
	for ( i = start; i< stop; i++)
	if (stk->stk[getArg(pci,i)].vtype == TYPE_bat && (bid = stk->stk[getArg(pci,i)].val.bval) && bid)
	{
		for ( h = j= 0; j< hottop; j++)
			if ( hotpotatoes[j].bid != ABS(bid))
				hotpotatoes[h++]= hotpotatoes[j];
			else{
#ifdef DEBUG_MEMORY_CLAIM
				if ( hotpotatoes[j].claim){
					str cv = NULL;
					ATOMformat(TYPE_bat, &hotpotatoes[hottop].bid, &cv);
					mnstr_printf(GDKout,"#DFLOWhotpotatoes[%d] drops  [%s]" LLFMT "\n", j, cv, hotpotatoes[j].claim);
					if (cv) GDKfree(cv);
				}
#endif
			}
		hottop = h;
	}
	/* input also invalidates part of the hot set */
	argclaim = argclaim * (memorypool / (memorypool+memoryused));
	for ( h = j= 0; j< hottop; j++)
	if ( argclaim > 0)
			argclaim -= hotpotatoes[j].claim;
	else	hotpotatoes[h++]= hotpotatoes[j];
	hottop = h;
	mal_unset_lock(mal_contextLock, "DFLOWdelay");
}

void
updMemoryUsed(MalStkPtr stk, InstrPtr pci, lng argclaim)
{
	lng action=0,total,t,vol;
	int i,h,bid;
	BUN cnt = 0;
	BAT *b;


	for ( i= 0; i< pci->retc && hottop < MAXHOT; i++)
	if (stk->stk[getArg(pci,i)].vtype == TYPE_bat && (bid = stk->stk[getArg(pci,i)].val.bval) && bid)
	{
		total = 0;
		@:calcclaim@
		(void) t;
		(void) h;
		if ( total ) {
			mal_set_lock(mal_contextLock, "DFLOWdelay");
			hotpotatoes[hottop].bid = ABS(stk->stk[getArg(pci,i)].val.bval);
			hotpotatoes[hottop].claim = total;
#ifdef DEBUG_MEMORY_CLAIM
			if ( total ) {
				str cv = NULL;
				ATOMformat(TYPE_bat, &hotpotatoes[hottop].bid, &cv);
				mnstr_printf(GDKout,"#DFLOWhotpotatoes[%d] claims [%s]" LLFMT "\n", hottop, cv, total);
				GDKfree(cv);
			}
#endif
			hottop++;
			action++;
			mal_unset_lock(mal_contextLock, "DFLOWdelay");
		}
	}
	updMemoryUsedPart(stk,pci, pci->retc,pci->argc,argclaim);
#ifdef DEBUG_MEMORY_CLAIM
	if ( total && action )
		mnstr_printf(GDKout,"#DFLOWhotpotatoes pool " LLFMT " used " LLFMT "\n", memorypool, memoryused);
#endif
}

int
DFLOWadmission(lng argclaim, lng retclaim, lng hotclaim)
{
	lng hot;
	/* optimistically set memory */
	if ( argclaim + retclaim == 0)
		return 0;

	mal_set_lock(mal_contextLock, "DFLOWdelay");
	if (memorypool <= 0 && memoryclaims == 0) {
			memorypool = (lng) (MEMORY_THRESHOLD * monet_memory);
			hottop = 0;
	}

	if ( argclaim + retclaim > 0 ) {
		if (memoryclaims == 0 || memorypool - memoryused > argclaim + retclaim -hotclaim){
			hot = getHotClaim();
			if ( memoryclaims && hotclaim == 0  && argclaim + retclaim > memorypool - memoryused - hot) {
				/* don't start unless you can eat the hot potatoes first */
#ifdef DEBUG_MEMORY_CLAIM
				mnstr_printf(GDKerr,"#Delayed due to hot potatoes pool " LLFMT " used " LLFMT " hot " LLFMT "\n", memorypool, memoryused,hot);
#endif
				mal_unset_lock(mal_contextLock, "DFLOWdelay");
				return -1;
			}
			memorypool -= (argclaim + retclaim);
			memoryclaims ++;
#ifdef DEBUG_MEMORY_CLAIM
			mnstr_printf(GDKout,"#DFLOWadmit %3d thread %d pool " LLFMT","LLFMT " claims " LLFMT "," LLFMT"," LLFMT"\n",
				memoryclaims, THRgettid(), memorypool, memoryused, argclaim, retclaim,hotclaim);
#endif
			mal_unset_lock(mal_contextLock, "DFLOWdelay");
			return 0;
		}
		mal_unset_lock(mal_contextLock, "DFLOWdelay");
		return -1;
	}
	/* release memory claimed before */
	memorypool += -argclaim -retclaim ;
	memoryclaims --;
#ifdef DEBUG_MEMORY_CLAIM
		mnstr_printf(GDKout,"#DFLOWadmit %3d thread %d pool " LLFMT","LLFMT " claims " LLFMT "," LLFMT"," LLFMT"\n",
			memoryclaims, THRgettid(), memorypool, memoryused, argclaim, retclaim,hotclaim);
		mnstr_flush(GDKout);
#endif
	assert(memoryclaims >= 0 );
	mal_unset_lock(mal_contextLock, "DFLOWdelay");
	return 0;
}

@-
The dataflow execution is confined to a barrier block.
Within the block there are multiple flows, which, in principle,
can be executed in parallel.
@c

static queue*
q_create( int sz )
{
	queue *q = (queue*)GDKmalloc(sizeof(queue));

	if ( q == NULL)
		return NULL;
	q->size = ((sz<<1)>>1); /* we want a multiple of 2 */
	q->last = 0;
	q->data = (void*)GDKmalloc(sizeof(void*)*q->size);
	if ( q->data == NULL){
		GDKfree(q);
		return NULL;
	}

	MT_lock_init(&q->l, "q_create");
	MT_sema_init(&q->s, 0, "q_create");
	return q;
}

/*
static void
q_destroy( queue *q )
{
	GDKfree(q->data);
	GDKfree(q);
}
*/

/* keep a simple FIFO queue. It won't be a large one, so shuffles of requeue is possible */
static void
q_enqueue(queue *q, void *d)
{
	MT_lock_set(&q->l, "q_enqueue");
	if (q->last == q->size) {
		/* enlarge buffer */
		q->size <<= 1;
		q->data = GDKrealloc(q->data, sizeof(void*)*q->size);
	}
	q->data[q->last++] = d;
	MT_lock_unset(&q->l, "q_enqueue");
	MT_sema_up(&q->s, "q_enqueue");
}

static void
q_requeue(queue *q, void *d)
{
	int i;
	MT_lock_set(&q->l, "q_requeue");
	if (q->last == q->size) {
		/* enlarge buffer */
		q->size <<= 1;
		q->data = GDKrealloc(q->data, sizeof(void*)*q->size);
	}
	for ( i=q->last; i > 0; i--)
		q->data[i]= q->data[i-1];
	q->data[0] = d;
	q->last++;
	MT_lock_unset(&q->l, "q_requeue");
	MT_sema_up(&q->s, "q_requeue");
}

static void *
q_dequeue(queue *q)
{
	void *r = NULL;

	MT_sema_down(&q->s, "q_dequeue");
	MT_lock_set(&q->l, "q_dequeue");
	assert(q->last > 0);
	/* LIFO favors garbage collection*/
	r = q->data[--q->last];

	MT_lock_unset(&q->l, "q_dequeue");
	return r;
}

@-
We simply move an instruction into the front of the queue.
Beware, we assume that variables are assigned a value once, otherwise
the order may really create errors.
The order of the instructions should be retained as long as possible.
@c
static str
DFLOWstep(FlowTask *t, FlowStep fs)
{
	DataFlow flow = fs->flow;
	int stkpc = fs->pc;

	ValPtr lhs,rhs,v;
	int i,k;
	int exceptionVar= -1;
	str ret = MAL_SUCCEED;
#if FAST
	int stamp = -1;
#endif
	bat *backup= (bat*) alloca(flow->mb->maxarg * sizeof(bat));
	str *sbackup= (str*) alloca(flow->mb->maxarg * sizeof(str));
	int *garbage= (int*) alloca(flow->mb->maxarg * sizeof(int));
	Client cntxt = flow->cntxt;
	MalBlkPtr mb = flow->mb;
	MalStkPtr stk = flow->stk;
	int startpc = flow->start;
	InstrPtr pci;
	lng oldtimer=0;
	struct Mallinfo oldMemory;
	MT_Lock *lock = &flow->done->l;
	int tid = t->id, prevpc= 0;
	lng argclaim,retclaim,hotclaim;

#ifdef HAVE_SYS_RESOURCE_H
	int oldinblock=0;
	int oldoublock=0;
	struct rusage oldResource;
#endif
	@:performanceVariables@

	if (cntxt->flags & memoryFlag)
		oldMemory = MT_mallinfo();
	else
		oldMemory.arena = 0;
	if (stk == NULL || stkpc < 0)
		throw(MAL, "mal.interpreter", MAL_STACK_FAIL);

	pci = getInstrPtr(flow->mb, stkpc);
#ifdef DEBUG_FLOW
	printf("#EXECUTE THREAD %d \n", tid);
	printInstruction(GDKstdout, flow->mb, 0, pci, LIST_MAL_STMT | LIST_MAPI);
#endif
	THRset_errbuf(THRget(THRgettid()), cntxt->errbuf);	/* where to leave errors */
	if (stk->cmd || mb->trap) {
		lng tm = 0;
		if( oldtimer)
			tm = GDKusec();
		if( cntxt->flags & bbpFlag)
			BBPTraceCall(cntxt,mb,stk,prevpc);
		prevpc = stkpc;
		mdbStep(cntxt,mb,stk, getPC(mb,pci));
		if (stk->cmd == 'x' || cntxt->mode == FINISHING) {
			/* need a way to skip */
			stkpc = mb->stop;
			fs->status = -1;
			return ret;
		}
		if (oldtimer ) {
			/* ignore debugger waiting time*/
			tm = GDKusec()-tm;
			oldtimer += tm;
#ifdef HAVE_SYS_RESOURCE_H
			getrusage(RUSAGE_SELF, &oldResource);
#endif
			if (cntxt->flags & memoryFlag)
				oldMemory = MT_mallinfo();
		}
	}

	@:beginProfile(t,0)@
	ret = MAL_SUCCEED;
	@:MALrecycleStart(t)@ {
@-
Delay processing when we run out of memory.  Push the instruction back
on the end of queue, waiting for another attempt. Problem might become
that all threads but one are cycling through the queue, each time
finding an eligible instruction, but without enough space.
Therefore, we wait for a few milliseconds as an initial punishment.

The process could be refined by checking for cheap operations,
i.e. those that would require no memory at all (aggr.count)
This, however, would lead to a dependency to the upper layers,
because in the kernel we don't know what routines are available
with this property. Nor do we maintain such properties.
@c
		getMemoryClaim(stk, pci, &argclaim, &retclaim,&hotclaim);
		if ( DFLOWadmission(argclaim,retclaim,hotclaim) ){
			PARDEBUG {
				mnstr_printf(GDKout,"#DFLOWdelay instruction %d pool  " LLFMT " claim "LLFMT"\n#", THRgettid(),  memorypool, argclaim+retclaim);
				printInstruction(GDKstdout, mb, 0, pci, LIST_MAL_STMT | LIST_MAPI);
			}
			for ( ; ; )
			{
				MT_sleep_ms(3); /* enough to pass some cheap instructions */
				if ( DFLOWadmission(argclaim,retclaim,hotclaim) == 0) {
					PARDEBUG {
						mnstr_printf(GDKout,"#DFLOWcont  thread %d delay " LLFMT " pool  " LLFMT" delayed " LLFMT " ms\n#", THRgettid(),  memorypool, argclaim+retclaim, (GDKusec()-stk->clk)/1000);
						printInstruction(GDKstdout, mb, 0, pci, LIST_MAL_STMT | LIST_MAPI);
					}
					break;
				}
				/* if we claim only part of memory, then let's wait */
				if (argclaim + retclaim -hotclaim <  (lng) (monet_memory / (memoryclaims+1)))
					continue;
				/* re-schedule instructions that require a lot of memory for postponed execution */
				PARDEBUG {
					mnstr_printf(GDKout,"#DFLOWrequeue instr  %d pool  " LLFMT " claim "LLFMT"\n#", THRgettid(),  memorypool, argclaim+retclaim);
					printInstruction(GDKstdout, mb, 0, pci, LIST_MAL_STMT | LIST_MAPI);
				}
				/* actually should use DFLOWretry status */
				throw(MAL,"DFLOWadmission","failed");
			}
		}
		/* remove all result hotpotatoes now */
		updMemoryUsedPart(stk,pci,0,pci->retc,-1);
		@:beginProfile(t,1)@
@-
To improve memory access behavior we could touch the pages of all BATs to enforce them to become memory resident.
This won't work, because it is not selective enough. The advice should be selectively given in the kernel.

The number of instructions allowed is severely limited.
We don't allow sequential flow control here.
@c
		switch (pci->token){
		case ASSIGNsymbol: @:assignStmt(FAST,fs->pc = -fs->pc; updMemoryUsed(stk,pci,argclaim); DFLOWadmission(-argclaim,-retclaim,-hotclaim); return ret,t)@ break;
		case PATcall: @:patterncall(FAST,fs->pc = -fs->pc; updMemoryUsed(stk,pci,argclaim); DFLOWadmission(-argclaim,-retclaim,-hotclaim); return ret,t)@ break;
		case CMDcall: @:commandcall(FAST,fs->pc = -fs->pc; updMemoryUsed(stk,pci,argclaim); DFLOWadmission(-argclaim,-retclaim,-hotclaim); return ret,t)@ break;
		case FACcall: @:factorycall(FAST,fs->pc = -fs->pc; updMemoryUsed(stk,pci,argclaim); DFLOWadmission(-argclaim,-retclaim,-hotclaim); return ret,t)@ break;
		case FCNcall: @:functioncall(FAST,fs->pc = -fs->pc; updMemoryUsed(stk,pci,argclaim); DFLOWadmission(-argclaim,-retclaim,-hotclaim); return ret,t)@ break;
		case NOOPsymbol:
		case REMsymbol:
			break;
		default:
			if( pci->token < 0 ){
				/* temporary NOOP instruction */
				break;
			}
			ret = createScriptException(mb, stkpc, MAL,
					NULL, "unkown operation");
		}
		updMemoryUsed(stk,pci,argclaim);
		DFLOWadmission(-argclaim,-retclaim,-hotclaim);
	}
	@:endProfile(t)@
	if (ret)
		fs->pc = -fs->pc;
	return ret;
}

@-
A consequence of multiple threads is that they may claim more
space then available. This may cause GDKmalloc to fail.
In many cases this situation will be temporary, because
threads will ultimately release resources.
Therefore, we wait for it.

Alternatively, a front-end can set the flow administration
program counter to -1, which leads to a soft abort.
[UNFORTUNATELY this approach does not (yet) work
because there seem to a possibility of a deadlock
between incref and bbptrim. Furthermore, we have
to be assured that the partial executed instruction
does not lead to ref-count errors.]

The worker produces a result which will potentially unblock
instructions. This it can find itself without the help of the scheduler
and without the need for a lock. (does it?, parallel workers?)
It could also give preference to an instruction that eats away the object
just produced. THis way it need not be saved on disk for a long time.
@c
static void
runDFLOWworker(void *t)
{
	FlowStep fs,oldfs =0;
	FlowTask *task = (FlowTask*) t;
	str err;
	Thread thr;

	thr = THRnew(MT_getpid(), "DFLOWworker");
	while(task) {
		fs = (FlowStep)q_dequeue(task->todo);
		PARDEBUG
			mnstr_printf(GDKstdout,"#execute pc=%d thread =%d \n",fs->pc, task->id);
		if ( fs == oldfs){
			q_requeue(task->todo,fs);
			MT_sleep_ms(10);
			oldfs = 0;	/* don't escape it always */
			continue;
		}
		oldfs = fs;
#ifdef DEBUG_FLOW
		if ( fs->pc >= 0)
			printInstruction(GDKstdout, fs->flow->mb, 0, getInstrPtr(fs->flow->mb,fs->pc), LIST_MAL_STMT | LIST_MAPI);
#endif
		err = fs->pc >0 ? DFLOWstep(task, fs): createException(MAL,"interpreter","flow step failed");
		/* restore the instruction and wait in specific cases*/
		if ( err != MAL_SUCCEED && strstr(err,"DFLOWadmission") != NULL && strstr(err,"failed") != NULL){
			FREE_EXCEPTION(err);
			fs->pc = ABS(fs->pc);
			fs->status = DFLOWrunning;
			q_requeue(task->todo,fs);
			continue;
		}
		fs->error = err;
		q_enqueue(fs->flow->done, fs);
	}
	THRdel(thr);
}

@-
The dataflow block assumes a linear MAL program.
The dataflow administration is based on three properties.
For each variable we keep a flag telling if it is blocked,
i.e. not available, because it has not been assigned a value yet.
Blocked[a]== 0 means that the variable can be used.

The property inus[a] tells how many instructions still
want to use the variable before it reaches the next assignment.
Each instruction is counted once, even if the same variable is used multiple times.

The eoscope statement should be treated with care, because it
can only be executed when the inuse[a] drops  to 1.
The instruction is enqued last.

Further complications are the definitions of variables outside
the dataflow block. They appear as input variables without assignment.
They are considered unblocked.

After an instruction has been executed, we should decrease
the inuse[a] property for all input arguments. Furthermore, all
target variables become nonblocked and can be used to enqueue instructions.

@c
static void
DFLOWinit(DataFlow flow, FlowStep fs)
{
	int i, n;

	PARDEBUG
		printf("Initialize dflow block\n");
	for (n=0, i = flow->start; i<flow->stop; i++, n++) {
		InstrPtr p = getInstrPtr(flow->mb, i);
		int j, a;

		PARDEBUG
			printInstruction(GDKstdout, flow->mb, 0, p, LIST_MAL_STMT | LIST_MAPI);

		/* initial state, ie everything can run */
		fs[n].pc = i;
		fs[n].status = DFLOWpending;
		fs[n].flow = flow;
		fs[n].cost = -1;
		fs[n].error = NULL;

		for (j=0; j<p->argc; j++){
			a = getArg(p, j);

			if (j<p->retc && flow->assign[a] != 0)
				assert(0);

			if (j<p->retc && flow->assign[a] == 0 && flow->inuse[a] == 0) {
				flow->assign[a] = i;
				flow->blocked[a] = isNotUsedIn(p,p->retc,a)?1:0;
			}

			if (j>=p->retc  && !isVarConstant(flow->mb, a)  )
				flow->inuse[a] += isNotUsedIn(p,j+1,a);
		}
	}

	memset(flow->inuse, 0, flow->mb->vtop * sizeof(flow->inuse[0]));

	PARDEBUG
	for (i=0; i < flow->mb->vtop; i++)
	if ( flow->blocked[i] || flow->inuse[i] || flow->assign[i] ){
		printf("%s %d %d [ %1d %2d ]\n", getVarName(flow->mb,i),
			getEndOfLife(flow->mb,i), i,
			flow->blocked[i],
			flow->inuse[i]);
	}
}
@-
The liberal use of MAL to construct programs complicate proper dataflow
dependency analysis. For example, consider the following fragment of
a remote execution
@verbatim
barrier go:=language.dataflow()
con:= remote.connect(...)
res:= remote.put(con, v:int)
inp:= remote.put(con, i:int)
res:= remote.exe(con,m,f,inp);
ans:= remote.get(con,res)
exit go
@end verbatim
Naive interpretation could lead to execution of either 'res:=' operation in non-determined order.
Moreover, the result 'ans:' should be obtained after the corresponding 'res:=' has been executed.
@c
static int
DFLOWeligible(DataFlow flow, FlowStep fs, int i, InstrPtr p, int pc)
{
	int j, k, l, blocked = 0;
	InstrPtr q;
	(void) pc;

	for(j=0; j<p->argc && !blocked; j++) {
		int var = getArg(p,j);
		if ( j >= p->retc && flow->blocked[var] ) {
			blocked = 1;
			break;
		}
		else
		if ( j < p->retc && flow->inuse[var] ) {
			blocked = 1;
			break;
		}
		else
		if ( getEndOfLife(flow->mb,var)  == fs[i].pc ) {
			/* make sure all instructions interested have already been executed */
			/* and the eoscope variables are not used anymore */

			if (flow->inuse[var] != 0) {
				blocked = 1;
				break;
			}
			else
				for ( k=0; k < i ; k++)
					if ( fs[k].status != DFLOWwrapup && fs[k].pc >= 0/* pc = -1 could be the case before wrapup is set*/
						 && !isNotUsedIn(getInstrPtr(flow->mb, fs[k].pc), 0, var) ) {
						blocked = 1;
						break;
					}
		} else {
			/* handle the dependencies sketched above */
			/* search the statement that assigns a value to the argument or target */
			/* it should have been finished already */
			for (l = flow->assign[var]; l < i && !blocked; l++)
				if ( fs[l].status != DFLOWwrapup && fs[l].pc >= 0){
					q= getInstrPtr(flow->mb, fs[l].pc);
					for ( k=0; k < q->retc; k++)
						if ( getArg(q,k) == var ) {
							blocked = 1;
							break;
						}
				}
		}
	}
	return blocked == 0;
}

static void
DFLOWactivate(DataFlow flow, FlowStep fs, int i,InstrPtr p)
{
	int j;
	for(j=p->retc; j<p->argc; j++) {
		if (!isVarConstant(flow->mb, getArg(p,j)))
			flow->inuse[getArg(p,j)] += isNotUsedIn(p,j+1,getArg(p,j));
	}

	/* the target variables become blocked until this instruction is finished */
	for ( j = 0; j< p->retc; j++)
		flow->blocked[getArg(p,j)] = 1;

	fs[i].status = DFLOWrunning;

	PARDEBUG {
		mnstr_printf(GDKstdout,"#enqueue pc=%d", fs[i].pc);
		for(j=p->retc; j<p->argc; j++)
			mnstr_printf(GDKstdout," %d ",flow->inuse[getArg(p,j)]);
		printInstruction(GDKstdout, flow->mb, 0, p, LIST_MAL_STMT | LIST_MAPI);
		mnstr_printf(GDKstdout,"\n");
	}
}
@-
Parallel processing is mostly driven by dataflow, but within this context
there may be different schemes to take instructions into execution.
The admission scheme (and wrapup) are the necessary scheduler hooks.
A scheduler registers the functions needed and should release them
at the end of the parallel block.
They take effect after we have ensured that the basic properties for
execution hold.
@c
static str
DFLOWscheduler( DataFlow flow )
{
	int queued = 0, candidates;
	int todo = 0, done = 0;
	int pc = 0, i, j, oa =0, ia,k;
	int limit = flow->stop - flow->start, lookahead =0;
	str ret = MAL_SUCCEED;
	FlowStep fs = (FlowStep)alloca(sizeof(FlowStepRec) * limit), f = 0;
	InstrPtr p, last=0;

	if ( limit == 0)
		throw(MAL,"dataflow","Empty dataflow block");
	/* initialize the eligible statements */
	DFLOWinit(flow, fs);

	if (flow->cntxt->flags & timerFlag)
		flow->cntxt->timer = GDKusec();

	if( limit)
		goto firststep;	/* confuse static code analysers, i want a jump */

	while(queued || todo != done){
		PARDEBUG mnstr_printf(GDKstdout,"#waiting for results, queued %d todo %d done %d\n", queued,todo,done);
		f = q_dequeue(flow->done);
		if ( f->status == DFLOWretry ){
			/* reschedule the instruction */
			f->status = DFLOWrunning;
			q_requeue(flow->todo, f);
			continue;
		}
		if ( f->flow->stk->wrapup ) /* clean up whatever is called for */
			(*f->flow->stk->wrapup)(f->flow->cntxt, f->flow->mb, f->flow->stk, getInstrPtr(flow->mb, abs(f->pc)));
		f->status = DFLOWwrapup;
		done++;
		queued--;
		if (f->pc < 0) {
			PARDEBUG
				mnstr_printf(GDKstdout,"#errors encountered %s ", f->error);
			/* we have to wait for all threads to report back */
			/* dequeue the remainders in case of an error */
			while(todo != done)  {
				if ( f->flow->stk->wrapup ) /* clean up whatever is called for */
					(*f->flow->stk->wrapup)(f->flow->cntxt, f->flow->mb, f->flow->stk, getInstrPtr(flow->mb, abs(f->pc)));
				(void)q_dequeue(flow->done);
				done++;
			}
			return f->error;
		} else {
			p = getInstrPtr(flow->mb, f->pc);
			PARDEBUG{
				mnstr_printf(GDKstdout,"#dequeue pc=%d", f->pc);
				for(j=p->retc; j<p->argc; j++)
					mnstr_printf(GDKstdout," %d ",flow->inuse[getArg(p,j)]);
				printInstruction(GDKstdout, flow->mb, 0, p, LIST_MAL_STMT | LIST_MAPI);
			}

			/* update the input args */
			for(j=p->retc; j<p->argc; j++) {
				ia = getArg(p,j);

				if (isVarConstant(flow->mb, ia))
					continue;

				flow->inuse[ia] -= isNotUsedIn(p,j+1,ia);
			}
			/* deblock the output args */
			for(j=0; j<p->retc; j++) {
				oa = getArg(p,j);
				/* find the last instruction that should be inspected for eligibility */
				if ( getEndOfLife(flow->mb,oa) > lookahead)
					lookahead = getEndOfLife(flow->mb,oa) +1;

				flow->blocked[oa] = 0;
				flow->inuse[oa] = 0;
			}
			last = p;
		}
		firststep:
		PARDEBUG if (queued)
			mnstr_printf(GDKstdout,"#schedule new instructions, start from %d\n", pc);

		/* avoid the head of the flow that has already been handled */
		for( ; pc < limit; pc++)
			if ( fs[pc].status != DFLOWwrapup)
				break;
		if (lookahead <= pc)
			lookahead = pc+1;
		if ( lookahead > limit)
			lookahead = limit;

		if (flow->stk->admit == 0) {
			@:DFLOWscheduler_body( DFLOWeligible(flow,fs,i,p,pc), foundit1 )@
		} else {
			@:DFLOWscheduler_body( DFLOWeligible(flow,fs,i,p,pc) && (*flow->stk->admit)(flow->cntxt, flow->mb, flow->stk, p), foundit2 )@
		}
@= DFLOWscheduler_body
		/* first try to find an instructions that use the released target */
		candidates = 0;
		if ( last)
		for(i = pc; i < lookahead ; i++)
			if (fs[i].status == DFLOWpending ) {
				p = getInstrPtr(flow->mb, fs[i].pc);
				for ( j= p->retc; j < p->argc; j++)
				for ( k= 0; k < last->retc; k++)
					if ( getArg(p,j)== getArg(last,k) ) {
						if ( @1 ) {
							queued++;
							todo++;
							candidates = 1;
							DFLOWactivate(flow,fs,i,p);
							q_enqueue(flow->todo, fs+i);
						}
						goto @2;
					}
				@2: /* it can only be activated once */;
			}
		/* if all work done then inspect rest */
		if (candidates < flow->nway)
			for(i = pc ; i < limit && queued < flow->nway ; i++)
				if (fs[i].status == DFLOWpending ) {
					p = getInstrPtr(flow->mb, fs[i].pc);
					if ( @1 ) {
						queued++;
						todo++;
						DFLOWactivate(flow,fs,i,p);
						q_enqueue(flow->todo, fs+i);
					}
				}
@c
	}
	PARDEBUG {
		candidates = 0;
		mnstr_printf(GDKstdout,"#end of data flow %d %d todo %d  done %d\n",pc,limit,todo,done);
		for ( i =0 ; i<lookahead; i++)
			if (fs[i].status != DFLOWwrapup  && fs[i].pc >=0) {
				mnstr_printf(GDKstdout,"#missed %d %d %d ",  i, fs[i].status, fs[i].pc);
				printInstruction(GDKstdout, flow->mb, 0, getInstrPtr(flow->mb,fs[i].pc), LIST_MAL_STMT | LIST_MAPI);
				candidates++;
			}
		if ( candidates)
		for (i=0; i < flow->mb->vtop; i++)
		if ( flow->blocked[i] || flow->inuse[i] )
			printf("%s %d [ %1d %2d ]\n", getVarName(flow->mb,i),
				getEndOfLife(flow->mb,i),
				flow->blocked[i],
				flow->inuse[i]);
		}
	return ret;
}

static DataFlow flows = NULL;
static int workerid = 0;

str runMALdataflow( Client cntxt, MalBlkPtr mb, int startpc,
		int stoppc, MalStkPtr stk, MalStkPtr env, InstrPtr pcicaller)
{
	DataFlow flow = NULL;
	str ret = MAL_SUCCEED;

#ifdef DEBUG_FLOW
	mnstr_printf(GDKstdout, "runMALdataflow for block %d - %d\n", startpc,stoppc);
	printFunction(GDKstdout, mb, 0, LIST_MAL_STMT | LIST_MAPI);
#endif

	/* 
  	 * TODO improve cost of DFLOWeligible 
 	 */
	if (stoppc && stoppc-startpc > 10000)
		return runMALsequence( cntxt, mb, startpc+1, stoppc, stk, env, pcicaller);

	(void)env;
	(void)pcicaller;

	/* in debugging mode we should not start multiple threads */
	if (stk->cmd) {
		return MAL_SUCCEED;
	}

	assert(stoppc > startpc);
	mal_set_lock(mal_contextLock, "runMALdataflow");
	flow = flows;

	if (flow) {
	 	flows = flow->free;
	} else {
		int i;

		flow = (DataFlow)GDKzalloc(sizeof(DataFlowRec));

		/* seems enough for the time being */
		flow->done = q_create(2048);
		flow->todo = q_create(2048);

		/* queues are available? */
		if ( flow->done == NULL || flow->todo == NULL) {
			mal_unset_lock(mal_contextLock, "runMALdataflow");
			return MAL_SUCCEED;
		}

		flow->worker = NULL;
		flow->nway = GDKnr_threads ? GDKnr_threads:1;
		flow->worker= (FlowTask *) GDKzalloc(sizeof(FlowTask)*flow->nway);
		for(i=0; i<flow->nway; i++) {
			flow->worker[i].id = workerid++;
			flow->worker[i].todo = flow->todo;
			/* create the thread and let it wait */
			MT_create_thread(&flow->worker[i].tid, runDFLOWworker, flow->worker+i, MT_THR_DETACHED);
		}
	}
	flow->cntxt = cntxt;
	flow->start = startpc+1;
	flow->stop = stoppc;
	flow->mb = mb;
	flow->stk = stk;

	flow->status = (char*) GDKzalloc((stoppc-startpc+1));
	flow->blocked = (char*) GDKzalloc(sizeof(char)*mb->vtop);
	flow->assign = (int*) GDKzalloc(sizeof(int)*mb->vtop);
	flow->inuse = (int*) GDKzalloc(sizeof(int)*mb->vtop);
	mal_unset_lock(mal_contextLock, "runMALdataflow");

	ret = DFLOWscheduler(flow);
	GDKfree(flow->status);
	GDKfree(flow->blocked);
	GDKfree(flow->assign);
	GDKfree(flow->inuse);
	mal_set_lock(mal_contextLock, "runMALdataflow");
	flow->free = flows;
	flows = flow;
	mal_unset_lock(mal_contextLock, "runMALdataflow");
	return ret;
}
@+ Independent threads
Distributed execution calls for asynchronous execution of MAL
instructions. To simplify the interpreter, we assume that all
the code to be executed is already grouped in a MAL function,
which is called independently. The result variables are initialized
to NIL before the code is started. When the process crashes,
an exception is raised.

@h
mal_export str runMALprocess(Client cntxt, MalBlkPtr mb, MalStkPtr stk, int start, int stop);
@c
typedef struct {
	MT_Id tid;
	Client cntxt;
	MalBlkPtr mb;
	MalStkPtr stk;
	int start,stop;
}Ptask;

/* runMALdetached is typically called as part of
 * starting a separate interpreter thread.
*/
static void
runMALdetached(void *t){
	Ptask *p = (Ptask *) t;
	Client cntxt= p->cntxt;
	MalBlkPtr mb = p->mb;
	MalStkPtr stk = p->stk;
	int sve;
	str msg= MAL_SUCCEED;

#ifdef DEBUG_DETACHED
	mnstr_printf(cntxt->fdout,"start thread in background\n");
#endif
	if (stk == NULL){
		GDKerror("mal.interpreter: " MAL_STACK_FAIL);
		return;
	}
	sve= stk->keepAlive;
	stk->keepAlive= TRUE;
	msg= reenterMAL(cntxt, mb, p->start, p->stop, stk, 0, 0);
	stk->keepAlive= sve;
	if  ( msg != MAL_SUCCEED)
		GDKerror(msg);		/* indirect way to pass an error */
#ifdef DEBUG_DETACHED
	mnstr_printf(cntxt->fdout,"finished thread in background\n");
#endif
}
str runMALprocess(Client cntxt, MalBlkPtr mb, MalStkPtr stk, int start, int stop)
{
	Ptask p;

	p.cntxt= cntxt;
	p.mb = mb;
	p.stk = stk;
	p.start = start;
	p.stop = stop;

	MT_create_thread(&p.tid, runMALdetached, &p, MT_THR_DETACHED);
	return MAL_SUCCEED;
}

@= MALwrapup
	if( exceptionVar >= 0) {
		if (ret) {
			str oldret = ret;
			ret = createScriptException(mb, mb->stop-1,
					getExceptionType(getVarName(mb,exceptionVar)),
					ret, "Exception not caught");
			FREE_EXCEPTION(oldret);
		} else {
			if (stk->stk[exceptionVar].vtype == TYPE_str) {
				ret = createScriptException(mb, mb->stop-1, MAL,
						stk->stk[exceptionVar].val.sval,
						"Exception not caught");
			} else {
				ret = createScriptException(mb, mb->stop-1, MAL,
						NULL, "Exception not caught");
			}
		}
	}
@+ Safeguarding
The physical stack for each thread is an operating system parameter.
We do not want recursive programs crashing the server, so once in
a while we check whether we are running dangerously low on available
stack space.

This situation can be detected by calling upon the GDK functionality
of by limiting the depth of a function calls.
Expensive? 70 msec for 1M calls. Use with care.
@h
mal_export str safeguardStack(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
@c
str
safeguardStack(Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci){
	int depth = *(int*) getArgReference(stk,pci,1);
	(void) cntxt;
	if (stk->stkdepth > depth * mb->vtop && THRhighwater()) {
		throw(MAL, "mal.interpreter", MAL_STACK_FAIL);
	}
	return MAL_SUCCEED;
}

@+ The interpreter loop
The interpreter is geared towards execution a MAL procedure together
with all its decendant invocations. As such, it provides the
MAL abtract machine processor.

The value-stack frame of the surrounding scope is needed to resolve
binding values.  Getting (putting) a value from (into) a surrounding
scope should be guarded with the exclusive access lock.
This situation is encapsulated by a bind() function call, whose parameters
contain the access mode required.

The formal procedure arguments are assumed to always occupy the first
elements in the value stack.
@+ The major switch

@= MALinterpret
	ret = 0;
	switch( pci->token){
	case ASSIGNsymbol: @:assignStmt(@1,continue,stk)@ break;
	case PATcall: @:patterncall(@1,continue,stk)@ break;
	case CMDcall: @:commandcall(@1,continue,stk)@ break;
	case FACcall: @:factorycall(@1,continue,stk)@ break;
	case FCNcall: @:functioncall(@1,continue,stk)@ break;
	case NOOPsymbol:
	case REMsymbol:
		break;
	case ENDsymbol:
		if( getInstrPtr(mb,0)->token == FACTORYsymbol)
			ret= shutdownFactory(cntxt,mb, 0);
#if @1
		if( oldtimer)
			cntxt->timer= oldtimer;
#endif
		if( pcicaller && garbageControl(getInstrPtr(mb,0)) )
			garbageCollector(cntxt, mb, stk, TRUE);
#if @1
		@:endProfile(stk)@
#endif
		stkpc= mb->stop;
		continue;
	default:
		if( pci->token < 0 ){
			/* temporary NOOP instruction */
			break;
		}
		ret = createScriptException(mb, stkpc,MAL,
				NULL, "unkown operation");
#if @1
		@:endProfile(stk)@
#endif
		stkpc= mb->stop;
		continue;
	}
@-
After the expression has been evaluated we should check for a
possible change in the control flow.
@= MALflowofcontrol
switch(pci->barrier){
	case BARRIERsymbol:
		@:barrierControl@ stkpc++;
		break;
	case LEAVEsymbol:
	case REDOsymbol:
		v= &stk->stk[getDestVar(pci)];
		/* skip to end of barrier, depending on the type */
		switch(v->vtype){
			case TYPE_bit:
				if( v->val.cval[0] == TRUE && v->val.cval[0] != bit_nil)
					stkpc= pci->jump;
				else stkpc++;
				break;
			case TYPE_chr:
				if( v->val.cval[0] )
					stkpc= pci->jump;
				else stkpc++;
				break;
			case TYPE_str:
				if( v->len > 0 && v->val.sval!= str_nil )
					stkpc= pci->jump;
				else stkpc++;
				break;
			case TYPE_sht:
				if( v->val.shval >= 0 && v->val.shval!= sht_nil )
					stkpc= pci->jump;
				else stkpc++;
				break;
			case TYPE_bat:
				if( v->val.bval > 0 )
					stkpc= pci->jump;
				else stkpc++;
				break;
			case TYPE_int:
				if( v->val.ival >= 0 && v->val.ival!= int_nil )
					stkpc= pci->jump;
				else stkpc++;
				break;
			case TYPE_wrd:
				if( v->val.wval >= 0 && v->val.wval!= wrd_nil )
					stkpc= pci->jump;
				else stkpc++;
				break;
			case TYPE_bte:
				if( v->val.btval >= 0 && v->val.btval!= bte_nil )
					stkpc= pci->jump;
				else stkpc++;
				break;
			case TYPE_lng:
				if( v->val.lval >= 0 && v->val.lval!= lng_nil)
					stkpc= pci->jump;
				else
			default:
					stkpc++;
		}
		break;
	case CATCHsymbol:
		/* catch blocks are skipped unless
		   searched for explicitly*/
		if(exceptionVar < 0) {
			stkpc= pci->jump;
			break;
		}
		exceptionVar = -1;
		stkpc++;
		break;
	case EXITsymbol:
		if( getDestVar(pci) == exceptionVar)
			exceptionVar = -1;
		stkpc++;
		break;
	case RAISEsymbol:
		exceptionVar = getDestVar(pci);
		ret = NULL;
		if (getVarType(mb, getDestVar(pci)) == TYPE_str) {
			ret = createScriptException(mb, stkpc, MAL, NULL,
				stk->stk[getDestVar(pci)].val.sval);
		}
		@:skipToCatch(exceptionVar,@2,stk)@
		if ( stkpc == mb->stop)
			ret = createScriptException(mb, stkpc, MAL, ret,
					"Exception raised");
		break;
	case YIELDsymbol: /* to be defined */
		if( oldtimer)
			cntxt->timer= oldtimer;
		return yieldFactory( mb, pci, stkpc);
	case RETURNsymbol:
		/* Return from factory involves cleanup */

		if( getInstrPtr(mb,0)->token == FACTORYsymbol){
			yieldResult(mb,pci,stkpc);
			shutdownFactory(cntxt,mb, TRUE);
		} else
			/* a fake multi-assignment */
			if( env != NULL && pcicaller != NULL){
				InstrPtr pp=pci;
				@:endProfile(stk)@
				pci= pcicaller;
				for(i=0;i < pci->retc; i++){
					rhs = &stk->stk[pp->argv[i]];
					lhs = &env->stk[pci->argv[i]];
					VALcopy(lhs,rhs);
					if( lhs->vtype == TYPE_bat )
						BBPincref(lhs->val.bval, TRUE);
				}
				if( garbageControl(getInstrPtr(mb,0)) )
					garbageCollector(cntxt, mb, stk, TRUE);
				/* reset the clock */
				if( oldtimer)
					cntxt->timer= oldtimer;
			} else {
				@:endProfile(stk)@
			}
		stkpc= mb->stop;
		continue;
	default:
		stkpc++;
}

@+ Assignment command
The assignment statement copies values around on the stack frame,
including multiple assignments.

Pushing constants/initial values onto the stack is a separate operation.
It takes the constant value discovered at compile time and stored in the
symbol table and moves it to the stackframe location. This activity
is made part of the start-up procedure.

The before after calls should be reconsidered here, because
their. They seem superflous and the way they are used will
cause errors in multi-assignment statements.
@-
@= assignStmt
{
	@:safeTarget(@1)@
	for(k=0, i=pci->retc; k<pci->retc && i<pci->argc; i++,k++){
		lhs = &stk->stk[pci->argv[k]];
		rhs = &stk->stk[pci->argv[i]];
		VALcopy(lhs,rhs);
		if( lhs->vtype == TYPE_bat && lhs->val.bval)
			BBPincref(lhs->val.bval, TRUE);
	}
	@:restoreTarget(@1,@3)@
	ret = 0;
	@:exceptionHndlr(@1,@2,@3)@
	@:timingHndlr(@1)@
}
@}
@-
@node MAL API, Exception Handling, The MAL Interpreter, The MAL Interpreter

@+ MAL API
The linkage between MAL interpreter and compiled C-routines
is kept as simple as possible.
Basically we distinguish four kinds of calling conventions:
CMDcall, FCNcall, FACcall, and  PATcall.
The FCNcall indicates calling a MAL procedure, which leads
to a recursive call to the interpreter.

CMDcall initiates calling a linked function, passing pointers
to the parameters and result variable, i.e.  f(ptr a0,..., ptr aN)
The function returns a MAL-SUCCEED upon success and a pointer
to an exception string upon failure.
Failure leads to raise-ing an exception in the interpreter loop,
by either looking up the relevant exception message in the module
administration or construction of a standard string.

The PATcall initiates a call which contains the MAL context,
i.e. f(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
The mb provides access to the code definitions. It is primarilly
used by routines intended to manipulate the code base itself, such
as the optimizers. The Mal stack frame pointer provides access
to the values maintained. The arguments passed are offsets
into the stack frame rather than pointers to the actual value.

@{
BAT parameters require some care. Ideally, a BAT should not be kept
around long. This would mean that each time we access a BAT it has to be
pinned in memory and upon leaving the function, it is unpinned.
This degrades performance significantly.
After the parameters are fixed, we can safely free the destination
variable and re-initialize it to nil.

Before we execute an instruction the variables to be garbage collected
are identified. In the post-execution phase they are removed.
@= safeTarget
#ifdef STACKTRACE
	printf("safeTarget %d\n", garbageControl(pci));
	printInstruction(cntxt->fdout,mb,pci, LIST_MAL_ALL);
#endif
	if( garbageControl(pci) ){
		for(i=0; i < pci->argc; i++) {
			sbackup[i]= 0;
			backup[i]= 0;
			garbage[i]= -1;
			if (stk->stk[getArg(pci,i)].vtype == TYPE_bat && getEndOfLife(mb,getArg(pci,i)) == stkpc && isNotUsedIn(pci,i+1,getArg(pci,i)) ){
				garbage[i]= getArg(pci,i);
#ifdef DEBUG_GC
				mnstr_printf(GDKstdout,"GC %d %s prep\n",getArg(pci,i), getArgName(mb,pci,i));
#endif
			}

			if( i < pci->retc &&  stk->stk[getArg(pci,i)].vtype == TYPE_bat) {
				backup[i]= stk->stk[getArg(pci,i)].val.bval;
#if @1
				stamp= BBPcurstamp();
#endif
			} else
			if( i < pci->retc &&  stk->stk[getArg(pci,i)].vtype == TYPE_str) {
				backup[i]= stk->stk[getArg(pci,i)].len;
				sbackup[i]= stk->stk[getArg(pci,i)].val.sval;
				backup[i] += (sbackup[i]!=NULL);
			}
		}
	}
@= restoreTarget
#ifdef STACKTRACE
	printf("restoreTarget %d\n", garbageControl(pci));
#endif
	/* Provide debugging support */
#if @1
	if( GDKdebug & 10 && exceptionVar < 0) {
		BAT *b;

		for( i=0; i< pci->retc; i++)
		if ( garbage[i] == -1 && stk->stk[getArg(pci,i)].vtype == TYPE_bat &&
				stk->stk[getArg(pci,i)].val.bval ){
			b= BATdescriptor(stk->stk[getArg(pci,i)].val.bval);
			if( b == NULL){
				ret = createException(MAL, "mal.propertyCheck", RUNTIME_OBJECT_MISSING);
				continue;
			}
			if( b->batStamp <= stamp){
				if( GDKdebug & 8){
					if (b->H != b->T) {
						BATpropcheck(BATmirror(b), BATPROPS_QUICK);
					}
					BATpropcheck(b, BATPROPS_QUICK);
				}
			} else
				if( GDKdebug & 2) {
					if (b->H != b->T) {
						BATpropcheck(BATmirror(b), BATPROPS_QUICK);
					}
					BATpropcheck(b, BATPROPS_QUICK);
				}
			BBPunfix(b->batCacheid);
		}
	}
#endif
	@:MALrecycleExit(@2)@
	if(ret==MAL_SUCCEED && garbageControl(pci) ){
		for(i=0; i<pci->argc; i++)
		if( isaBatType(getArgType(mb,pci,i)) ){
			bat bid = stk->stk[getArg(pci,i)].val.bval;

			/* update the bigfoot information only if we need to gc */
			if (cntxt->flags &  bigfootFlag)
				updateBigFoot(cntxt, bid, TRUE);
			if (i<pci->retc && backup[i]){
				if (backup[i] != bid && i < pci->retc) {
					/* possible garbage collect the variable */
					if (cntxt->flags &  bigfootFlag)
							updateBigFoot(cntxt, backup[i], FALSE);
				}
				BBPdecref(backup[i], TRUE);
				backup[i]=0;
			}
			if ( garbage[i] >= 0){
				bid = ABS(stk->stk[garbage[i]].val.bval);
				BBPdecref( bid, TRUE);
				PARDEBUG mnstr_printf(GDKstdout,"#GC pc=%d bid=%d %s done\n",stkpc,bid,getVarName(mb,garbage[i]));
				stk->stk[garbage[i]].val.bval = 0;
			}
		} else if( i < pci->retc && stk->stk[getArg(pci,i)].vtype == TYPE_str){
			int a= getArg(pci,i);
			if( sbackup[i] && sbackup[i]!= stk->stk[a].val.sval){
				if( backup[i] > 0)
					GDKfree(sbackup[i]);
				if (i >= pci->retc){
					stk->stk[getArg(pci,i)].val.sval= 0;
					stk->stk[getArg(pci,i)].len= 0;
				}
				backup[i]=0;
				sbackup[i]=0;
			}
		}
	}
@-
@= commandcall
{
	@:safeTarget(@1)@
	/* improve performance with 20 ms/1M calls*/
	assert(pci->fcn != NULL);
	switch(pci->argc){
	case 0 : ret = (str) (*pci->fcn)(); break;
	case 1 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0)); break;
	case 2 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0),
			(ptr) getArgReference(stk,pci,1));
			 break;
	case 3 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0),
			(ptr) getArgReference(stk,pci,1),
			(ptr) getArgReference(stk,pci,2));
			 break;
	case 4 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0),
			(ptr) getArgReference(stk,pci,1),
			(ptr) getArgReference(stk,pci,2),
			(ptr) getArgReference(stk,pci,3));
			 break;
	case 5 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0),
			(ptr) getArgReference(stk,pci,1),
			(ptr) getArgReference(stk,pci,2),
			(ptr) getArgReference(stk,pci,3),
			(ptr) getArgReference(stk,pci,4));
			 break;
	case 6 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0),
			(ptr) getArgReference(stk,pci,1),
			(ptr) getArgReference(stk,pci,2),
			(ptr) getArgReference(stk,pci,3),
			(ptr) getArgReference(stk,pci,4),
			(ptr) getArgReference(stk,pci,5));
			 break;
	case 7 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0),
			(ptr) getArgReference(stk,pci,1),
			(ptr) getArgReference(stk,pci,2),
			(ptr) getArgReference(stk,pci,3),
			(ptr) getArgReference(stk,pci,4),
			(ptr) getArgReference(stk,pci,5),
			(ptr) getArgReference(stk,pci,6));
			 break;
	case 8 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0),
			(ptr) getArgReference(stk,pci,1),
			(ptr) getArgReference(stk,pci,2),
			(ptr) getArgReference(stk,pci,3),
			(ptr) getArgReference(stk,pci,4),
			(ptr) getArgReference(stk,pci,5),
			(ptr) getArgReference(stk,pci,6),
			(ptr) getArgReference(stk,pci,7));
			 break;
	case 9 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0),
			(ptr) getArgReference(stk,pci,1),
			(ptr) getArgReference(stk,pci,2),
			(ptr) getArgReference(stk,pci,3),
			(ptr) getArgReference(stk,pci,4),
			(ptr) getArgReference(stk,pci,5),
			(ptr) getArgReference(stk,pci,6),
			(ptr) getArgReference(stk,pci,7),
			(ptr) getArgReference(stk,pci,8));
			 break;
	case 10 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0),
			(ptr) getArgReference(stk,pci,1),
			(ptr) getArgReference(stk,pci,2),
			(ptr) getArgReference(stk,pci,3),
			(ptr) getArgReference(stk,pci,4),
			(ptr) getArgReference(stk,pci,5),
			(ptr) getArgReference(stk,pci,6),
			(ptr) getArgReference(stk,pci,7),
			(ptr) getArgReference(stk,pci,8),
			(ptr) getArgReference(stk,pci,9));
			 break;
	case 11 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0),
			(ptr) getArgReference(stk,pci,1),
			(ptr) getArgReference(stk,pci,2),
			(ptr) getArgReference(stk,pci,3),
			(ptr) getArgReference(stk,pci,4),
			(ptr) getArgReference(stk,pci,5),
			(ptr) getArgReference(stk,pci,6),
			(ptr) getArgReference(stk,pci,7),
			(ptr) getArgReference(stk,pci,8),
			(ptr) getArgReference(stk,pci,9),
			(ptr) getArgReference(stk,pci,10));
			 break;
	case 12 : ret = (str) (*pci->fcn)(
			(ptr) getArgReference(stk,pci,0),
			(ptr) getArgReference(stk,pci,1),
			(ptr) getArgReference(stk,pci,2),
			(ptr) getArgReference(stk,pci,3),
			(ptr) getArgReference(stk,pci,4),
			(ptr) getArgReference(stk,pci,5),
			(ptr) getArgReference(stk,pci,6),
			(ptr) getArgReference(stk,pci,7),
			(ptr) getArgReference(stk,pci,8),
			(ptr) getArgReference(stk,pci,9),
			(ptr) getArgReference(stk,pci,10),
			(ptr) getArgReference(stk,pci,11));
			 break;
	default:
		ret = createScriptException(mb, stkpc, MAL, NULL,
				"too many arguments for command call");
	}
	@:restoreTarget(@1,@3)@
	@:exceptionHndlr(@1,@2,@3)@
	@:timingHndlr(@1,@2)@
}
@-
@= patterncall
	if (pci->fcn == NULL) {
		ret = createScriptException(mb, stkpc, MAL, NULL,
			"address of pattern %s.%s missing", pci->modname, pci->fcnname);
	} else {
		@:safeTarget(@1)@
		ret = (str) (*pci->fcn)(cntxt,mb,stk,pci);
		@:restoreTarget(@1,@3)@
	}
	@:exceptionHndlr(@1,@2,@3)@
	@:timingHndlr(@1,@2)@
@-
MAL function calls are relatively expensive, because they have to assemble
a new stack frame and do housekeeping, such as garbagecollection of all
non-returned values.

@-
@= functioncall
{
	stk->pcup = stkpc;
	@:safeTarget(@1)@
	ret= runMAL(cntxt,pci->blk,1,mb,stk,pci);
	@:restoreTarget(@1,@3)@
	@:exceptionHndlr(@1,@2,@3)@
	@:timingHndlr(@1)@
}
@-
Factory calls are more involved. At this stage it is a synchrononous
call to the factory manager.
Factory calls should deal with the reference counting.
@= factorycall
	if( pci->blk== NULL)
		ret = createScriptException(mb, stkpc, MAL, NULL,
				"reference to MAL function missing");
	else
		ret= runFactory(cntxt,pci->blk,mb,stk,pci);
	@:exceptionHndlr(@1,@2,@3)@
	@:timingHndlr(SLOW)@
@-
The type dispatching table in getArgReference can be removed if we
determine at compile time the address offset within a ValRecord.
We leave this optimization for the future, it leads to about 10%
improvement (100ms for 1M calls).

@+ Flow of control statements
Each assignment (function call) may be part of the initialization
of a barrier- block. In that case we have to test the
outcome of the operation and possibly skip the block altogether.
The latter is implemented as a linear scan for the corresponding
labeled statemtent. This might be optimized later.

@= barrierControl
{   v= &stk->stk[getDestVar(pci)];
	/* skip to end of barrier, depends on the type */
	switch(v->vtype){
		case TYPE_bit:
			if( v->val.cval[0] == FALSE || v->val.cval[0] == bit_nil)
				stkpc= pci->jump;
			break;
		case TYPE_chr:
			if( v->val.cval[0] == chr_nil )
				stkpc= pci->jump;
			break;
		case TYPE_oid:
			if( v->val.oval == oid_nil )
				stkpc= pci->jump;
			break;
		case TYPE_sht:
			if( v->val.shval < 0 || v->val.shval == sht_nil)
				stkpc= pci->jump;
			break;
		case TYPE_int:
			if( v->val.ival < 0 || v->val.ival == int_nil)
				stkpc= pci->jump;
			break;
		case TYPE_lng:
			if( v->val.lval < 0 || v->val.lval == lng_nil)
				stkpc= pci->jump;
			break;
		case TYPE_flt:
		case TYPE_dbl:
			if( v->val.dval < 0 || v->val.dval == dbl_nil)
				stkpc= pci->jump;
			break;
		case TYPE_str:
			if( v->len == 0 || v->val.sval == str_nil)
				stkpc= pci->jump;
			break;
		default:
			ret = createScriptException(mb, stkpc, MAL, NULL,
					"%s: Unknown barrier type",
					getVarName(mb, getDestVar(pci)));
	}
}

@-
You can skip to a catch block by searching for the corresponding 'lab'
The return value should be set to pass the error automatically upon
reaching end of function block.
@-
@= skipToCatch
	if( stk->cmd == 'C' || mb->trap) {
		stk->cmd = 'n';
		if( cntxt->flags & bbpFlag)
			BBPTraceCall(cntxt,mb,stk,prevpc);
		prevpc = stkpc;
		mdbStep(cntxt,mb,stk,stkpc);
		if( stk->cmd == 'x' || cntxt->mode == FINISHING) {
			stkpc = mb->stop;
			@2;
		}
	}
	/* skip to catch block or end */
	for( ; stkpc<mb->stop; stkpc++){
		InstrPtr l= getInstrPtr(mb,stkpc);
		if( l->barrier == CATCHsymbol ){
			int j;
			for(j=0;j<l->retc; j++)
				if( getArg(l,j) == @1) break;
			else if ( getArgName(mb,l,j)  ||
				strcmp(getArgName(mb,l,j), "ANYexception") == 0)
					break;
			if(j < l->retc) break;
		}
	}
	if( stkpc== mb->stop) {
		@:endProfile(@3)@
			@2;
	}
@-
Each time we enter a barrier block, we could keep its position in the
interpreter stack frame. It forms the starting point to issue a redo.
Unfortunately, this does not easily work in the presence of optimizers, which
may change the order/block structure. Therefore, we simple have to search
the beginning or ensure that during chkProgram the barrier/redo/leave/catch
jumps are re-established.

@}
@-
@node Exception Handling, Garbage Collection, MAL API, The MAL Interpreter
@+ Exception handling
Calling a built-in or user-defined routine may lead to an error or a
cached status message to be dealt with in MAL.
To improve error handling in MAL, an exception handling
scheme based on @sc{catch}-@sc{exit} blocks. The @sc{catch}
statement identifies a (string-valued) variable, which carries the
exception message from
the originally failed routine or @sc{raise} exception assignment.
During normal processing @sc{catch}-@sc{exit} blocks are simply skipped.
Upon receiving an exception status from a function call, we set the
exception variable and skip to the first associated @sc{catch}-@sc{exit}
block.
MAL interpretation then continues until it reaches the end of the block.
If no exception variable was defined, we should abandon the function
alltogether searching for a catch block at a higher layer.

@{
For the time being we have ignored cascaded/stacked exceptions.
The policy is to pass the first recognized exception to a context
in which it can be handled.

@}
@-
Exceptions raised within a linked-in function requires some care.
First, the called procedure does not know anything about the MAL
interpreter context. Thus, we need to return all relevant information
upon leaving the linked library routine.

Second, exceptional cases can be handled deeply in the recursion, where they
may also be handled, i.e. by issueing an GDKerror message. The upper layers
merely receive a negative integer value to indicate occurrence of an
error somewhere in the calling sequence.
We then have to also look into GDKerrbuf to see if there was
an error raised deeply inside the system.

The policy is to require all C-functions to return a string-pointer.
Upon a successfull call, it is a NULL string. Otherwise it contains an
encoding of the exceptional state encountered. This message
starts with the exception identifer, followed by contextual details.
@h
mal_export str catchKernelException(Client cntxt, str ret);
@c
str catchKernelException(Client cntxt, str ret){
	str z;
	if(cntxt->errbuf && cntxt->errbuf[0] ) {
		if (ret != MAL_SUCCEED){
			z= (char*) GDKmalloc( strlen(ret)+strlen(cntxt->errbuf)+2);
			if( z ){
				strcpy(z,ret);
				if (z[strlen(z)-1] != '\n') strcat(z,"\n");
				strcat(z,cntxt->errbuf);
			}
		} else {
			/* trap hidden (GDK) exception */
			z= (char*) GDKmalloc( strlen("GDKerror:")+strlen(cntxt->errbuf)+2);
			if ( z )
				sprintf(z,"GDKerror:%s\n",cntxt->errbuf);
		}
		/* did we eat the error away of not */
		if (z )
			cntxt->errbuf[0] = '\0';
	} else z = ret;
	return z;
}
@{
@= exceptionHndlr
if(cntxt->errbuf && cntxt->errbuf[0] ) {
	str oldret = ret;
	ret = catchKernelException(cntxt, ret);
	FREE_EXCEPTION(oldret);
}

if( ret != MAL_SUCCEED ) {
	str msg = 0;

	if( stk->cmd || mb->trap  ) {
		mnstr_printf(cntxt->fdout,"!ERROR: %s\n",ret);
		stk->cmd= '\n';	/* in debugging go to step mode */
		mdbStep(cntxt,mb,stk,stkpc);
		if( stk->cmd == 'x' || stk->cmd == 'q'  || cntxt->mode == FINISHING) {
			stkpc= mb->stop;
			@2;
		}
		if( stk->cmd == 'r') {
			stk->cmd = 'n';
			stkpc = startpc;
			exceptionVar = -1;
			@2;
		}
	}
	/* Detect any exception received from the implementation. */
	/* The first identifier is an optional exception name */
	if( strstr(ret,"!skip-to-end") ){
		GDKfree(ret);		/* no need to check for M5OutOfMemory */
		ret= MAL_SUCCEED;
		stkpc= mb->stop;
		@2;
	}
/*
Exceptions are catched based on their name, which is part of
the exception message. The ANYexception variable catches
all.
*/
	exceptionVar = -1;
	msg = strchr(ret,':');
	if(msg) {
		*msg= 0;
		exceptionVar = findVariableLength(mb,ret,(int)(msg-ret));
		*msg=':';
	}
	if (exceptionVar == -1)
		exceptionVar = findVariableLength(mb, (str) "ANYexception", 12);

	/* unknown exceptions lead to propagation */
	if( exceptionVar == -1){
		@:endProfile(@3)@
		stkpc= mb->stop;
		@2;
	}
	/* assure correct variable type */
	if (getVarType(mb,exceptionVar) == TYPE_str){
		v=  &stk->stk[exceptionVar];
		if ( v->val.sval)
			FREE_EXCEPTION(v->val.sval);	/* old exception*/
		v->vtype = TYPE_str;
		v->val.sval= ret;
		v->len= (int)strlen(v->val.sval);
		ret = 0;
	} else {
		mnstr_printf(cntxt->fdout,"%s",ret);
		FREE_EXCEPTION(ret);
	}
	/* position yourself at the catch instruction for further decisions */
	@:skipToCatch(exceptionVar,@2,@3)@
	pci= getInstrPtr(mb,stkpc);
}
@-
@+ Result Recycler
An optimization scheme for query sequences is to re-use variables
as much as possible.
The recycler works for any variable and relies on policy functions
registered.
@= MALrecycleStart
	if ( pci->recycle > 0)
		@1->clk = GDKusec();
	if( !RECYCLEentry(cntxt, mb,stk,pci) )
@= MALrecycleExit
	if( pci->recycle > 0 ){
		RECYCLEexit(cntxt, mb,stk,pci,@1->clk);
	}
@}
@-
@node Garbage Collection, Stack Management, Exception Handling, The MAL Interpreter
@+ Garbage collection
Garbage collection is relatively straightforward, because most values are
retained on the stackframe of an interpreter call. However, two storage
types and possibly user-defined type garbage collector definitions
require attention: BATs and strings.

A key issue is to deal with temporary BATs in an efficient way.
References to bats in the buffer pool may cause dangling references
at the language level. This appears as soons as your share
a reference and delete the BAT from one angle. If not carefull, the
dangling pointer may subsequently be associated with another BAT

All string values are private to the VALrecord, which means they
have to be freed explicitly before a MAL function returns.
The first step is to always safe the destination variable
before a function call is made.
@{
@-
@c
void garbageElement(Client cntxt, ValPtr v)
{
	if( v->vtype == TYPE_str) {
		if(v->val.sval) {
			GDKfree(v->val.sval);
			v->val.sval = NULL;
		}
		v->len = 0;
		return;
	}
	if( v->vtype== TYPE_bat ) {
@}
@-
All operations are responsible to properly set the
reference count of the BATs being produced or destroyed.
The libraries should not leave the
physical reference count being set. This is only
allowed during the execution of a GDK operation.
All references should be logical.
@-
@{
@c
		bat bid = ABS(v->val.bval);
		/* printf("garbage collecting: %d lrefs=%d refs=%d\n",
		   bid, BBP_lrefs(bid),BBP_refs(bid));*/
		v->val.bval = 0;
		if (bid == 0 )
			return;
		if (!BBP_lrefs(bid))
			return;
		if (cntxt && cntxt->flags &  bigfootFlag)
			updateBigFoot(cntxt, bid, FALSE);
		BBPdecref(bid,TRUE);
	}
}
@-
@}

Before we return from the interpreter, we should free all
dynamically allocated objects and adjust the BAT reference counts.
Early experience shows that for small stack frames the overhead
is about 200 ms for a 1M function call loop (tst400e). This means that
for the time being we do not introduce more complex garbage
administration code.

Also note that for top-level stack frames (no environment available),
we should retain the value stack because it acts as a global variables.
This situation is indicated by the 'global' in the stack frame.
@{
Upon termination of the session, the stack should be cleared.
Beware that variables may be know polymorphic, their actual
type should be saved for variables that recide on a global
stack frame.
@c
void garbageCollector(Client cntxt, MalBlkPtr mb, MalStkPtr stk, int flag)
{
	int k;
	ValPtr v;

#ifdef STACKTRACE
	mnstr_printf(cntxt->fdout,"#--->stack before garbage collector\n");
	printStack(cntxt->fdout,mb,stk,0);
#endif
	for(k=0;k<mb->vtop; k++) {
		if(isVarCleanup(mb,k) && (flag || isTmpVar(mb,k) )){
			garbageElement(cntxt, v= &stk->stk[k]);
			v->vtype= TYPE_int;
			v->val.ival= int_nil;
		}
	}
#ifdef STACKTRACE
	mnstr_printf(cntxt->fdout,"#-->stack after garbage collector\n");
	printStack(cntxt->fdout,mb,stk,0);
#else
	(void) cntxt;
#endif
}
@-
Sometimes it helps to release a BAT when it won;t be used anymore.
In this case, we have to assure that all references are cleared
as well. The routine below performs this action in the local
stack frame and its parents only.
@c
void releaseBAT(MalBlkPtr mb, MalStkPtr stk, int bid)
{
	int k;

	do {
		for(k=0;k<mb->vtop; k++)
			if( stk->stk[k].vtype== TYPE_bat && abs(stk->stk[k].val.bval)==bid) {
				BBPdecref(bid,TRUE);
				stk->stk[k].val.ival= 0;
			}
		if(stk->up){
			stk= stk->up;
			mb= stk->blk;
		} else
			break;
	} while(stk);
}

@-
@+ Performance section
Running the program under dataflow control will screw up the
order in which performance trace data is displayed. Moreover,
we do not clearly see the start and end of the dataflow execution,
because the performance data is the result of the 'failed' runMALdataflow().
It simply skips the barrier block upon return.

@= performanceVariables
	lng newclk=0;
	int ppc= -2;
	lng tcs = 0;
	(void) tcs;
	if (malProfileMode ) {
		setFilterOnBlock(mb, 0, 0);
		ppc = -1;
	}
@= beginProfile
	if ( stk) {
		gettimeofday(&stk->clock, NULL);
		if( mb->profiler != NULL ){
			@1->clk= GDKusec();
			mal_set_lock(mal_contextLock, "DFLOWdelay");
			if( mb->profiler[stkpc].trace)
			{
				ppc= stkpc;
				mb->profiler[ppc].clk= 0;
				mb->profiler[ppc].ticks= 0;
				mb->profiler[ppc].clock= stk->clock;
				/* emit the instruction upon start as well */
				if ( @2 )profilerEvent(cntxt->idx,mb,stk,stkpc);
#ifdef HAVE_TIMES
				times(&stk->timer);
				mb->profiler[ppc].timer= stk->timer;
#endif
				mb->profiler[ppc].clk= @1->clk;
			}
			mal_unset_lock(mal_contextLock, "DFLOWdelay");
		}
	}
@= endProfile
	if ( stk != NULL) {
		if( malProfileMode == 0)
			/* mostly true */;
		else
		if(@1 != NULL && ppc>= 0 && mb->profiler != NULL && mb->profiler[ppc].trace  && mb->profiler[ppc].clk)
		{
			newclk= GDKusec();
			mb->profiler[ppc].counter++;
			mb->profiler[ppc].ticks = newclk - @1->clk;
			mb->profiler[ppc].clk += mb->profiler[ppc].clk;
			if( pci){
				mb->profiler[ppc].rbytes= getVolume(stk,pci,0);
				mb->profiler[ppc].wbytes= getVolume(stk,pci,1);
			}
			profilerEvent(cntxt->idx,mb,stk,ppc);
			ppc= -1;
		}
		if ( cntxt->qtimeout &&  time(NULL) - stk->clock.tv_usec > cntxt->qtimeout)
			throw(MAL, "mal.interpreter", RUNTIME_QRY_TIMEOUT);
	}

@-
#if @1
@= timingHndlr
if( cntxt->flags && stk->cmd != 't' && stk->cmd != 'C'){
	if (lock)
		MT_lock_set(&*lock, "timing");
	mnstr_printf(cntxt->fdout,"= ");	/* single column rendering */
	if( cntxt->flags & timerFlag){
		char buf[32];
		snprintf(buf,sizeof(buf),LLFMT,GDKusec()-cntxt->timer);
		mnstr_printf(cntxt->fdout, "%8s usec ",buf);
	}
	if( cntxt->flags & threadFlag)
		mnstr_printf(cntxt->fdout,"\@%d ",tid);
#ifdef HAVE_SYS_RESOURCE_H
	if( cntxt-> flags & ioFlag){
		struct  rusage resource;
		getrusage(RUSAGE_SELF, &resource);
		mnstr_printf(cntxt->fdout," %3d R",
			resource.ru_inblock- oldinblock);
		mnstr_printf(cntxt->fdout," %3d W ",
			resource.ru_oublock- oldoublock);
	}
#endif
	if( cntxt->flags & memoryFlag){
		struct Mallinfo memory;
		memory= MT_mallinfo();
		if( memory.arena- oldMemory.arena > 0)
			mnstr_printf(cntxt->fdout," " SZFMT " bytes ",
				(size_t) (memory.arena-oldMemory.arena) );
	}
	if( cntxt->flags & flowFlag){
		/* calculate the read/write byte flow */
		displayVolume(cntxt, getVolume(stk,pci,0));
		mnstr_printf(cntxt->fdout,"/");
		displayVolume(cntxt, getVolume(stk,pci,1));
		mnstr_printf(cntxt->fdout," ");
	}
	if( cntxt->flags & bigfootFlag){
		displayVolume(cntxt,cntxt->vmfoot);
		mnstr_printf(cntxt->fdout,":");
		displayVolume(cntxt,cntxt->bigfoot);
		mnstr_printf(cntxt->fdout," ");
	}
	if (cntxt->flags & cntFlag){
		char buf[32];
		snprintf(buf, sizeof(buf), BUNFMT , cntxt->cnt);
		mnstr_printf(cntxt->fdout,":%6s ", buf);
	}
	{str line;
	line= instruction2str(mb, stk, pci, LIST_MAL_DEBUG);
	if ( line) {
		mnstr_printf(cntxt->fdout, " %s\n", line);
		GDKfree(line);
	}
	}
	if( cntxt->flags & timerFlag)
		cntxt->timer = GDKusec();
	if (lock)
		MT_lock_unset(&*lock, "timing");
}
@-
#endif
@-
For performance evaluation it is handy to know the
maximal amount of bytes read/written. The actual
amount is harder to guess, because it too much
depends on the operation.
@c
lng getVolume(MalStkPtr stk, InstrPtr pci, int rd)
{
	int i, limit;
	lng vol=0;
	BAT *b;
	int isview = 0;

	limit = rd == 0?pci->retc:pci->argc;
	i = rd?pci->retc:0;

	if( stk->stk[getArg(pci,0)].vtype == TYPE_bat){
		b = BBPquickdesc(ABS(stk->stk[getArg(pci,0)].val.bval), TRUE);
		if (b)
			isview = isVIEW(b);
	}
	for(; i<limit; i++) {
		if (stk->stk[getArg(pci,i)].vtype == TYPE_bat){
			BUN cnt = 0;

			b = BBPquickdesc(ABS(stk->stk[getArg(pci,i)].val.bval), TRUE);
			if (b==NULL)
				continue;
			cnt = BATcount(b);
			/* Usually reading views cost as much as full bats.
			   But when we output a slice that is not the case. */
			vol += ((rd && !isview) || !VIEWhparent(b))?headsize(b,cnt):0;
			vol += ((rd && !isview) || !VIEWtparent(b))?tailsize(b,cnt):0;
		}
	}
	return vol;
}

void displayVolume(Client cntxt, lng vol){
	char buf[32];
	formatVolume(buf,(int)sizeof(buf),vol);
	mnstr_printf(cntxt->fdout,"%s",buf);
}
@h
#endif /*  _MAL_INTERPRET_H*/
@}
