@/
The contents of this file are subject to the MonetDB Public License
Version 1.1 (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
http://www.monetdb.org/Legal/MonetDBLicense

Software distributed under the License is distributed on an "AS IS"
basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
License for the specific language governing rights and limitations
under the License.

The Original Code is the MonetDB Database System.

The Initial Developer of the Original Code is CWI.
Portions created by CWI are Copyright (C) 1997-July 2008 CWI.
Copyright August 2008-2011 MonetDB B.V.
All Rights Reserved.
@

@f cluster

@c
/*
 * @a Martin Kersten, Niels Nes
 * @v 1.0
 * @t Hash cluster Algorithms
 *
 * @* Introduction
 * Hash structures in MonetDB are optimized to build in a single scan.
 * Also their use is limited to a single bat. Read optimized hashes (or clusters)
 * could be used in many algorithms, such as select, join, group by and
 * distinct checking. This calls for physical locality of elements
 * hashing to the same element. Preferrable the elements in a collision
 * list are physically close, as are the lists of subsequent lists.
 *
 * This module extends the built in hashing scheme with a method
 * to reorganize BATs based on their hash key. It is a linear-time,
 * near-optimal N-way reclustering based on hash key ranges.
 *
 * We start with collecting all hash keys from the underlying
 * table into the table H[:oid,:oid].
 * The next step is a reclustering step to bring
 * elements together based on the hash key. This step is based
 * on the assumption that values in the hash-key are uniformly
 * distributed. We create as many buckets as we  consider
 * justified in terms of the IO. The tuples are 'thrown' into
 * their bucket until they become full or can be extended
 * by harvesting free space from its direct neighor buckets.
 * If there is no free space left, we circularly look for a bucket
 * with space, partly  polluting the clustering objective.
 *
 * The result is a void-oid table that represents an IO
 * 'optimal' sequence of tuples. IO optimal, because
 * with determining N we have 2N read/write pointers
 * in the table. Tuples are reclustered amongst those
 * using an ordinary join operation.
 * The outerloop touches each tuple once, causing
 * the order in the oid list to represent the IO
 * activity too. This means we can use it directly
 * as a driver for redistributing value columns.
 *
 * The remaining step is to perform this in parallel
 * for all BATs comprising a relational table.
 */
@mal
module cluster;

command key(b:bat[:oid,:any_1]) :bat[:oid,:oid]
address CLUSTER_key
comment "Create the hash key list";

command map(b:bat[:oid,:oid]) :bat[:oid,:oid]
address CLUSTER_map
comment "Recluster a hash key table and produce a re-allocation map";

pattern column(m:bat[:oid,:oid], b:bat[:oid,:any_1]):bat[:oid,:any_1]
address CLUSTER_column
comment "Reorder tail of the BAT using the cluster map";

pattern table(b:bat[:oid,:any]...):bat[:oid,:oid]
address CLUSTER_table
comment "Cluster the BATs using the first one as reference.
Return the oid map used";

@= mal_cls_new
command new(b:bat[:oid,:@1], bits:int, offset:int) 
	(psum:bat[:oid,:wrd], map:bat[:oid,:wrd])
address CLS_create_@1
comment "Compute the cluster map for bat b of hash key values. A cluster map is a list of unique (new) BUN positions. The p(refix) sum is a by product which returns the prefix sum of the per masked key frequency.";

command new(b:bat[:oid,:@1], bits:int, offset:int, order:bit) 
	(psum:bat[:oid,:wrd], map:bat[:oid,:bte])
address CLS_create2_@1
comment "Compute the cluster map for bat b. A cluster map is a list of partition ids. The p(refix) sum is a by product which returns the prefix sum of the per partition frequency. Prefix sum and map can be use to 'cluster' related columns based on b. Incase the offset is non negative it is used to shift the key values. Offset together with the mask bits should make sure that the result of the partitioning can be used in a order by sequence. If this holds and the input is sorted we return a 'compressed' representation of the map, ie [:oid,:bte], the repeated values are not inserted. The order flag indicates that the clustering is used for ordering, ie partition keys aren't fixed so we can internaly optimize partition sizes.";
@
@mal

@:mal_cls_new(bte)@
@:mal_cls_new(chr)@
@:mal_cls_new(sht)@
@:mal_cls_new(int)@
@:mal_cls_new(wrd)@
@:mal_cls_new(lng)@
@:mal_cls_new(flt)@
@:mal_cls_new(dbl)@

command map(cluster:bat[:oid,:wrd], b:bat[:oid,:any_1]) :bat[:oid,:any_1]
address CLS_map
comment "Reorder tail of bat b, using a cluster map";

command map(psum:bat[:oid,:wrd], cluster:bat[:oid,:bte], b:bat[:oid,:any_1]) :bat[:oid,:any_1]
address CLS_map2
comment "Reorder tail of bat b, using a cluster prefix sum and map. In case the
map is sorted with a non dense head we assume no remapping is needed";

pattern split(clustered:bat[:oid,:any_1], psum:bat[:oid,:wrd]) :bat[:oid,:any_1]...
address CLS_split
comment "split the clustered bat into parts";

@h
#ifndef _CLUSTER_H
#define _CLUSTER_H

#include <mal.h>
#include "mal_interpreter.h"
#include "mal_client.h"

/*#define _CLUSTER_DEBUG	for local debugging */

#ifdef WIN32
#if !defined(LIBMAL) && !defined(LIBATOMS) && !defined(LIBKERNEL) && !defined(LIBMAL) && !defined(LIBOPTIMIZER) && !defined(LIBSCHEDULER) && !defined(LIBMONETDB5)
#define cluster_export extern __declspec(dllimport)
#else
#define cluster_export extern __declspec(dllexport)
#endif
#else
#define cluster_export extern
#endif

cluster_export str CLUSTER_key( bat *M, bat *B);
cluster_export str CLUSTER_map(bat *RB, bat *B);
cluster_export str CLUSTER_apply(bat *bid, BAT *nb, BAT *cmap);
cluster_export str CLUSTER_column( Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
cluster_export str CLUSTER_table( Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);

@= hdr_cls_new
cluster_export str  CLS_create_@1(bat *rpsum, bat *rcmap, bat *b, unsigned int *bits, unsigned int *offset);
cluster_export str  CLS_create2_@1(bat *rpsum, bat *rcmap, bat *b, unsigned int *bits, unsigned int *offset, bit *order);
@
@h
@:hdr_cls_new(bte)@
@:hdr_cls_new(chr)@
@:hdr_cls_new(sht)@
@:hdr_cls_new(int)@
@:hdr_cls_new(wrd)@
@:hdr_cls_new(lng)@
@:hdr_cls_new(flt)@
@:hdr_cls_new(dbl)@

cluster_export str  CLS_map(bat *rb, bat *cmap, bat *b);
cluster_export str  CLS_map2(bat *rb, bat *psum, bat *cmap, bat *b);
cluster_export str CLS_split( Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);

#endif /* _CLUSTER_H */
@c

#include "monetdb_config.h"
#include "cluster.h"
#include <mal_exception.h>
#include "algebra.h"

@= map_fixed
static void
CLUSTER_key_@1( BAT *map, BAT *b)
{
	@1 *bt, *be;
	oid *o;

	assert(BUNfirst(map) == 0);
	assert(BUNfirst(b) == 0);
	o = (oid*)Tloc(map, 0);
	bt = (@1*)Tloc(b, 0);
	be = bt + BATcount(b);
	for ( ; bt < be; bt++){
		BUN h = hash_@1(b->T->hash,bt);
		*o++= h;
	}
}

#if 0
static str
CLUSTER_column_@1(BAT *nb, BAT *b, BAT *cmap)
{
	@1 *r,*qb;
	oid *ct, *ce;
	int cnt=0;
	
	assert(BUNfirst(nb) == 0);
	assert(BUNfirst(b) == 0);
	assert(BUNfirst(cmap) == 0);
	assert(cmap->ttype == TYPE_oid);
	r = (@1*)Tloc(nb, 0);
	qb = (@1*)Tloc(b, 0);
	ct = (oid *)Tloc(cmap, 0);
	ce = ct + BATcount(cmap);
	nb->H->heap.dirty = nb->T->heap.dirty= TRUE;
	for ( ; ct < ce; ct++){
		*r++ = qb[*ct];
		if ( ((++cnt) % 1000000) == 0){
			BATsave(nb);
			nb->H->heap.dirty = nb->T->heap.dirty= TRUE;
		}
	}
	BATsetcount(nb, BATcount(b));
	nb->tsorted= FALSE;
	nb->tdense= FALSE;
    	if (nb->H != nb->T) 
        	BATpropcheck(BATmirror(nb), BATPROPS_QUICK);
    	BATpropcheck(nb, BATPROPS_QUICK);
	return MAL_SUCCEED;
}
#endif

@
@c
@:map_fixed(chr)@
@:map_fixed(bte)@
@:map_fixed(sht)@
@:map_fixed(oid)@
@:map_fixed(wrd)@
@:map_fixed(int)@
@:map_fixed(lng)@
@:map_fixed(flt)@
@:map_fixed(dbl)@

static void
CLUSTER_key_str( BAT *map, BAT *b)
{
	char *bt, *be;
	oid *o;
	BUN h;

	assert(BUNfirst(b) == 0);
	assert(BUNfirst(map) == 0);
	o = (oid*)Tloc(map, 0);
	bt = (char *)Tloc(b, 0);
	be = bt + (BATcount(b) << b->T->width);
	switch (b->T->width) {
	case 1:
		for ( ; bt < be; bt += 1){
		/* hash on the string reference */
			h = hash_bte(b->T->hash,bt);
			*o++= h;
		}
		break;
	case 2:
		for ( ; bt < be; bt += 2){
		/* hash on the string reference */
			h = hash_sht(b->T->hash,bt);
			*o++= h;
		}
		break;
#if SIZEOF_VAR_T == 8
	case 4:
		for ( ; bt < be; bt += 4){
		/* hash on the string reference */
			h = hash_int(b->T->hash,bt);
			*o++= h;
		}
		break;
#endif
	default:
		for ( ; bt < be; bt += 8){
		/* hash on the string reference */
			h = hash_lng(b->T->hash,bt);
			*o++= h;
		}
		break;
	}
}
static str  
CLUSTER_column_any(BAT *nb, BAT *b, BAT *cmap)
{
	oid *ct, *ce, o = 0;
	BATiter bi= bat_iterator(b);
	
	ct = (oid *)Tloc(cmap, 0);
	ce = ct + BATcount(cmap);
	nb->H->heap.dirty = nb->T->heap.dirty= TRUE;
	for ( ; ct < ce; ct++){
		BUNfastins(nb, &o, BUNtail(bi, (BUN) *ct));
		o++;
		if ( (o % 1000000) == 0){
			BATsave(nb);
			nb->H->heap.dirty = nb->T->heap.dirty= TRUE;
		}
	}
	BATsetcount(nb, BATcount(b));
    if (nb->H != nb->T)
        BATpropcheck(BATmirror(nb), BATPROPS_QUICK);
	if (!(nb->batDirty&2)) 
		nb = BATsetaccess(nb, BAT_READ);
    BATpropcheck(nb, BATPROPS_QUICK);
	return MAL_SUCCEED;
}
/*
 * @-
 * The hash key and the oid are materialized to prepare for reclustering.
 */
str
CLUSTER_key( bat *M, bat *B){
	BAT *map, *b;

	if ((b = BATdescriptor(*B)) == NULL)
		throw(MAL, "cluster.key", INTERNAL_BAT_ACCESS);
	(void) BATprepareHash(BATmirror(b)); /* only produce the hash structure! */

	if ((map = BATnew(TYPE_void, TYPE_oid, BATcount(b)+1)) == NULL) {
		BBPunfix(*B);
		throw(MAL, "cluster.key", MAL_MALLOC_FAIL);
	}
	map->tsorted= FALSE;
	map->tdense= FALSE;
	BATseqbase(map, 0);
	BATsetcount(map, BATcount(b));
	map->H->nonil = b->H->nonil;
	map->T->nonil = b->T->nonil;

	switch(ATOMstorage(b->ttype)) {
		case TYPE_chr: CLUSTER_key_chr(map,b); break;
		case TYPE_bte: CLUSTER_key_bte(map,b); break;
		case TYPE_sht: CLUSTER_key_sht(map,b); break;
		case TYPE_oid: CLUSTER_key_oid(map,b); break;
		case TYPE_wrd: CLUSTER_key_wrd(map,b); break;
		case TYPE_int: CLUSTER_key_int(map,b); break;
		case TYPE_lng: CLUSTER_key_lng(map,b); break;
		case TYPE_flt: CLUSTER_key_flt(map,b); break;
		case TYPE_dbl: CLUSTER_key_dbl(map,b); break;
		case TYPE_str: CLUSTER_key_str(map,b); break;
		default:
			throw(MAL, "cluster.key", MAL_MALLOC_FAIL);
		
	}
	BATsave(map);	/* dump dirty pages from memory */
	BBPunfix(*B);
	BBPkeepref(*M = map->batCacheid);
	return MAL_SUCCEED;
}
/*
 * @-
 * Recluster the hash <oid,oid> table into a number of buckets
 * on the high order bits,
 * If the baskets are full before we have moved everything
 * in place, we seek forward for a bucket to dump the elements.
 *
 * The self-organizing version should determine the optimal
 * number of buckets. Thereafter it can just call the
 * remapping;
 */
typedef struct{
		BUN base,limit,nxt;
} Basket;

str  
CLUSTER_map(bat *RB, bat *B)
{
	BUN rng,bsize, bnr=0, h, N= 2; /* number of buckets */
	BAT *b, *map;
	BUN p,q;
	oid *mp, idx = 0, *bp;
	int i;
	Basket *basket;
	(void) RB;

	if ( (b = BATdescriptor(*B)) == NULL)
		throw(MAL, "cluster.new", INTERNAL_BAT_ACCESS);

	if ((map = BATnew(TYPE_void, TYPE_oid, BATcount(b)+1)) == NULL) {
		BBPunfix(*B);
		throw(MAL, "cluster.new", MAL_MALLOC_FAIL);
	}
	map->hsorted= TRUE;
	map->hdense= TRUE;
	BATkey(map, TRUE);
	BATseqbase(map, 0);
	BATkey(map,TRUE);
	map->tsorted= FALSE;
	map->tdense= FALSE;
	BATsetcount(map, BATcount(b));
	map->H->nonil = b->H->nonil;
	map->T->nonil = TRUE;
	BATmax(b, (ptr) &rng); /* get the maximum hash key , could use mask !*/
	rng++; 
	/*
	 * @-
	 * The key challenge is to determine the number of clusters.
	 * A large number of clusters benefits subsequent performance,
	 * but also challenges the prepare phase. The clustering should
	 * work both for relatively small tables and those that do not
	 * fit in memory.
	 *
	 * The bottomline is the number of elements that fit in a single
	 * diskblock.
	 */
	N= (BUN)MT_npages() /10;
	bsize= (BUN) (MT_pagesize()/sizeof(lng));
	if (N > (rng / bsize))
		N = rng / bsize;
	if ( N ==0) N++;
	bsize= (rng+N-1) / N;
#ifdef _CLUSTER_DEBUG
	N=2; /* for debugging only */
	mnstr_printf(GDKout,"bucket pages %d size %d max %d  N %d\n", 
		(int)MT_npages(), (int)bsize, (int)rng, (int)N);
#endif
	basket = (Basket*) alloca((N+1) * sizeof(Basket));
	if (basket==NULL)
		throw(MAL, "cluster.new", MAL_MALLOC_FAIL);

	/* prepare buffers */
	basket[0].base = 0;
	basket[0].limit = BATcount(b) / N;
	basket[0].nxt = BUN_NONE;
	for (h=1; h < N; h++){
		basket[h].base= basket[h-1].limit;
		basket[h].limit= basket[h-1].limit + basket[0].limit;
		basket[h].nxt= BUN_NONE;
	}
	basket[N-1].limit= BATcount(b); /* last piece */

	mp = (oid*) Tloc(map, 0);
	bp = (oid*) Tloc(b, 0);
	BATaccessBegin(b,USE_TAIL,MMAP_SEQUENTIAL);
	BATaccessBegin(map,USE_TAIL,MMAP_WILLNEED);
	BATloop(b,p,q){
		oid ocur = bp[p];

		bnr = ocur/bsize;
		assert(bnr<N);
		if (basket[bnr].base == basket[bnr].limit){ /* full */
			if (basket[bnr].nxt == BUN_NONE ||
				basket[basket[bnr].nxt].base == basket[basket[bnr].nxt].limit){
				/* find a maximal empty slot somewhere*/
				BUN nr, max= (bnr+1) % N;
				nr= bnr;
				i= (int) N;
				do {
					nr= (nr+1) % N;
					if (basket[nr].limit-basket[nr].base >
						basket[max].limit-basket[max].base)
						max = nr;
				} while( --i >=0);
				/* last basket bounds */
				basket[bnr].nxt = max;
				bnr= max;
			} else bnr = basket[bnr].nxt;
		}
		mp[basket[bnr].base] = idx++;
		basket[bnr].base++;
	}
	BATaccessEnd(b,USE_TAIL,MMAP_SEQUENTIAL);
	BATaccessEnd(map,USE_TAIL,MMAP_WILLNEED);
	BBPunfix(*B);
	BBPkeepref(*RB= map->batCacheid);
	return MAL_SUCCEED;
}
/*
 * @-
 * The order of the tuples in the cluster map
 * represent the read/write order. Under the assumption
 * that those read/writes are already localized, it becomes
 * opportune to simply rebuild the clustered column by
 * probing.
 *
 * Extend this operation to accept a sequence of BATs.
 * We change the BAT in place using a temporary copy
 * to guide the move.
 */
str 
CLUSTER_apply(bat *bid, BAT *b, BAT *cmap)
{
	BAT *nb;
	nb= BATnew(b->htype, b->ttype, BATcapacity(b));
	nb->tsorted= FALSE;
	nb->tdense= FALSE;
	BATseqbase(nb,0); 

	/* determine the work for all threads */
	/* to be done, first assume that we can remap in one go */
	assert(BATcount(b)==BATcount(cmap));

	BATseqbase(nb,0);
	switch(ATOMstorage(b->ttype)) {
/*
	case TYPE_chr: CLUSTER_column_chr(nb, b, cmap);break;
	case TYPE_bte: CLUSTER_column_bte(nb, b, cmap);break;
	case TYPE_sht: CLUSTER_column_sht(nb, b, cmap);break;
	case TYPE_oid: CLUSTER_column_oid(nb, b, cmap);break;
	case TYPE_wrd: CLUSTER_column_wrd(nb, b, cmap);break;
	case TYPE_int: CLUSTER_column_int(nb, b, cmap);break;
	case TYPE_lng: CLUSTER_column_lng(nb, b, cmap);break;
	case TYPE_flt: CLUSTER_column_flt(nb, b, cmap);break;
	case TYPE_dbl: CLUSTER_column_dbl(nb, b, cmap);break;
*/
	default:
		CLUSTER_column_any(nb, b, cmap);
	}
	BBPkeepref(*bid= nb->batCacheid);
	return MAL_SUCCEED;
}

str  
CLUSTER_column( Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	int *res =(int *) getArgReference(stk, pci, 0);
	bat *CMAP =(int *) getArgReference(stk, pci, 1);
	bat *B =(int *) getArgReference(stk, pci, 2);
	BAT *cmap = NULL, *b = NULL;
	str msg= MAL_SUCCEED;

	(void) cntxt;
	(void) mb;
	if ( (cmap = BATdescriptor(*CMAP)) == NULL )
		throw(MAL, "cluster.column", INTERNAL_BAT_ACCESS);
	if ( (b = BATdescriptor(*B)) == NULL ){
		BBPunfix(*CMAP);
		throw(MAL, "cluster.column", INTERNAL_BAT_ACCESS);
	}

	msg = CLUSTER_apply(res, b,cmap);
	BBPunfix(*CMAP);
	BBPunfix(b->batCacheid);
	return msg;
}

str  
CLUSTER_table( Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	BAT *map,*b;
	int *res, hid, mid, *bid,i;
	str msg;
	(void) cntxt;
	(void) mb;

	res =(int *) getArgReference(stk, pci, 0);
	bid = (int*) getArgReference(stk,pci,pci->retc);
	msg = CLUSTER_key(&hid,bid);
	if (msg)
		return msg;
	msg = CLUSTER_map(&mid,&hid);
	if (msg)
		return msg;
	map = BATdescriptor(mid);
	if (map== NULL)
		throw(MAL,"cluster.table",INTERNAL_BAT_ACCESS);

	for ( i=pci->retc; i<pci->argc; i++){
		bid = (int*) getArgReference(stk,pci,i);
		b = BATdescriptor(*bid);
		if ( b== NULL)
			throw(MAL,"cluster.table",INTERNAL_BAT_ACCESS);
		msg = CLUSTER_apply(res, b,map);
		BBPunfix(b->batCacheid);
	}
	*res= mid;
	return MAL_SUCCEED;
}


#include "cluster.h"
#include <mal_exception.h>

@= c_cls_new
str
CLS_create_@1( bat *rpsum, bat *rcmap, bat *B, unsigned int *Bits, unsigned int *offset)
{
	BAT *psum, *cmap, *b;
	int i, mask = 0, off = *offset;
	unsigned int bits = *Bits;
	@1 *bt, *be; 
	wrd *cnt, *pos, sum, *m;

	if (off < 0)
		off = 0;
	if (bits >= sizeof(int)*8)
		throw(MAL, "cluster.new", TOO_MANY_BITS);

	if ((bits) != 0)
		bits--;
	mask = (1<<bits) - 1;
	if ((b = BATdescriptor(*B)) == NULL)
		throw(MAL, "cluster.new", INTERNAL_BAT_ACCESS);

	if ((psum = BATnew(TYPE_void, TYPE_wrd, mask+1)) == NULL) {
		BBPunfix(*B);
		throw(MAL, "cluster.new", MAL_MALLOC_FAIL);
	}
	BATseqbase(psum,0);
	BATsetcount(psum, mask+1);
	psum->tsorted= TRUE;
	psum->tdense= FALSE;
	cnt = (wrd*)Tloc(psum, BUNfirst(psum));
	for (i=0 ; i <= mask; i++)
		cnt[i] = 0;

	bt = (@1*)Tloc(b, BUNfirst(b));
	be = bt + BATcount(b);
	/* First make a histogram */
	for ( ; bt < be; bt++) {
		int h = (((int)(*bt)) >> off) & mask;
		cnt[h]++;
	}

	/* convert histogram into prefix sum */
	pos = (wrd*)alloca(sizeof(wrd) * (mask+1)); 
	for (sum = 0, i=0 ; i <= mask; i++) {
		wrd psum = sum;

		sum += cnt[i];
		pos[i] = cnt[i] = psum;
	}
	
	/* time to create the cluster map */
	if ((cmap = BATnew(TYPE_void, TYPE_wrd, BATcount(b))) == NULL) {
		BBPunfix(*B);
		BBPunfix(psum->batCacheid);
		throw(MAL, "cluster.new", MAL_MALLOC_FAIL);
	}
	BATseqbase(cmap, b->H->seq);
	BATsetcount(cmap, BATcount(b));
	cmap->tsorted= FALSE;
	cmap->tdense= FALSE;
	m = (wrd*)Tloc(cmap, BUNfirst(cmap));

	bt = (@1*)Tloc(b, BUNfirst(b));
	be = bt + BATcount(b);
	for ( ; bt < be; ) {
		int h = (((int)(*bt++)) >> off) & mask;
		*m++ = pos[h]++;
	}

	BBPunfix(*B);
	BBPkeepref(*rpsum = psum->batCacheid);
	BBPkeepref(*rcmap = cmap->batCacheid);
	psum = BATsetaccess(psum, BAT_READ);
	cmap = BATsetaccess(cmap, BAT_READ);
	return MAL_SUCCEED;
}
@
@c
@:c_cls_new(bte)@
@:c_cls_new(chr)@
@:c_cls_new(sht)@
@:c_cls_new(int)@
@:c_cls_new(wrd)@
@:c_cls_new(lng)@
@:c_cls_new(flt)@
@:c_cls_new(dbl)@

@= c_cls_new2
str
CLS_create2_@1( bat *rpsum, bat *rcmap, bat *B, unsigned int *Bits, unsigned int *offset, bit *order)
{
	BAT *psum, *cmap, *b;
	int i, mask = 0, off = *offset;
	unsigned int bits = *Bits;
	@1 *bt, *be, *bs; 
	wrd *cnt, sum;

	if (off < 0)
		off = 0;
	if (bits >= sizeof(int)*8)
		throw(MAL, "cluster.new", TOO_MANY_BITS);

	if ((bits) != 0)
		bits--;
	mask = (1<<bits) - 1;
	if ((b = BATdescriptor(*B)) == NULL)
		throw(MAL, "cluster.new", INTERNAL_BAT_ACCESS);

	if ((psum = BATnew(TYPE_void, TYPE_wrd, mask+1)) == NULL) {
		BBPunfix(*B);
		throw(MAL, "cluster.new", MAL_MALLOC_FAIL);
	}
	BATseqbase(psum,0);
	BATsetcount(psum, mask+1);
	psum->tsorted= TRUE;
	psum->tdense= FALSE;
	cnt = (wrd*)Tloc(psum, BUNfirst(psum));
	for (i=0 ; i <= mask; i++)
		cnt[i] = 0;

	bs = bt = (@1*)Tloc(b, BUNfirst(b));
	be = bt + BATcount(b);

	/* Make a histogram and fill the cluster map */
	if (b->tsorted) {
		bte *mb, *m, h;

		/* time to create the cluster map */
		if ((cmap = BATnew((!*order)?TYPE_void:TYPE_oid, TYPE_bte, BATcount(b))) == NULL) {
			BBPunfix(*B);
			BBPunfix(psum->batCacheid);
			throw(MAL, "cluster.new", MAL_MALLOC_FAIL);
		}
		BATseqbase(cmap, b->H->seq);
		cmap->tdense = FALSE;
		mb = m = (bte*)Tloc(cmap, BUNfirst(cmap));

		if (!*order) {
			cmap->tsorted = FALSE;
			for ( ; bt < be; bt++) {
				int h = (((int)(*bt)) >> off) & mask;
			   	*m++ = h;
				cnt[h]++;
			}
		} else { /* try an optimized distribution, 1/Nth in each part */
			oid *o, base;
			lng sz = 0, parts = mask+1, psz = BATcount(b)/parts;
			@1 prev = *bt - 1;
			h = -1;

			cmap->hdense= FALSE;
			base = b->hseqbase;
			o = (oid*)Hloc(cmap, BUNfirst(cmap));
			for ( ; bt < be; bt++, sz++) {
				if (prev != *bt && sz >= (h+1)*psz && h < (parts-1)) {
					h++;
					assert(base + bt - bs >= 0);
					assert(base + bt - bs <= (ptrdiff_t) GDK_oid_max);
					*o++ = (oid) (base + bt - bs);
			   		*m++ = h;
				}
				cnt[h]++;
				prev = *bt;
			}
		}
		assert(m - mb >= 0);
		assert((lng) (m - mb) <= (lng) BUN_MAX);
		BATsetcount(cmap, (BUN) (m - mb));
	} else {
		bte *m;

		/* time to create the cluster map */
		if ((cmap = BATnew(TYPE_void, TYPE_bte, BATcount(b))) == NULL) {
			BBPunfix(*B);
			BBPunfix(psum->batCacheid);
			throw(MAL, "cluster.new", MAL_MALLOC_FAIL);
		}
		BATseqbase(cmap, b->H->seq);
		BATsetcount(cmap, BATcount(b));
		cmap->tsorted = FALSE;
		cmap->tdense = FALSE;
		m = (bte*)Tloc(cmap, BUNfirst(cmap));

		for ( ; bt < be; bt++) {
			int h = (((int)(*bt)) >> off) & mask;
			cnt[h]++;
			*m++ = h;
		}
	}

	/* convert histogram into prefix sum */
	for (sum = 0, i=0 ; i <= mask; i++) {
		wrd psum = sum;

		sum += cnt[i];
		cnt[i] = psum;
	}
	
	BBPunfix(*B);
	BBPkeepref(*rpsum = psum->batCacheid);
	BBPkeepref(*rcmap = cmap->batCacheid);
	psum = BATsetaccess(psum, BAT_READ);
	cmap = BATsetaccess(cmap, BAT_READ);
	return MAL_SUCCEED;
}
@
@c
@:c_cls_new2(bte)@
@:c_cls_new2(chr)@
@:c_cls_new2(sht)@
@:c_cls_new2(int)@
@:c_cls_new2(wrd)@
@:c_cls_new2(lng)@
@:c_cls_new2(flt)@
@:c_cls_new2(dbl)@

@= c_cls_map
static str  
CLS_map_@1(BAT *rb, BAT *cmap, BAT *b)
{
	wrd *m;
	@1 *r, *bt, *be;

	r = (@1*)Tloc(rb, BUNfirst(rb));
	m = (wrd*)Tloc(cmap, BUNfirst(cmap));
	bt = (@1*)Tloc(b, BUNfirst(b));
	be = bt + BATcount(b);
	for ( ; bt < be; ) 
		r[*m++] = *bt++;
	BBPunfix(cmap->batCacheid);
	BBPunfix(b->batCacheid);
	BBPkeepref(rb->batCacheid);
	rb = BATsetaccess(rb, BAT_READ);
	return MAL_SUCCEED;
}

@
@c
@:c_cls_map(bte)@
@:c_cls_map(sht)@
@:c_cls_map(int)@
@:c_cls_map(lng)@

@= c_cls_map2
static str  
CLS_map2_@1(BAT *rb, wrd *psum, BAT *cmap, BAT *b)
{
	bte *m;
	@1 *r, *bt, *be;

	r = (@1*)Tloc(rb, BUNfirst(rb));
	m = (bte*)Tloc(cmap, BUNfirst(cmap));
	bt = (@1*)Tloc(b, BUNfirst(b));
	be = bt + BATcount(b);
	for ( ; bt < be; ) 
		r[psum[*m++]++] = *bt++;
	GDKfree(psum);
	BBPunfix(cmap->batCacheid);
	BBPunfix(b->batCacheid);
	BBPkeepref(rb->batCacheid);
	rb = BATsetaccess(rb, BAT_READ);
	return MAL_SUCCEED;
}

@
@c
@:c_cls_map2(bte)@
@:c_cls_map2(sht)@
@:c_cls_map2(int)@
@:c_cls_map2(lng)@

str  
CLS_map(bat *RB, bat *CMAP, bat *B)
{
	BATiter bi;
	BAT *rb, *cmap = NULL, *b = NULL;
	BUN i = 0, bf, mf;
	wrd *m;

	if ((cmap = BATdescriptor(*CMAP)) == NULL ||
	    (b = BATdescriptor(*B)) == NULL) {
		if (cmap) 
			BBPunfix(*CMAP);
		throw(MAL, "cluster.map", INTERNAL_BAT_ACCESS);
	}
	if (BATcount(cmap) != BATcount(b) ||
	    cmap->H->seq != b->H->seq) {
		BBPunfix(*CMAP);
		BBPunfix(*B);
			throw(MAL, "cluster.map", OPERATION_FAILED " Counts of operands do not match");
	}

	if ((rb = BATnew(TYPE_void, b->ttype, BATcount(b))) == NULL) {
		BBPunfix(*CMAP);
		BBPunfix(*B);
		throw(MAL, "cluster.map", MAL_MALLOC_FAIL);
	} 
	BATseqbase(rb, b->H->seq);
	BATsetcount(rb, BATcount(b));
	rb->tsorted= FALSE;
	rb->tdense= FALSE;
	rb->H->nonil = b->H->nonil;
	rb->T->nonil = b->T->nonil;
	*RB = rb->batCacheid;

	switch(ATOMstorage(b->ttype)) {
	case TYPE_chr:
	case TYPE_bte:
			return CLS_map_bte(rb, cmap, b);
	case TYPE_sht:
			return CLS_map_sht(rb, cmap, b);
#if SIZEOF_WRD == SIZEOF_INT
	case TYPE_wrd:
#endif
#if SIZEOF_OID == SIZEOF_INT
	case TYPE_oid:
#endif
	case TYPE_flt:
	case TYPE_int:
			return CLS_map_int(rb, cmap, b);
#if SIZEOF_WRD == SIZEOF_LNG
	case TYPE_wrd:
#endif
#if SIZEOF_OID == SIZEOF_LNG
	case TYPE_oid:
#endif
	case TYPE_dbl:
	case TYPE_lng:
			return CLS_map_lng(rb, cmap, b);
	default:
		break;
	}
	bi = bat_iterator(b);
	bf = BUNfirst(b);
	mf = BUNfirst(cmap);
	m = (wrd*)Tloc(cmap, BUNfirst(cmap));
	if (b->T->varsized) {
		for (i = 0; i < BATcount(b); i++) {
			BUNinplace(rb, (BUN)m[mf+i], NULL, BUNtvar(bi, bf+i), 0);
		}
	} else {
		for (i = 0; i < BATcount(b); i++) {
			BUNinplace(rb, (BUN)m[mf+i], NULL, BUNtloc(bi, bf+i), 0);
		}
	}
	BBPunfix(*CMAP);
	BBPunfix(*B);
	rb = BATsetaccess(rb, BAT_READ);
	BBPkeepref(*RB = rb->batCacheid);
	return MAL_SUCCEED;
}

str  
CLS_map2(bat *RB, bat *PSUM, bat *CMAP, bat *B)
{
	BATiter bi;
	BAT *rb, *psum = NULL, *cmap = NULL, *b = NULL;
	BUN i = 0, bf, mf;
	bte *m; 
	wrd *psumcp;

	if ((psum = BATdescriptor(*PSUM)) == NULL ||
	    (cmap = BATdescriptor(*CMAP)) == NULL ||
	    (b = BATdescriptor(*B)) == NULL) {
		if (psum) 
			BBPunfix(*PSUM);
		if (cmap) 
			BBPunfix(*CMAP);
		throw(MAL, "cluster.map", INTERNAL_BAT_ACCESS);
	}
	if (cmap->tsorted) {
		/* input to cluster was sorted, ie nothing to do here 
		   then to return the input */
		BBPunfix(*PSUM);
		BBPunfix(*CMAP);
		BBPkeepref(*RB = b->batCacheid);
		return MAL_SUCCEED;
	}
	/* work around non aligned bats */
	if (BATcount(cmap) && 
	    cmap->H->seq != b->H->seq && b->H->type != TYPE_void) {
		BAT *ob = b;
		BAT *v = VIEWcombine(cmap);

		b = BATleftjoin(v, b, BATcount(b));
		BBPunfix(ob->batCacheid);
	}
	if (BATcount(cmap) != BATcount(b) ||
	   (BATcount(cmap) && cmap->H->seq != b->H->seq)) {
		BBPunfix(*PSUM);
		BBPunfix(*CMAP);
		BBPunfix(b->batCacheid);
		throw(MAL, "cluster.map", OPERATION_FAILED " Counts of operands do not match");
	}

	psumcp = (wrd*)GDKmalloc(BATcount(psum) * sizeof(wrd));
	if ( psumcp == NULL || (rb = BATnew(TYPE_void, ATOMtype(b->ttype), BATcount(b))) == NULL) {
		if (psumcp != NULL) {
			GDKfree(psumcp);
		}
		BBPunfix(*PSUM);
		BBPunfix(*CMAP);
		BBPunfix(b->batCacheid);
		throw(MAL, "cluster.map", MAL_MALLOC_FAIL);
	} 
	BATseqbase(rb, b->H->seq);
	BATsetcount(rb, BATcount(b));
	rb->tsorted= FALSE;
	rb->tdense= FALSE;
	rb->H->nonil = b->H->nonil;
	rb->T->nonil = b->T->nonil;
	*RB = rb->batCacheid;

	memcpy(psumcp, Tloc(psum,BUNfirst(psum)), BATcount(psum) * sizeof(wrd));
	BBPunfix(*PSUM);

	switch(ATOMstorage(b->ttype)) {
	case TYPE_chr:
	case TYPE_bte:
			return CLS_map2_bte(rb, psumcp, cmap, b);
	case TYPE_sht:
			return CLS_map2_sht(rb, psumcp, cmap, b);
#if SIZEOF_WRD == SIZEOF_INT
	case TYPE_wrd:
#endif
#if SIZEOF_OID == SIZEOF_INT
	case TYPE_oid:
#endif
	case TYPE_flt:
	case TYPE_int:
			return CLS_map2_int(rb, psumcp, cmap, b);
#if SIZEOF_WRD == SIZEOF_LNG
	case TYPE_wrd:
#endif
#if SIZEOF_OID == SIZEOF_LNG
	case TYPE_oid:
#endif
	case TYPE_dbl:
	case TYPE_lng:
			return CLS_map2_lng(rb, psumcp, cmap, b);
	default:
		break;
	}
	bi = bat_iterator(b);
	bf = BUNfirst(b);
	mf = BUNfirst(cmap);
	m = (bte*)Tloc(cmap, BUNfirst(cmap));
	if (b->T->varsized) {
		for (i = 0; i < BATcount(b); i++) {
			BUNinplace(rb, (BUN)(psumcp[m[mf+i]]), NULL, BUNtvar(bi, bf+i), 0);
			psumcp[m[mf+i]]++;
		}
	} else {
		for (i = 0; i < BATcount(b); i++) {
			BUNinplace(rb, (BUN)(psumcp[m[mf+i]]), NULL, BUNtloc(bi, bf+i), 0);
			psumcp[m[mf+i]]++;
		}
	}
	GDKfree(psumcp);
	BBPunfix(*CMAP);
	BBPunfix(b->batCacheid);
	rb = BATsetaccess(rb, BAT_READ);
	BBPkeepref(*RB = rb->batCacheid);
	return MAL_SUCCEED;
}
str  
CLS_split( Client cntxt, MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	int i;
	bat *bid = (bat *) getArgReference(stk, pci, pci->retc);
	bat *psum = (bat *) getArgReference(stk, pci, pci->retc+1);
	BAT *b, *pb;
	wrd *cnt, *end;
	BUN l = 0, h = l;

	(void)cntxt;
	(void)mb;

	b = BATdescriptor(*bid);
	if ( b == NULL)
		throw(MAL,"cluster.split", RUNTIME_OBJECT_MISSING);

	pb = BATdescriptor(*psum);
	if ( pb == NULL){
		BBPreleaseref(b->batCacheid);
		throw(MAL,"cluster.split", RUNTIME_OBJECT_MISSING);
	}
	cnt = (wrd*)Tloc(pb, BUNfirst(pb));
	end = cnt + BATcount(pb);

	for( i = 0; i<pci->retc && cnt < end; i++, cnt++) {
		bat *res = (bat*) getArgReference(stk, pci, i);
		BAT *v;

		assert((lng) *cnt <= (lng) BUN_MAX);
		assert(*cnt >= 0);
		l = (BUN) *cnt;
		if (cnt+1 < end) {
			assert(*(cnt+1) >= 0);
			assert((lng) *(cnt+1) <= (lng) BUN_MAX);
			h = (BUN) *(cnt+1);
		} else
			h = BATcount(b)+1;
		v = BATslice(b, l, h);
		BBPkeepref(*res = v->batCacheid); 
	} 
	BBPunfix(*bid);
	BBPunfix(*psum);
	return MAL_SUCCEED;
}
	
