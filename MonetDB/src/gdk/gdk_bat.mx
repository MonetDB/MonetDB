@' The contents of this file are subject to the MonetDB Public License
@' Version 1.1 (the "License"); you may not use this file except in
@' compliance with the License. You may obtain a copy of the License at
@' http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html
@'
@' Software distributed under the License is distributed on an "AS IS"
@' basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
@' License for the specific language governing rights and limitations
@' under the License.
@'
@' The Original Code is the MonetDB Database System.
@'
@' The Initial Developer of the Original Code is CWI.
@' Portions created by CWI are Copyright (C) 1997-2007 CWI.
@' All Rights Reserved.

@f gdk_bat
@a M. L. Kersten, P. Boncz
@* BAT Module
In this Chapter we describe the BAT implementation in more detail.
The routines mentioned are primarily meant to simplify the library
implementation.

@+ BAT Construction
BATs are implemented in several blocks of memory, prepared for disk
storage and easy shipment over a network.

The BAT starts with a descriptor, which indicates the required BAT
library version and the BAT administration details.  In particular, it
describes the binary relationship maintained and the location of
fields required for storage.

The general layout of the BAT in this implementation is as follows.
Each BAT comes with a heap for the loc-size buns and, optionally,
with heaps to manage the variable-sized data items of both
dimensions.  The buns are assumed to be stored as loc-size
objects.  This is essentially an array of structs to store the
associations.  The size is determined at BAT creation time using an
upper bound on the number of elements to be accommodated.  In case of
overflow, its storage space is extended automatically.

The capacity of a BAT places an upper limit on the number of BUNs to
be stored initially. The actual space set aside may be quite large.
Moreover, the size is aligned to int boundaries to speedup access and
avoid some machine limitations.

Initialization of the variable parts rely on type specific routines
called atomHeap.
@{ 
@h
#ifndef _GDK_BAT_H_
#define _GDK_BAT_H_

#include "gdk.h"

gdk_export void BATinit_idents(BAT *bn);
gdk_export ssize_t void_replace_bat(BAT *b, BAT *u, bit force);
gdk_export int void_inplace(BAT *b, oid id, ptr val, bit force);

extern int default_ident(char *s);
extern oid MAXoid(BAT *i);

#endif /* _GDK_BAT_H_ */
@c
#include "monetdb_config.h"
#include "gdk.h"

#ifdef ALIGN
#undef ALIGN
#endif
#define ALIGN(n,b)	((b)?(b)*(1+(((n)-1)/(b))):n)

#define ATOMneedheap(tpe) (BATatoms[tpe].atomHeap != NULL)

char *BATstring_h = "h";
char *BATstring_t = "t";

int
default_ident(char *s)
{
	return ((s) == BATstring_h || (s) == BATstring_t);
}

void
BATinit_idents(BAT *bn)
{
	bn->hident = (char *) BATstring_h;
	bn->tident = (char *) BATstring_t;
}

BAT *
BATcreatedesc(int ht, int tt, int heapnames)
{
	BAT *bn;

@-
Alloc space for the BAT and its dependent records.
@c
	BATstore *bs = (BATstore *) GDKzalloc(sizeof(BATstore));

@-
assert needed in the kernel to get symbol eprintf resolved.
Else modules using assert fail to load.
@c
	assert(ht >= 0 && tt >= 0);
	bn = &bs->B;
	bn->H = &bs->H;
	bn->T = &bs->T;
	bn->P = &bs->P;
	bn->U = &bs->U;

@-
Fill in basic column info
@c
	bn->htype = ht;
	bn->ttype = tt;
	bn->hkey = FALSE;
	bn->tkey = FALSE;
	bn->hsorted = ((bit) ATOMlinear(ht) ? GDK_SORTED : FALSE);
	bn->tsorted = ((bit) ATOMlinear(tt) ? GDK_SORTED : FALSE);
	bn->GDKversion = GDKLIBRARY;

	bn->batBuns = &bn->U->buns;
	bn->hident = (char *) BATstring_h;
	bn->tident = (char *) BATstring_t;
	bn->halign = OIDnew(2);
	bn->talign = bn->halign + 1;
	bn->hseqbase = (ht == TYPE_void) ? oid_nil : 0;
	bn->tseqbase = (tt == TYPE_void) ? oid_nil : 0;
	bn->batPersistence = TRANSIENT;
	bn->H->props = bn->T->props = NULL;

	bn->void_tid = -1;
	bn->void_cnt = 0;
	bn->void_seq1 = oid_nil;
	bn->void_seq2 = oid_nil;
@-
add to BBP
@c
	BBPinsert(bn);
@-
fill in heap names, so HEAPallocs can resort to disk for very large writes.
@c
	bn->batBuns->filename = NULL;
	bn->batMapbuns = STORE_UNSET;
	if (heapnames) {
		str nme = BBP_physical(bn->batCacheid);

		bn->batBuns->filename = (str) GDKmalloc(strlen(nme) + 12);
		GDKfilepath(bn->batBuns->filename, NULL, nme, "buns");

		if (ATOMneedheap(ht)) {
			bn->hheap = (Heap *) GDKzalloc(sizeof(Heap));
			bn->hheap->filename = (str) GDKmalloc(strlen(nme) + 12);
			GDKfilepath(bn->hheap->filename, NULL, nme, "hheap");
			bn->batMaphheap = STORE_UNSET;
		}

		if (ATOMneedheap(tt)) {
			bn->theap = (Heap *) GDKzalloc(sizeof(Heap));
			bn->theap->filename = (str) GDKmalloc(strlen(nme) + 12);
			GDKfilepath(bn->theap->filename, NULL, nme, "theap");
			bn->batMaptheap = STORE_UNSET;
		}
	}
	bn->batDirty = TRUE;
	return bn;
}

int
BATelmshift(BAT *b)
{
	int sh, i = BUNsize(b) >> 1;

	for (sh = 0; i != 0; sh++) {
		i >>= 1;
	}
	if (BUNsize(b) != ((size_t) 1 << sh)) {
		return -1;
	}
	return sh;
}


void
BATsetdims(BAT *b)
{
	if (ATOMalign(b->htype) >= ATOMalign(b->ttype)) {
		b->tloc = ALIGN(ATOMsize(b->htype), ATOMalign(b->htype));
		b->hloc = 0;
		b->dims.bunwidth = b->tloc + ATOMsize(b->ttype);
		if (b->ttype == TYPE_void)
			b->tloc = 0;
	} else {
		b->hloc = ALIGN(ATOMsize(b->ttype), ATOMalign(b->htype));
		b->tloc = 0;
		b->dims.bunwidth = b->hloc + ATOMsize(b->htype);
		if (b->htype == TYPE_void)
			b->hloc = 0;
	}
	if (b->dims.bunwidth == 0)
		b->dims.bunwidth = 1;
	b->dims.bunwidth = ALIGN(b->dims.bunwidth, ATOMalign(b->htype));
	b->dims.bunwidth = ALIGN(b->dims.bunwidth, ATOMalign(b->ttype));
	b->dims.bunshift = BATelmshift(b);
	b->hvarsized = BATatoms[b->htype].varsized;
	b->tvarsized = BATatoms[b->ttype].varsized;
}

@- BAT allocation 
Allocate BUN heap and variable-size atomheaps (see e.g. strHeap).
We now initialize new BATs with their heapname such that the modified
HEAPalloc/HEAPextend primitives can possibly use memory mapped files
as temporary heap storage.

In case of huge bats, we want HEAPalloc to write a file to disk, and memory map
it. To make this possible, we must provide it with filenames.
@c
BAT *
BATnewstorage(int ht, int tt, size_t cap)
{
	BAT *bn, *recycled;
	int vv = (!ht && !tt);

	bn = recycled = BBPrecycle(ht, tt, cap);

	if (!bn)
		bn = BATcreatedesc(ht, tt, (ht || tt));
	if (bn == NULL)
		return NULL;

	if (!recycled) {
		BATsetdims(bn);

		/* alloc the main heaps */
		if ((ht || tt) && HEAPalloc(bn->batBuns, cap, bn->dims.bunwidth) < 0) {
			return NULL;
		}

		if (ATOMheap(ht, bn->hheap, cap) < 0) {
			HEAPfree(bn->batBuns);
			GDKfree(bn->hheap);
			if (bn->theap)
				GDKfree(bn->theap);
			return NULL;
		}
		if (ATOMheap(tt, bn->theap, cap) < 0) {
			HEAPfree(bn->batBuns);
			if (bn->hheap) {
				HEAPfree(bn->hheap);
				GDKfree(bn->hheap);
			}
			GDKfree(bn->theap);
			return NULL;
		}
		DELTAinit(bn);
		BBPcacheit(bn);
	}
	if (vv) {
		bn->batBuns->base = (char *) 1;
		DELTAinit(bn);
	}
	return bn;
}

BAT *
BATnew(int ht, int tt, size_t cap)
{
	ERRORcheck((ht < 0) || (ht > GDKatomcnt), "BATnew:ht error\n");
	ERRORcheck((tt < 0) || (tt > GDKatomcnt), "BATnew:tt error\n");

	/* determine the minimum size. BATTINY bats will be cached */
	cap = MAX(BATTINY, cap);
	if (ht == TYPE_void && tt == TYPE_void)
		cap = 1;

	return BATnewstorage(ht, tt, cap);
}

@-
The routine BATclone creates a bat with the same types as b.
@c
BAT *
BATclone(BAT *b, size_t cap)
{
	BAT *c = BATnew(b->htype, b->ttype, cap);

	if (c->htype == TYPE_void && b->hseqbase != oid_nil)
		BATseqbase(c, b->hseqbase);
	if (c->ttype == TYPE_void && b->tseqbase != oid_nil)
		BATseqbase(BATmirror(c), b->tseqbase);
	return c;
}

@- 
If the BAT runs out of storage for BUNS it will reallocate space.
For memory mapped BATs we simple extend the administration after
having an assurance that the BAT still can be safely stored away.

@-
Most BAT operations use a BAT to assemble the result. In several cases
it is rather difficult to give a precise estimate of the required space.
The routine @%BATguess@ is used internally for this purpose.
It balances the cost of small BATs with their probability of occurrence.
Small results BATs are more likely then 100M BATs.

Likewise, the routine @%BATgrows@ provides a heuristic to enlarge the space.
@c
size_t
BATguess(BAT *b)
{
	size_t newcap;

	BATcheck(b, "BATguess");
	newcap = BATcount(b);
	if (newcap < 10 * BATTINY)
		return newcap;
	if (newcap < 50 * BATTINY)
		return newcap / 2;
	if (newcap < 100 * BATTINY)
		return newcap / 10;
	return newcap / 100;
}

size_t
BATgrows(BAT *b)
{
	size_t oldcap, newcap;

	BATcheck(b, "BATgrows");

	newcap = oldcap = BATcapacity(b);
	if (newcap < BATTINY)
		newcap = 2 * BATTINY;
	else if (newcap < 10 * BATTINY)
		newcap = 4 * newcap;
	else if (newcap < 50 * BATTINY)
		newcap = 2 * newcap;
	else
		newcap = (size_t) ((double) newcap * BATMARGIN);
	if (newcap == oldcap)
		newcap += 10;

	/* if we can extend in reserved space, do not miss the opportunity */
	if (b->batBuns->size + BUNsize(b) <= b->batBuns->maxsize) {
		size_t rescap = oldcap + (b->batBuns->maxsize - b->batBuns->size) / BUNsize(b);

		newcap = MIN(newcap, rescap);
	}
	return newcap;
}

@-
The routine should ensure that the BAT keeps its location
in the BAT buffer.

Overflow in the other heaps are dealt with in the atom  routines.
Here we merely copy their references into the new administration space.

@c
BAT *
BATextend(BAT *b, size_t newcap)
{
	size_t heap_size;
	int ret;

	assert(b->htype || b->ttype);
	BATcheck(b, "BATextend");
@- 
The main issue is to properly predict the new BAT size.
storage overflow. The assumption taken is that capacity
overflow is rare. It is changed only when the position
of the next available BUN surpasses the free area marker.
Be aware that the newcap should be greater than the old
value, otherwise you may easily corrupt the administration of
malloc.
@c
	if (newcap <= BATbuncount(b)) {
		return b;
	}
	heap_size = BUNsize(b) * newcap;

	DELTAsave(b);
	ret = HEAPextend(b->batBuns, heap_size);
	DELTAload(b);
	if (ret < 0)
		return NULL;

	HASHdestroy(b);

	return b;
}

@} 


@+ BAT destruction
@-
BATclear quickly removes all elements from a BAT. It must respect the
transaction rules; so stable elements must be moved to the "deleted" 
section of the BAT (they cannot be fully deleted yet). For the elements
that really disappear, we must free heapspace and unfix the atoms if
they have fix/unfix handles. As an optimization, in the case of no stable
elements, we quickly empty the heaps by copying a standard small empty image 
over them.
@c
@{
BAT *
BATclear(BAT *b)
{	
	int bs;
	BUN p, q;
	int voidbat;
	BAT *bm;

	BATcheck(b, "BATclear");

	bs = BUNsize(b);
	voidbat = 0;
	bm = BATmirror(b);

	if (BAThdense(b) && b->htype == TYPE_void) {
		voidbat = 1;
	}
	if (BATtdense(b) && b->ttype == TYPE_void) {
		voidbat = 1;
	}

	/* small BAT: delete all elements by hand */
	if (!voidbat && BATcount(b) < 20) {
		BATloopDEL(b, p, q, bs) {
			p = BUNdelete(b, p, FALSE);
		}
		return b;
	}

	/* kill all search accelerators */
	if (b->hhash) {
		HASHremove(b);
	}
	if (b->thash) {
		HASHremove(bm);
	}

	/* we must dispose of all inserted atoms */
	if (b->batDeleted == b->batInserted && 
	    BATatoms[b->htype].atomDel == NULL && 
	    BATatoms[b->ttype].atomDel == NULL) {
		Heap hh, th;

		/* no stable elements: we do a quick heap clean */
		/* need to clean heap which keep data even though the
		   BUNs got removed. This means reinitialize when
		   free > 0
		*/
		size_t cap = 0;

		hh.filename = th.filename = NULL;
		if (b->hheap && b->hheap->free > 0) {
			if (ATOMheap(b->htype, &hh, cap) < 0)
				return NULL;
		}
		if (b->theap && b->theap->free > 0 && ATOMheap(b->ttype, &th, cap) < 0) {
			if (b->hheap && b->hheap->free > 0)
				HEAPfree(&hh);
			return NULL;
		}
		if (b->hheap && b->hheap->free > 0) {
			HEAPfree(b->hheap);
			*b->hheap = hh;
		}
		if (b->theap && b->theap->free > 0) {
			HEAPfree(b->theap);
			*b->theap = th;
		}
	} else {
		/* do heap-delete of all inserted atoms */
		void (*hatmdel)(Heap*,var_t*) = BATatoms[b->htype].atomDel;
		void (*tatmdel)(Heap*,var_t*) = BATatoms[b->ttype].atomDel;

		if (hatmdel || tatmdel) {
			for(p = b->batInserted, q = BUNlast(b); p < q; p += bs) {
				if (hatmdel)
					(*hatmdel)(b->hheap, (var_t*) BUNhloc(b,p));
				if (tatmdel)
					(*tatmdel)(b->theap, (var_t*) BUNtloc(b,p));
			}
		}
	}

	b->batFirst = b->batInserted;
	b->batBuns->free = b->batInserted - b->batBuns->base;
	BATsetcount(b,0);
	b->batDirty = TRUE;
	return b; 
}

/* free a cached BAT; leave the bat descriptor cached */
int
BATfree(BAT *b)
{
	BATcheck(b, "BATfree");

	/* deallocate all memory for a bat */
	if (b->batCacheid < 0)
		b = BBP_cache(-(b->batCacheid));
	if (b->hident && !default_ident(b->hident)) 
		GDKfree(b->hident);
	b->hident = BATstring_h;
	if (b->tident && !default_ident(b->tident)) 
		GDKfree(b->tident);
	b->tident = BATstring_t;
	if (b->H->props)
		PROPdestroy(b->H->props);
	b->H->props = NULL;
	if (b->T->props)
		PROPdestroy(b->T->props);
	b->T->props = NULL;
	HASHdestroy(b);
	DELTAsave(b);	       /* convert to disk format */
	if (b->htype != b->ttype || b->htype != TYPE_void)
		HEAPfree(b->batBuns);
	if (b->hheap) 
		HEAPfree(b->hheap);
	if (b->theap) 
		HEAPfree(b->theap);

	b = BBP_cache(-b->batCacheid);
	if (b) {
		BBP_cache(b->batCacheid) = NULL;
		GDKfree(b);
	}
	return 0;
}

/* free a cached BAT descriptor */
void
BATdestroy( BAT *b )
{
	if (b->hident && !default_ident(b->hident)) 
		GDKfree(b->hident);
	b->hident = BATstring_h;
	if (b->tident && !default_ident(b->tident)) 
		GDKfree(b->tident);
	b->tident = BATstring_t;
	if (b->hheap)
		GDKfree(b->hheap);
	if (b->theap)
		GDKfree(b->theap);
	if (b->H->props)
		PROPdestroy(b->H->props);
	if (b->T->props)
		PROPdestroy(b->T->props);
	GDKfree(b);
}

@}
@+ BAT copying

BAT copying is an often used operation. So it deserves attention.
When making a copy of a BAT, the following aspects are of importance:
@itemize 
@item the requested head and tail types. The purpose of the copy may be 
to slightly change these types (e.g. void <-> oid). We may also remap between 
types as long as they share the same ATOMstorage(type), i.e. the types
have the same physical implementation. We may even want to allow 'dirty'
trick such as viewing a flt-column suddenly as int.

To allow such changes, the desired head- and tail-types are a parameter of BATcopy.

@item access mode. If we want a read-only copy of a read-only BAT, a
VIEW may do (in this case, the user may be after just an independent BAT 
header and id). This is indicated by the parameter (writeable = FALSE).  

In other cases, we really want an independent physical copy (writeable = TRUE).
Note that in the MIL interpreter (as opposed to the C/C++ GDK API), the result 
of MIL-copy() will by default be BAT_READ, the default mode for all new BATs. 
However, changing the mode to BAT_WRITE will be a zero-cost operation if the 
BAT was copied with (writeable = TRUE), such as done by MIL-copy().
@end itemize
In GDK, the result is a BAT that is BAT_WRITE iff (writeable == TRUE).

NEW: there is now a special parameter setting (writeable == 2), which does create
an independent BAT (not a view that shares the same heaps), however tries 
to share VM heap resources using copy-on-write maps. Note that the result of
this is a read-only BAT (BAT_READ). The copy-on-write VM tricks can be used, 
however, to isolate these copies from changes the in parent.

In these cases the copy becomes a logical view on the original, which ensures
that the original cannot be modified or destroyed (which could affect the shared 
heaps).

This new mode is used by the XQuery isolation mechanism and is available in MIL 
as rcopy(). 
@{
@c
static int
heapcopy(Heap *dst, Heap *src, int *remap)
{
	if (*remap && src->storage == STORE_MMAP) {
		/* use copy-on-write mmap for isolatable copy */
		*dst = *src;
		dst->base = (char *) -1;
		dst->filename = GDKstrdup(src->filename);
		if (dst->filename) {
			char path[PATHLENGTH];

			GDKfilepath(path, BATDIR, dst->filename, NULL);
			dst->base = GDKmmap(path, MMAP_READ | MMAP_SEQUENTIAL | MMAP_COPY, 0, dst->maxsize);
			if (dst->base != (char *) -1) {
				dst->copied = 1;
				dst->storage = STORE_PRIV;
				return 0;
			}
			GDKfree(dst->filename);
			dst->filename = NULL;
		}
	}
	*remap = 0;
	return HEAPcopy(dst, src);
}

static void
heapfree(Heap *src, Heap *dst)
{
	if (dst->filename == NULL) {
		dst->filename = src->filename;
		src->filename = NULL;
	}
	HEAPfree(src);
	*src = *dst;
}

static int
wrongtype(int t1, int t2)
{
	/* check if types are compatible. be extremely forgiving */
	if (t1) {
		t1 = ATOMtype(ATOMstorage(t1));
		t2 = ATOMtype(ATOMstorage(t2));
		if (t1 != t2) {
			if (ATOMvarsized(t1) ||
			    ATOMvarsized(t2) ||
			    ATOMsize(t1) != ATOMsize(t2) ||
			    ATOMalign(t1) != ATOMalign(t2) ||
			    BATatoms[t1].atomFix ||
			    BATatoms[t2].atomFix)
				return TRUE;
		}
	}
	return FALSE;
}

@-
There are four main implementation cases: 
(1) we are allowed to return a view (zero effort),
(2) the result is void,void (zero effort),
(3) we can copy the heaps (memcopy, or even VM page sharing)
(4) we must insert BUN-by-BUN into the result (fallback) 
The latter case is still optimized for the case that the result 
is bat[void,T] for a simple fixed-size type T. In that case we 
do inline array[T] inserts.
@c
BAT *
BATcopy(BAT *b, int ht, int tt, int writeable)
{
	ssize_t bunstocopy = -1;
	size_t cnt;
	BAT *bn = NULL;

	BATcheck(b, "BATcopy");
	cnt = BATcount(b);

	/* maybe a bit ugly to change the requested bat types?? */
	if (b->htype == TYPE_void && !writeable)
		ht = TYPE_void;
	if (b->ttype == TYPE_void && !writeable)
		tt = TYPE_void;

	if (ht != b->htype && wrongtype(ht, b->htype)) {
		GDKerror("BATcopy: wrong head-type requested\n");
		return NULL;
	}
	if (tt != b->ttype && wrongtype(tt, b->ttype)) {
		GDKerror("BATcopy: wrong tail-type requested\n");
		return NULL;
	}

	/* first try case (1); create a view, possibly with different atom-types */
	if (BATrestricted(b) == BAT_READ && !writeable) {
		bn = VIEWcreate(b);
		if (bn == NULL)
			return NULL;
		if (ht != bn->htype) {
			BAT *bm = BATmirror(bn);
			bn->htype = bm->ttype = ht;
			bn->hvarsized = bm->tvarsized = ATOMvarsized(ht);
			bn->hseqbase = bm->tseqbase = b->hseqbase;
		}
		if (tt != bn->ttype) {
			BAT *bm = BATmirror(bn);
			bn->ttype = bm->htype = tt;
			bn->tvarsized = bm->hvarsized = ATOMvarsized(tt);
			bn->tseqbase = bm->hseqbase = b->tseqbase;
		}
	} else {
		/* check whether we need case (4); BUN-by-BUN copy (by setting bunstocopy >=0) */
		if (ATOMsize(ht) != ATOMsize(b->htype) ||
		    ATOMsize(tt) != ATOMsize(b->ttype)) {	/* oops, void materialization */
			bunstocopy = cnt;
		} else if (BATatoms[ht].atomFix || BATatoms[tt].atomFix) { /* oops, we need to fix/unfix atoms */
			bunstocopy = cnt;
		} else if (VIEWparent(b)) {
			/* extra checks needed for views */
			BAT *p = BBP_cache(VIEWparent(b));

			if (b->hloc == b->tloc ||	/* oops, mirror view! */
			    ATOMsize(ht) != ATOMsize(p->htype) ||
			    ATOMsize(tt) != ATOMsize(p->ttype) || /* oops, parent BUN layout was different */
			    (ht == TYPE_void) != (p->htype == TYPE_void) ||
			    (tt == TYPE_void) != (b->ttype == TYPE_void) || /* oops, BUN layout changes */
			    BATcount(p) > cnt + cnt) {	/* reduced slice view: do not copy too much garbage */
				bunstocopy = cnt;
			}
		}

		bn = BATnew(ht, tt, MAX(1, bunstocopy));
		if (bn == NULL)
			return NULL;

		if (ht == TYPE_void && tt == TYPE_void) {
			/* case (2): a void,void result => nothing to copy! */
			bn->batBuns->free = cnt * BUNsize(bn);
		} else if (bunstocopy < 0) {
			/* case (3): just copy the heaps; if possible with copy-on-write VM support */
			int remap = (writeable == 2) && (BATrestricted(b) != BAT_WRITE);
			int hremap = remap && (ATOMstorage(ht) == TYPE_str) && !GDK_ELIMDOUBLES(b->hheap);
			int tremap = remap && (ATOMstorage(tt) == TYPE_str) && !GDK_ELIMDOUBLES(b->theap);
			Heap hp, hhp, thp;
			memset(&hp, 0, sizeof(Heap));
			memset(&hhp, 0, sizeof(Heap));
			memset(&thp, 0, sizeof(Heap));

			if (heapcopy(&hp, b->batBuns, &remap) < 0 ||
			    (bn->hheap && heapcopy(&hhp, b->hheap, &hremap) < 0) ||
			    (bn->theap && heapcopy(&thp, b->theap, &tremap) < 0)) {
				if (hhp.base)
					HEAPfree(&hhp);
				if (hp.base)
					HEAPfree(&hp);
				BBPreclaim(bn);
				return NULL;
			}

			/* succeeded; replace dummy small heaps by the real ones */
			DELTAsave(bn);
			heapfree(bn->batBuns, &hp);
			if (bn->hheap)
				heapfree(bn->hheap, &hhp);
			if (bn->theap)
				heapfree(bn->theap, &thp);
			DELTAload(bn);

			/* hloc/tloc must be as in src BUN heap */
			if (bn->hloc != b->hloc || bn->tloc != b->tloc) {
				BAT *bm = BATmirror(bn);
				bn->hloc = bm->tloc = b->hloc;
				bn->tloc = bm->hloc = b->tloc;
			}
			/* first/inserted must point equally far into the heap as in the source */
			bn->batFirst = Bunbase(bn) + (b->batFirst - Bunbase(b));
			bn->batInserted = Bunbase(bn) + (b->batInserted - Bunbase(b));

			/* if we have copy-on-write heaps, bn is a logical view on b to ensure the heaps stay stable */
			if (remap || hremap || tremap) {
				bn->batLview = TRUE;
				BBPshare(bn->batParentid = ABS(b->batCacheid));
			}
		} else if (BATatoms[ht].atomFix || BATatoms[tt].atomFix || (ht && tt) || ATOMstorage(MAX(ht, tt)) >= TYPE_str) {
			/* case (4): one-by-one BUN insert (really slow) */
			BUN p, q, r = BUNfirst(bn);
			int xx, yy = BUNsize(bn);

			BATloopFast(b, p, q, xx) {
				ptr h = BUNhead(b, p);
				ptr t = BUNtail(b, p);

				bunfastins_nocheck(bn, r, h, t, yy);
				r += yy;
			}
		} else if ((ht && b->htype == TYPE_void) || (tt && b->ttype == TYPE_void)) {
			/* case (4): optimized for unary void materialization */
			oid cur = ht ? b->hseqbase : b->tseqbase, *dst = (oid *) BUNfirst(bn);
			oid inc = (cur != oid_nil);
			bn->batBuns->free = bunstocopy * sizeof(oid);
			while (bunstocopy--) {
				*dst++ = cur;
				cur += inc;
			}
		} else {
			/* case (4): optimized for simple array copy */
			int tpe = ATOMstorage(ht | tt);
			BUN cur = ht ? BUNhloc(b, BUNfirst(b)) : BUNtloc(b, BUNfirst(b));
			int inc = BUNsize(b) / ATOMsize(tpe);

			bn->batBuns->free = bunstocopy * ATOMsize(tpe);
			if (tpe == TYPE_chr || tpe == TYPE_bte) {
				bte *src = (bte *) cur, *dst = (bte *) BUNfirst(bn);

				while (bunstocopy--) {
					*dst++ = *src;
					src += inc;
				}
			} else if (tpe == TYPE_sht) {
				sht *src = (sht *) cur, *dst = (sht *) BUNfirst(bn);

				while (bunstocopy--) {
					*dst++ = *src;
					src += inc;
				}
			} else if ((tpe == TYPE_int) || (tpe == TYPE_flt)) {
				int *src = (int *) cur, *dst = (int *) BUNfirst(bn);

				while (bunstocopy--) {
					*dst++ = *src;
					src += inc;
				}
			} else {
				lng *src = (lng *) cur, *dst = (lng *) BUNfirst(bn);

				while (bunstocopy--) {
					*dst++ = *src;
					src += inc;
				}
			}
		}
		/* copy all properties (size+other) from the source bat */
		BATsetcount(bn, cnt);
	}
	/* set properties (note that types may have changed in the copy) */
	if (ATOMtype(ht) == ATOMtype(b->htype)) {
		ALIGNsetH(bn, b);
	} else if (ATOMtype(ATOMstorage(ht)) == ATOMtype(ATOMstorage(b->htype))) {
		bn->hsorted = b->hsorted;
		bn->hdense = b->hdense;
		if (b->hkey)
			BATkey(bn, TRUE);
	} else {
		bn->hsorted = bn->hdense = 0;
	}
	if (ATOMtype(tt) == ATOMtype(b->ttype)) {
		ALIGNsetT(bn, b);
	} else if (ATOMtype(ATOMstorage(tt)) == ATOMtype(ATOMstorage(b->ttype))) {
		bn->tsorted = b->tsorted;
		bn->tdense = b->tdense;
		if (b->tkey)
			BATkey(BATmirror(bn), TRUE);
	} else {
		bn->tsorted = bn->tdense = 0;
	}
	if (writeable != TRUE)
		bn->batRestricted = BAT_READ;
	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;
}

@+ BAT Unit Manipulation
Binary units (tuples) are the elements stored in BATs. We
discuss here BUN insert, replace and delete.
Below are help macro's that actually move the BUNs
around and adapt search accelerator structures.
 
@h
#define hashins(h,i,v,n) HASHins_any(h,i,v)
#define hashdel(h,i,v,n) HASHdel(h,i,v,n)

@= bun_move
	if (bs == 8) {
		* (lng *) @2 = * (lng *) @1;
	} else if (bs == 4) {
		* (int *) @2 = * (int *) @1;
	} else {
		str _dst = (str) @2, _src = (str) @1, _end = _src + bs;

		while (_src < _end)
			*_dst++ = *_src++;
	}
@= hacc_update
{
	if (b->hhash) {
		hash@1(b->hhash, @4, BUN@2(b, @3), @3 < last); 
	}
} 
@= tacc_update
{
	if (b->thash) {
		hash@1(b->thash, (hash_t)@4, BUN@2(b, @3), @3 < last); 
	}
}
@= acc_move
{
	char *tmp = alloca(bs);

	if (b->hhash) {
		HASHmove(b->hhash, (hash_t) @3, (hash_t) @4, BUNhead(b, @1), @1 < last); 
	}
	if (b->thash) {
		HASHmove(b->thash, (hash_t) @3, (hash_t) @4, BUNtail(b, @1), @1 < last); 
	}

	/* move first to tmp); */
	@:bun_move(@1,tmp)@
	/* move delete to first */
	@:bun_move(@2,@1)@
	/* move first to deleted */
	@:bun_move(tmp,@2)@

}

@- BUN Insertion
Insertion into a BAT is split into two operations @%BUNins@ and
@%BUNfastins@.  The former should be used when integrity enforcement
and index maintenance is required.  The latter is used to quickly
insert the BUN into the result without any additional check.
For those cases where speed is required, the type decoding can
be circumvented by asking for a BUN using @%BATbunalloc@ and fill
it directly. See gdk.mx for the bunfastins(b,h,t) macros.
@c
BAT *
BUNfastins(BAT *b, ptr h, ptr t)
{
	bunfastins(b, h, t);
	if (!b->batDirty)
		b->batDirty = TRUE;
	return b;
      bunins_failed:
	return NULL;
}


@- 
The interface routine should also perform integrity checks.
Null values should have been obtained at a higher level.
This code assumes that new elements are appended to the BUN list.
@c
@= void_insertbun
	if ((@1) && b->@1type == TYPE_void && b->@1seqbase != oid_nil) {
		if (* (oid *) @1 != oid_nil) {
			if (BATcount(b) == 0) {
				b->@1seqbase = * (oid *) @1;
				bm->@2seqbase = * (oid *) @1;
			} else if (* (oid *) @1 != (b->@1seqbase + BUNgetpos(b, BUNlast(b)))) {
		 		b = BATmaterialize@1(b, (size_t) ((double) BATcount(b) * 1.2));
				countonly = 0;
				if (b == NULL)
					return b;
			}
		} else { 
		 	b = BATmaterialize@1(b, (size_t) ((double) BATcount(b) * 1.2));
			countonly = 0;
			if (b == NULL)
				return b;
		}
	}
@c
BAT *
BUNins(BAT *b, ptr h, ptr t, bit force)
{
	int countonly = (b->htype == TYPE_void && b->ttype == TYPE_void);
	BUN p;
	BAT *bm;

	BATcheck(b, "BUNins");
	BATcheck(h, "BUNins: head value is nil\n");
	bm = BBP_cache(-b->batCacheid);

	@:void_insertbun(h,t)@
	@:void_insertbun(t,h)@

	if (b->batSet && BUNlocate(b, h, t)) {
		return b;
	}
	if ((b->hkey & BOUND2BTRUE) && (p = BUNfnd(b, h))) {
		if (BUNinplace(b, p, h, t, 0) == NULL)
			return NULL;
	} else if ((b->tkey & BOUND2BTRUE) && (p = BUNfnd(bm, t))) {
		if (BUNinplace(bm, p, t, h, 0) == NULL)
			return NULL;
	} else {
		size_t i;
		size_t hsize = 0, tsize = 0;

		if (b->hhash && b->hheap)
			hsize = b->hheap->size;
		if (b->thash && b->theap)
			tsize = b->theap->size;

		ALIGNins(b, "BUNins", force);
		b->batDirty = 1;
		p = BUNlast(b);	/* insert at end */
		i = BUNindex(b, p);
		if (p > b->batFirst) {
			unsigned int bunsize = BUNsize(b);

			if (b->htype != TYPE_void) {
				int cmp = 0;

				if (b->hsorted & 1) {
					ptr prv = BUNhead(b, p - bunsize);

					cmp = atom_CMP(h, prv, b->htype);
					if (cmp < 0) {
						b->H->nosorted = i;
						b->hsorted = FALSE;
					} else if (cmp && b->hdense && *(oid *) h != 1 + *(oid *) prv) {
						b->H->nodense = i;
						b->hdense = FALSE;
					}
					/* as nil < any, we only need to 
					 * check on second BUNins if the 
					 * first was nil */
					if (i == 2 && cmp > 0) {	/* StM: i==1 ? */
						int ht = b->htype;

						cmp = atom_CMP(prv, ATOMnilptr(ht), ht);
						if (cmp == 0) {
							b->H->nosorted = 1;
							b->hsorted = FALSE;
						}
					}
				} else if (b->hsorted == (bit) GDK_SORTED_REV) {
					ptr prv = BUNhead(b, p - bunsize);

					cmp = atom_CMP(h, prv, b->htype);
					if (cmp > 0) {
						b->H->nosorted_rev = i;
						b->hsorted = FALSE;
					}
				}
				if (b->hkey == TRUE && cmp <= 0) {
					b->H->nokey[0] = i - 1;
					b->H->nokey[1] = i;
					b->hkey = bm->tkey = b->hdense = FALSE;
				}
			}
			if (b->ttype != TYPE_void) {
				int cmp = 0;

				if (b->tsorted & 1) {
					ptr prv = BUNtail(b, p - bunsize);

					cmp = atom_CMP(t, prv, b->ttype);
					if (cmp < 0) {
						b->T->nosorted = i;
						b->tsorted = FALSE;
					} else if (cmp && b->tdense && *(oid *) t != 1 + *(oid *) prv) {
						b->T->nodense = i;
						b->tdense = FALSE;
					}
					/* as nil < any, we only need to 
					 * check on second BUNins if the 
					 * first was nil */
					if (i == 2 && cmp > 0) {	/* StM: i==1 ? */
						int tt = b->ttype;

						cmp = atom_CMP(prv, ATOMnilptr(tt), tt);
						if (cmp == 0) {
							b->T->nosorted = 1;
							b->tsorted = FALSE;
						}
					}
				} else if (b->tsorted == (bit) GDK_SORTED_REV) {
					ptr prv = BUNtail(b, p - bunsize);

					cmp = atom_CMP(t, prv, b->ttype);
					if (cmp > 0) {
						b->T->nosorted_rev = i;
						b->tsorted = FALSE;
					}
				}
				if (b->tkey == TRUE && cmp <= 0) {
					b->T->nokey[0] = i - 1;
					b->T->nokey[1] = i;
					b->tkey = bm->hkey = b->tdense = FALSE;
				}
			}
		} else {
			if (b->htype == TYPE_oid) {
				b->hkey = bm->tkey |= b->hdense = TRUE;
				b->hseqbase = bm->tseqbase = *(oid *) h;
			} else if (b->htype) {
				b->hkey = bm->tkey |= TRUE;
			}
			if (b->ttype == TYPE_oid) {
				b->tkey = bm->hkey |= b->tdense = TRUE;
				b->tseqbase = bm->hseqbase = *(oid *) t;
			} else if (b->ttype) {
				b->tkey = bm->hkey |= TRUE;
			}
		}
		if (!countonly) {
			bunfastins(b, h, t);
		} else {
			b->batBuns->free += 1;
			BATsetcount(b, b->batCount + 1);
		}

		/* first adapt the hashes; then the user-defined accelerators.
		 * REASON: some accelerator updates (qsignature) use the hashes! 
		 */
		if (b->hhash) {
			HASHins(b, (hash_t) i, h);
			if (hsize && hsize != b->hheap->size)
				HEAPwarm(b->hheap);
		}
		if (b->thash) {
			HASHins(bm, (hash_t) i, t);

			if (tsize && tsize != b->theap->size)
				HEAPwarm(b->theap);
		}
	}
	return b;
      bunins_failed:
	return NULL;
}

oid
MAXoid(BAT *i)
{
	oid o = i->hseqbase - 1;

	if (BATcount(i))
		o = *(oid *) BUNhead(i, BUNlast(i) - BUNsize(i));
	if (!BAThordered(i)) {
		BUN r, s;
		int d;

		BATloopFast(i, r, s, d) {
			oid v = *(oid *) BUNhead(i, r);

			if (v > o)
				o = v;
		}
	}
	return o;
}

@+ BUNappend
The BUNappend function can be used to add a single value to void and oid  
headed bats. The new head value will be a unique number, (max(bat)+1). 
@c
BAT *
BUNappend(BAT *b, ptr t, bit force)
{
	size_t i;
	BUN p;
	BAT *bm;
	ptr h = NULL;
	oid id = 0;
	int countonly;
	size_t hsize = 0, tsize = 0;

	if (b->hhash && b->hheap)
		hsize = b->hheap->size;
	if (b->thash && b->theap)
		tsize = b->theap->size;

	BATcheck(b, "BUNappend");
	bm = BBP_cache(-b->batCacheid);

	countonly = (b->htype == TYPE_void && b->ttype == TYPE_void);
	if (b->htype != TYPE_void && b->htype != TYPE_oid) {
		GDKerror("BUNappend: can only append to void and oid bats\n");
		return NULL;
	}

	ALIGNapp(b, "BUNappend", force);
	b->batDirty = 1;
	p = BUNlast(b);		/* insert at end */
	i = BUNindex(b, p);
	if ((b->tkey & BOUND2BTRUE) && BUNfnd(bm, t)) {
		return b;
	}
	if (p > b->batFirst) {
		unsigned int bunsize = BUNsize(b);

		if (b->htype == TYPE_oid) {
			h = &id;
			id = MAXoid(b) + 1;
		}
		if (b->ttype != TYPE_void) {
			int cmp = 0;

			if (b->tsorted & 1) {
				ptr prv = BUNtail(b, p - bunsize);

				cmp = atom_CMP(t, prv, b->ttype);
				if (cmp < 0) {
					b->T->nosorted = i;
					b->tsorted = FALSE;
				} else if (cmp && b->tdense && *(oid *) t != 1 + *(oid *) prv) {
					b->T->nodense = i;
					b->tdense = FALSE;
				}
				/* as nil < any, we only need to 
				 * check on second BUNins if the 
				 * first was nil */
				if (i == 2 && cmp > 0) {	/* StM: i==1 ? */
					int tt = b->ttype;

					cmp = atom_CMP(prv, ATOMnilptr(tt), tt);
					if (cmp == 0) {
						b->T->nosorted = 1;
						b->tsorted = FALSE;
					}
				}
			} else if (b->tsorted == (bit) GDK_SORTED_REV) {
				ptr prv = BUNtail(b, p - bunsize);

				cmp = atom_CMP(t, prv, b->ttype);
				if (cmp > 0) {
					b->T->nosorted_rev = i;
					b->tsorted = FALSE;
				}
			}
			if (b->tkey == TRUE && cmp <= 0) {
				b->T->nokey[0] = i - 1;
				b->T->nokey[1] = i;
				b->tkey = bm->hkey = b->tdense = FALSE;
			}
		} else if (b->tseqbase != oid_nil) {	/* virtual ids */
			if (b->tseqbase + BATcount(b) != *(oid *) t) {
				size_t cnt = BATcount(b);

				b = BATmaterializet(b, BATcount(b) + 1);
				countonly = 0;
				b->T->nodense = cnt;
				b->tdense = FALSE;
				if (b->tsorted & 1) {
					if (b->tseqbase + cnt > *(oid *) t || *(oid *) t == oid_nil) {
						b->T->nosorted = 1;
						b->tsorted = FALSE;

						b->T->nokey[0] = cnt - 1;
						b->T->nokey[1] = cnt;
						b->tkey = bm->hkey = b->tdense = FALSE;
					}
				} else if (b->tsorted == (bit) GDK_SORTED_REV) {
					if (b->tseqbase + cnt < *(oid *) t) {
						b->T->nosorted = 1;
						b->tsorted = FALSE;

						b->T->nokey[0] = cnt - 1;
						b->T->nokey[1] = cnt;
						b->tkey = bm->hkey = b->tdense = FALSE;
					}
				}
			}
		}
	} else {
		b->hkey = bm->tkey |= TRUE;

		if (b->htype == TYPE_oid) {	/* empty oid column */
			h = &id;
			id = 0;

			b->hdense = TRUE;
			b->hseqbase = bm->tseqbase = *(oid *) h;
		}
		if (b->ttype == TYPE_oid) {
			b->tkey = bm->hkey |= b->tdense = TRUE;
			b->tseqbase = bm->hseqbase = *(oid *) t;
		} else if (b->ttype == TYPE_void && b->tseqbase != oid_nil) {
			if (*(oid *) t == oid_nil) {
				BATmaterializet(b, BATcount(b) + 1);
				countonly = 0;
			} else {
				b->tseqbase = bm->hseqbase = *(oid *) t;
			}
		} else if (b->ttype) {
			b->tkey = bm->hkey |= TRUE;
		}
	}
	if (!countonly) {
		bunfastins(b, h, t);
	} else {
		b->batBuns->free += 1;
		BATsetcount(b, b->batCount + 1);
	}

	/* first adapt the hashes; then the user-defined accelerators.
	 * REASON: some accelerator updates (qsignature) use the hashes! 
	 */
	if (b->hhash && h) {
		HASHins(b, (hash_t) i, h);
		if (hsize && hsize != b->hheap->size)
			HEAPwarm(b->hheap);
	}
	if (b->thash) {
		HASHins(bm, (hash_t) i, t);

		if (tsize && tsize != b->theap->size)
			HEAPwarm(b->theap);
	}
	return b;
      bunins_failed:
	return NULL;
}


@- BUN Delete
Deletes should maintain the BAT as a contiguous array. This
implementation permits using a BATloop for(;;) construction
to use the BUNdelete routines, by not modifying what is in
front of the deleted bun. 

This routine returns the next BUN in b after deletion of p.
Note: to cause less trouble when updating BATs with void columns
the delete policy has been changed. Deleted volatile elements 
are now being overwritten by the last element; instead of causing 
a cascade of moves. The sequential deletability property
is changed somewhat: instead of doing 
@verbatim
	BATloop(b,p,q) BUNdelete(b,p,FALSE)
one now must do:
	BATloopDEL(b,p) p = BUNdelete(b,p,FALSE)
@end verbatim
@
@c
static INLINE BUN
BUNdelete_(BAT *b, BUN p, bit force)
{
	BAT *bm = BBP_cache(-b->batCacheid);
	int bs = BUNsize(b);
	BUN l, last = BUNlast(b) - bs;
	size_t idx1, idx2;

	ALIGNdel(b, "BUNdelete", force);	/* zap alignment info */

@- Committed Delete. 
Deleting a (committed) bun the first and deleted swap position.
@c
	if (p < b->batInserted && !force) {
		idx1 = BUNindex(b, p);

		if (p == b->batFirst) {	/* first can simply be discarded */
			@:hacc_update(del,head,p,idx1)@
			@:tacc_update(del,tail,p,idx1)@

			if (BAThdense(b)) {
				bm->tseqbase = ++b->hseqbase;
			}
			if (BATtdense(b)) {
				bm->hseqbase = ++b->tseqbase;
			}
		} else {
			@:hacc_update(del,head,p,idx1)@
			@:tacc_update(del,tail,p,idx1)@

			l = BUNfirst(b);
			idx2 = BUNindex(b, l);
			@:acc_move(l,p,idx2,idx1)@
			if (b->hsorted & 1) {
				b->hsorted = FALSE;
				b->H->nosorted = idx1;
			} else if (b->hsorted == (bit) GDK_SORTED_REV) {
				b->hsorted = FALSE;
				b->H->nosorted_rev = idx1;
			}
			if (b->tsorted & 1) {
				b->tsorted = FALSE;
				b->T->nosorted = idx1;
			} else if (b->tsorted == (bit) GDK_SORTED_REV) {
				b->tsorted = FALSE;
				b->T->nosorted_rev = idx1;
			}
		}
		b->batFirst += bs;
	} else {
@- Uncommitted Delete.
This bun was not committed, and should therefore disappear. The 
last inserted bun (if present) is copied over it. 
@c
		int (*hunfix) (ptr) = BATatoms[b->htype].atomUnfix;
		int (*tunfix) (ptr) = BATatoms[b->ttype].atomUnfix;
		void (*hatmdel) (Heap *, var_t *) = BATatoms[b->htype].atomDel;
		void (*tatmdel) (Heap *, var_t *) = BATatoms[b->ttype].atomDel;

		if (hunfix) {
			(*hunfix) (BUNhead(b, p));
		}
		if (tunfix) {
			(*tunfix) (BUNtail(b, p));
		}
		if (hatmdel) {
			(*hatmdel) (b->hheap, (var_t *) BUNhloc(b, p));
		}
		if (tatmdel) {
			(*tatmdel) (b->theap, (var_t *) BUNtloc(b, p));
		}
		idx1 = BUNindex(b, p);
		@:hacc_update(del,head,p,idx1)@
		@:tacc_update(del,tail,p,idx1)@
		idx2 = BUNindex(b, last);
		if (p != last) {
			@:acc_move(last,p,idx2,idx1)@
			if (b->hsorted & 1) {
				b->hsorted = FALSE;
				b->H->nosorted = idx1;
				if (b->hdense) {
					b->hdense = FALSE;
					b->H->nodense = idx1;
				}
			} else if (b->hsorted == (bit) GDK_SORTED_REV) {
				b->hsorted = FALSE;
				b->H->nosorted_rev = idx1;
			}
			if (b->tsorted & 1) {
				b->tsorted = FALSE;
				b->H->nosorted = idx1;
				if (b->tdense) {
					b->tdense = FALSE;
					b->T->nodense = idx1;
				}
			} else if (b->tsorted == (bit) GDK_SORTED_REV) {
				b->tsorted = FALSE;
				b->H->nosorted_rev = idx1;
			}
		}
		b->batBuns->free -= bs;
		p = ((char *) p) - bs;
	}
	b->batCount--;
	b->batDirty = 1;	/* bat is dirty */
	return p;
}

BUN
BUNdelete(BAT *b, BUN p, bit force)
{
	if (p == NULL) {
		return p;
	}
	if ((b->htype == TYPE_void && b->hseqbase != oid_nil) || (b->ttype == TYPE_void && b->tseqbase != oid_nil)) {
		int bs = BUNsize(b);
		BUN last = BUNlast(b) - bs;

		if ((p < b->batInserted || p != last) && !force) {
			size_t i = BUNindex(b, p);

			b = BATmaterialize(b, BATcount(b));
			if (b == NULL)
				return NULL;
			p = BUNptr(b, i);
		}
	}
	return BUNdelete_(b, p, force);
}

BAT *
BUNdel(BAT *b, ptr x, ptr y, bit force)
{
	BUN p;

	BATcheck(b, "BUNdel");
	BATcheck(x, "BUNdel: head value is nil\n");

	if ((p = BUNlocate(b, x, y)) != NULL) {
		ALIGNdel(b, "BUNdel", force);	/* zap alignment info */
		BUNdelete(b, p, force);
		return b;
	}
	return 0;
}

@- 
The routine @%BUNdelHead@ is similar, but removes all BUNs whose head matches
the argument passed.
@c
BAT *
BUNdelHead(BAT *b, ptr x, bit force)
{
	BUN p;

	BATcheck(b, "BUNdelHead");

	if (x == NULL) {
		x = ATOMnilptr(b->htype);
	}
	if ((p = BUNfnd(b, x)) != NULL) {
		ALIGNdel(b, "BUNdelHead", force);	/* zap alignment info */
		do {
			BUNdelete(b, p, force);
		} while ((p = BUNfnd(b, x)) != NULL);
	}
	return b;
}

@
Deletion of strings leads to garbage on the variable stack.
This can be removed by compaction of the BAT through copying it.

@-  BUN replace
The last operation in this context is BUN replace. It assumes that
the header denotes a key. The old value association is destroyed (if it
exists in the first place) and the new value takes its place.

In order to make updates on void columns workable; replaces on them 
are always done in-place. Performing them without bun-movements 
greatly simplifies the problem. The 'downside' is that when transaction
management has to be performed, replaced values should be saved 
explicitly.

@= uncommit_replace
	@:tacc_update(del,t@1,p,pit)@
	ATOMreplace(b->ttype, b->theap, BUNtloc(b, p), t);
	@:tacc_update(ins,t@1,p,pit)@
	if (BATtordered(b) & 1 || BATtordered(b) == (bit) GDK_SORTED_REV) {
		int bs = BUNsize(b), tt = b->ttype;
		BUN prv = p - bs;
		BUN nxt = p + bs;

		if (prv < b->batFirst)
			prv = NULL;
		if (nxt > last)
			nxt = NULL;

		if (BATtordered(b) & 1) {
			if ((prv && ATOMcmp(tt, t, BUNt@1(b,prv)) < 0) ||
			    (nxt && ATOMcmp(tt, t, BUNt@1(b,nxt)) > 0)) {
				b->tsorted = FALSE;
				b->T->nosorted = pit;
			} else if (b->ttype != TYPE_void && b->tdense) {
				if (((prv && 1 + * (oid *) BUNtloc(b, prv) != * (oid *) t) ||
				     (nxt && * (oid *) BUNtloc(b, nxt) != 1 + * (oid *) t))) {
					b->tdense = FALSE;
					b->T->nodense = pit;
				} else if (!prv && !nxt) {
					bm->hseqbase = b->tseqbase = * (oid *) t;
				}
			}
		} else {
			if ((prv && ATOMcmp(tt, t, BUNt@1(b, prv)) > 0) ||
			    (nxt && ATOMcmp(tt, t, BUNt@1(b, nxt)) < 0)) {
				b->tsorted = FALSE;
				b->T->nosorted_rev = pit;
			}
		}
	}
@c
BAT *
BUNinplace(BAT *b, BUN p, ptr h, ptr t, bit force)
{
	if (p >= b->batInserted || force) {
		/* uncommitted BUN elements */
		BUN last = BUNlast(b) - BUNsize(b);
		BAT *bm = BBP_cache(-b->batCacheid);
		size_t pit = BUNindex(b, p);

		ALIGNinp(b, "BUNreplace", force);	/* zap alignment info */
		if (b->tvarsized) {
			size_t tsize = b->theap->size;

			@:uncommit_replace(var)@
			if (b->thash && tsize != b->theap->size)
				HEAPwarm(b->theap);
		} else {
			@:uncommit_replace(loc)@
		}
		if (((b->ttype != TYPE_void) & b->tkey & !(b->tkey & BOUND2BTRUE)) && BATcount(b) > 1) {
			BATkey(bm, FALSE);
		}
		b->batDirtybuns = b->theapdirty = TRUE;
	} else {
		/* committed BUN */
		BUNdelete(b, p, force);
		if (BUNins(b, h, t, force) == NULL) {
		      bunins_failed:
			return NULL;
		}
	}
	return b;
}

BAT *
BUNreplace(BAT *b, ptr h, ptr t, bit force)
{
	BUN p;

	BATcheck(b, "BUNreplace\n");
	BATcheck(h, "BUNreplace: head value is nil\n");
	BATcheck(t, "BUNreplace: tail value is nil\n");

	if (!(p = BUNfnd(b, h)))
		return b;

	if ((b->tkey & BOUND2BTRUE) && BUNfnd(BATmirror(b), t)) {
		return b;
	}
	if (b->ttype == TYPE_void) {
		size_t i;

		/* no need to materialize if value doesn't change */
		if (b->tseqbase == oid_nil || *(oid *) BUNtpos(b, p) == *(oid *) t)
			return b;
		i = BUNindex(b, p);
		b = BATmaterializet(b, BATcount(b));
		if (b == NULL)
			return NULL;
		p = BUNptr(b, i);
	}

	return BUNinplace(b, p, h, t, force);
}

int
void_inplace(BAT *b, oid id, ptr val, bit force)
{
	int res = GDK_SUCCEED;
	BUN p = NULL;
	BUN oldInserted = b->batInserted;

	assert(b->htype == TYPE_void);
	assert(b->hseqbase != oid_nil);
	assert(BATcount(b) > (id -b->hseqbase));

	b->batInserted = NULL;
	BUNfndVOID(p, b, (ptr) &id);

	assert(p >= b->batInserted);	/* we don't want delete/ins */
	assert(force || !b->batRestricted);
	if (!BUNinplace(b, p, (ptr) &id, val, force))
		 res = GDK_FAIL;

	b->batInserted = oldInserted;
	return res;
}

ssize_t
void_replace_bat(BAT *b, BAT *u, bit force)
{
	size_t nr = 0;
	BUN r, s;

	BATloop(u, r, s) {
		oid updid = *(oid *) BUNhead(u, r);
		ptr val = BUNtail(u, r);

		if (void_inplace(b, updid, val, force) == GDK_FAIL)
			return -1;
		nr++;
	}
	return nr;
}

@- BUN Lookup
Location of a BUN using a value should use the available indexes
to speed up access. If indexes are lacking then a hash index
is constructed under the assumption that 1) multiple access to the BAT 
can be expected and 2) building the hash is only slightly more expensive
than the full linear scan.
NULL is returned if no such element could be found.
In those cases where the type is known and a hash index is available,
one should use the inline functions to speed-up processing.
@c
BUN
BUNfnd(BAT *b, ptr v)
{
	BUN r;

	BATcheck(b, "BUNfnd");
	if (BAThvoid(b)) {
		BUNfndVOID(r, b, v);
		return r;
	}
	if (!b->hhash) {
		if (BAThordered(b) & 1)
			return (BUN) SORTfnd(b, v);
	}
	switch (ATOMstorage(b->htype)) {
	case TYPE_chr:
		HASHfnd_chr(r, b, v);
		break;
	case TYPE_bte:
		HASHfnd_bte(r, b, v);
		break;
	case TYPE_sht:
		HASHfnd_sht(r, b, v);
		break;
	case TYPE_int:
	case TYPE_flt:
		HASHfnd_int(r, b, v);
		break;
	case TYPE_dbl:
	case TYPE_lng:
		HASHfnd_lng(r, b, v);
		break;
	case TYPE_str:
		HASHfnd_str(r, b, v);
		break;
	default:
		HASHfnd(r, b, v);
	}
	return r;
}

@= swapif
	if (@1) {
		int (*_cmp) (ptr, ptr);
		ptr _p;

		_cmp = hcmp;
		hcmp = tcmp;
		tcmp = _cmp;
		_p = x;
		x = y;
		y = _p;
		b = BATmirror(b);
		if (v)
			v = BATmirror(v);
	}	
			    
@= dohash
        ATOMstorage(@1->@2type) != TYPE_chr && (ATOMstorage(@1->@2type) != TYPE_str || !GDK_ELIMDOUBLES(@1->@2heap)) 
@c
BUN
BUNlocate(BAT *b, ptr x, ptr y)
{
	int (*hcmp) (ptr, ptr) = BATatoms[b->htype].atomCmp;
	int (*tcmp) (ptr, ptr) = BATatoms[b->ttype].atomCmp;
	int htpe, ttpe, hint = 0, tint = 0, hlng = 0, tlng = 0, xx;
	var_t hidx, tidx;
	BUN p, q;
	BAT *v = NULL;

	BATcheck(b, "BUNlocate: BAT parameter");
	BATcheck(x, "BUNlocate: value parameter");
	p = BUNfirst(b);
	q = BUNlast(b);
	xx = BUNsize(b);
	if (p == q)
		return NULL;	/* empty bat */

	/* sometimes BUNlocate is just about a single column */
	@:swapif(y && ((BAThordered(b)&1) && (*hcmp)(x,BUNhead(b,p)) == 0 && (*hcmp)(x,BUNhead(b,q-xx)) == 0))@
	if (y == NULL || ((BATtordered(b) & 1) && (*tcmp) (y, BUNtail(b, p)) == 0 && (*tcmp) (y, BUNtail(b, q - xx)) == 0)) {
		return BUNfnd(b, x);
	}

	/* positional lookup is always the best choice */
	@:swapif(BATtdense(b))@
	if (BAThdense(b)) {
		oid i = *(oid *) x - b->hseqbase;

		if ((size_t) i < BATcount(b)) {
			i += BUNindex(b, BUNfirst(b));
			p = BUNptr(b, i);
			if ((*tcmp) (y, BUNtail(b, p)) == 0)
				return p;
		}
		return NULL;
	}

	/* next, try to restrict the range using sorted columns */
	if (BATtordered(b) & 1) {
		p = SORTfndfirst(b, y);
		q = SORTfndlast(b, y);
	}
	if (BAThordered(b) & 1) {
		BUN mp = SORTfndfirst(BATmirror(b), x);
		BUN mq = SORTfndlast(BATmirror(b), x);

		if (mp > p)
			p = mp;
		if (mq < p)
			q = mq;
	}
	if (p >= q)
		return NULL;	/* value combination cannot occur */

	/* if the range is still larger than 32 BUNs, consider investing in a hash table */
	if ((q - p) > (xx << 5)) {
		/* regrettably MonetDB support only single-column hashes 
		 * strategy: create a hash on both columns, and select the column with the best distribution
		 */
		@:swapif((b->thash && b->hhash == NULL) || !(@:dohash(b,h)@))@
		if (b->hhash == NULL && (v = VIEWcreate_(b, TRUE)) != NULL) {
			/* As we are going to remove the worst hash table later, we must do everything 
			 * in a view, as it is not permitted to remove a hash table from a read-only 
			 * operation (like BUNlocate). Other threads might then crash. 
			 */
			if (@:dohash(v,h)@)
				(void) BATprepareHash(v);
			if (@:dohash(v,t)@)
				(void) BATprepareHash(BATmirror(v));
			if (v->hhash && v->thash) {	/* we can choose between two hash tables */
				size_t hcnt = 0, tcnt = 0, i;

				for (i = 0; i <= v->hhash->mask; i++)
					hcnt += (v->hhash->hash[i] != HASH_MAX);
				for (i = 0; i <= v->thash->mask; i++)
					tcnt += (v->thash->hash[i] != HASH_MAX);
				@:swapif(hcnt < tcnt)@

				/* remove the least selective hash table */
				HASHremove(BATmirror(v));
			}
			@:swapif(v->hhash == NULL)@
			if (v->hhash) {
				gdk_set_lock(GDKhashLock(ABS(b->batCacheid) & BBP_BATMASK), "BUNlocate");
				if (b->hhash == NULL) {	/* give it to the parent */
					b->hhash = BATmirror(b)->thash = v->hhash;
				}
				gdk_unset_lock(GDKhashLock(ABS(b->batCacheid) & BBP_BATMASK), "BUNlocate");
			}
			BBPreclaim(v);
			v = NULL;
		}
	}

	/* exploit string double elimination, when present */
	htpe = ATOMstorage(b->htype);
	ttpe = ATOMstorage(b->ttype);
	if (htpe == TYPE_str && GDK_ELIMDOUBLES(b->hheap)) {
		hidx = strLocate(b->hheap, x);
		if (hidx == 0)
			return NULL;	/* x does not occur */
		if (b->hhash == NULL) {
			htpe = TYPE_oid;
			x = &hidx;
		}
	}
	if (ttpe == TYPE_str && GDK_ELIMDOUBLES(b->theap)) {
		tidx = strLocate(b->theap, y);
		if (tidx == 0)
			return NULL;	/* y does not occur */
		ttpe = TYPE_oid;
		y = &tidx;
	}

	/* type analysis. For equi-lookup {flt,dbl,wrd,oid} can all be treated as either int or lng */
	if (!ATOMvarsized(htpe)) {
		hint = (ATOMsize(htpe) == sizeof(int));
		hlng = (ATOMsize(htpe) == sizeof(lng));
	}
	if (!ATOMvarsized(ttpe)) {
		tint = (ATOMsize(ttpe) == sizeof(int));
		tlng = (ATOMsize(ttpe) == sizeof(lng));
	}

	/* hashloop over head values, check tail values */
	if (b->hhash) {
		hash_t h;

		if (hint && tint) {
			HASHloop_int(b, b->hhash, h, x, p)
				if (*(int *) y == *(int *) BUNtloc(b, p))
					return p;
		} else if (hint && tlng) {
			HASHloop_int(b, b->hhash, h, x, p)
				if (*(lng *) y == *(lng *) BUNtloc(b, p))
					return p;
		} else if (hlng && tint) {
			HASHloop_lng(b, b->hhash, h, x, p)
				if (*(int *) y == *(int *) BUNtloc(b, p))
					return p;
		} else if (hlng && tlng) {
			HASHloop_lng(b, b->hhash, h, x, p)
				if (*(lng *) y == *(lng *) BUNtloc(b, p))
					return p;
		} else {
			HASHloop(b, b->hhash, h, x)
				if ((*tcmp) (y, BUNtail(b, p = BUNptr(b, h))) == 0)
					return p;
		}
		return NULL;
	}

	/* linear check; we get here for small ranges, [chr,chr] bats, and hash alloc failure */
	if (ATOMstorage(b->htype) == TYPE_chr && ATOMstorage(b->ttype) == TYPE_chr) {
		for (; p < q; p += xx)
			if (*(chr *) BUNhloc(b, p) == *(chr *) x &&
			    *(chr *) BUNtloc(b, p) == *(chr *) y)
				return p;
	} else if (hint && tint) {
		for (; p < q; p += xx)
			if (*(int *) BUNhloc(b, p) == *(int *) x &&
			    *(int *) BUNtloc(b, p) == *(int *) y)
				return p;
	} else if (hint && tlng) {
		for (; p < q; p += xx)
			if (*(int *) BUNhloc(b, p) == *(int *) x &&
			    *(lng *) BUNtloc(b, p) == *(lng *) y)
				return p;
	} else if (hlng && tint) {
		for (; p < q; p += xx)
			if (*(lng *) BUNhloc(b, p) == *(lng *) x &&
			    *(int *) BUNtloc(b, p) == *(int *) y)
				return p;
	} else if (hlng && tlng) {
		for (; p < q; p += xx)
			if (*(lng *) BUNhloc(b, p) == *(lng *) x &&
			    *(lng *) BUNtloc(b, p) == *(lng *) y)
				return p;
	} else {
		for (; p < q; p += xx)
			if ((*hcmp) (x, BUNhead(b, p)) == 0 &&
			    (*tcmp) (y, BUNtail(b, p)) == 0)
				return p;
	}
	return NULL;
}

@}


@+ BAT Property Management

The function @%BATcount@ returns the number of active elements in a BAT.
Counting is type independent.
It can be implemented quickly, because the system ensures a dense
BUN list.
@{
@c
size_t
BATcount(BAT *b)
{
	BATcheck(b, "BATcount");
	return b->batCount;
}

@-
The alternative routine is @%BATbuncount@, which calculates the
total buns in use.
@c
size_t
BATbuncount(BAT *b)
{
	size_t f;

	BATcheck(b, "BATbuncount");
	f = b->batBuns->size - (BUNfirst(b) - b->batBuns->base);

	return f / BUNsize(b);
}

size_t
BATvmsize(BAT *b, int dirty)
{
	BATcheck(b, "BATvmsize");
	if (b->batDirty || (b->batPersistence != TRANSIENT && !b->batCopiedtodisk))
		dirty = 0;
	return ((dirty == 0 || b->batDirtybuns) ? HEAPvmsize(b->batBuns) : 0) +
		(((dirty == 0 || b->batDirtybuns) && b->hhash) ? HEAPvmsize(b->hhash->heap) : 0) +
		(((dirty == 0 || b->batDirtybuns) && b->thash) ? HEAPvmsize(b->thash->heap) : 0) +
		(((dirty == 0 || b->hheapdirty) && b->hheap) ? HEAPvmsize(b->hheap) : 0) +
		(((dirty == 0 || b->theapdirty) && b->theap) ? HEAPvmsize(b->theap) : 0);
}

size_t
BATmemsize(BAT *b, int dirty)
{
	BATcheck(b, "BATmemsize");
	if (b->batDirty || (b->batPersistence != TRANSIENT && !b->batCopiedtodisk))
		dirty = 0;
	return ((dirty == 0 || b->batDirtydesc) ? sizeof(BATstore) : 0) +
		((dirty == 0 || b->batDirtybuns) ? HEAPmemsize(b->batBuns) : 0) +
		(((dirty == 0 || b->batDirtybuns) && b->hhash) ? HEAPmemsize(b->hhash->heap) : 0) +
		(((dirty == 0 || b->batDirtybuns) && b->thash) ? HEAPmemsize(b->thash->heap) : 0) +
		(((dirty == 0 || b->hheapdirty) && b-> hheap) ? HEAPmemsize(b-> hheap) : 0) +
		(((dirty == 0 || b->theapdirty) && b->theap) ? HEAPmemsize(b->theap) : 0);
}

@
@}
@-
The key and name properties can be changed at any time.
Keyed dimensions are automatically supported by an auxiliary hash-based
access structure to speed up searching. Turning off the key integrity 
property does not cause the index to disappear. It can still be used to
speed-up retrieval. The routine @%BATkey@ sets the key property of the
association head. 

@{
@c
BAT *
BATkey(BAT *b, int flag)
{
	bat parent;

	BATcheck(b, "BATkey");
	parent = VIEWparentcol(b);
	if (b->htype == TYPE_void) {
		if (b->hseqbase == oid_nil && flag == BOUND2BTRUE) {
			GDKerror("BATkey: nil-column cannot be kept unique.\n");
		}
		if (b->hseqbase != oid_nil && flag == FALSE) {
			GDKerror("BATkey: dense column must be unique.\n");
		}
		if (b->hseqbase == oid_nil || flag == FALSE) {
			return b;
		}
	}
	if (flag)
		flag |= (1 | b->hkey);
	if (b->hkey != flag)
		b->batDirtydesc = TRUE;
	BATmirror(b)->tkey = b->hkey = flag;
	if (!flag)
		BATmirror(b)->tdense = b->hdense = 0;
	if (flag && parent && ALIGNsynced(b, BBP_cache(parent)))
		BATkey(BBP_cache(parent), TRUE);
	return b;
}


BAT *
BATset(BAT *b, int flag)
{
	BATcheck(b, "BATset");
	if (b->htype == TYPE_void) {
		if (b->hseqbase == oid_nil && flag == BOUND2BTRUE)
			BATkey(BATmirror(b), flag);
	} else if (b->ttype == TYPE_void) {
		if (b->tseqbase == oid_nil && flag == BOUND2BTRUE)
			BATkey(b, flag);
	} else {
		if (flag)
			flag = TRUE;
		if (b->batSet != flag)
			b->batDirtydesc = TRUE;
		b->batSet = flag;
	}
	return b;
}

BAT *
BATseqbase(BAT *b, oid o)
{
	BATcheck(b, "BATseqbase");
	if (ATOMtype(b->htype) == TYPE_oid) {
		BAT *m = BATmirror(b);

		if (b->hseqbase != o) {
			b->batDirtydesc = TRUE;
			/* zap alignment if column is changed by new seqbase */
			if (b->htype == TYPE_void)
				b->halign = m->talign = 0;
		}
		m->tseqbase = b->hseqbase = o;

		/* adapt keyness */
		if (BAThvoid(b)) {
			if (o == oid_nil) {
				if (b->hkey)
					m->tkey = b->hkey = FALSE;
			} else {
				if (!b->hkey) {
					m->tkey = b->hkey = TRUE;
					b->H->nokey[0] = b->H->nokey[1] = 0;
				}
			}
		}
	}
	return b;
}

@}
@- 
BATs have a logical name that is independent of their 
location in the file system (this depends on batCacheid).
The dimensions of the BAT can be given a separate name.
It helps front-ends in identifying the column of interest.
The new name should be recognizable as an identifier.
Otherwise interaction through the front-ends becomes
complicated.
@{
@c
int
BATname(BAT *b, str nme)
{
	BATcheck(b, "BATname");
	return BBPrename(b->batCacheid, nme);
}

str
BATrename(BAT *b, str nme)
{
	int ret = BATname(b, nme);

	if (ret == 1) {
		GDKerror("BATrename: identifier expected: %s\n", nme);
	} else if (ret == BBPRENAME_ALREADY) {
		GDKerror("BATrename: name is in use: '%s'.\n", nme);
	} else if (ret == BBPRENAME_ILLEGAL) {
		GDKerror("BATrename: illegal temporary name: '%s'\n", nme);
	} else if (ret == BBPRENAME_LONG) {
		GDKerror("BATrename: name too long: '%s'\n", nme);
	} else if (b == NULL) {
		GDKerror("BATrename: BAT argument missing\n");
	}
	return BBPname(b->batCacheid);
}


BAT *
BATroles(BAT *b, str hnme, str tnme)
{
	BATcheck(b, "BATroles");
	if (b->hident && !default_ident(b->hident))
		GDKfree(b->hident);
	if (hnme)
		b->hident = GDKstrdup(hnme);
	else
		b->hident = BATstring_h;
	if (b->tident && !default_ident(b->tident))
		GDKfree(b->tident);
	if (tnme)
		b->tident = GDKstrdup(tnme);
	else
		b->tident = BATstring_t;
	return b;
}

BAT *
BATcol_name(BAT *b, str tnme)
{
	BATcheck(b, "BATcol_name");
	if (b->tident && !default_ident(b->tident))
		GDKfree(b->tident);
	if (tnme)
		b->tident = GDKstrdup(tnme);
	else
		b->tident = BATstring_t;
	return b;
}

@}

@+ BAT permissions, persistency and memory mapped heaps
The way large heaps are memory mapped is dependent both on the BAT persistency status (persistent or not)
as well as their update permissions (readonly,append-only,writable).

Let us recall the two main memory mapped file modes used to store heaps:
@multitable @columnfractions .12 .8
@item STORE_MMAP 
@tab 
files must be readonly, because you never know the exact saved status. 
      HEAPsave consists of the rather efficient msync(X).
@item STORE_PRIV 
@tab files modify pages in swap area, and can be writable. 
      HEAPsave actually does a full write(X), while the mapped file stays in X.priv
@end multitable
Notice that PRIV storage is only required for persistent BATs that are already committed 
on disk. The crash-consistent state of transient BATs is irrelevant as they disappear
after a crash. Even the crash-consistency of persistent BATs that did not make their first
commit is not relevant as they also will disappear.

Also, some heaps may be in use with STORE_MMAP even if they are appendable, as we suppose our
code is bug-free and we know we won't modify the already committed parts of the mapped
file pages. For string-heaps append-bats may mmap the heap if doubles are not  being eliminated
anymore (i.e. when the contents of the builtin hash table at the start of the string heap
are not crucial anymore).
@{
@c
#define ATOMappendpriv(t,h) ((BATatoms[t].atomHeapCheck != HEAP_check || !HEAP_mmappable(h)) && \
			     (ATOMstorage(t) != TYPE_str || GDK_ELIMDOUBLES(h)))

@}
@- BATmmap
Changing the storage status of heaps in a BAT is done in @:BATmmap@. 
The new semantics is to do nothing: the new mapping only takes effect the next time the bat is loaded. 

Thus we cannot modify the hp->storage fields, but rather store the new modes in special
batMap fields that are used when the BAT descriptor is saved.

This makes the BATmmap safer \& simpler as it is now
incorporated in the normal bat loading and saving mechanism.

It also makes the mmap faster as when through caching you
are finished with the BAT before it is ever swapped to disk
it will never have been written, whereas the old mmap obliged you to 
save a BAT directly.
@{
@c
int
BATmmap(BAT *b, int bns, int hhp, int thp)
{
	BATcheck(b, "BATmmap");
	IODEBUG THRprintf(GDKout, "#BATmmap(%s,%d,%d,%d)\n", BATgetId(b), bns, hhp, thp);

	/* Reverse back if required, as this determines which heap is saved in the 
	 * "hheap" file and which in the "theap" file.
	 */
	if (b->batCacheid < 0) {
		int swap = hhp;

		hhp = thp;
		thp = swap;
		b = BATmirror(b);
	}
	b->batMapdirty = TRUE;
	b->batMapbuns = bns;
	b->batMaphheap = hhp;
	b->batMaptheap = thp;
	if (b->batBuns)
		b->batBuns->newstorage = bns;
	if (b->hheap)
		b->hheap->newstorage = hhp;
	if (b->theap)
		b->theap->newstorage = thp;
	b->batDirtydesc = 1;
	return 0;
}

@- BATmadvise
@= madvise
	if (@1 >= 0 && (@2) && (@2)->base && ((@2)->storage & STORE_MMAP) &&
	    MT_madvise((@2)->base, (@2)->free, @1)) {
		GDKsyserror("madvise on @2 @1 failed.\n");
		return -1;
	}
@= pin
	if ((@2) && (@2)->base && ((@2)->storage & STORE_MMAP)) {
		MT_mmap_@1((@2)->base, (@2)->maxsize);
	}
@c
int
BATmadvise(BAT *b, int bns, int hhp, int thp)
{
	BATcheck(b, "BATmadvise");
	@:madvise(bns,b->batBuns)@
	@:madvise(hhp,b->hheap)@
	@:madvise(thp,b->theap)@
	return 0;
}

int
BATmmap_pin(BAT *b)
{
	BATcheck(b, "BATmmap_pin");
	@:pin(pin,b->batBuns)@
	@:pin(pin,b->hheap)@
	@:pin(pin,b->theap)@
	return 0;
}

int
BATmmap_unpin(BAT *b)
{
	BATcheck(b, "BATmmap_unpin");
	@:pin(unpin,b->batBuns)@
	@:pin(unpin,b->hheap)@
	@:pin(unpin,b->theap)@
	return 0;
}

@}
@- BATcheckmodes

Checks legal heap modes. This is done at BATsave time on a temporary copy of the BAT descriptor
(DESCsetmodes). It now is also used from TMcommit, as one of the criteria for whether a heap
needs priv storage is whether the BAT has been committed ever (see also dirty_bat() in gdk_bbp.mx).
@{
@c
static int
HEAPcheckmode(Heap *h, int persistent, int unloadable, int writeable)
{
	/* user may have requested illegal or system-wise unwanted mmap modes. correct this */
	if (h->size > 0 && h->storage == STORE_MMAP && persistent && writeable) {
		/* in a commit, we are sometimes forced to start treating MMAP heaps as PRIV */
		if (!unloadable)
			h->storage = STORE_PRIV;
		return 1;
	}
	return 0;
}

int
BATcheckmodes(BAT *b, int persistent, int unloadable)
{
	int dirty = 0;

	BATcheck(b, "BATcheckmodes");
	if (HEAPcheckmode(b->batBuns, persistent, unloadable, b->batRestricted == BAT_WRITE)) {
		b->batMapbuns = STORE_PRIV;
		dirty = b->batMapdirty = TRUE;
	}
	if (b->hheap && (HEAPcheckmode(b->hheap, persistent, unloadable, b->batRestricted == BAT_WRITE || (b->batRestricted == BAT_APPEND && ATOMappendpriv(b->htype, b->hheap))))) {
		b->batMaphheap = STORE_PRIV;
		dirty = TRUE;
	}
	if (b->theap && (HEAPcheckmode(b->theap, persistent, unloadable, b->batRestricted == BAT_WRITE || (b->batRestricted == BAT_APPEND && ATOMappendpriv(b->ttype, b->theap))))) {
		b->batMaptheap = STORE_PRIV;
		dirty = TRUE;
	}
	b->batMapdirty |= dirty;
	b->batDirtydesc |= dirty;
	return dirty;
}

@}

@- Change the BAT access permissions (read, append, write)
BATsetaccess() may seem simple, but this has become very tricky when memory-mapped files 
are involved. In case of bats which are still transient changes are simple
(just the batRestricted field).
@-
In case of a change from writable->readonly (PRIV->MMAP), nothing needs to be done immediately.
The mapped BAT is saved in the old mode (in X, not X.priv), and made un-modifiable.
As there are no updates, we need not worry about saving either.
@-
A change from readonly->writable (MMAP->PRIV) is more traumatic. We must unload, and re-load 
immediately, before the BAT can become modifiable.
@-
This picture is complicated further by the new MMAP heaps for temporary BATs.
While such BATs are non-persistent, it is legal to have them as MMAP, because
they won't need to survive a system crash (ie global abort), so we don't care
about consistent files.
@-
Now, for such non-persistent MMAP bats we want to keep the change writable->readonly 
(i.e. MMAP->MMAP) efficient, that is a simple msync(X) should be sufficient (no writing 
to X.priv). To change a temporary writable MMAP heap into a readonly permanent
MMAP heap, we must *modify* the filename.
@-
To summarize, there are three heap attributes of interest;
@itemize 
@item
H =(priv,map) heap mode as registered in h->storage 
@item
M =(priv,map) heap mode as has been requested from the OS 
@item
F =(X,X.priv) h->filename 
@end itemize

We show now all 4 legal heap states, and transitions between them:

@multitable @columnfractions 0.25 0.25 0.25
item 
tab
writable:                      
tab 
initially created by:
tab 
when made readonly:
item (1)
tab
[ H=priv,M=priv,F=X.priv ] 
tab
load a writable mmap bat  
tab
goto (4) 
item (2)
tab
[ H=map, M=map, F=X.priv ] 
tab
new temporary heap bat    
tab
goto (3)

readonly:                                                when made writable:

item (3) 
tab
[ H=map, M=map, F=X]       
tab
load a readonly mmap bat  
tab
if (persistent) goto (1) else goto (2)
@item (4) 
[ H=map, M=priv,F=X.priv ] 
tab
n.a.                      
tab
goto (1)
@end multitable

Now we see that for BBPsync (heap\_move) it is sufficient to check for the .priv
suffix to determine the appropriate backup\_bat behavior (i.e. register a X .killfile
anticipating the write(X) besides a X.priv).

HEAPsave: we do not need to worry about saving readonly bats: as we save them in 
BATsetaccess anyway just before changing modes, we know that readonly heaps will 
never be dirty and as such never saved. 

HEAPsave on a writable BAT just needs to look at H (h->storage) to know what to do.

@{
@c
/* transition heap from readonly to writable (or appendable) */
static int
HEAPsetpriv(Heap *hp, int committed, int *remap, int *reload)
{
	str p;

	assert(hp);

	if (hp->base == NULL || hp->storage == STORE_MEM || hp->filename == NULL || !committed) {
		return hp->storage;
	}
	/* STORE_PRIV would indicate an illegal heap state */
	assert(hp->storage != STORE_PRIV);

	p = strstr(hp->filename, ".priv");
	if (p) {
		/* state(4), goto state (1) */
		*remap = TRUE;
		return hp->storage = STORE_PRIV;
	}
	*remap = TRUE;
	/* state(3), goto state (1) */
	*reload = TRUE;
	return STORE_PRIV;
}

/* transition heap from writable (or appendable) to readonly */
static int
HEAPsetmmap(Heap *hp, int committed, int *remap)
{
	assert(hp);

	if (hp->base == NULL || hp->storage == STORE_MEM || hp->filename == NULL || !committed) {
		return hp->storage;
	}
	*remap = TRUE;
	if (hp->storage == STORE_MMAP) {
		/* state(2), goto state (3) */
		long_str src, dst;
		str p = strstr(hp->filename, ".priv");
		int ret;

		assert(p);	/* absence of .priv would indicate an illegal heap state */

		GDKfilepath(src, BATDIR, hp->filename, NULL);
		*p = 0;		/* cut off .priv */
		GDKfilepath(dst, BATDIR, hp->filename, NULL);

		/* rename X.priv->X is not crucial for this to work (X.priv is not in the way) */
		ret = rename(src, dst);
		IODEBUG THRprintf(GDKout, "#BATsetaccess(HEAPsetmmap) rename(%s,%s) = %d\n", src, dst, ret);
	} else {
		/* state(1), goto state (4) */
		hp->storage = STORE_MMAP;	/* direct change! */
	}
	return STORE_MMAP;
}

@= heap_unshare
	if (b->@1->copied) {
		Heap hp;

		memset(&hp, 0, sizeof(Heap));
		if (HEAPcopy(&hp, b->@1) < 0) {
			GDKerror("%s: remapped @1 of %s could not be copied.\n", fcn, BATgetId(b));
			return -1;
		}
		HEAPfree(b->@1);
		* (b->@1) = hp;
		b->@1->copied = 0;
	}
@c
static int
batunshare(BAT *b, str fcn)
{
	@:heap_unshare(batBuns)@
	if (b->hheap)
		@:heap_unshare(hheap)@
	if (b->theap)
		@:heap_unshare(theap)@
	b->batLview = 0;
	BBPunshare(b->batParentid);
	return 0;
}

BAT *
BATsetaccess(BAT *b, int mode)
{
	BATcheck(b, "BATsetaccess");
	if (VIEWparent(b) && mode != BAT_READ) {
		if (VIEWreset(b) == NULL)
			return NULL;
	}
	if (b->batRestricted != mode) {
		int m1 = 0, bak1 = b->batBuns->storage;
		int m2 = 0, bak2 = b->hheap ? b->hheap->storage : -1;
		int m3 = 0, bak3 = b->theap ? b->theap->storage : -1;
		int committed = BBP_status(b->batCacheid) & BBPEXISTING;
		int bak = b->batRestricted;
		int dirty = BATdirty(b);
		int reload = FALSE;
		int remap = FALSE;

		/* copy-on-write isolated bats that are changed mode should be made independent */
		if (b->batLview) {
			if (batunshare(b, "BATsetaccess") < 0)
				return NULL;
		}

		if (b->batSharecnt && mode != BAT_READ) {
			GDKwarning("BATsetaccess: %s has %d views; deliver a copy.\n", BATgetId(b), b->batSharecnt);
			b = BATsetaccess(BATcopy(b, b->htype, b->ttype, TRUE), mode);
			if (b == NULL)
				return 0;
			if (b->batStamp > 0)
				b->batStamp = -b->batStamp;	/* prevent MIL setaccess */
		} else {
			if (mode == BAT_WRITE) {
				m1 = HEAPsetpriv(b->batBuns, committed, &remap, &reload);
			} else if (bak == BAT_WRITE) {
				m1 = HEAPsetmmap(b->batBuns, committed, &remap);
			}
			if (bak2 >= 0) {
				if (mode == BAT_WRITE || (mode == BAT_APPEND && ATOMappendpriv(b->htype, b->hheap))) {
					m2 = HEAPsetpriv(b->hheap, committed, &remap, &reload);
				} else if (bak == BAT_WRITE || (bak == BAT_APPEND && ATOMappendpriv(b->htype, b->hheap))) {
					m2 = HEAPsetmmap(b->hheap, committed, &remap);
				}
			}
			if (bak3 >= 0) {
				if (mode == BAT_WRITE || (mode == BAT_APPEND && ATOMappendpriv(b->ttype, b->theap))) {
					m3 = HEAPsetpriv(b->theap, committed, &remap, &reload);
				} else if (bak == BAT_WRITE || (bak == BAT_APPEND && ATOMappendpriv(b->ttype, b->theap))) {
					m3 = HEAPsetmmap(b->theap, committed, &remap);
				}
			}
		}
		if (remap && b->batCopiedtodisk && dirty) {
			/* make sure any disk images are clean */
			int dirtydesc = b->batDirtydesc;

			b->batDirtydesc = FALSE;

			/* TODO? saving entire bat may be a bit overkill if only one heap needs it.. */
			if (BBPsave(b)) {
				/* deal with BAT write errors: no access mode change */
				b->batDirtydesc = dirtydesc;
				return NULL;
			}
		}
		/* set new access mode */
		b->batRestricted = mode;
		b->batDirtydesc = TRUE;

		if (remap) {
			BATmmap(b, m1, m2, m3);
		}
		if (reload) {
			/* we assume total exclusive access when B.access() is done. MIL USER RESPONABILITY!!! */
			bat bid = b->batCacheid;

			/* TODO? saving entire bat may be a bit overkill if only one heap needs it.. */
			if (BBPsave(b)) {
				/* deal with BAT write errors: no access mode change */
				b->batRestricted = bak;
				BATmmap(b, bak1, bak2, bak3);
				return NULL;
			}
			BATfree(b);
			BBPuncacheit(bid);
			b = BATload_intern(bid);
		}
	}
	return b;
}

int
BATgetaccess(BAT *b)
{
	BATcheck(b, "BATgetaccess");
	return b->batRestricted;
}

@}
@- change BAT persistency (persistent,session,transient)
In the past, we prevented BATS with certain types from being saved at all:
- BATs of BATs, as having recursive bats creates cascading complexities in commits/aborts. 
- any atom with refcounts, as the BBP has no overview of such user-defined refcounts.
- pointer types, as the values they point to are bound to be transient.

However, nowadays we do allow such saves, as the BBP swapping mechanism was altered
to be able to save transient bats temporarily to disk in order to make room.
Thus, we must be able to save any transient BAT to disk. 

What we don't allow is to make such bats persistent. 

Although the persistent state does influence the allowed mmap modes, this only
goes for the *real* committed persistent state. Making the bat persistent with BATmode 
does not matter for the heap modes until the commit point is reached. So we do not
need to do anything with heap modes yet at this point.
@{
@= check_type
	if (ATOMisdescendant(@1, TYPE_ptr) || ATOMisdescendant(@1, TYPE_bat) ||	
	    BATatoms[@1].atomUnfix || BATatoms[@1].atomFix) {
		GDKerror("BATmode: %s type implies that %s[%s,%s] cannot be made persistent.\n",
			 ATOMname(@1), BATgetId(b),
			 ATOMname(b->htype), ATOMname(b->ttype));
		return NULL;
	}
@c
BAT *
BATmode(BAT *b, int mode)
{
	BATcheck(b, "BATmode");

	if (mode != b->batPersistence) {
		bat bid = ABS(b->batCacheid);

		if (b->batLview) {
			if (batunshare(b, "BATmode") < 0)
				return NULL;
		}
		if (mode == PERSISTENT) {
			@:check_type(b->htype)@
			@:check_type(b->ttype)@
		}
		BBPdirty(1);

		/* a SESSION bat is a TRANSIENT with one logical reference added */
		if (mode == SESSION) {
			BBPincref(bid, TRUE);
		} else if (b->batPersistence == SESSION) {
			BBPdecref(bid, TRUE);
		}
		if (mode == PERSISTENT && VIEWparent(b)) {
			VIEWreset(b);
		}
		/* persistent BATs get a logical reference */
		if (mode == PERSISTENT) {
			BBPincref(bid, TRUE);
		} else if (b->batPersistence == PERSISTENT) {
			BBPdecref(bid, TRUE);
		}
		gdk_set_lock(GDKswapLock(bid & BBP_BATMASK), "BATmode");
		if (mode == PERSISTENT) {
			if (!(BBP_status(bid) & BBPDELETED))
				BBP_status_on(bid, BBPNEW, "BATmode");
			BBP_status_off(bid, BBPDELETED, "BATmode");
		} else if (b->batPersistence == PERSISTENT) {
			if (!(BBP_status(bid) & BBPNEW))
				BBP_status_on(bid, BBPDELETED, "BATmode");
			BBP_status_off(bid, BBPPERSISTENT, "BATmode");
		}
		/* session bats or persistent bats that did not witness a commit yet may have been saved */
		if (b->batCopiedtodisk) {
			if (mode == PERSISTENT) {
				BBP_status_off(bid, BBPTMP, "BATmode");
			} else {
				/* TMcommit must remove it to guarantee free space */
				BBP_status_on(bid, BBPTMP, "BATmode");
			}
		}
		b->batPersistence = mode;
		gdk_unset_lock(GDKswapLock(bid & BBP_BATMASK), "BATmode");
	}
	return b;
}

@}
@+ BATpropcheck

This is a low-cost routine that smartly tries to deduce as 
much properties possible on the head column of its BAT parameter.

with PROPDEBUG (-d8) enabled, it is also a powerful tool
to check whether all properties of a BAT are set correctly.

It uses efficient algorithms to either prove or disprove
the validity of the hkey, hsorted and hdense properties.

If each such property is already set, we know already for certain 
and do not have to check. If in the course of this routine we find 
proof that the property does not hold, we record this proof
using special fields in the BAT descriptor. 
This means that a subsequent execution of this routine 
does not have to check the property exhaustively anymore.

This routine now guarantees that any property that could be set 
on the BAT head column, is set after execution. Hence it can be
used for determining with certainty whether the head column of a 
BAT is sorted, key or dense. 
@{
@c
BAT *
BATpropcheck(BAT *b, int mode)
{
	int disprove_dense, disprove_sorted, disprove_key = TRUE;
	int dense_bak = 0, key_bak = 0, sorted_bak = 0;
	oid seq_bak = 0;
	size_t xx, yy;
	int zz, tpe;
	BUN p, q, r;
	ptr last;
	bit isKey = FALSE;
	BAT *parent;

	BATcheck(b, "BATpropcheck: BAT parameter");
	if (b->halign == 0) {
		b->batDirtydesc = 1;
		b->halign = OIDnew(1);
	}
	tpe = b->htype;
	yy = BUNindex(b, BUNfirst(b));
	xx = BUNindex(b, BUNlast(b));
	disprove_sorted = ATOMlinear(tpe);
@- 
check if duplicated properties are equal
@c
	PROPDEBUG mode |= BATPROPS_CHECK;

	if (mode & BATPROPS_CHECK) {
		BAT *bm = BATmirror(b);

		if (BAThvoid(b) && b->hseqbase != bm->tseqbase) {
			oid o = (b->htype && yy != xx) ? *(oid *) BUNhloc(b, BUNfirst(b)) : oid_nil;
			GDKerror("BATpropcheck: BAT %s(%d) set inconsistent hseqbase: %d != %d => %d\n", BATgetId(b), b->batCacheid, b->hseqbase, bm->tseqbase, o);
			b->hseqbase = bm->tseqbase = o;

			b->batDirty = TRUE;
		}
		zz = (b->GDKversion != bm->GDKversion) |
		     ((b->U != bm->U) << 1) |
		     ((b->P != bm->P) << 2) |
		     ((b->H != bm->T) << 3) |
		     ((b->htype != bm->ttype) << 4) |
		     ((b->hloc != bm->tloc) << 5) |
		     ((b->dims.headvarsized != bm->dims.tailvarsized) << 6) |
		     ((b->dims.bunshift != bm->dims.bunshift) << 7) |
		     ((b->dims.bunwidth != bm->dims.bunwidth) << 8) |
		     ((b->batDeleted < b->batBuns->base) << 9) |
		     ((b->batFirst < b->batDeleted) << 10) |
		     ((b->batFirst > b->batInserted) << 11) |
		     ((b->batInserted > b->batBuns->base + b->batBuns->free) << 12) |
		     ((b->batBuns->size > b->batBuns->maxsize) << 13) |
		     (((b->batBuns->free > b->batBuns->size) & ((b->htype != TYPE_void) |
		     (b->ttype != TYPE_void))) << 14) |
		     (((xx - yy) != BATcount(b)) << 15);

		if (zz) {
			GDKfatal("BATpropcheck: BAT %s(%d) has inconsistent descriptor %d (%o)\n", BATgetId(b), b->batCacheid, zz, zz);

		}
		if (b->hhash != bm->thash) {
			GDKerror("BATpropcheck: BAT %s(%d) has inconsistent accrefs\n", BATgetId(b), b->batCacheid);
			HASHdestroy(b);
			b->batDirty = TRUE;
		}
		if (b->dims.headkey != bm->dims.tailkey) {
			GDKerror("BATpropcheck: BAT %s(%d) recovered hkey\n", BATgetId(b), b->batCacheid);
			b->dims.headkey = bm->dims.tailkey = b->batDirty = TRUE;
		}
		if (BAThdense(b) && !b->hkey) {
			GDKerror("BATpropcheck: BAT %s(%d) is dense but not key!?\n", BATgetId(b), b->batCacheid);
		}
	}
	if (BAThdense(b) && !b->hkey)
		BATkey(b, TRUE);
@-
quick check on trivial cases (void columns, 0 or 1 tuple bats).
@c
	if (tpe == TYPE_void) {
		return b;
	}
	if (yy > xx && BAThdense(b) && b->htype == TYPE_oid && *(oid *) BUNhloc(b, BUNfirst(b)) != b->hseqbase) {
		GDKerror("BATpropcheck: BAT %s(%d) seqbase of dense oid bat is wrong! " OIDFMT " != " OIDFMT "\n",
			 BATgetId(b), b->batCacheid, b->hseqbase, *(oid *) BUNhloc(b, BUNfirst(b)));
	}
	if (yy + 1 >= xx) {	/* BATcount(b) <= 1 */
		if (ATOMlinear(tpe) && !(b->hsorted & 1)) {
			XPROPDEBUG GDKwarning("BATpropcheck: BAT %s(%d) with %d tuples is (h)sorted!\n", BATgetId(b), b->batCacheid, BATcount(b));

			b->batDirtydesc = TRUE;
			b->hsorted = GDK_SORTED;
		}
		if (!b->hkey) {
			XPROPDEBUG GDKwarning("BATpropcheck: BAT %s(%d) with %d tuples is (h)key!\n", BATgetId(b), b->batCacheid, BATcount(b));

			BATkey(b, TRUE);
		}
		if (tpe == TYPE_oid && !BAThdense(b)) {
			oid hsb = oid_nil;

			if (yy == xx) {	/* BATcount(b) == 0 */
				hsb = 0;	/* does not really matter */
			} else {
				hsb = *(oid *) BUNhloc(b, BUNfirst(b));
			}
			if (hsb != oid_nil) {
				XPROPDEBUG GDKwarning("BATpropcheck: [oid,?]-BAT %s(%d) with %d tuples is (h)dense!\n", BATgetId(b), b->batCacheid, BATcount(b));

				b->hdense = b->batDirtydesc = TRUE;
				BATseqbase(b, hsb);
			}
		}
		return b;
	}
@-
first propagate already known properties. that will save some effort.
@c
	if (VIEWparentcol(b) && ALIGNsynced(parent = BBP_cache(VIEWparent(b)), b)) {
		/* quickly propagate properties from parent to child */
		if (((BAThordered(parent) & 1) && !(BAThordered(b) & 1)) && !b->batBuns->copied) {
			XPROPDEBUG GDKwarning("BATpropcheck: BAT %s(%d) inherits (h)sorted from BAT %s(%d)!\n", BATgetId(b), b->batCacheid, BATgetId(parent), parent->batCacheid);

			b->batDirtydesc = TRUE;
			b->hsorted = GDK_SORTED;
		}
		if (parent->hkey && !b->hkey) {
			XPROPDEBUG GDKwarning("BATpropcheck: BAT %s(%d) inherits (h)key from BAT %s(%d)!\n", BATgetId(b), b->batCacheid, BATgetId(parent), parent->batCacheid);

			BATkey(b, TRUE);
		}
		if (BAThdense(parent) && tpe == TYPE_oid && !BAThdense(b)) {
			XPROPDEBUG GDKwarning("BATpropcheck: [oid,?]-BAT %s(%d) inherits (h)dense from BAT %s(%d)!\n", BATgetId(b), b->batCacheid, BATgetId(parent), parent->batCacheid);

			b->hdense = b->batDirtydesc = TRUE;
			BATseqbase(b, *(oid *) BUNhloc(b, BUNfirst(b)));
		}
	}
	disprove_dense = (tpe == TYPE_oid);

	if (mode & BATPROPS_CHECK) {
		dense_bak = BAThdense(b);
		seq_bak = b->hseqbase;
		sorted_bak = BAThordered(b) & 1;	/* StM: GDK_SORTED_REV ? */
		key_bak = b->hkey;
		BATkey(b, FALSE);
		b->hsorted &= (bit) ~1;	/* FALSE */	/* StM: GDK_SORTED_REV ? */
		b->hdense = FALSE;
	} else if (b->hdense) {
		disprove_dense = FALSE;
	}
@-
check whether whatever we want need to prove was already disproven 
@c
	if (disprove_key) {
		if (b->hkey ||
		    ((b->H->nokey[0] != b->H->nokey[1]) && (b->H->nokey[0] >= yy) && (b->H->nokey[0] < xx) && (b->H->nokey[1] >= yy) && (b->H->nokey[1] < xx) &&
		     ATOMcmp(tpe, BUNhead(b, BUNptr(b, b->H->nokey[0])), BUNhead(b, BUNptr(b, b->H->nokey[1]))) == 0)) {
			disprove_key = FALSE;
		} else {
			b->H->nokey[0] = b->H->nokey[1] = 0;
		}
	}
	if (disprove_sorted) {	/* StM: GDK_SORTED_REV ? */
		if ((BAThordered(b) & 1) ||
		    ATOMlinear(tpe) == 0 ||
		    (b->H->nosorted > yy &&
		     b->H->nosorted < xx &&
		     ATOMcmp(tpe, BUNhead(b, BUNptr(b, b->H->nosorted - 1)), BUNhead(b, BUNptr(b, b->H->nosorted))) > 0)) {
			disprove_sorted = FALSE;
		} else {
			b->H->nosorted = 0;	/* StM: nosorted_rev ? */
		}
	}
	if (disprove_dense) {	/* StM: GDK_SORTED_REV ? */
		if (((b->hsorted & 1) == FALSE && disprove_sorted == FALSE) ||
		    (b->H->nodense > yy &&
		     b->H->nodense < xx &&
		     *(oid *) BUNhloc(b, BUNptr(b, b->H->nodense - 1)) + 1 != *(oid *) BUNhloc(b, BUNptr(b, b->H->nodense)))) {
			disprove_dense = FALSE;
		} else {
			b->H->nodense = 0;
		}
	}
@-
still got something to prove? If not, we're done.
@c
	if (!(disprove_sorted || disprove_key || disprove_dense)) {
		goto exit;
	}
@-
Prepare to scan.
@c
	p = BUNfirst(b);
	q = BUNlast(b);
	last = BUNhead(b, p);
	xx = BUNsize(b);
@-
disprove_dense is only set for oid columns, as the 'dense' property
is only relevant for this type..
@c
	if (disprove_dense)
		while ((p += xx) < q) {
			ptr v = BUNhloc(b, p);

			if ((*(oid *) last + 1) != *(oid *) v) {
				disprove_dense = FALSE;
				b->hdense = FALSE;
				b->H->nodense = BUNindex(b, p);
				b->batDirtydesc = 1;
				break;
			}
			last = v;
	} else
		p += xx;
	if (disprove_dense)
		isKey = TRUE;
@-
Merge scan check to see if head values are sorted (&key) 
@c
	switch (ATOMstorage(tpe)) {
#ifndef NOEXPAND_CHR
	case TYPE_chr:
		@:merge_disprove(simple,chr,loc)@
#endif
#ifndef NOEXPAND_BTE
	case TYPE_bte:
		@:merge_disprove(simple,bte,loc)@
#endif
#ifndef NOEXPAND_SHT
	case TYPE_sht:
		@:merge_disprove(simple,sht,loc)@
#endif
#ifndef NOEXPAND_INT
	case TYPE_int:
		@:merge_disprove(simple,int,loc)@
#endif
#ifndef NOEXPAND_FLT
	case TYPE_flt:
		@:merge_disprove(simple,flt,loc)@
#endif
#ifndef NOEXPAND_LNG
	case TYPE_lng:
		@:merge_disprove(simple,lng,loc)@
#endif
#ifndef NOEXPAND_DBL
	case TYPE_dbl:
		@:merge_disprove(simple,dbl,loc)@
#endif
	default:
		@:merge_disprove(atom,tpe,ead)@
	}

@= merge_disprove
	if (disprove_sorted) {	/* StM: GDK_SORTED_REV ? */
		while (p < q) {
			ptr v = BUNh@3(b, p);
			int ret = @1_CMP(v, last, @2);

			if (ret < 0) {
				disprove_sorted = FALSE;
				b->H->nosorted = BUNindex(b, p);	/* StM: nosorted_rev ? */
				b->batDirtydesc = 1; 
				break;
			} else if (ret == 0 && disprove_key) {
				b->H->nokey[0] = BUNindex(b, p) - 1;
				b->H->nokey[1] = BUNindex(b, p);
				disprove_key = FALSE;
				b->batDirtydesc = 1; 
			} 
			p += xx;
			last = v;
		}
	}
	break;
@-
@}
To see if head values are key
we create a view on the bat as the hash table created is 
partial; hence inconsistent (it should also not molest
existing consistent hash tables). On this VIEW we can do a HASHfnd

The code was modified to limit memory consumption in the hash-table.
Basically, unless we really need to determine that a bat is key,
we say that it isn't if we cannot determine easily. Easily here means
'with a small hash table'. In the case of a sanity check,
we also do full key derivation (with whatever it takes).

We also insert a debug statement triggered with BATDEBUG (mask 32) 
that displays the size of the hash table used.  We chose BATDEBUG because 
that also gives the best overview of MIL execution - necessary
for determining which algebra commands set properties sub-optimally.
@{
@c
	if (disprove_key) {
		if (p < q) {
			size_t cnt = BATcount(b);
			size_t lim = (size_t) ((mode & BATPROPS_ALL) ? GDK_int_max : 16000);

			lim = MIN(cnt, lim);
			q = BUNptr(b, yy + lim);
			if (p < q) {
				BAT *bv = VIEWcreate(b);
				Heap *hp = (Heap *) GDKmalloc(sizeof(Heap));
				str nme = BBP_physical(bv->batCacheid);

				hp->filename = GDKmalloc(strlen(nme) + 12);
				sprintf(hp->filename, "%s.%chash", nme, b->batCacheid > 0 ? 'h' : 't');
				if ((bv->hhash = HASHnew(hp, tpe, yy + lim, HASHmask(lim))) == NULL) {
					GDKfree(hp->filename);
					GDKfree(hp);
					THRprintf(GDKout, "#BATpropcheck: BAT %s(%d): could not allocate hash table for key test\n", BATgetId(b), b->batCacheid);
				} else {
					BATmirror(bv)->thash = bv->hhash;

					switch (ATOMstorage(tpe)) {
#ifndef NOEXPAND_CHR
					case TYPE_chr:
						@:hash_disprove(_chr,loc)@
#endif
#ifndef NOEXPAND_BTE
					case TYPE_bte:
						@:hash_disprove(_bte,loc)@
#endif
#ifndef NOEXPAND_SHT
					case TYPE_sht:
						@:hash_disprove(_sht,loc)@
#endif
#if !defined(NOEXPAND_INT) || !defined(NOEXPAND_FLT)
					case TYPE_int:
					case TYPE_flt:
						@:hash_disprove(_int,loc)@
#endif
#if !defined(NOEXPAND_LNG) || !defined(NOEXPAND_DBL)
					case TYPE_lng:
					case TYPE_dbl:
						@:hash_disprove(_lng,loc)@
#endif
					default:
						@:hash_disprove(_any,ead)@
					}
					BATDEBUG THRprintf(GDKout, "#BATpropcheck: BAT %s(%d): used hashtable of size " SZFMT "\n", BATgetId(b), b->batCacheid, lim);
				}
				BBPreclaim(bv);
			}
		} else {
			isKey = TRUE;
		}
	}

@= hash_disprove
	for (r = BUNfirst(b); r < p; r += xx, yy++) {
		HASHins@1(bv->hhash, yy, BUNh@2(bv, r));
	}
	while (p < q) {
		ptr v = BUNh@2(bv, p);

		HASHfnd@1(r,bv,v); /* purify: UMR */
		if (r != NULL) {
			b->H->nokey[0] = BUNindex(bv, r);
			b->H->nokey[1] = yy;
			disprove_key = FALSE;
			b->batDirtydesc = 1;
			break;
		}
		HASHins@1(bv->hhash, yy, v);
		yy++;
		p += xx;
	}
	if (disprove_key && cnt == lim)
		isKey = TRUE;
	break;
@-
failed to disprove on exhaustive check => succeeded to prove
@c
	if (disprove_key || disprove_dense) {
		BATkey(b, key_bak | isKey);	/* respect BOUND2BTRUE */
	}
	if (disprove_sorted || disprove_dense) {	/* StM: GDK_SORTED_REV ? */
		b->batDirtydesc = TRUE;
		b->hsorted = GDK_SORTED;
	}
	if (disprove_dense) {
		b->batDirtydesc = b->hdense = TRUE;
		BATseqbase(b, *(oid *) BUNhloc(b, BUNfirst(b)));
	}
      exit:
	if (mode & BATPROPS_CHECK) {
		if ((sorted_bak & 1) && !(BAThordered(b) & 1)) {
			GDKwarning("BATpropcheck: BAT %s(%d) was incorrectly marked sorted!\n", BATgetId(b), b->batCacheid);
			if (BAThordered(b))
				GDKwarning("BATpropcheck: BAT %s(%d) remains marked radix-clustered on %d bits; not checked!", BATgetId(b), b->batCacheid, BAThordered(b) >> 1);
		}
		if (key_bak && !b->hkey)
			GDKwarning("BATpropcheck: BAT %s(%d) was incorrectly marked keyed!\n", BATgetId(b), b->batCacheid);
		if (dense_bak && disprove_dense) {
			if (!BAThdense(b))
				GDKwarning("BATpropcheck: BAT %s(%d) was incorrectly marked dense!\n", BATgetId(b), b->batCacheid);
			if (seq_bak != b->hseqbase)
				GDKwarning("BATpropcheck: BAT %s(%d) had incorrect seqbase!\n", BATgetId(b), b->batCacheid);
		}
		XPROPDEBUG {
			if (!(sorted_bak & 1) && (BAThordered(b) & 1))	/* StM: GDK_SORTED_REV ? */
				GDKwarning("BATpropcheck: BAT %s(%d) was not marked sorted!\n", BATgetId(b), b->batCacheid);
			if (!key_bak && b->hkey)
				GDKwarning("BATpropcheck: BAT %s(%d) was not marked keyed!\n", BATgetId(b), b->batCacheid);
			if (!dense_bak && disprove_dense) {
				if (BAThdense(b))
					GDKwarning("BATpropcheck: BAT %s(%d) was not marked dense!\n", BATgetId(b), b->batCacheid);
			}
		}
	}
	return b;
}

@
@}
