@' The contents of this file are subject to the MonetDB Public License
@' Version 1.1 (the "License"); you may not use this file except in
@' compliance with the License. You may obtain a copy of the License at
@' http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html
@'
@' Software distributed under the License is distributed on an "AS IS"
@' basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
@' License for the specific language governing rights and limitations
@' under the License.
@'
@' The Original Code is the MonetDB Database System.
@'
@' The Initial Developer of the Original Code is CWI.
@' Portions created by CWI are Copyright (C) 1997-2006 CWI.
@' All Rights Reserved.

@f gdk_heap
@a Peter Boncz, Wilko Quak
@+ Atom Heaps
Heaps are the basic mass storage structure of Monet. A heap is a handle
to a large, possibly huge, contiguous area of main memory, that can
be allocated in various ways (discriminated by the heap->storage field):

@table @code
@item STORE_MEM: malloc-ed memory
small (or rather: not huge) heaps are allocated with GDKmalloc.
Notice that GDKmalloc may redirect big requests to anonymous
virtual memory to prevent @emph{memory fragmentation} in the 
malloc library (see gdk_utils.mx). 

@item STORE_MMAP: read-only mapped region
this is a file on disk that is mapped into virtual memory.   
This is normally done MAP_SHARED, so we can use msync() to commit dirty 
data using the OS virtual memory management.

@item STORE_PRIV: read-write mapped region
in order to preserve ACID properties, we use a different memory mapping
on virtual memory that is writable, This is because in case of a crash
on a dirty STORE_MMAP heap, the OS may have written some of the dirty pages
to disk and other not (but it is impossible to determine which).  The OS 
MAP_PRIVATE mode does not modify the file on which is being mapped, rather 
creates substitute pages dynamically taken from the swap file when modifications 
occur. This is the only way to make writing to mmap()-ed regions safe.

@end table

On huge requests, we now open a X.priv file and memory map it (STORE_MMAP).
This is done for heaps of new BATs: these are writable (non-readonly), but 
are non-persistent (yet). Such BATs may be made persistent later on, of course.
Thus, the commit protocol BBPsync/heap_move (gdk_bbp.mx) actually does
not check anymore for hp->storage == STORE_PRIV, but rather for a .priv suffix 
in hp->filename. Thus, persistent STORE_MMAP/.priv heaps are saved with
by explicitly writing a separate full file X to disk (this is expensive, though!).

Related to this is saving BAT descriptors. These contain hp->storage fields that 
reflect how the heap should be loaded the *next* time the BAT is re-loaded (may differ
from the *current* mode). In the case of persistent, writable STORE_MMAP
bats (with a X.priv file), we set the `future-storage' to STORE_PRIV. Thus, after
surviving their first commit, any re-load of the BAT will put it in its safe
storage mapping (STORE_PRIV). This is in DESCsetmodes/HEAPcheckmode (gdk_storage.mx).

Another hairy heap issue is changing the BAT readonly/writable state. This 
sometimes implies flushing heaps to disk and even re-loading them with a new 
storage mode.  This is discussed in detail in BATsetaccess (gdk_bat.mx).
@{
@c
#include "monetdb_config.h"
#include "gdk.h"

static char *
decompose_filename(str nme)
{
	char *ext, *priv;

	ext = strchr(nme, '.');	/* extract base and ext from heap file name */
	if (ext) {
		*ext++ = 0;
		priv = strchr(ext, '.');
		if (priv)
			*priv = 0;
	}
	return ext;
}

@}
@- HEAPalloc

Normally, we use GDKmalloc for creating a new heap.  Huge heaps, though, come 
from X.priv files that we create with a large seek (fast, and leads to 
files-with-holes on Unixes).  For this purpose, the filename (X) is supposed 
to have been stored in the heap (NULL is a legal value).

It would have been better to pass this name as a parameter, but this would
also require changing the atom extension ADT interface plus modifying all
extension modules that introduce variable-size atoms (e.g. polygon), as these
provide overloaded versions of HEAPalloc (without heap name, currently).
@{
@c
int
HEAPalloc(Heap *h, size_t nitems, size_t itemsize)
{
	char nme[PATHLENGTH], *ext = NULL;

	if (h->filename) {
		strcpy(nme, h->filename);
		ext = decompose_filename(nme);
	}
	h->base = NULL;
	h->maxsize = h->size = 1;
	h->copied = 0;
	if (itemsize)
		h->maxsize = h->size = MAX(1, nitems) * itemsize;
	h->free = 0;

	/* check for overflow */
	if (itemsize && nitems > (h->size/itemsize)) 
		return -1;

	/* when using anonymous vm we malloc we need 64K chunks, also we
	 * 20% extra malloc */
	if (h->size > GDK_mem_bigsize) {
		h->maxsize = (size_t) ((double) h->maxsize * BATMARGIN) - 1;
		h->maxsize = (1 + (h->maxsize >> 16)) << 16;
	}
	if (h->filename == NULL || (h->size < GDK_vm_minsize)) {
		h->storage = STORE_MEM;
		h->base = (char *) GDKmallocmax(h->size, &h->maxsize, 0);
		if (h->base == 0) 
			GDKerror("HEAPalloc: Insufficient space for HEAP.");
	}
	if (h->filename && h->base == NULL) {
		char privext[PATHLENGTH], *of = h->filename;
		FILE *fp;

		h->filename = NULL;
		sprintf(privext, "%s.priv", ext);
		fp = GDKfilelocate(nme, "wb", privext);
		if (fp != NULL) {
			fclose(fp);
			/* a non-persistent heap: we create a .priv but *not* MMAP_PRIV !!! */
			h->storage = STORE_MMAP;
			HEAPload(h, nme, ext, FALSE);
		}
		GDKfree(of);
	}
	h->newstorage = h->storage;
	return (h->base == NULL) ? -1 : 0;
}

@}
@- HEAPextend

Normally (last case in the below code), we use GDKrealloc, except for the case that the 
heap extends to a huge size, in which case we open an X.priv file and memory map it.

Observe that we may assume that the BAT is writable here (otherwise, why extend?).

For memory mapped files, we may try to extend the file after the end, and also
extend the VM space we already have. This may fail, e.g. due to VM fragmentation
or no swap space (we map the new segment STORE_PRIV). Also, some OS-es might
not support this at all (NOEXTEND_PRIVMAP).

The other way is to just save the mmap-ed heap, free it and reload it.
@{
@c
int
HEAPextend(Heap *h, size_t size)
{
	char nme[PATHLENGTH], *ext = NULL;

	if (h->filename) {
		strcpy(nme, h->filename);
		ext = decompose_filename(nme);
	}
	if (size <= h->size)
		return 0;

	if (h->storage & STORE_MMAP) {
		/* memory mapped files extend: save and remap */
		if (HEAPsave(h, nme, ext) < 0)
			return -1;
		HEAPfree(h);
		h->maxsize = h->size = size;
		if (HEAPload(h, nme, ext, FALSE) >= 0)
			return 0;
	} else {
		/* extend a malloced heap, possibly switching over to file-mapped storage */
		Heap bak = *h;
		int can_mmap = (h->filename && size >= GDK_mem_bigsize);
		int must_mmap = can_mmap && (size >= GDK_vm_minsize || (h->newstorage & STORE_MMAP));
		h->size = size;

		if (can_mmap) {
			/* in anonymous vm, if have to realloc anyway, we reserve some extra space */
			if (size > h->maxsize) {
				h->maxsize = (size_t) ((double) size * BATMARGIN);
			}
			/* when using anonymous vm we malloc we need 64K chunks */
			h->maxsize = (1 + ((h->maxsize-1) >> 16)) << 16;
		} else {
			h->maxsize = size; /* for normal GDKmalloc, maxsize = size */
		}

		/* try GDKrealloc if the heap size stays within reasonable limits */
		if (!must_mmap) {
			h->storage = STORE_MEM;
			h->base = (char *) GDKreallocmax(h->base, size, &h->maxsize, 0);
			if (h->base)
				return 0;
		}
		/* too big: convert it to a disk-based temporary heap */
		if (can_mmap) {
			char privext[PATHLENGTH], *of = h->filename;
			FILE *fp;

			h->filename = NULL;
			sprintf(privext, "%s.priv", ext);
			fp = GDKfilelocate(nme, "wb", privext);
			if (fp != NULL) {
				fclose(fp);
				/* a non-persistent heap: we create a .priv but *not* MMAP_PRIV !!! */
				h->storage = STORE_MMAP;
				if (HEAPload(h, nme, ext, FALSE) >= 0) {
					memcpy(h->base, bak.base, bak.free);
					HEAPfree(&bak);
					return 0;
				}
			}
			GDKfree(of);
		}
		*h = bak;
	}
	return -1;
}

@}
@- HEAPcopy
simple: alloc and copy. Notice that we suppose a preallocated dst->filename (or NULL),
which might be used in HEAPalloc().
@{
@c
int
HEAPcopy(Heap *dst, Heap *src)
{
	if (HEAPalloc(dst, src->size, 1) == 0) {
		dst->free = src->free;
		memcpy(dst->base, src->base, src->free);
		return 0;
	}
	return -1;
}

@}
@- HEAPfree
Is now called even on heaps without memory, just to free the pre-allocated filename.
simple: alloc and copy.
@{
@c
int
HEAPfree(Heap *h)
{
	if (h->base) {
		if (h->storage == STORE_MEM) {	/* plain memory */
			GDKfree(h->base);
		} else {	/* mapped file, or STORE_PRIV */
			int ret = GDKmunmap(h->base, h->maxsize);

			if (ret < 0) {
				GDKsyserror("HEAPfree: %s was not mapped\n", h->filename);
				assert(0);
			}
			IODEBUG THRprintf(GDKout, "#munmap(base=" PTRFMT ", size=" SZFMT ") = %d\n", PTRFMTCAST(void *)h->base, h->maxsize, ret);
		}
		h->base = NULL;
	}
	if (h->filename) {
		GDKfree(h->filename);
		h->filename = NULL;
	}
	return 0;
}

@}
@- HEAPload

If we don't find file X, we try to move X.priv to it. 

If we find both an X and X.priv, the latter is killed.

For STORE_PRIV, we actually then move X to X.priv and mmap on it.
For the other modes, we access X as-is.

This routine initializes the h->filename without deallocating
its previous contents.
@{
@c
int
HEAPload(Heap *h, str nme, str ext, int trunc)
{
	FILE *fp = (FILE *) GDKfilelocate(nme, "mrb", ext);
	int ret = 0, desc_status = 0;
	size_t truncsize = (1 + (((size_t) (h->free * 1.05)) >> REMAP_PAGE_MAXBITS)) << REMAP_PAGE_MAXBITS;
	size_t minsize = (1 + ((h->size - 1) >> REMAP_PAGE_MAXBITS)) << REMAP_PAGE_MAXBITS;
	int priv_storage = (h->storage == STORE_PRIV);
	char priv[80]={0};

	h->maxsize = h->size;
	h->filename = NULL;

	/* round up mmap heap sizes to REMAP_PAGE_MAXSIZE (usually 512KB) segments */
	if ((h->storage & STORE_MMAP) && (minsize != h->size)) {
		h->size = minsize;
		h->maxsize = MAX(minsize, h->maxsize);
	}
	IODEBUG {
		THRprintf(GDKout, "#HEAPload(%s.%s,storage=%d,free=" SZFMT ",size=" SZFMT ")\n", nme, ext, h->storage, h->free, h->size);
	}
	/* On some OSs (WIN32,Solaris), it is prohibited to write to a file that is open 
	 * in MAP_PRIVATE (FILE_MAP_COPY) solution: read from a file renamed to .ext.priv 
	 * .ex.priv files are now also used with STORE_MMAP mode on huge uncommitted BATs.
	 */
	strcpy(priv, ext);
	strcat(priv, ".priv");
	if (fp) {
		ret = fclose(fp);
	} else {
		priv_storage = TRUE;	/* file may be in X.priv file iso X */
	}
	if (priv_storage) {
		long_str path;

		GDKfilepath(path, BATDIR, nme, priv);
		if (fp == NULL) {
			struct stat st;

			ret = stat(path, &st);
		} else {
			/* silently remove any previous .ext.priv file */
			(void) unlink(path);
			ret = GDKmove(BATDIR, nme, ext, BATDIR, nme, priv);
		}
		ext = priv;
	}
	if (ret) {
		return -1;	/* file could not be located */
	}
	/* legacy 2: some old repositories have wasted space => truncate during load */
	if (trunc && truncsize < h->size) {
		fp = (FILE *) GDKfilelocate(nme, "mrb+", ext);
		if (fp) {
			ret = ftruncate(fileno(fp), (off_t) truncsize);
			IODEBUG THRprintf(GDKout, "#ftruncate(file=%s.%s, size=" SZFMT ") = %d\n", nme, ext, truncsize, ret);

			fclose(fp);
			if (ret == 0) {
				h->size = h->maxsize = truncsize;
				desc_status = 1;
			}
		}
	}
	h->base = (char *) GDKload(nme, ext, h->free, h->size, h->storage);
	if (h->base == NULL) {
		return -1;	/* file could  not be read satisfactorily */
	}
	h->newstorage = h->storage;
	h->filename = (char *) GDKmalloc(strlen(nme) + strlen(ext) + 2);
	sprintf(h->filename, "%s.%s", nme, ext);

	return desc_status;	/* ok */
}

@}
@- HEAPsave

Saving STORE_MEM will do a write(fd, buf, size) in GDKsave (explicit IO).

Saving a STORE_PRIV (X.priv) heap means that we must actually write to X, thus
we convert the mode passed to GDKsave to STORE_MEM.

Saving STORE_MMAP will do a msync(buf, MSSYNC) in GDKsave (implicit IO).

After GDKsave returns successfully (>=0), we assume the heaps are safe on stable storage.
@c
@{
int HEAPsave(Heap* h, str nme, str ext) {
	int store = h->storage;
	char *p = h->filename;

	if (h->base == NULL) {
		return -1;
	} 
	if (p == NULL || store == STORE_PRIV) {
		/* anonymous or private VM is saved as if it were malloced */
		store = STORE_MEM; 
	}
	IODEBUG {
		THRprintf(GDKout, "#HEAPsave(%s.%s,storage=%d,free=" SZFMT ",size=" SZFMT ")\n", 
			nme, ext, h->storage, h->free, h->size);
	}
	return GDKsave(nme, ext, h->base, h->free, store);
}
@}
@- HEAPload
Delete any saved heap file. For memory mapped files, also try to remove any remaining X.priv
@{
@c
int
HEAPdelete(Heap *h, str o, str ext)
{
	char ext2[64];

	if (h->size <= 0) {
                return 0;
	}
	if (h->base) {
		if (h->copied == 0 && h->storage & STORE_MMAP) {
			/* truncate file, so OS does not try to flush dirty data in mmap to file that is deleted anyway */
			int ret, fd = GDKfdlocate(h->filename, "rb+", NULL);
			IODEBUG THRprintf(GDKout, "#HEAPdelete(%s) GDKfdlocate(\"rb+\") = %d\n", h->filename, fd);

			ret = ftruncate(fd, LL_CONSTANT(0));
			IODEBUG THRprintf(GDKout, "#HEAPdelete(%s) ftruncate(%d,0LL) = %d\n", h->filename, fd, ret);

			ret = close(fd);
			IODEBUG THRprintf(GDKout, "#HEAPdelete(%s) close(%d) = %d\n", h->filename, fd, ret);
		}
		HEAPfree(h);
	}
	if (h->copied) {
            return 0;
        }
	strcpy(ext2, ext);
	strcat(ext2, ".priv");
	return (GDKunlink(BATDIR, o, ext) == 0) | (GDKunlink(BATDIR, o, ext2) == 0)?0:-1;
}

int HEAPwarm(Heap *h) 
{
	int bogus_result = 0;
	if (h->storage & STORE_MMAP) {
		/* touch the heap sequentially */
                int *cur = (int*) h->base;
                int *lim = (int*) (h->base + h->free) - 4096;
		for(; cur<lim; cur+=4096) /* try to schedule 4 parallel memory accesses */
			bogus_result += cur[0] + cur[1024] + cur[2048] + cur[3072];
	}
	return bogus_result;
}


@}
@- HEAPvmsize
count all memory that takes up address space.
@{
@c
size_t
HEAPvmsize(Heap *h)
{
	if (h && h->free)
		return h->maxsize;
	return 0;
}

@}
@- HEAPmemsize
count all memory that takes up swap space. We conservatively count STORE_PRIV heaps as 
fully backed by swap space.
@{
@c
size_t
HEAPmemsize(Heap *h)
{
	if (h && h->free && h->storage != STORE_MMAP)
		return h->size;
	return 0;
}

@}

@+ Standard Heap Library
This library contains some routines which implement a @emph{ malloc} and @emph{
free} function on the Monet @emph{Heap} structure. They are useful when
implementing a new @emph{ variable-size} atomic data type, or for implementing
new search accelerators.  All functions start with the prefix @emph{HEAP_}. T

Due to non-careful design, the HEADER field was found to be 32/64-bit dependent. 
As we do not (yet) want to change the BAT image on disk, This is now fixed by 
switching on-the-fly between two representations. We ensure that the 64-bit memory 
representation is just as long as the 32-bits version (20 bytes) so the rest of 
the heap never needs to shift. The function HEAP\_checkformat converts at load 
time dynamically between the layout found on disk and the memory format.
Recognition of the header mode is done by looking at the first two ints: 
alignment must be 4 or 8, and head can never be 4 or eight. 

TODO: user HEADER64 for both 32 and 64 bits (requires BAT format change)
@{
@c
/* #define DEBUG */
/* #define TRACE */

#define HEAPVERSION	20030408

typedef struct heapheader {
	size_t head;		/* index to first free block            */
	int alignment;		/* alignment of objects on heap         */
	size_t firstblock;	/* first block in heap                  */
	int version;
	int (*sizefcn) (ptr);	/* ADT function to ask length           */
} HEADER32;

typedef struct {
	int version;
	int alignment;
	size_t head;
	size_t firstblock;
	int (*sizefcn) (ptr);
} HEADER64;

#if SIZEOF_SIZE_T==8
typedef HEADER64 HEADER;
typedef HEADER32 HEADER_OTHER;
#else
typedef HEADER32 HEADER;
typedef HEADER64 HEADER_OTHER;
#endif
typedef struct hfblock {
	size_t size;		/* Size of this block in freelist        */
	size_t next;		/* index of next block                   */
} CHUNK;

@c
#define roundup_8(x)	(((x)+7)&~7)
#define roundup_4(x)	(((x)+3)&~3)
#define blocksize(h,p)	((p)->size)

static INLINE size_t
roundup_num(size_t number, size_t alignment)
{
	size_t rval = number + alignment - 1;

	rval -= (rval % alignment);
	return (rval);
}

size_t
HEAP_private(Heap *h)
{
	(void) h;
	return roundup_8(sizeof(HEADER));
}

#ifdef TRACE
static void
HEAP_printstatus(Heap *heap)
{
	HEADER *hheader = HEAP_index(heap, 0, HEADER);
	size_t block, cur_free = hheader->head;
	CHUNK *blockp;

	THRprintf(GDKout, "#HEAP has head " SZFMT " and alignment %d and size " SZFMT "\n", hheader->head, hheader->alignment, heap->free);

	/*
	   // Walk the blocklist;
	 */
	block = hheader->firstblock;

	while (block < heap->free) {
		blockp = HEAP_index(heap, block, CHUNK);

		if (block == cur_free) {
			THRprintf(GDKout, "#   free block at " PTRFMT " has size " SZFMT " and next " SZFMT "\n", PTRFMTCAST(void *)block, blockp->size, blockp->next);

			cur_free = blockp->next;
			block += blockp->size;
		} else {
			size_t size = blocksize(hheader, blockp);

			THRprintf(GDKout, "#   block at " SZFMT " with size " SZFMT "\n", block, size);
			block += size;
		}
	}
}
#endif /* TRACE */

static void
HEAP_empty(Heap *heap, size_t nprivate, int alignment)
{
	/*
	   // Find position of header block.
	 */
	HEADER *hheader = HEAP_index(heap, 0, HEADER);

	/*
	   // Calculate position of first and only free block.
	 */
	size_t head = roundup_num(roundup_8(sizeof(HEADER)) + roundup_8(nprivate), alignment);
	CHUNK *headp = HEAP_index(heap, head, CHUNK);

	/*
	   // Fill header block.
	 */
	hheader->head = head;
	hheader->sizefcn = NULL;
	hheader->alignment = alignment;
	hheader->firstblock = head;
	hheader->version = HEAPVERSION;

	/*
	   // Fill first free block.
	 */
	headp->size = heap->size - head;
	headp->next = 0;
#ifdef TRACE
	THRprintf(GDKout, "#We created the following heap\n");
	HEAP_printstatus(heap);
#endif
}

void
HEAP_initialize(Heap *heap, size_t nbytes, size_t nprivate, int alignment)
{
	/*
	   // For now we know about two alignments.
	 */
	if (alignment != 8) {
		alignment = 4;
	}
	if ((size_t) alignment < sizeof(size_t))
		alignment = sizeof(size_t);

	/*
	   // Calculate number of bytes needed for heap + structures.
	 */
	{
		size_t total = 100 + nbytes + nprivate + sizeof(HEADER) + sizeof(CHUNK);

		total = roundup_8(total);
		if (HEAPalloc(heap, total, 1) < 0)
			return;
		heap->free = heap->size;
	}

	/*
	   // initialize heap as empty
	 */
	HEAP_empty(heap, nprivate, alignment);
}


var_t
HEAP_malloc(Heap *heap, size_t nbytes)
{
	size_t block, trail, ttrail;
	CHUNK *blockp;
	CHUNK *trailp;
	HEADER *hheader = HEAP_index(heap, 0, HEADER);

#ifdef TRACE
	THRprintf(GDKout, "#Enter malloc with " SZFMT " bytes\n", nbytes);
#endif

	/* add space for size field */
	nbytes += hheader->alignment;
	if (hheader->alignment == 8) {
		nbytes = roundup_8(nbytes);
	} else if (hheader->alignment == 4) {
		nbytes = roundup_4(nbytes);
	} else {
		GDKfatal("HEAP_malloc: Heap structure corrupt\n");
	}
	if (nbytes < sizeof(CHUNK))
		nbytes = sizeof(CHUNK);

	/*
	   // block  -- points to block with acceptable size (if available).
	   // trail  -- points to predecessor of block.
	   // ttrail -- points to predecessor of trail.
	 */
	ttrail = 0;
	trail = 0;
	for (block = hheader->head; block != 0; block = HEAP_index(heap, block, CHUNK)->next) {
		blockp = HEAP_index(heap, block, CHUNK);

#ifdef TRACE
		THRprintf(GDKout, "#block " SZFMT " is " SZFMT " bytes\n", block, blockp->size);
#endif
		if ((trail != 0) && (block <= trail))
			GDKfatal("HEAP_malloc: Free list is not orderered\n");

		if (blockp->size >= nbytes)
			break;
		ttrail = trail;
		trail = block;
	}

	/*
	   // If no block of acceptable size is found we try to enlarge the heap.
	 */
	if (block == 0) {
		size_t newsize = roundup_8((size_t) (heap->free + MAX(heap->free, nbytes)));

		block = heap->free;	/* current end-of-heap */

#ifdef TRACE
		THRprintf(GDKout, "#No block found\n");
#endif

		/*
		   // Double the size of the heap.
		   // TUNE: increase heap by diffent amount.
		 */
		if (HEAPextend(heap, newsize) < 0)
			return 0;
		heap->free = newsize;
		hheader = HEAP_index(heap, 0, HEADER);

		blockp = HEAP_index(heap, block, CHUNK);
		trailp = HEAP_index(heap, trail, CHUNK);

#ifdef TRACE
		THRprintf(GDKout, "#New block made at pos " SZFMT " with size " SZFMT "\n", block, heap->size - block);
#endif

		blockp->next = 0;
		blockp->size = heap->free - block;	/* determine size of allocated block */

		/*
		   // Try to join the last block in the freelist and the newly allocated
		   // memory
		 */
		if ((trail != 0) && (trail + trailp->size == block)) {
#ifdef TRACE
			THRprintf(GDKout, "#Glue newly generated block to adjacent last\n");
#endif

			trailp->size += blockp->size;
			trailp->next = blockp->next;

			block = trail;
			trail = ttrail;
		}
	}

	/*
	   // Now we have found a block which is big enough in block.
	   // The predecessor of this block is in trail.
	 */
	trailp = HEAP_index(heap, trail, CHUNK);
	blockp = HEAP_index(heap, block, CHUNK);

	/*
	   // If selected block is bigger than block needed split block in two.
	   // TUNE: use different amount than 2*sizeof(CHUNK)
	 */
	if (blockp->size >= nbytes + 2 * sizeof(CHUNK)) {
		size_t newblock = block + nbytes;
		CHUNK *newblockp = HEAP_index(heap, newblock, CHUNK);

		newblockp->size = blockp->size - nbytes;
		newblockp->next = blockp->next;

		blockp->next = newblock;
		blockp->size = nbytes;
	}

	/*
	   // Delete block from freelist
	 */
	if (trail == 0) {
		hheader->head = blockp->next;
	} else {
		trailp = HEAP_index(heap, trail, CHUNK);

		trailp->next = blockp->next;
	}

	block += hheader->alignment;
	return block;
}

void
HEAP_free(Heap *heap, var_t block)
{
	HEADER *hheader = HEAP_index(heap, 0, HEADER);
	CHUNK *beforep;
	CHUNK *blockp;
	CHUNK *afterp;
	size_t after, before;

	if (hheader->alignment != 8 && hheader->alignment != 4) {
		GDKfatal("HEAP_free: Heap structure corrupt\n");
	}

	block -= hheader->alignment;
	blockp = HEAP_index(heap, block, CHUNK);

	/*
	   // block   -- block which we want to free
	   // before  -- first free block before block
	   // after   -- first free block after block
	 */

	before = 0;
	for (after = hheader->head; after != 0; after = HEAP_index(heap, after, CHUNK)->next) {
		if (after > block)
			break;
		before = after;
	}

	beforep = HEAP_index(heap, before, CHUNK);
	afterp = HEAP_index(heap, after, CHUNK);

	/*
	   // If it is not the last free block.
	 */
	if (after != 0) {
		/*
		   // If this block and the block after are consecutive.
		 */
		if (block + blockp->size == after) {
			/*
			   // We unite them.
			 */
			blockp->size += afterp->size;
			blockp->next = afterp->next;
		} else
			blockp->next = after;
	} else {
		/*
		   // It is the last block in the freelist.
		 */
		blockp->next = 0;
	}

	/*
	   //  If it is not the first block in the list.
	 */
	if (before != 0) {
		/*
		   // If the before block and this block are consecutive.
		 */
		if (before + beforep->size == block) {
			/*
			   // We unite them.
			 */
			beforep->size += blockp->size;
			beforep->next = blockp->next;
		} else
			beforep->next = block;
	} else {
		/*
		   //  Add block at head of free list.
		 */
		hheader->head = block;
	}
}

int
HEAP_check(Heap *heap, HeapRepair *hr)
{
	HEADER *hheader = HEAP_index(heap, 0, HEADER);
	size_t head = hheader->head, alignshift = 2;
	size_t block, nwords = (heap->free - 1) >> 7;
	size_t *freemask, prevblock = 0;
	CHUNK *blockp;

	hr->alignment = hheader->alignment;
	hr->minpos = sizeof(HEADER);
	hr->maxpos = heap->free;
	hr->validmask = NULL;

	if (hheader->alignment == 8) {
		nwords >>= 1;
		alignshift = 3;
	} else if (hheader->alignment != 4) {
		GDKerror("HEAP_check: Heap structure corrupt alignment = %d\n", hheader->alignment);
		return FALSE;
	}
	if ((head != roundup_num(head, hheader->alignment))) {
		GDKerror("HEAP_check: Heap structure corrupt: head = %d\n", head);
		return FALSE;
	}

	/*
	   // Create bitmasks that will hold all valid block positions
	 */
	hr->validmask = (size_t *) GDKmalloc(sizeof(size_t) * ++nwords);
	freemask = (size_t *) GDKmalloc(sizeof(size_t) * nwords);
	for (block = 0; block < nwords; block++)
		freemask[block] = hr->validmask[block] = 0;

	/*
	   // Walk the freelist; register them in freemask
	 */
	for (block = hheader->head; block != 0; block = HEAP_index(heap, block, CHUNK)->next) {
		size_t idx = block >> alignshift;
		size_t pos = idx >> 5;
		size_t mask = (size_t) 1 << (idx & 31);

		if ((block <= prevblock) && (block != 0)) {
			GDKerror("HEAP_check: Freelist is not ordered\n");
		} else if (block <= 0 || block > heap->free) {
			GDKerror("HEAP_check: Entry freelist corrupt: block %d not in heap\n", block);
		} else {
			freemask[pos] |= mask;
			continue;
		}
		goto xit;
	}

	/*
	   // Walk the blocklist; register in validmask/eliminate from freemask
	 */
	block = hheader->firstblock;
	while (block < heap->free) {
		size_t idx = block >> alignshift;
		size_t pos = idx >> 5;
		size_t mask = (size_t) 1 << (idx & 31);

		hr->validmask[pos] |= mask;
		blockp = HEAP_index(heap, block, CHUNK);

		if (freemask[pos] & mask) {
			freemask[pos] &= ~mask;
			block += blockp->size;
		} else {
			block += blocksize(hheader, blockp);
		}
	}
	if (block != heap->free) {
		GDKerror("HEAP_check: Something wrong with heap\n");
		goto xit;
	}

	/*
	   // Check if there are left over free blocks
	 */
	for (block = hheader->head; block != 0; block = HEAP_index(heap, block, CHUNK)->next) {
		size_t idx = block >> alignshift;
		size_t pos = idx >> 5;
		size_t mask = (size_t) 1 << (idx & 31);

		if (freemask[pos] & mask) {
			GDKerror("HEAP_check: Entry freelist corrupt: block %d not in blocklist\n", block);
			goto xit;
		}
	}
	GDKfree(freemask);
	return TRUE;
      xit:
	GDKfree(freemask);
	GDKfree(hr->validmask);
	hr->validmask = NULL;
	return FALSE;
}

void
HEAP_checkformat(Heap *heap)
{
#if 0
	HEADER_OTHER image = *HEAP_index(heap, 0, HEADER_OTHER);

	if (image.alignment == 4 || image.alignment == 8) {
		/* it is the other format => correct to the desired format */
		HEADER *hheader = HEAP_index(heap, 0, HEADER);

#if SIZEOF_SIZE_T==8
		size_t hasfcn = *(size_t *) & image.sizefcn;
#else
		size_t hasfcn = (size_t) (image.sizefcn || image.dummy);

		hheader->dummy = 0;
#endif
		hheader->head = image.head;
		hheader->firstblock = image.firstblock;
		hheader->alignment = image.alignment;
		hheader->sizefcn = (int (*)(ptr)) hasfcn;
	}
#else
	(void) heap;
#endif
}

@}
@-
If the elements in the heap tend to be small, it is a waste to allocate extra space
for a size field. especially so if we know that we are going to store only one kind
of atoms in the heap. from the content of the atom we can then derive its length. 
Such a heap can now be created with the HEAP_initialize_compact() function.
The HEAP_init() function is called in the BAT load sequence, if Monet sees that a 
standard heap is being loaded (it looks for a directly registered HEAP_check ADT function). 
@{
@c
/* save space in the heap by registering a size function */
void
HEAP_initialize_compact(Heap *heap, size_t nbytes, size_t nprivate, int alignment, int (*sizefcn) (ptr val))
{
	HEAP_initialize(heap, nbytes, nprivate, alignment);
	if (heap->base) {
		HEADER *hheader = HEAP_index(heap, 0, HEADER);

		hheader->sizefcn = sizefcn;
	}
}

/* reinitialize the size function after a load */
void
HEAP_init(Heap *heap, int tpe)
{
	HEADER *hheader = HEAP_index(heap, 0, HEADER);

	if (hheader->sizefcn) {
		hheader->sizefcn = BATatoms[tpe].atomLen;
	}

	/* make sure the freelist does not point after the end of the heap */
	if (hheader->head > heap->free) {
		hheader->head = 0;	/* cut off free block */
	} else if (hheader->head) {
		size_t idx = hheader->head;

		while (idx) {
			CHUNK *blk = HEAP_index(heap, idx, CHUNK);

			if (idx + blk->size > heap->free) {
				blk->size = heap->free - idx;	/* cut off illegal tail of block */
			}
			if (blk->next > heap->free || blk->next < (idx + blk->size) || (blk->next & (hheader->alignment - 1))) {
				blk->next = 0;	/* cut off next block */
				break;
			}
			idx = blk->next;
		}
	}
}

/* a heap is mmapabble (in append-only mode) if it only has a hole at the end */
int
HEAP_mmappable(Heap *heap)
{
	HEADER *hheader = HEAP_index(heap, 0, HEADER);

	if (hheader->head) {
		CHUNK *blk = HEAP_index(heap, hheader->head, CHUNK);

		if (hheader->head + blk->size >= heap->free) {
			return TRUE;
		}
	}
	return FALSE;
}

@}
