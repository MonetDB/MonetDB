@/
The contents of this file are subject to the MonetDB Public License
Version 1.1 (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html

Software distributed under the License is distributed on an "AS IS"
basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
License for the specific language governing rights and limitations
under the License.

The Original Code is the MonetDB Database System.

The Initial Developer of the Original Code is CWI.
Portions created by CWI are Copyright (C) 1997-July 2008 CWI.
Copyright August 2008-2011 MonetDB B.V.
All Rights Reserved.
@

@f gdk_bat
@a M. L. Kersten, P. Boncz, N. Nes
@* BAT Module
In this Chapter we describe the BAT implementation in more detail.
The routines mentioned are primarily meant to simplify the library
implementation.

@+ BAT Construction
BATs are implemented in several blocks of memory, prepared for disk
storage and easy shipment over a network.

The BAT starts with a descriptor, which indicates the required BAT
library version and the BAT administration details.  In particular, it
describes the binary relationship maintained and the location of
fields required for storage.

The general layout of the BAT in this implementation is as follows.
Each BAT comes with a heap for the loc-size buns and, optionally,
with heaps to manage the variable-sized data items of both
dimensions.  The buns are assumed to be stored as loc-size
objects.  This is essentially an array of structs to store the
associations.  The size is determined at BAT creation time using an
upper bound on the number of elements to be accommodated.  In case of
overflow, its storage space is extended automatically.

The capacity of a BAT places an upper limit on the number of BUNs to
be stored initially. The actual space set aside may be quite large.
Moreover, the size is aligned to int boundaries to speedup access and
avoid some machine limitations.

Initialization of the variable parts rely on type specific routines
called atomHeap.
@{ 
@h
#ifndef _GDK_BAT_H_
#define _GDK_BAT_H_

gdk_export void BATinit_idents(BAT *bn);
gdk_export BUN void_replace_bat(BAT *b, BAT *u, bit force);
gdk_export int void_inplace(BAT *b, oid id, ptr val, bit force);
gdk_export BAT *BATattach(int tt, const char *heapfile);

extern int default_ident(char *s);
extern oid MAXoid(BAT *i);

#endif /* _GDK_BAT_H_ */
@c
#include "monetdb_config.h"
#include "gdk.h"

#ifdef ALIGN
#undef ALIGN
#endif
#define ALIGN(n,b)	((b)?(b)*(1+(((n)-1)/(b))):n)

#define ATOMneedheap(tpe) (BATatoms[tpe].atomHeap != NULL)

char *BATstring_h = "h";
char *BATstring_t = "t";

int
default_ident(char *s)
{
	return ((s) == BATstring_h || (s) == BATstring_t);
}

void
BATinit_idents(BAT *bn)
{
	bn->hident = (char *) BATstring_h;
	bn->tident = (char *) BATstring_t;
}

BATstore *
BATcreatedesc(int ht, int tt, int heapnames)
{
	BAT *bn;

@-
Alloc space for the BAT and its dependent records.
@c
	BATstore *bs = (BATstore *) GDKzalloc(sizeof(BATstore));

	if (bs == NULL)
		return NULL;
@-
assert needed in the kernel to get symbol eprintf resolved.
Else modules using assert fail to load.
@c
	assert(ht >= 0 && tt >= 0);
	bs->BM.H = &bs->T;
	bs->BM.T = &bs->H;
	bs->BM.P = &bs->P;
	bs->BM.U = &bs->U;
	bs->B.H = &bs->H;
	bs->B.T = &bs->T;
	bs->B.P = &bs->P;
	bs->B.U = &bs->U;

	bn = &bs->B;

@-
Fill in basic column info
@c
	bn->htype = ht;
	bn->ttype = tt;
	bn->hkey = FALSE;
	bn->tkey = FALSE;
	bn->H->nonil = TRUE;
	bn->T->nonil = TRUE;
	bn->hsorted = ((bit) ATOMlinear(ht) ? GDK_SORTED : FALSE);
	bn->tsorted = ((bit) ATOMlinear(tt) ? GDK_SORTED : FALSE);

	bn->hident = (char *) BATstring_h;
	bn->tident = (char *) BATstring_t;
	bn->halign = OIDnew(2);
	bn->talign = bn->halign + 1;
	bn->hseqbase = (ht == TYPE_void) ? oid_nil : 0;
	bn->tseqbase = (tt == TYPE_void) ? oid_nil : 0;
	bn->batPersistence = TRANSIENT;
	bn->H->props = bn->T->props = NULL;
@-
add to BBP
@c
	BBPinsert(bs);
@-
fill in heap names, so HEAPallocs can resort to disk for very large writes.
@c
	assert(bn->batCacheid > 0);
	bn->H->heap.filename = NULL;
	bn->T->heap.filename = NULL;
	bn->batMaphead = 0;
	bn->batMaptail = 0;
	bn->batMaphheap = 0;
	bn->batMaptheap = 0;
	if (heapnames) {
		str nme = BBP_physical(bn->batCacheid);

		if (ht) {
			bn->H->heap.filename = (str) GDKmalloc(strlen(nme) + 12);
			if (bn->H->heap.filename == NULL)
				goto bailout;
			GDKfilepath(bn->H->heap.filename, NULL, nme, "head");
		}

		if (tt) {
			bn->T->heap.filename = (str) GDKmalloc(strlen(nme) + 12);
			if (bn->T->heap.filename == NULL)
				goto bailout;
			GDKfilepath(bn->T->heap.filename, NULL, nme, "tail");
		}

		if (ATOMneedheap(ht)) {
			if ((bn->H->vheap = (Heap *) GDKzalloc(sizeof(Heap))) == NULL || (bn->H->vheap->filename = (str) GDKmalloc(strlen(nme) + 12)) == NULL)
				goto bailout;
			GDKfilepath(bn->H->vheap->filename, NULL, nme, "hheap");
			bn->H->vheap->parentid = bn->batCacheid;
		}

		if (ATOMneedheap(tt)) {
			if ((bn->T->vheap = (Heap *) GDKzalloc(sizeof(Heap))) == NULL || (bn->T->vheap->filename = (str) GDKmalloc(strlen(nme) + 12)) == NULL)
				goto bailout;
			GDKfilepath(bn->T->vheap->filename, NULL, nme, "theap");
			bn->T->vheap->parentid = bn->batCacheid;
		}
	}
	bn->batDirty = TRUE;
	return bs;
      bailout:
	if (ht)
		HEAPfree(&bn->H->heap);
	if (tt)
		HEAPfree(&bn->T->heap);
	if (bn->H->vheap) {
		HEAPfree(bn->H->vheap);
		GDKfree(bn->H->vheap);
	}
	if (bn->T->vheap) {
		HEAPfree(bn->T->vheap);
		GDKfree(bn->T->vheap);
	}
	GDKfree(bs);
	return NULL;
}

chr
ATOMelmshift(int sz)
{
	chr sh;
	int i = sz >> 1;

	for (sh = 0; i != 0; sh++) {
		i >>= 1;
	}
	return sh;
}


void
BATsetdims(BAT *b)
{
	if (b->htype == TYPE_str)
		b->H->width = 1;
	else
		b->H->width = ATOMsize(b->htype);
	if (b->ttype == TYPE_str)
		b->T->width = 1;
	else
		b->T->width = ATOMsize(b->ttype);
	b->H->shift = ATOMelmshift(Hsize(b));
	b->T->shift = ATOMelmshift(Tsize(b));
	assert_shift_width(b->H->shift, b->H->width);
	assert_shift_width(b->T->shift, b->T->width);
	b->H->varsized = BATatoms[b->htype].varsized;
	b->T->varsized = BATatoms[b->ttype].varsized;
}

@- BAT allocation 
Allocate BUN heap and variable-size atomheaps (see e.g. strHeap).
We now initialize new BATs with their heapname such that the modified
HEAPalloc/HEAPextend primitives can possibly use memory mapped files
as temporary heap storage.

In case of huge bats, we want HEAPalloc to write a file to disk, and memory map
it. To make this possible, we must provide it with filenames.
@c
static BATstore *
BATnewstorage(int ht, int tt, BUN cap)
{
	BATstore *bs, *recycled;
	BAT *bn;

	assert(cap <= BUN_MAX);
	/* and in case we don't have assertions enabled: limit the size */
	if (cap > BUN_MAX)
		cap = BUN_MAX;
	bs = recycled = BBPrecycle(ht, tt, cap);
	if (!bs)
		bs = BATcreatedesc(ht, tt, (ht || tt));
	if (bs == NULL)
		return NULL;
	bn = &bs->B;

	if (!recycled) {
		BATsetdims(bn);
		bn->U->capacity = cap;

		/* alloc the main heaps */
		if (ht && HEAPalloc(&bn->H->heap, cap, bn->H->width) < 0) {
			return NULL;
		}
		if (tt && HEAPalloc(&bn->T->heap, cap, bn->T->width) < 0) {
			if (ht)
				HEAPfree(&bn->H->heap);
			return NULL;
		}

		if (ATOMheap(ht, bn->H->vheap, cap) < 0) {
			if (ht)
				HEAPfree(&bn->H->heap);
			if (tt)
				HEAPfree(&bn->T->heap);
			GDKfree(bn->H->vheap);
			if (bn->T->vheap)
				GDKfree(bn->T->vheap);
			return NULL;
		}
		if (ATOMheap(tt, bn->T->vheap, cap) < 0) {
			if (ht)
				HEAPfree(&bn->H->heap);
			if (tt)
				HEAPfree(&bn->T->heap);
			if (bn->H->vheap) {
				HEAPfree(bn->H->vheap);
				GDKfree(bn->H->vheap);
			}
			GDKfree(bn->T->vheap);
			return NULL;
		}
		DELTAinit(bn);
		BBPcacheit(bs, 1);
	}
	return bs;
}

BAT *
BATnew(int ht, int tt, BUN cap)
{
	BATstore *bs;

	assert(cap <= BUN_MAX);
	ERRORcheck((ht < 0) || (ht > GDKatomcnt), "BATnew:ht error\n");
	ERRORcheck((tt < 0) || (tt > GDKatomcnt), "BATnew:tt error\n");

	/* round up to multiple of BATTINY */
	if (cap < BUN_MAX - BATTINY)
		cap = (cap + BATTINY - 1) & ~(BATTINY - 1);
	if (cap < BATTINY)
		cap = BATTINY;
	/* and in case we don't have assertions enabled: limit the size */
	if (cap > BUN_MAX)
		cap = BUN_MAX;
	bs = BATnewstorage(ht, tt, cap);
	return bs == NULL ? NULL : &bs->B;
}

BAT *
BATattach(int tt, const char *heapfile)
{
	BATstore *bs;
	BAT *bn;
	struct stat st;
	int atomsize;
	BUN cap;
	char path[PATHLENGTH];

	ERRORcheck(tt <= 0 , "BATattach: bad tail type (<=0)\n");
	ERRORcheck(ATOMvarsized(tt), "BATattach: bad tail type (varsized)\n");
	ERRORcheck(heapfile == 0, "BATattach: bad heapfile name\n");
	if (lstat(heapfile, &st) < 0) {
		GDKerror("BATattach: cannot stat heapfile\n");
		return 0;
	}
	ERRORcheck(!S_ISREG(st.st_mode), "BATattach: heapfile must be a regular file\n");
	ERRORcheck(st.st_nlink != 1, "BATattach: heapfile must have only one link\n");
	atomsize = ATOMsize(tt);
	ERRORcheck(st.st_size % atomsize != 0, "BATattach: heapfile size not integral number of atoms\n");
	ERRORcheck(st.st_size / atomsize > (off_t) BUN_MAX, "BATattach: heapfile too large\n");
	cap = (BUN) (st.st_size / atomsize);
	bs = BATcreatedesc(TYPE_void, tt, 1);
	if (bs == NULL)
		return NULL;
	bn = &bs->B;
	BATsetdims(bn);
	GDKfilepath(path, BATDIR, bn->T->heap.filename, "new");
	GDKcreatedir(path);
	if (rename(heapfile, path) < 0) {
		GDKsyserror("BATattach: cannot rename heapfile\n");
		HEAPfree(&bn->T->heap);
		GDKfree(bs);
		return NULL;
	}
	bn->hseqbase = 0;
	BATkey(bn, TRUE);
	BATsetcapacity(bn, cap);
	BATsetcount(bn, cap);
	if (cap > 1) {
		bn->tsorted = 0;
		bn->tdense = 0;
		bn->tkey = 0;
	}
	bn->batRestricted = BAT_READ;
	bn->T->heap.size = (size_t) st.st_size;
	bn->T->heap.newstorage = bn->T->heap.storage = (bn->T->heap.size < REMAP_PAGE_MAXSIZE) ? STORE_MEM : STORE_MMAP;
	HEAPload(&bn->T->heap, BBP_physical(bn->batCacheid), "tail", TRUE);
	BBPcacheit(bs, 1);
	return bn;
}

@-
The routine BATclone creates a bat with the same types as b.
@c
BAT *
BATclone(BAT *b, BUN cap)
{
	BAT *c = BATnew(b->htype, b->ttype, cap);

	if (c && c->htype == TYPE_void && b->hseqbase != oid_nil)
		BATseqbase(c, b->hseqbase);
	if (c && c->ttype == TYPE_void && b->tseqbase != oid_nil)
		BATseqbase(BATmirror(c), b->tseqbase);
	return c;
}

@- 
If the BAT runs out of storage for BUNS it will reallocate space.
For memory mapped BATs we simple extend the administration after
having an assurance that the BAT still can be safely stored away.

@-
Most BAT operations use a BAT to assemble the result. In several cases
it is rather difficult to give a precise estimate of the required space.
The routine @%BATguess@ is used internally for this purpose.
It balances the cost of small BATs with their probability of occurrence.
Small results BATs are more likely then 100M BATs.

Likewise, the routines @%Hgrows@ and @%Tgrows@  provides a heuristic to enlarge the space.
@c
BUN
BATguess(BAT *b)
{
	BUN newcap;

	BATcheck(b, "BATguess");
	newcap = b->batCount;
	if (newcap < 10 * BATTINY)
		return newcap;
	if (newcap < 50 * BATTINY)
		return newcap / 2;
	if (newcap < 100 * BATTINY)
		return newcap / 10;
	return newcap / 100;
}

BUN
BATgrows(BAT *b)
{
	BUN oldcap, newcap;

	BATcheck(b, "BATgrows");

	newcap = oldcap = BATcapacity(b);
	if (newcap < BATTINY)
		newcap = 2 * BATTINY;
	else if (newcap < 10 * BATTINY)
		newcap = 4 * newcap;
	else if (newcap < 50 * BATTINY)
		newcap = 2 * newcap;
	else if ((double) newcap * BATMARGIN <= (double) BUN_MAX)
		newcap = (BUN) ((double) newcap * BATMARGIN);
	else
		newcap = BUN_MAX;
	if (newcap == oldcap) {
		if (newcap <= BUN_MAX - 10)
			newcap += 10;
		else
			newcap = BUN_MAX;
	}
	return newcap;
}

@-
The routine should ensure that the BAT keeps its location
in the BAT buffer.

Overflow in the other heaps are dealt with in the atom  routines.
Here we merely copy their references into the new administration space.

@c
BAT *
BATextend(BAT *b, BUN newcap)
{
	size_t hheap_size = newcap, theap_size = newcap;

	assert(newcap <= BUN_MAX);
	BATcheck(b, "BATextend");
@- 
The main issue is to properly predict the new BAT size.
storage overflow. The assumption taken is that capacity
overflow is rare. It is changed only when the position
of the next available BUN surpasses the free area marker.
Be aware that the newcap should be greater than the old
value, otherwise you may easily corrupt the administration of
malloc.
@c
	if (newcap <= BATcapacity(b)) {
		return b;
	}

	b->batCapacity = newcap;

	hheap_size *= Hsize(b);
	if (b->H->heap.base && GDKdebug & EXTENDMASK)
		fprintf(stderr, "#HEAPextend in BATextend %s " SZFMT " " SZFMT "\n", b->H->heap.filename, b->H->heap.size, hheap_size);
	if (b->H->heap.base && HEAPextend(&b->H->heap, hheap_size) < 0)
		return NULL;
	theap_size *= Tsize(b);
	if (b->T->heap.base && GDKdebug & EXTENDMASK)
		fprintf(stderr, "#HEAPextend in BATextend %s " SZFMT " " SZFMT "\n", b->T->heap.filename, b->T->heap.size, theap_size);
	if (b->T->heap.base && HEAPextend(&b->T->heap, theap_size) < 0)
		return NULL;
	HASHdestroy(b);
	return b;
}

@} 


@+ BAT destruction
@-
BATclear quickly removes all elements from a BAT. It must respect the
transaction rules; so stable elements must be moved to the "deleted" 
section of the BAT (they cannot be fully deleted yet). For the elements
that really disappear, we must free heapspace and unfix the atoms if
they have fix/unfix handles. As an optimization, in the case of no stable
elements, we quickly empty the heaps by copying a standard small empty image 
over them.
@c
@{
BAT *
BATclear(BAT *b)
{	
	BUN p, q;
	int voidbat;
	BAT *bm;

	BATcheck(b, "BATclear");

	voidbat = 0;
	bm = BATmirror(b);

	if (BAThdense(b) && b->htype == TYPE_void) {
		voidbat = 1;
	}
	if (BATtdense(b) && b->ttype == TYPE_void) {
		voidbat = 1;
	}

	/* small BAT: delete all elements by hand */
	if (!voidbat && b->batCount < 20) {
		BATloopDEL(b, p, q) {
			p = BUNdelete(b, p, FALSE);
		}
		return b;
	}

	/* kill all search accelerators */
	if (b->H->hash) {
		HASHremove(b);
	}
	if (b->T->hash) {
		HASHremove(bm);
	}

	/* we must dispose of all inserted atoms */
	if (b->batDeleted == b->batInserted && 
	    BATatoms[b->htype].atomDel == NULL && 
	    BATatoms[b->ttype].atomDel == NULL) {
		Heap hh, th;

		/* no stable elements: we do a quick heap clean */
		/* need to clean heap which keep data even though the
		   BUNs got removed. This means reinitialize when
		   free > 0
		*/
		size_t cap = 0;

		memset(&hh, 0, sizeof(hh));
		memset(&th, 0, sizeof(th));
		if (b->H->vheap &&
		    b->H->vheap->free > 0 &&
		    ATOMheap(b->htype, &hh, cap) < 0) {
			return NULL;
		}
		if (b->T->vheap &&
		    b->T->vheap->free > 0 &&
		    ATOMheap(b->ttype, &th, cap) < 0) {
			if (b->H->vheap && b->H->vheap->free > 0)
				HEAPfree(&hh);
			return NULL;
		}
		assert(b->H->vheap == NULL || b->H->vheap->parentid == ABS(b->batCacheid));
		if (b->H->vheap && b->H->vheap->free > 0) {
			hh.parentid = b->H->vheap->parentid;
			HEAPfree(b->H->vheap);
			*b->H->vheap = hh;
		}
		assert(b->T->vheap == NULL || b->T->vheap->parentid == ABS(b->batCacheid));
		if (b->T->vheap && b->T->vheap->free > 0) {
			th.parentid = b->T->vheap->parentid;
			HEAPfree(b->T->vheap);
			*b->T->vheap = th;
		}
	} else {
		/* do heap-delete of all inserted atoms */
		void (*hatmdel)(Heap*,var_t*) = BATatoms[b->htype].atomDel;
		void (*tatmdel)(Heap*,var_t*) = BATatoms[b->ttype].atomDel;

		/* TYPE_str has no del method, so we shouldn't get here */
		assert(hatmdel == NULL || b->H->width == sizeof(var_t));
		assert(tatmdel == NULL || b->T->width == sizeof(var_t));
		if (hatmdel || tatmdel) {
			BATiter bi = bat_iterator(b);

			for(p = b->batInserted, q = BUNlast(b); p < q; p++) {
				if (hatmdel)
					(*hatmdel)(b->H->vheap, (var_t*) BUNhloc(bi,p));
				if (tatmdel)
					(*tatmdel)(b->T->vheap, (var_t*) BUNtloc(bi,p));
			}
		}
	}

	b->batFirst = b->batInserted;
	BATsetcount(b,0);
	b->batDirty = TRUE;
	return b; 
}

/* free a cached BAT; leave the bat descriptor cached */
int
BATfree(BAT *b)
{
	BATcheck(b, "BATfree");

	/* deallocate all memory for a bat */
	if (b->batCacheid < 0)
		b = BBP_cache(-(b->batCacheid));
	if (b->hident && !default_ident(b->hident)) 
		GDKfree(b->hident);
	b->hident = BATstring_h;
	if (b->tident && !default_ident(b->tident)) 
		GDKfree(b->tident);
	b->tident = BATstring_t;
	if (b->H->props)
		PROPdestroy(b->H->props);
	b->H->props = NULL;
	if (b->T->props)
		PROPdestroy(b->T->props);
	b->T->props = NULL;
	HASHdestroy(b);
	if (b->htype)
		HEAPfree(&b->H->heap);
	else
		assert(!b->H->heap.base);
	if (b->ttype)
		HEAPfree(&b->T->heap);
	else
		assert(!b->T->heap.base);
	if (b->H->vheap) {
		assert(b->H->vheap->parentid == b->batCacheid);
		HEAPfree(b->H->vheap);
	}
	if (b->T->vheap) {
		assert(b->T->vheap->parentid == b->batCacheid);
		HEAPfree(b->T->vheap);
	}

	b = BBP_cache(-b->batCacheid);
	if (b) {
		BBP_cache(b->batCacheid) = NULL;
	}
	return 0;
}

/* free a cached BAT descriptor */
void
BATdestroy( BATstore *bs )
{
	if (bs->H.id && !default_ident(bs->H.id)) 
		GDKfree(bs->H.id);
	bs->H.id = BATstring_h;
	if (bs->T.id && !default_ident(bs->T.id)) 
		GDKfree(bs->T.id);
	bs->T.id = BATstring_t;
	if (bs->H.vheap)
		GDKfree(bs->H.vheap);
	if (bs->T.vheap)
		GDKfree(bs->T.vheap);
	if (bs->H.props)
		PROPdestroy(bs->H.props);
	if (bs->T.props)
		PROPdestroy(bs->T.props);
	GDKfree(bs);
}

@}
@+ BAT copying

BAT copying is an often used operation. So it deserves attention.
When making a copy of a BAT, the following aspects are of importance:
@itemize 
@item the requested head and tail types. The purpose of the copy may be 
to slightly change these types (e.g. void <-> oid). We may also remap between 
types as long as they share the same ATOMstorage(type), i.e. the types
have the same physical implementation. We may even want to allow 'dirty'
trick such as viewing a flt-column suddenly as int.

To allow such changes, the desired head- and tail-types are a parameter of BATcopy.

@item access mode. If we want a read-only copy of a read-only BAT, a
VIEW may do (in this case, the user may be after just an independent BAT 
header and id). This is indicated by the parameter (writable = FALSE).  

In other cases, we really want an independent physical copy (writable = TRUE).
Changing the mode to BAT_WRITE will be a zero-cost operation if the 
BAT was copied with (writable = TRUE).
@end itemize
In GDK, the result is a BAT that is BAT_WRITE iff (writable == TRUE).

There is a special parameter setting (writable == 2), which does create
an independent BAT (not a view that shares the same heaps), however tries 
to share VM heap resources using copy-on-write maps. Note that the result of
this is a read-only BAT (BAT_READ). The copy-on-write VM tricks can be used, 
 to isolate these copies from changes in the parent.

In these cases the copy becomes a logical view on the original, which ensures
that the original cannot be modified or destroyed (which could affect the shared 
heaps).

@{
@c
int
HEAPshare(Heap *dst, Heap *src, int copy_on_write)
{
	/* use copy-on-write mmap for isolatable copy */
	if (src->storage == STORE_MMAP) {
		*dst = *src;
		dst->base = (char *) -1;
		dst->filename = GDKstrdup(src->filename);
		if (dst->filename) {
			char path[PATHLENGTH];

			GDKfilepath(path, BATDIR, dst->filename, NULL);
			dst->base = GDKmmap(path, MMAP_READ | MMAP_SEQUENTIAL | (copy_on_write ? MMAP_COPY : 0), 0, dst->maxsize);
			if (dst->base != (char *) -1) {
				dst->copied = 1;
				dst->newstorage = dst->storage = copy_on_write ? STORE_PRIV : STORE_MMAP;
				return 0;
			}
			GDKfree(dst->filename);
			dst->filename = NULL;
		}
	}
	return -1;
}

static int
heapcopy(BAT *bn, char *ext, Heap *dst, Heap *src, int *remap)
{
	if (*remap && HEAPshare(dst, src, *remap) == 0) {
		return 0;	/* use a shared memory heap */
	}
	*remap = 0;
	if (src->filename && src->newstorage != STORE_MEM) {
		str nme = BBP_physical(bn->batCacheid);

		if ((dst->filename = (str) GDKmalloc(strlen(nme) + 12)) == NULL)
			return -1;
		GDKfilepath(dst->filename, NULL, nme, ext);
	}
	return HEAPcopy(dst, src);
}

static void
heapfree(Heap *src, Heap *dst)
{
	if (dst->filename == NULL) {
		dst->filename = src->filename;
		src->filename = NULL;
	}
	HEAPfree(src);
	*src = *dst;
}

static int
wrongtype(int t1, int t2)
{
	/* check if types are compatible. be extremely forgiving */
	if (t1) {
		t1 = ATOMtype(ATOMstorage(t1));
		t2 = ATOMtype(ATOMstorage(t2));
		if (t1 != t2) {
			if (ATOMvarsized(t1) ||
			    ATOMvarsized(t2) ||
			    ATOMsize(t1) != ATOMsize(t2) ||
			    ATOMalign(t1) != ATOMalign(t2) ||
			    BATatoms[t1].atomFix ||
			    BATatoms[t2].atomFix)
				return TRUE;
		}
	}
	return FALSE;
}

@-
There are four main implementation cases: 
(1) we are allowed to return a view (zero effort),
(2) the result is void,void (zero effort),
(3) we can copy the heaps (memcopy, or even VM page sharing)
(4) we must insert BUN-by-BUN into the result (fallback) 
The latter case is still optimized for the case that the result 
is bat[void,T] for a simple fixed-size type T. In that case we 
do inline array[T] inserts.
@c
/* TODO make it simpler, ie copy per column */
BAT *
BATcopy(BAT *b, int ht, int tt, int writable)
{
	BUN bunstocopy = BUN_NONE;
	BUN cnt;
	BAT *bn = NULL;

	BATcheck(b, "BATcopy");
	cnt = b->batCount;

	/* maybe a bit ugly to change the requested bat types?? */
	if (b->htype == TYPE_void && !writable)
		ht = TYPE_void;
	if (b->ttype == TYPE_void && !writable)
		tt = TYPE_void;

	if (ht != b->htype && wrongtype(ht, b->htype)) {
		GDKerror("BATcopy: wrong head-type requested\n");
		return NULL;
	}
	if (tt != b->ttype && wrongtype(tt, b->ttype)) {
		GDKerror("BATcopy: wrong tail-type requested\n");
		return NULL;
	}

	/* first try case (1); create a view, possibly with different atom-types */
	if (BAThrestricted(b) == BAT_READ && BATtrestricted(b) == BAT_READ && !writable) {
		bn = VIEWcreate(b, b);
		if (bn == NULL)
			return NULL;
		if (ht != bn->htype) {
			assert(bn->H != bn->T);
			bn->htype = ht;
			bn->hvarsized = ATOMvarsized(ht);
			bn->hseqbase = b->hseqbase;
		}
		if (tt != bn->ttype) {
			assert(bn->H != bn->T);
			bn->ttype = tt;
			bn->tvarsized = ATOMvarsized(tt);
			bn->tseqbase = b->tseqbase;
		}
	} else {
		/* check whether we need case (4); BUN-by-BUN copy (by setting bunstocopy != BUN_NONE) */
		if (ATOMsize(ht) != ATOMsize(b->htype) ||
		    ATOMsize(tt) != ATOMsize(b->ttype)) {
			/* oops, void materialization */
			bunstocopy = cnt;
		} else if (BATatoms[ht].atomFix || BATatoms[tt].atomFix) {
			/* oops, we need to fix/unfix atoms */
			bunstocopy = cnt;
		} else if (isVIEW(b)) {
			/* extra checks needed for views */
			bat hp = VIEWhparent(b), tp = VIEWtparent(b);

			if (isVIEWCOMBINE(b) ||	/* oops, mirror view! */
			    /* reduced slice view: do not copy too much garbage */
			    (hp != 0 && BATcapacity(BBP_cache(hp)) > cnt + cnt) ||
			    (tp != 0 && BATcapacity(BBP_cache(tp)) > cnt + cnt))
				bunstocopy = cnt;
		}

		bn = BATnew(ht, tt, MAX(1, bunstocopy == BUN_NONE ? 0 : bunstocopy));
		if (bn == NULL)
			return NULL;

		if (bn->hvarsized && bn->htype) {
			bn->H->shift = b->H->shift;
			bn->H->width = b->H->width;
			if (HEAPextend(&bn->H->heap, BATcapacity(bn) << bn->H->shift) < 0)
				goto bunins_failed;
		}
		if (bn->tvarsized && bn->ttype) {
			bn->T->shift = b->T->shift;
			bn->T->width = b->T->width;
			if (HEAPextend(&bn->T->heap, BATcapacity(bn) << bn->T->shift) < 0)
				goto bunins_failed;
		}

		if (ht == TYPE_void && tt == TYPE_void) {
			/* case (2): a void,void result => nothing to copy! */
			bn->H->heap.free = 0;
			bn->T->heap.free = 0;
		} else if (bunstocopy == BUN_NONE) {
			/* case (3): just copy the heaps; if possible with copy-on-write VM support */
			int remap = writable == 2;
			int hremap = remap && BAThrestricted(b) != BAT_WRITE && ht != TYPE_void;
			int tremap = remap && BATtrestricted(b) != BAT_WRITE && tt != TYPE_void;
			int hvremap = hremap && ATOMstorage(ht) == TYPE_str && !GDK_ELIMDOUBLES(b->H->vheap);
			int tvremap = tremap && ATOMstorage(tt) == TYPE_str && !GDK_ELIMDOUBLES(b->T->vheap);
			BUN hcap = 0, tcap = 0;
			Heap bhhp, bthp, hhp, thp;
			memset(&bhhp, 0, sizeof(Heap));
			memset(&bthp, 0, sizeof(Heap));
			memset(&hhp, 0, sizeof(Heap));
			memset(&thp, 0, sizeof(Heap));

			if ((b->htype && heapcopy(bn, "head", &bhhp, &b->H->heap, &hremap) < 0) ||
			    (b->ttype && heapcopy(bn, "tail", &bthp, &b->T->heap, &tremap) < 0) ||
			    (bn->H->vheap && heapcopy(bn, "hheap", &hhp, b->H->vheap, &hvremap) < 0) ||
			    (bn->T->vheap && heapcopy(bn, "theap", &thp, b->T->vheap, &tvremap) < 0)) {
				HEAPfree(&thp);
				HEAPfree(&hhp);
				HEAPfree(&bthp);
				HEAPfree(&bhhp);
				BBPreclaim(bn);
				return NULL;
			}
			/* succeeded; replace dummy small heaps by the real ones */
			heapfree(&bn->H->heap, &bhhp);
			heapfree(&bn->T->heap, &bthp);
			hhp.parentid = bn->batCacheid;
			thp.parentid = bn->batCacheid;
			if (bn->H->vheap)
				heapfree(bn->H->vheap, &hhp);
			if (bn->T->vheap)
				heapfree(bn->T->vheap, &thp);

			/* make sure we use the correct capacity */
			hcap = (BUN) (bn->htype ? bn->H->heap.size >> bn->H->shift : 0);
			tcap = (BUN) (bn->ttype ? bn->T->heap.size >> bn->T->shift : 0);
			if (hcap && tcap)
				bn->U->capacity = MIN(hcap, tcap);
			else if (hcap)
				bn->U->capacity = hcap;
			else
				bn->U->capacity = tcap;


			/* first/inserted must point equally far into the heap as in the source */
			bn->batFirst = b->batFirst;
			bn->batInserted = b->batInserted;

			/* if we have copy-on-write heaps, bn is a logical view on b to ensure the heaps stay stable */
			if (hremap || hvremap) {
				bn->P->lview = TRUE;
				BBPshare(bn->H->heap.parentid = b->batCacheid);
			}
			if (tremap || tvremap) {
				bn->P->lview = TRUE;
				BBPshare(bn->T->heap.parentid = -b->batCacheid);
			}
		} else if (BATatoms[ht].atomFix || BATatoms[tt].atomFix || (ht && tt) || ATOMstorage(MAX(ht, tt)) >= TYPE_str) {
			/* case (4): one-by-one BUN insert (really slow) */
			BUN p, q, r = BUNfirst(bn);
			BATiter bi = bat_iterator(b);

			BATloop(b, p, q) {
				ptr h = BUNhead(bi, p);
				ptr t = BUNtail(bi, p);

				bunfastins_nocheck(bn, r, h, t, Hsize(bn), Tsize(bn));
				r++;
			}
		} else if ((ht && b->htype == TYPE_void) || (tt && b->ttype == TYPE_void)) {
			/* case (4): optimized for unary void materialization */
			oid cur = ht ? b->hseqbase : b->tseqbase, *dst = (oid *) (ht ? bn->H->heap.base : bn->T->heap.base);
			oid inc = (cur != oid_nil);

			bn->H->heap.free = bn->T->heap.free = 0;
			if (ht)
				bn->H->heap.free = bunstocopy * sizeof(oid);
			else
				bn->T->heap.free = bunstocopy * sizeof(oid);
			while (bunstocopy--) {
				*dst++ = cur;
				cur += inc;
			}
		} else {
			/* case (4): optimized for simple array copy */
			int tpe = ATOMstorage(ht | tt);
			BUN p = BUNfirst(b);
			char *cur = (ht ? Hloc(b, p) : Tloc(b, p));
			char *d = (ht ? Hloc(bn, 0) : Tloc(bn, 0));

			bn->H->heap.free = bn->T->heap.free = 0;
			if (ht)
				bn->H->heap.free = bunstocopy * Hsize(bn);
			else
				bn->T->heap.free = bunstocopy * Tsize(bn);

			if (tpe == TYPE_chr || tpe == TYPE_bte) {
				bte *src = (bte *) cur, *dst = (bte *) d;

				while (bunstocopy--) {
					*dst++ = *src++;
				}
			} else if (tpe == TYPE_sht) {
				sht *src = (sht *) cur, *dst = (sht *) d;

				while (bunstocopy--) {
					*dst++ = *src++;
				}
			} else if ((tpe == TYPE_int) || (tpe == TYPE_flt)) {
				int *src = (int *) cur, *dst = (int *) d;

				while (bunstocopy--) {
					*dst++ = *src++;
				}
			} else {
				lng *src = (lng *) cur, *dst = (lng *) d;

				while (bunstocopy--) {
					*dst++ = *src++;
				}
			}
		}
		/* copy all properties (size+other) from the source bat */
		BATsetcount(bn, cnt);
	}
	/* set properties (note that types may have changed in the copy) */
	if (ATOMtype(ht) == ATOMtype(b->htype)) {
		ALIGNsetH(bn, b);
	} else if (ATOMtype(ATOMstorage(ht)) == ATOMtype(ATOMstorage(b->htype))) {
		bn->hsorted = b->hsorted;
		bn->hdense = b->hdense;
		if (b->hkey)
			BATkey(bn, TRUE);
		bn->H->nonil = b->H->nonil;
	} else {
		bn->hsorted = bn->hdense = bn->T->nonil = 0;
	}
	if (ATOMtype(tt) == ATOMtype(b->ttype)) {
		ALIGNsetT(bn, b);
	} else if (ATOMtype(ATOMstorage(tt)) == ATOMtype(ATOMstorage(b->ttype))) {
		bn->tsorted = b->tsorted;
		bn->tdense = b->tdense;
		if (b->tkey)
			BATkey(BATmirror(bn), TRUE);
		bn->T->nonil = b->T->nonil;
	} else {
		bn->tsorted = bn->tdense = bn->T->nonil = 0;
	}
	if (writable != TRUE)
		bn->batRestricted = BAT_READ;
	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;
}

@+ BAT Unit Manipulation
Binary units (tuples) are the elements stored in BATs. We
discuss here BUN insert, replace and delete.
Below are help macros that actually move the BUNs
around and adapt search accelerator structures.
 
@h
#define hashins(h,i,v,n) HASHins_any(h,i,v)
#define hashdel(h,i,v,n) HASHdel(h,i,v,n)

@= un_move
	if (@3 == 8) {
		* (lng *) @2 = * (lng *) @1;
	} else if (@3 == 4) {
		* (int *) @2 = * (int *) @1;
	} else {
		str _dst = (str) @2, _src = (str) @1, _end = _src + @3;

		while (_src < _end)
			*_dst++ = *_src++;
	}
@= hacc_update
{
	if (b->H->hash) {
		hash@1(b->H->hash, @4, BUN@2(bi, @3), @3 < last); 
	}
} 
@= tacc_update
{
	if (b->T->hash) {
		hash@1(b->T->hash, (BUN)@4, BUN@2(bi, @3), @3 < last); 
	}
}
@= acc_move
{
	char *htmp = alloca(hs);
	char *ttmp = alloca(ts);

	if (b->H->hash) {
		HASHmove(b->H->hash, @3, @4, BUNhead(bi, @1), @1 < last); 
	}
	if (b->T->hash) {
		HASHmove(b->T->hash, @3, @4, BUNtail(bi, @1), @1 < last); 
	}

	/* move first to tmp */
	@:un_move(Hloc(b,@1),htmp,hs)@
	@:un_move(Tloc(b,@1),ttmp,ts)@
	/* move delete to first */
	@:un_move(Hloc(b,@2),Hloc(b,@1),hs)@
	@:un_move(Tloc(b,@2),Tloc(b,@1),ts)@
	/* move first to deleted */
	@:un_move(htmp,Hloc(b,@2),hs)@
	@:un_move(ttmp,Tloc(b,@2),ts)@

}

@- BUN Insertion
Insertion into a BAT is split into two operations @%BUNins@ and
@%BUNfastins@.  The former should be used when integrity enforcement
and index maintenance is required.  The latter is used to quickly
insert the BUN into the result without any additional check.
For those cases where speed is required, the type decoding can
be circumvented by asking for a BUN using @%BATbunalloc@ and fill
it directly. See gdk.mx for the bunfastins(b,h,t) macros.
@c
BAT *
BUNfastins(BAT *b, ptr h, ptr t)
{
	bunfastins(b, h, t);
	if (!b->batDirty)
		b->batDirty = TRUE;
	return b;
      bunins_failed:
	return NULL;
}


@- 
The interface routine should also perform integrity checks.
Null values should have been obtained at a higher level.
This code assumes that new elements are appended to the BUN list.
@c
@= void_insertbun
	if ((@1) && b->@1type == TYPE_void && b->@1seqbase != oid_nil) {
		if (* (oid *) @1 != oid_nil) {
			if (b->batCount == 0) {
				b->@1seqbase = * (oid *) @1;
			} else if (* (oid *) @1 != (b->@1seqbase + BUNlast(b))) {
		 		b = BATmaterialize@1(b);
				countonly = 0;
				if (b == NULL)
					return b;
			}
		} else { 
		 	b = BATmaterialize@1(b);
			countonly = 0;
			if (b == NULL)
				return b;
		}
	}
@c
BAT *
BUNins(BAT *b, ptr h, ptr t, bit force)
{
	int countonly;
	BUN p;
	BAT *bm;

	BATcheck(b, "BUNins");
	BATcheck(h, "BUNins: head value is nil");

	countonly = (b->htype == TYPE_void && b->ttype == TYPE_void);
	bm = BBP_cache(-b->batCacheid);

	@:void_insertbun(h)@
	@:void_insertbun(t)@

	if (b->batSet && BUNlocate(b, h, t) != BUN_NONE) {
		return b;
	}
	if ((b->hkey & BOUND2BTRUE) && (p = BUNfnd(b, h)) != BUN_NONE) {
		if (BUNinplace(b, p, h, t, force) == NULL)
			return NULL;
	} else if ((b->tkey & BOUND2BTRUE) && (p = BUNfnd(bm, t)) != BUN_NONE) {
		if (BUNinplace(bm, p, t, h, force) == NULL)
			return NULL;
	} else {
		BUN i;
		size_t hsize = 0, tsize = 0;
		BATiter bi = bat_iterator(b);

		p = BUNlast(b);	/* insert at end */
		if (p == BUN_MAX || b->batCount == BUN_MAX) {
			GDKerror("BUNins: bat too large\n");
			return NULL;
		}

		ALIGNins(b, "BUNins", force);
		b->batDirty = 1;
		i = p;
		if (b->H->hash && b->H->vheap)
			hsize = b->H->vheap->size;
		if (b->T->hash && b->T->vheap)
			tsize = b->T->vheap->size;

		if (p > b->batFirst) {
			if (b->htype != TYPE_void) {
				int cmp = 0;

				if (b->hsorted & 1) {
					ptr prv = BUNhead(bi, p - 1);

					cmp = atom_CMP(h, prv, b->htype);
					if (cmp < 0) {
						b->H->nosorted = i;
						b->hsorted = FALSE;
						if (b->hdense & 1) {
							b->hdense = FALSE;
							b->H->nodense = i;
						}
					} else if (cmp && b->hdense && *(oid *) h != 1 + *(oid *) prv) {
						b->H->nodense = i;
						b->hdense = FALSE;
					}
					/* as nil < any, we only need to 
					 * check on second BUNins if the 
					 * first was nil */
					if (i == 2 && cmp > 0) {	/* StM: i==1 ? */
						int ht = b->htype;

						cmp = atom_CMP(prv, ATOMnilptr(ht), ht);
						if (cmp == 0) {
							b->H->nosorted = 1;
							b->hsorted = FALSE;
							if (b->hdense & 1) {
								b->hdense = FALSE;
								b->H->nodense = 1;
							}
						}
					}
				} else if (b->hsorted == (bit) GDK_SORTED_REV) {
					ptr prv = BUNhead(bi, p - 1);

					cmp = atom_CMP(h, prv, b->htype);
					if (cmp > 0) {
						b->H->nosorted_rev = i;
						b->hsorted = FALSE;
					}
				}
				if (b->hkey == TRUE && cmp <= 0) {
					b->H->nokey[0] = i - 1;
					b->H->nokey[1] = i;
					b->hkey = b->hdense = FALSE;
				}
				if (b->H->nonil)
					b->H->nonil = h && atom_CMP(h, ATOMnilptr(b->htype), b->htype) != 0;
			}
			if (b->ttype != TYPE_void) {
				int cmp = 0;

				if (b->tsorted & 1) {
					ptr prv = BUNtail(bi, p - 1);

					cmp = atom_CMP(t, prv, b->ttype);
					if (cmp < 0) {
						b->T->nosorted = i;
						b->tsorted = FALSE;
						if (b->tdense & 1) {
							b->tdense = FALSE;
							b->T->nodense = i;
						}
					} else if (cmp && b->tdense && *(oid *) t != 1 + *(oid *) prv) {
						b->T->nodense = i;
						b->tdense = FALSE;
					}
					/* as nil < any, we only need to 
					 * check on second BUNins if the 
					 * first was nil */
					if (i == 2 && cmp > 0) {	/* StM: i==1 ? */
						int tt = b->ttype;

						cmp = atom_CMP(prv, ATOMnilptr(tt), tt);
						if (cmp == 0) {
							b->T->nosorted = 1;
							b->tsorted = FALSE;
							if (b->tdense & 1) {
								b->tdense = FALSE;
								b->T->nodense = 1;
							}
						}
					}
				} else if (b->tsorted == (bit) GDK_SORTED_REV) {
					ptr prv = BUNtail(bi, p - 1);

					cmp = atom_CMP(t, prv, b->ttype);
					if (cmp > 0) {
						b->T->nosorted_rev = i;
						b->tsorted = FALSE;
					}
				}
				if (b->tkey == TRUE && cmp <= 0) {
					b->T->nokey[0] = i - 1;
					b->T->nokey[1] = i;
					b->tkey = b->tdense = FALSE;
				}
				if (b->T->nonil)
					b->T->nonil = t && atom_CMP(t, ATOMnilptr(b->ttype), b->ttype) != 0;
			}
		} else {
			if (b->htype == TYPE_oid) {
				b->hkey |= b->hdense = TRUE;
				b->hseqbase = *(oid *) h;
			} else if (b->htype) {
				b->hkey |= TRUE;
			}
			if (b->H->nonil)
				b->H->nonil = h && atom_CMP(h, ATOMnilptr(b->htype), b->htype) != 0;
			if (b->ttype == TYPE_oid) {
				b->tkey |= b->tdense = TRUE;
				b->tseqbase = *(oid *) t;
			} else if (b->ttype) {
				b->tkey |= TRUE;
			}
			if (b->T->nonil)
				b->T->nonil = t && atom_CMP(t, ATOMnilptr(b->ttype), b->ttype) != 0;
		}
		if (!countonly) {
			bunfastins(b, h, t);
		} else {
			BATsetcount(b, b->batCount + 1);
		}

		if (b->H->hash) {
			HASHins(b, i, h);
			if (hsize && hsize != b->H->vheap->size)
				HEAPwarm(b->H->vheap);
		}
		if (b->T->hash) {
			HASHins(bm, i, t);

			if (tsize && tsize != b->T->vheap->size)
				HEAPwarm(b->T->vheap);
		}
	}
	return b;
      bunins_failed:
	return NULL;
}

oid
MAXoid(BAT *i)
{
	BATiter ii = bat_iterator(i);
	oid o = i->hseqbase - 1;

	if (i->batCount)
		o = *(oid *) BUNhead(ii, BUNlast(i) - 1);
	if (!BAThordered(i)) {
		BUN r, s;

		BATloop(i, r, s) {
			oid v = *(oid *) BUNhead(ii, r);

			if (v > o)
				o = v;
		}
	}
	return o;
}

@+ BUNappend
The BUNappend function can be used to add a single value to void and oid  
headed bats. The new head value will be a unique number, (max(bat)+1). 
@c
BAT *
BUNappend(BAT *b, ptr t, bit force)
{
	BUN i;
	BUN p;
	BAT *bm;
	ptr h = NULL;
	oid id = 0;
	int countonly;
	size_t hsize = 0, tsize = 0;

	BATcheck(b, "BUNappend");

	if (b->htype != TYPE_void && b->htype != TYPE_oid) {
		GDKerror("BUNappend: can only append to void and oid bats\n");
		return NULL;
	}

	bm = BBP_cache(-b->batCacheid);
	if ((b->tkey & BOUND2BTRUE) && BUNfnd(bm, t) != BUN_NONE) {
		return b;
	}

	p = BUNlast(b);		/* insert at end */
	if (p == BUN_MAX || b->batCount == BUN_MAX) {
		GDKerror("BUNappend: bat too large\n");
		return NULL;
	}

	i = p;
	ALIGNapp(b, "BUNappend", force);
	b->batDirty = 1;
	countonly = (b->htype == TYPE_void && b->ttype == TYPE_void);
	if (b->H->hash && b->H->vheap)
		hsize = b->H->vheap->size;
	if (b->T->hash && b->T->vheap)
		tsize = b->T->vheap->size;

	if (p > b->batFirst) {
		BATiter bi = bat_iterator(b);

		if (b->htype == TYPE_oid) {
			h = &id;
			id = MAXoid(b) + 1;
		}
		if (b->ttype != TYPE_void) {
			int cmp = 0;

			if (b->tsorted & 1) {
				ptr prv = BUNtail(bi, p - 1);

				cmp = atom_CMP(t, prv, b->ttype);
				if (cmp < 0) {
					b->T->nosorted = i;
					b->tsorted = FALSE;
					if (b->tdense & 1) {
						b->tdense = FALSE;
						b->T->nodense = i;
					}
				} else if (cmp && b->tdense && *(oid *) t != 1 + *(oid *) prv) {
					b->T->nodense = i;
					b->tdense = FALSE;
				}
				/* as nil < any, we only need to 
				 * check on second BUNins if the 
				 * first was nil */
				if (i == 2 && cmp > 0) {	/* StM: i==1 ? */
					int tt = b->ttype;

					cmp = atom_CMP(prv, ATOMnilptr(tt), tt);
					if (cmp == 0) {
						b->T->nosorted = 1;
						b->tsorted = FALSE;
						if (b->tdense & 1) {
							b->tdense = FALSE;
							b->T->nodense = 1;
						}
					}
				}
				if (b->tkey == TRUE && cmp <= 0) {
					/* cmp==0: definitely not key,
					 * cmd<0: we don't know */
					b->T->nokey[0] = i - 1;
					b->T->nokey[1] = i;
					b->tkey = bm->hkey = b->tdense = FALSE;
				}
			} else if (b->tsorted == (bit) GDK_SORTED_REV) {
				ptr prv = BUNtail(bi, p - 1);

				cmp = atom_CMP(t, prv, b->ttype);
				if (cmp > 0) {
					b->T->nosorted_rev = i;
					b->tsorted = FALSE;
				}
				if (b->tkey == TRUE && cmp >= 0) {
					/* cmp==0: definitely not key,
					 * cmd>0: we don't know */
					b->T->nokey[0] = i - 1;
					b->T->nokey[1] = i;
					b->tkey = bm->hkey = b->tdense = FALSE;
				}
			} else if (b->tkey == TRUE) {
				/* we don't know anything, so unset key */
				b->T->nokey[0] = i - 1;
				b->T->nokey[1] = i;
				b->tkey = bm->hkey = b->tdense = FALSE;
			}
		} else if (b->tseqbase != oid_nil) {	/* virtual ids */
			if (b->tseqbase + b->batCount != *(oid *) t) {
				BUN cnt = b->batCount;

				b = BATmaterializet(b);
				countonly = 0;
				if (b == NULL)
					return NULL;
				b->T->nodense = cnt;
				b->tdense = FALSE;
				if (b->tsorted & 1) {
					if (b->tseqbase + cnt > *(oid *) t || *(oid *) t == oid_nil) {
						b->T->nosorted = 1;
						b->tsorted = FALSE;
						if (b->tdense & 1) {
							b->tdense = FALSE;
							b->T->nodense = 1;
						}

						b->T->nokey[0] = cnt - 1;
						b->T->nokey[1] = cnt;
						b->tkey = bm->hkey = b->tdense = FALSE;
					}
				} else if (b->tsorted == (bit) GDK_SORTED_REV) {
					if (b->tseqbase + cnt < *(oid *) t) {
						b->T->nosorted_rev = 1;
						b->tsorted = FALSE;

						b->T->nokey[0] = cnt - 1;
						b->T->nokey[1] = cnt;
						b->tkey = bm->hkey = b->tdense = FALSE;
					}
				}
			}
		}
	} else {
		b->hkey = bm->tkey |= TRUE;

		if (b->htype == TYPE_oid) {	/* empty oid column */
			h = &id;
			id = 0;

			b->hdense = TRUE;
			b->hseqbase = bm->tseqbase = *(oid *) h;
		}
		if (b->ttype == TYPE_oid) {
			b->tkey = bm->hkey |= b->tdense = TRUE;
			b->tseqbase = bm->hseqbase = *(oid *) t;
		} else if (b->ttype == TYPE_void && b->tseqbase != oid_nil) {
			if (*(oid *) t == oid_nil) {
				b = BATmaterializet(b);
				countonly = 0;
				if (b == NULL)
					return NULL;
			} else {
				b->tseqbase = bm->hseqbase = *(oid *) t;
			}
		} else if (b->ttype) {
			b->tkey = bm->hkey |= TRUE;
		}
	}
	if (b->T->nonil)
		b->T->nonil = t && atom_CMP(t, ATOMnilptr(b->ttype), b->ttype) != 0;
	if (!countonly) {
		bunfastins(b, h, t);
	} else {
		BATsetcount(b, b->batCount + 1);
	}

	/* first adapt the hashes; then the user-defined accelerators.
	 * REASON: some accelerator updates (qsignature) use the hashes! 
	 */
	if (b->H->hash && h) {
		HASHins(b, i, h);
		if (hsize && hsize != b->H->vheap->size)
			HEAPwarm(b->H->vheap);
	}
	if (b->T->hash) {
		HASHins(bm, i, t);

		if (tsize && tsize != b->T->vheap->size)
			HEAPwarm(b->T->vheap);
	}
	return b;
      bunins_failed:
	return NULL;
}


@- BUN Delete
Deletes should maintain the BAT as a contiguous array. This
implementation permits using a BATloop for(;;) construction
to use the BUNdelete routines, by not modifying what is in
front of the deleted bun. 

This routine returns the next BUN in b after deletion of p.
Note: to cause less trouble when updating BATs with void columns
the delete policy has been changed. Deleted volatile elements 
are now being overwritten by the last element; instead of causing 
a cascade of moves. The sequential deletability property
is changed somewhat: instead of doing 
@verbatim
	BATloop(b,p,q) BUNdelete(b,p,FALSE)
one now must do:
	BATloopDEL(b,p) p = BUNdelete(b,p,FALSE)
@end verbatim
@
@c
static inline BUN
BUNdelete_(BAT *b, BUN p, bit force)
{
	BATiter bi = bat_iterator(b);
	BAT *bm = BBP_cache(-b->batCacheid);
	BUN l, last = BUNlast(b) - 1;
	BUN idx1, idx2;

	ALIGNdel(b, "BUNdelete", force);	/* zap alignment info */

@- Committed Delete. 
Deleting a (committed) bun: the first and deleted swap position.
@c
	if (p < b->batInserted && !force) {
		idx1 = p;
		if (p == b->batFirst) {	/* first can simply be discarded */
			@:hacc_update(del,head,p,idx1)@
			@:tacc_update(del,tail,p,idx1)@

			if (BAThdense(b)) {
				bm->tseqbase = ++b->hseqbase;
			}
			if (BATtdense(b)) {
				bm->hseqbase = ++b->tseqbase;
			}
		} else {
			unsigned short hs = Hsize(b), ts = Tsize(b);

			@:hacc_update(del,head,p,idx1)@
			@:tacc_update(del,tail,p,idx1)@

			l = BUNfirst(b);
			idx2 = l;
			@:acc_move(l,p,idx2,idx1)@
			if (b->hsorted & 1) {
				b->hsorted = FALSE;
				b->H->nosorted = idx1;
			} else if (b->hsorted == (bit) GDK_SORTED_REV) {
				b->hsorted = FALSE;
				b->H->nosorted_rev = idx1;
			}
			if (b->hdense) {
				b->hdense = FALSE;
				b->H->nodense = idx1;
			}
			if (b->tsorted & 1) {
				b->tsorted = FALSE;
				b->T->nosorted = idx1;
			} else if (b->tsorted == (bit) GDK_SORTED_REV) {
				b->tsorted = FALSE;
				b->T->nosorted_rev = idx1;
			}
			if (b->tdense) {
				b->tdense = FALSE;
				b->T->nodense = idx1;
			}
		}
		b->batFirst++;
	} else {
@- Uncommitted Delete.
This bun was not committed, and should therefore disappear. The 
last inserted bun (if present) is copied over it. 
@c
		int (*hunfix) (ptr) = BATatoms[b->htype].atomUnfix;
		int (*tunfix) (ptr) = BATatoms[b->ttype].atomUnfix;
		void (*hatmdel) (Heap *, var_t *) = BATatoms[b->htype].atomDel;
		void (*tatmdel) (Heap *, var_t *) = BATatoms[b->ttype].atomDel;

		if (hunfix) {
			(*hunfix) (BUNhead(bi, p));
		}
		if (tunfix) {
			(*tunfix) (BUNtail(bi, p));
		}
		if (hatmdel) {
			assert(b->H->width == sizeof(var_t));
			(*hatmdel) (b->H->vheap, (var_t *) BUNhloc(bi, p));
		}
		if (tatmdel) {
			assert(b->T->width == sizeof(var_t));
			(*tatmdel) (b->T->vheap, (var_t *) BUNtloc(bi, p));
		}
		idx1 = p;
		@:hacc_update(del,head,p,idx1)@
		@:tacc_update(del,tail,p,idx1)@
		idx2 = last;
		if (p != last) {
			unsigned short hs = Hsize(b), ts = Tsize(b);
			BATiter bi2 = bat_iterator(b);

			@:acc_move(last,p,idx2,idx1)@
			/* If a column was sorted before the BUN was
			   deleted, check whether it is still sorted
			   afterward.  This is done by comparing the
			   value that was put in place of the deleted
			   value is still ordered correctly with
			   respect to the following value.  Note that
			   if p+1==last, the new value is now the
			   last, so no comparison is needed. */
			if (b->hsorted & 1) {
				if (p + 1 < last && ATOMcmp(b->htype, BUNhead(bi, p), BUNhead(bi2, p + 1)) > 0) {
					b->hsorted = FALSE;
					b->H->nosorted = idx1;
				}
				if (b->hdense) {
					b->hdense = FALSE;
					b->H->nodense = idx1;
				}
			} else if (b->hsorted == (bit) GDK_SORTED_REV) {
				if (p + 1 < last && ATOMcmp(b->htype, BUNhead(bi, p), BUNhead(bi2, p + 1)) < 0) {
					b->hsorted = FALSE;
					b->H->nosorted_rev = idx1;
				}
			}
			if (b->tsorted & 1) {
				if (p + 1 < last && ATOMcmp(b->ttype, BUNtail(bi, p), BUNtail(bi2, p + 1)) > 0) {
					b->tsorted = FALSE;
					b->H->nosorted = idx1;
				}
				if (b->tdense) {
					b->tdense = FALSE;
					b->T->nodense = idx1;
				}
			} else if (b->tsorted == (bit) GDK_SORTED_REV) {
				if (p + 1 < last && ATOMcmp(b->ttype, BUNtail(bi, p), BUNtail(bi2, p + 1)) < 0) {
					b->tsorted = FALSE;
					b->H->nosorted_rev = idx1;
				}
			}
		}
		b->H->heap.free -= Hsize(b);
		b->T->heap.free -= Tsize(b);
		p--;
	}
	b->batCount--;
	b->batDirty = 1;	/* bat is dirty */
	return p;
}

BUN
BUNdelete(BAT *b, BUN p, bit force)
{
	if (p == BUN_NONE) {
		return p;
	}
	if ((b->htype == TYPE_void && b->hseqbase != oid_nil) || (b->ttype == TYPE_void && b->tseqbase != oid_nil)) {
		BUN last = BUNlast(b) - 1;

		if ((p < b->batInserted || p != last) && !force) {
			b = BATmaterialize(b);
			if (b == NULL)
				return BUN_NONE;
		}
	}
	return BUNdelete_(b, p, force);
}

BAT *
BUNdel(BAT *b, ptr x, ptr y, bit force)
{
	BUN p;

	BATcheck(b, "BUNdel");
	BATcheck(x, "BUNdel: head value is nil");

	if ((p = BUNlocate(b, x, y)) != BUN_NONE) {
		ALIGNdel(b, "BUNdel", force);	/* zap alignment info */
		BUNdelete(b, p, force);
		return b;
	}
	return 0;
}

@- 
The routine @%BUNdelHead@ is similar, but removes all BUNs whose head matches
the argument passed.
@c
BAT *
BUNdelHead(BAT *b, ptr x, bit force)
{
	BUN p;

	BATcheck(b, "BUNdelHead");

	if (x == NULL) {
		x = ATOMnilptr(b->htype);
	}
	if ((p = BUNfnd(b, x)) != BUN_NONE) {
		ALIGNdel(b, "BUNdelHead", force);	/* zap alignment info */
		do {
			BUNdelete(b, p, force);
		} while ((p = BUNfnd(b, x)) != BUN_NONE);
	}
	return b;
}

@
Deletion of strings leads to garbage on the variable stack.
This can be removed by compaction of the BAT through copying it.

@-  BUN replace
The last operation in this context is BUN replace. It assumes that
the header denotes a key. The old value association is destroyed (if it
exists in the first place) and the new value takes its place.

In order to make updates on void columns workable; replaces on them 
are always done in-place. Performing them without bun-movements 
greatly simplifies the problem. The 'downside' is that when transaction
management has to be performed, replaced values should be saved 
explicitly.

@= uncommit_replace
	@:tacc_update(del,t@1,p,pit)@
	Treplacevalue(b, BUNtloc(bi, p), t);
	@:tacc_update(ins,t@1,p,pit)@
	if (BATtordered(b) & 1 || BATtordered(b) == (bit) GDK_SORTED_REV) {
		int tt = b->ttype;
		BUN prv = p > b->batFirst ? p - 1 : BUN_NONE;
		BUN nxt = p < last ? p + 1 : BUN_NONE;

		if (BATtordered(b) & 1) {
			if ((prv != BUN_NONE && ATOMcmp(tt, t, BUNt@1(bi,prv)) < 0) ||
			    (nxt != BUN_NONE && ATOMcmp(tt, t, BUNt@1(bi,nxt)) > 0)) {
				b->tsorted = FALSE;
				b->T->nosorted = pit;
			} else if (b->ttype != TYPE_void && b->tdense) {
				if (((prv != BUN_NONE && 1 + * (oid *) BUNtloc(bi, prv) != * (oid *) t) ||
				     (nxt != BUN_NONE && * (oid *) BUNtloc(bi, nxt) != 1 + * (oid *) t))) {
					b->tdense = FALSE;
					b->T->nodense = pit;
				} else if (prv == BUN_NONE && nxt == BUN_NONE) {
					bm->hseqbase = b->tseqbase = * (oid *) t;
				}
			}
		} else {
			if ((prv != BUN_NONE && ATOMcmp(tt, t, BUNt@1(bi, prv)) > 0) ||
			    (nxt != BUN_NONE && ATOMcmp(tt, t, BUNt@1(bi, nxt)) < 0)) {
				b->tsorted = FALSE;
				b->T->nosorted_rev = pit;
			}
		}
	}
@c
BAT *
BUNinplace(BAT *b, BUN p, ptr h, ptr t, bit force)
{
	if (p >= b->batInserted || force) {
		/* uncommitted BUN elements */
		BUN last = BUNlast(b) - 1;
		BAT *bm = BBP_cache(-b->batCacheid);
		BUN pit = p;
		BATiter bi = bat_iterator(b);

		ALIGNinp(b, "BUNreplace", force);	/* zap alignment info */
		if (b->tvarsized) {
			size_t tsize = b->T->vheap->size;

			@:uncommit_replace(var)@
			if (b->T->hash && tsize != b->T->vheap->size)
				HEAPwarm(b->T->vheap);
		} else {
			@:uncommit_replace(loc)@
		}
		if (((b->ttype != TYPE_void) & b->tkey & !(b->tkey & BOUND2BTRUE)) && b->batCount > 1) {
			BATkey(bm, FALSE);
		}
		if (b->T->nonil)
			b->T->nonil = t && atom_CMP(t, ATOMnilptr(b->ttype), b->ttype) != 0;
		b->T->heap.dirty = TRUE;
		if (b->T->vheap)
			b->T->vheap->dirty = TRUE;
	} else {
		/* committed BUN */
		BUNdelete(b, p, force);
		if (BUNins(b, h, t, force) == NULL) {
		      bunins_failed:
			return NULL;
		}
	}
	return b;
}

BAT *
BUNreplace(BAT *b, ptr h, ptr t, bit force)
{
	BUN p;

	BATcheck(b, "BUNreplace");
	BATcheck(h, "BUNreplace: head value is nil");
	BATcheck(t, "BUNreplace: tail value is nil");

	if ((p = BUNfnd(b, h)) == BUN_NONE)
		return b;

	if ((b->tkey & BOUND2BTRUE) && BUNfnd(BATmirror(b), t) != BUN_NONE) {
		return b;
	}
	if (b->ttype == TYPE_void) {
		BUN i;

		/* no need to materialize if value doesn't change */
		if (b->tseqbase == oid_nil || (b->hseqbase + p) == *(oid *) t)
			return b;
		i = p;
		b = BATmaterializet(b);
		if (b == NULL)
			return NULL;
		p = i;
	}

	return BUNinplace(b, p, h, t, force);
}

int
void_inplace(BAT *b, oid id, ptr val, bit force)
{
	int res = GDK_SUCCEED;
	BUN p = BUN_NONE;
	BUN oldInserted = b->batInserted;
	BATiter bi = bat_iterator(b);

	assert(b->htype == TYPE_void);
	assert(b->hseqbase != oid_nil);
	assert(b->batCount > (id -b->hseqbase));

	b->batInserted = 0;
	BUNfndVOID(p, bi, (ptr) &id);

	assert(p >= b->batInserted);	/* we don't want delete/ins */
	assert(force || !b->batRestricted);
	if (!BUNinplace(b, p, (ptr) &id, val, force))
		 res = GDK_FAIL;

	b->batInserted = oldInserted;
	return res;
}

BUN
void_replace_bat(BAT *b, BAT *u, bit force)
{
	BUN nr = 0;
	BUN r, s;
	BATiter ui = bat_iterator(u);

	BATaccessBegin(u, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
	BATloop(u, r, s) {
		oid updid = *(oid *) BUNhead(ui, r);
		ptr val = BUNtail(ui, r);

		if (void_inplace(b, updid, val, force) == GDK_FAIL)
			return BUN_NONE;
		nr++;
	}
	BATaccessEnd(u, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
	return nr;
}

@- BUN Lookup
Location of a BUN using a value should use the available indexes
to speed up access. If indexes are lacking then a hash index
is constructed under the assumption that 1) multiple access to the BAT 
can be expected and 2) building the hash is only slightly more expensive
than the full linear scan.
BUN_NONE is returned if no such element could be found.
In those cases where the type is known and a hash index is available,
one should use the inline functions to speed-up processing.
@c
BUN
BUNfnd(BAT *b, ptr v)
{
	BUN r = BUN_NONE;
	BATiter bi = bat_iterator(b);

	BATcheck(b, "BUNfnd");
	if (!v)
		return r;
	if (BAThvoid(b)) {
		BUNfndVOID(r, bi, v);
		return r;
	}
	if (!b->H->hash) {
		if (BAThordered(b) & 1)
			return (BUN) SORTfnd(b, v);
	}
	switch (ATOMstorage(b->htype)) {
	case TYPE_chr:
		HASHfnd_chr(r, bi, v);
		break;
	case TYPE_bte:
		HASHfnd_bte(r, bi, v);
		break;
	case TYPE_sht:
		HASHfnd_sht(r, bi, v);
		break;
	case TYPE_int:
	case TYPE_flt:
		HASHfnd_int(r, bi, v);
		break;
	case TYPE_dbl:
	case TYPE_lng:
		HASHfnd_lng(r, bi, v);
		break;
	case TYPE_str:
		HASHfnd_str(r, bi, v);
		break;
	default:
		HASHfnd(r, bi, v);
	}
	return r;
}

@= swap
	{
		int (*_cmp) (ptr, ptr);
		ptr _p;

		_cmp = hcmp;
		hcmp = tcmp;
		tcmp = _cmp;
		_p = x;
		x = y;
		y = _p;
		bi.b = b = BATmirror(b);
	}	
			    
@= dohash
        ATOMstorage(@1->@2->type) != TYPE_chr && (ATOMstorage(@1->@2->type) != TYPE_str || !GDK_ELIMDOUBLES(@1->@2->vheap)) 
@c
BUN
BUNlocate(BAT *b, ptr x, ptr y)
{
	BATiter bi = bat_iterator(b);
	int (*hcmp) (ptr, ptr), (*tcmp) (ptr, ptr);
	int htpe, ttpe, hint = 0, tint = 0, hlng = 0, tlng = 0;
	union {
		var_t v;
		int i;
		lng l;
	} hidx, tidx;
	BUN p, q;
	BAT *v = NULL;

	BATcheck(b, "BUNlocate: BAT parameter required");
	BATcheck(x, "BUNlocate: value parameter required");
	hcmp = BATatoms[b->htype].atomCmp;
	tcmp = BATatoms[b->ttype].atomCmp;
	p = BUNfirst(b);
	q = BUNlast(b);
	if (p == q)
		return BUN_NONE;	/* empty bat */

	/* sometimes BUNlocate is just about a single column */
	if (y &&
	    ((BAThordered(b) & 1) &&
	     (*hcmp) (x, BUNhead(bi, p)) == 0 &&
	     (*hcmp) (x, BUNhead(bi, q - 1)) == 0))
		@:swap()@
	if (y == NULL ||
	    ((BATtordered(b) & 1) &&
	     (*tcmp) (y, BUNtail(bi, p)) == 0 &&
	     (*tcmp) (y, BUNtail(bi, q - 1)) == 0)) {
		return BUNfnd(b, x);
	}

	/* positional lookup is always the best choice */
	if (BATtdense(b))
		@:swap()@
	if (BAThdense(b)) {
		BUN i = (BUN) (*(oid *) x - b->hseqbase);

		if (i < b->batCount) {
			i += BUNfirst(b);
			p = i;
			if ((*tcmp) (y, BUNtail(bi, p)) == 0)
				return p;
		}
		return BUN_NONE;
	}

	/* next, try to restrict the range using sorted columns */
	if (BATtordered(b) & 1) {
		p = SORTfndfirst(b, y);
		q = SORTfndlast(b, y);
	}
	if (BAThordered(b) & 1) {
		BUN mp = SORTfndfirst(BATmirror(b), x);
		BUN mq = SORTfndlast(BATmirror(b), x);

		if (mp > p)
			p = mp;
		if (mq < p)
			q = mq;
	}
	if (p >= q)
		return BUN_NONE;	/* value combination cannot occur */

	/* if the range is still larger than 32 BUNs, consider investing in a hash table */
	if ((q - p) > (1 << 5)) {
		/* regrettably MonetDB support only single-column hashes 
		 * strategy: create a hash on both columns, and select the column with the best distribution
		 */
		if ((b->T->hash && b->H->hash == NULL) || !(@:dohash(b,H)@))
			@:swap()@
		if (b->H->hash == NULL && (v = VIEWcreate_(b, b, TRUE)) != NULL) {
			/* As we are going to remove the worst hash table later, we must do everything 
			 * in a view, as it is not permitted to remove a hash table from a read-only 
			 * operation (like BUNlocate). Other threads might then crash. 
			 */
			if (@:dohash(v,H)@)
				(void) BATprepareHash(v);
			if (@:dohash(v,T)@)
				(void) BATprepareHash(BATmirror(v));
			if (v->H->hash && v->T->hash) {	/* we can choose between two hash tables */
				BUN hcnt = 0, tcnt = 0;
				BUN i;

				for (i = 0; i <= v->H->hash->mask; i++)
					hcnt += (v->H->hash->hash[i] != BUN_NONE);
				for (i = 0; i <= v->T->hash->mask; i++)
					tcnt += (v->T->hash->hash[i] != BUN_NONE);
				if (hcnt < tcnt) {
					@:swap()@
					v = BATmirror(v);
				}
				/* remove the least selective hash table */
				HASHremove(BATmirror(v));
			}
			if (v->H->hash == NULL) {
				@:swap()@
				v = BATmirror(v);
			}
			if (v->H->hash) {
				gdk_set_lock(GDKhashLock(ABS(b->batCacheid) & BBP_BATMASK), "BUNlocate");
				if (b->H->hash == NULL) {	/* give it to the parent */
					b->H->hash = v->H->hash;
				}
				gdk_unset_lock(GDKhashLock(ABS(b->batCacheid) & BBP_BATMASK), "BUNlocate");
			}
			BBPreclaim(v);
			v = NULL;
		}
	}

	/* exploit string double elimination, when present */
	htpe = ATOMstorage(b->htype);
	ttpe = ATOMstorage(b->ttype);
	if (htpe == TYPE_str && GDK_ELIMDOUBLES(b->H->vheap) && b->H->width > 2) {
		hidx.v = strLocate(b->H->vheap, x);
		if (hidx.v == 0)
			return BUN_NONE;	/* x does not occur */
		if (b->H->hash == NULL) {
			switch (b->H->width) {
			case SIZEOF_INT:
				hidx.i = (int) hidx.v;
				x = &hidx.i;
				htpe = TYPE_int;
				break;
			case SIZEOF_LNG:
				hidx.l = (lng) hidx.v;
				x = &hidx.l;
				htpe = TYPE_lng;
				break;
			}
		}
	}
	if (ttpe == TYPE_str && GDK_ELIMDOUBLES(b->T->vheap) && b->T->width > 2) {
		tidx.v = strLocate(b->T->vheap, y);
		if (tidx.v == 0)
			return BUN_NONE;	/* y does not occur */
		if (b->T->hash == NULL) {
			switch (b->T->width) {
			case SIZEOF_INT:
				tidx.i = (int) tidx.v;
				y = &tidx.i;
				ttpe = TYPE_int;
				break;
			case SIZEOF_LNG:
				tidx.l = (lng) tidx.v;
				y = &tidx.l;
				ttpe = TYPE_lng;
				break;
			}
		}
	}

	/* type analysis. For equi-lookup {flt,dbl,wrd,oid} can all be treated as either int or lng */
	if (!ATOMvarsized(htpe)) {
		hint = (ATOMsize(htpe) == sizeof(int));
		hlng = (ATOMsize(htpe) == sizeof(lng));
	}
	if (!ATOMvarsized(ttpe)) {
		tint = (ATOMsize(ttpe) == sizeof(int));
		tlng = (ATOMsize(ttpe) == sizeof(lng));
	}

	/* hashloop over head values, check tail values */
	if (b->H->hash) {
		BUN h;

		if (hint && tint) {
			HASHloop_int(bi, b->H->hash, h, x)
			    if (*(int *) y == *(int *) BUNtloc(bi, h))
				return h;
		} else if (hint && tlng) {
			HASHloop_int(bi, b->H->hash, h, x)
			    if (*(lng *) y == *(lng *) BUNtloc(bi, h))
				return h;
		} else if (hlng && tint) {
			HASHloop_lng(bi, b->H->hash, h, x)
			    if (*(int *) y == *(int *) BUNtloc(bi, h))
				return h;
		} else if (hlng && tlng) {
			HASHloop_lng(bi, b->H->hash, h, x)
			    if (*(lng *) y == *(lng *) BUNtloc(bi, h))
				return h;
		} else {
			HASHloop(bi, b->H->hash, h, x)
			    if ((*tcmp) (y, BUNtail(bi, h)) == 0)
				return h;
		}
		return BUN_NONE;
	}

	/* linear check; we get here for small ranges, [chr,chr] bats, and hash alloc failure */
	if (ATOMstorage(b->htype) == TYPE_chr && ATOMstorage(b->ttype) == TYPE_chr) {
		for (; p < q; p++)
			if (*(chr *) BUNhloc(bi, p) == *(chr *) x &&
			    *(chr *) BUNtloc(bi, p) == *(chr *) y)
				return p;
	} else if (hint && tint) {
		for (; p < q; p++)
			if (*(int *) BUNhloc(bi, p) == *(int *) x &&
			    *(int *) BUNtloc(bi, p) == *(int *) y)
				return p;
	} else if (hint && tlng) {
		for (; p < q; p++)
			if (*(int *) BUNhloc(bi, p) == *(int *) x &&
			    *(lng *) BUNtloc(bi, p) == *(lng *) y)
				return p;
	} else if (hlng && tint) {
		for (; p < q; p++)
			if (*(lng *) BUNhloc(bi, p) == *(lng *) x &&
			    *(int *) BUNtloc(bi, p) == *(int *) y)
				return p;
	} else if (hlng && tlng) {
		for (; p < q; p++)
			if (*(lng *) BUNhloc(bi, p) == *(lng *) x &&
			    *(lng *) BUNtloc(bi, p) == *(lng *) y)
				return p;
	} else {
		for (; p < q; p++)
			if ((*hcmp) (x, BUNhead(bi, p)) == 0 &&
			    (*tcmp) (y, BUNtail(bi, p)) == 0)
				return p;
	}
	return BUN_NONE;
}

@}


@+ BAT Property Management

The function @%BATcount@ returns the number of active elements in a BAT.
Counting is type independent.
It can be implemented quickly, because the system ensures a dense
BUN list.
@{
@c
void
BATsetcapacity(BAT *b, BUN cnt)
{
	b->U->capacity = cnt;
	assert(b->batCount <= cnt);
}

void
BATsetcount(BAT *b, BUN cnt)
{
	b->batCount = cnt;
	b->batDirtydesc = TRUE;
	b->H->heap.free = headsize(b, BUNfirst(b) + cnt);
	b->T->heap.free = tailsize(b, BUNfirst(b) + cnt);
	if (b->H->type == TYPE_void && b->T->type == TYPE_void)
		b->batCapacity = cnt;
	assert(b->batCapacity >= cnt);
}

@-
The alternative routine is @%BATbuncount@, which calculates the
total buns in use.
@c
BUN
BATbuncount(BAT *b)
{
	BATcheck(b, "BATbuncount");
	return BUNlast(b);
}

size_t
BATvmsize(BAT *b, int dirty)
{
	BATcheck(b, "BATvmsize");
	if (b->batDirty || (b->batPersistence != TRANSIENT && !b->batCopiedtodisk))
		dirty = 0;
	return ((dirty == 0 || b->H->heap.dirty) ? HEAPvmsize(&b->H->heap) : 0) +
		((dirty == 0 || b->T->heap.dirty) ? HEAPvmsize(&b->T->heap) : 0) +
		(((dirty == 0 || b->H->heap.dirty) && b->H->hash) ? HEAPvmsize(b->H->hash->heap) : 0) +
		(((dirty == 0 || b->T->heap.dirty) && b->T->hash) ? HEAPvmsize(b->T->hash->heap) : 0) +
		((b->H->vheap && (dirty == 0 || b->H->vheap->dirty)) ? HEAPvmsize(b->H->vheap) : 0) +
		((b->T->vheap && (dirty == 0 || b->T->vheap->dirty)) ? HEAPvmsize(b->T->vheap) : 0);
}

size_t
BATmemsize(BAT *b, int dirty)
{
	BATcheck(b, "BATmemsize");
	if (b->batDirty || (b->batPersistence != TRANSIENT && !b->batCopiedtodisk))
		dirty = 0;
	return ((dirty == 0 || b->batDirtydesc) ? sizeof(BATstore) : 0) +
		((dirty == 0 || b->H->heap.dirty) ? HEAPmemsize(&b->H->heap) : 0) +
		((dirty == 0 || b->T->heap.dirty) ? HEAPmemsize(&b->T->heap) : 0) +
		(((dirty == 0 || b->H->heap.dirty) && b->H->hash) ? HEAPmemsize(b->H->hash->heap) : 0) +
		(((dirty == 0 || b->T->heap.dirty) && b->T->hash) ? HEAPmemsize(b->T->hash->heap) : 0) +
		((b->H->vheap && (dirty == 0 || b->H->vheap->dirty)) ? HEAPmemsize(b->H->vheap) : 0) +
		((b->T->vheap && (dirty == 0 || b->T->vheap->dirty)) ? HEAPmemsize(b->T->vheap) : 0);
}

@
@}
@-
The key and name properties can be changed at any time.
Keyed dimensions are automatically supported by an auxiliary hash-based
access structure to speed up searching. Turning off the key integrity 
property does not cause the index to disappear. It can still be used to
speed-up retrieval. The routine @%BATkey@ sets the key property of the
association head. 

@{
@c
BAT *
BATkey(BAT *b, int flag)
{
	bat parent;

	BATcheck(b, "BATkey");
	parent = VIEWparentcol(b);
	if (b->htype == TYPE_void) {
		if (b->hseqbase == oid_nil && flag == BOUND2BTRUE) {
			GDKerror("BATkey: nil-column cannot be kept unique.\n");
		}
		if (b->hseqbase != oid_nil && flag == FALSE) {
			GDKerror("BATkey: dense column must be unique.\n");
		}
		if (b->hseqbase == oid_nil || flag == FALSE) {
			return b;
		}
	}
	if (flag)
		flag |= (1 | b->hkey);
	if (b->hkey != flag)
		b->batDirtydesc = TRUE;
	b->hkey = flag;
	if (!flag)
		b->hdense = 0;
	if (flag && parent && ALIGNsynced(b, BBP_cache(parent)))
		BATkey(BBP_cache(parent), TRUE);
	return b;
}


BAT *
BATset(BAT *b, int flag)
{
	BATcheck(b, "BATset");
	if (b->htype == TYPE_void) {
		if (b->hseqbase == oid_nil && flag == BOUND2BTRUE)
			BATkey(BATmirror(b), flag);
	} else if (b->ttype == TYPE_void) {
		if (b->tseqbase == oid_nil && flag == BOUND2BTRUE)
			BATkey(b, flag);
	} else {
		if (flag)
			flag = TRUE;
		if (b->batSet != flag)
			b->batDirtydesc = TRUE;
		b->batSet = flag;
	}
	return b;
}

BAT *
BATseqbase(BAT *b, oid o)
{
	BATcheck(b, "BATseqbase");
	if (ATOMtype(b->htype) == TYPE_oid) {
		if (b->hseqbase != o) {
			b->batDirtydesc = TRUE;
			/* zap alignment if column is changed by new seqbase */
			if (b->htype == TYPE_void)
				b->halign = 0;
		}
		b->hseqbase = o;

		/* adapt keyness */
		if (BAThvoid(b)) {
			if (o == oid_nil) {
				if (b->hkey)
					b->hkey = FALSE;
				b->H->nonil = 0;
				b->H->nil = 1;
			} else {
				if (!b->hkey) {
					b->hkey = TRUE;
					b->H->nokey[0] = b->H->nokey[1] = 0;
					b->H->nonil = 1;
					b->H->nil = 0;
				}
			}
		}
	}
	return b;
}

@}
@- 
BATs have a logical name that is independent of their 
location in the file system (this depends on batCacheid).
The dimensions of the BAT can be given a separate name.
It helps front-ends in identifying the column of interest.
The new name should be recognizable as an identifier.
Otherwise interaction through the front-ends becomes
complicated.
@{
@c
int
BATname(BAT *b, const char *nme)
{
	BATcheck(b, "BATname");
	return BBPrename(b->batCacheid, nme);
}

str
BATrename(BAT *b, const char *nme)
{
	int ret;

	BATcheck(b, "BATrename");
	ret = BATname(b, nme);
	if (ret == 1) {
		GDKerror("BATrename: identifier expected: %s\n", nme);
	} else if (ret == BBPRENAME_ALREADY) {
		GDKerror("BATrename: name is in use: '%s'.\n", nme);
	} else if (ret == BBPRENAME_ILLEGAL) {
		GDKerror("BATrename: illegal temporary name: '%s'\n", nme);
	} else if (ret == BBPRENAME_LONG) {
		GDKerror("BATrename: name too long: '%s'\n", nme);
	}
	return BBPname(b->batCacheid);
}


BAT *
BATroles(BAT *b, const char *hnme, const char *tnme)
{
	BATcheck(b, "BATroles");
	if (b->hident && !default_ident(b->hident))
		GDKfree(b->hident);
	if (hnme)
		b->hident = GDKstrdup(hnme);
	else
		b->hident = BATstring_h;
	if (b->tident && !default_ident(b->tident))
		GDKfree(b->tident);
	if (tnme)
		b->tident = GDKstrdup(tnme);
	else
		b->tident = BATstring_t;
	return b;
}

BAT *
BATcol_name(BAT *b, const char *tnme)
{
	BATcheck(b, "BATcol_name");
	if (b->tident && !default_ident(b->tident))
		GDKfree(b->tident);
	if (tnme)
		b->tident = GDKstrdup(tnme);
	else
		b->tident = BATstring_t;
	return b;
}

@}

@+ BAT permissions, persistency and memory mapped heaps
The way large heaps are memory mapped is dependent both on the BAT persistency status (persistent or not)
as well as their update permissions (readonly,append-only,writable).

Let us recall the two main memory mapped file modes used to store heaps:
@multitable @columnfractions .12 .8
@item STORE_MMAP 
@tab files must be readonly, because you never know the exact saved status. 
      HEAPsave consists of the rather efficient msync(X).
@item STORE_PRIV 
@tab files modify pages in swap area, and can be writable. 
      HEAPsave actually does a full write(X.new), while the mapped file stays in X
@end multitable
Notice that PRIV storage is only required for persistent BATs that are already committed 
on disk. The crash-consistent state of transient BATs is irrelevant as they disappear
after a crash. Even the crash-consistency of persistent BATs that did not make their first
commit is not relevant as they also will disappear.

Also, some heaps may be in use with STORE_MMAP even if they are appendable, as we suppose our
code is bug-free and we know we won't modify the already committed parts of the mapped
file pages. For string-heaps append-bats may mmap the heap if doubles are not  being eliminated
anymore (i.e. when the contents of the builtin hash table at the start of the string heap
are not crucial anymore).
@{
@h
#define ATOMappendpriv(t,h) ((BATatoms[t].atomHeapCheck != HEAP_check || !HEAP_mmappable(h)) && \
			     (ATOMstorage(t) != TYPE_str || GDK_ELIMDOUBLES(h)))

@}
@- BATmmap
Changing the storage status of heaps in a BAT is done in @:BATmmap@. 
The new semantics is to do nothing: the new mapping only takes effect the next time the bat is loaded or extended. The latter is needed for loading large data
sets. These transient bats should switch cheaply between malloced and memory
mapped modes.

We modify the hp->storage fields using HEAPnewstorage and store that 
we want malloced or memory mapped heaps in special binary batMap fields 
that are used when the BAT descriptor is saved.
@{
@c
/* TODO niels: merge with BATsetmodes in gdk_storage */
#define STORE_MODE(m,r,e,s,f) (((m) == STORE_MEM)?STORE_MEM:((r)&&(e)&&!(f))||(s)==STORE_PRIV?STORE_PRIV:STORE_MMAP)
static void
HEAPnewstorage(BAT *b, int force)
{
	int existing = (BBPstatus(b->batCacheid) & BBPEXISTING);
	int brestrict = (b->batRestricted == BAT_WRITE);

	if (b->batMaphead) {
		b->H->heap.newstorage = STORE_MODE(b->batMaphead, brestrict, existing, b->H->heap.storage, force);
		if (force)
			b->H->heap.forcemap = 1;
	}
	if (b->batMaptail) {
		b->T->heap.newstorage = STORE_MODE(b->batMaptail, brestrict, existing, b->T->heap.storage, force);
		if (force)
			b->T->heap.forcemap = 1;
	}
	if (b->H->vheap && b->batMaphheap) {
		int hrestrict = (b->batRestricted == BAT_APPEND) && ATOMappendpriv(b->htype, b->H->vheap);
		b->H->vheap->newstorage = STORE_MODE(b->batMaphheap, brestrict || hrestrict, existing, b->H->vheap->storage, force);
		if (force)
			b->H->vheap->forcemap = 1;
	}
	if (b->T->vheap && b->batMaptheap) {
		int trestrict = (b->batRestricted == BAT_APPEND) && ATOMappendpriv(b->ttype, b->T->vheap);
		b->T->vheap->newstorage = STORE_MODE(b->batMaptheap, brestrict || trestrict, existing, b->T->vheap->storage, force);
		if (force)
			b->T->vheap->forcemap = 1;
	}
}

int
BATmmap(BAT *b, int hb, int tb, int hhp, int thp, int force)
{
	BATcheck(b, "BATmmap");
	IODEBUG THRprintf(GDKout, "#BATmmap(%s,%d,%d,%d,%d%s)\n", BATgetId(b), hb, tb, hhp, thp, force ? ",force" : "");

	/* Reverse back if required, as this determines which heap is saved in the 
	 * "hheap" file and which in the "theap" file.
	 */
	if (b->batCacheid < 0) {
		int swap = hb;
		hb = tb;
		tb = swap;
		swap = hhp;
		hhp = thp;
		thp = swap;
		b = BATmirror(b);
	}
	b->batMaphead = hb;
	b->batMaptail = tb;
	b->batMaphheap = hhp;
	b->batMaptheap = thp;
	HEAPnewstorage(b, force);
	b->batDirtydesc = 1;
	return 0;
}

@- BATmadvise
@= madvise
	if (@1 >= 0 && (@2) && @3 > 0 && (@2)->base &&
			((@2)->storage != STORE_MEM) && MT_madvise((@2)->base, @3, BUF_TO_MMAP[@1]))
	{
		GDKsyserror("madvise(%x, " SZFMT ", %d) on @2 @1 failed\n",
				(@2)->base, @3, @1);
		return -1;
	}
@c

static int BUF_TO_MMAP[] = {
	/* BUF_NORMAL     */ MMAP_NORMAL,
	/* BUF_RANDOM     */ MMAP_RANDOM,
	/* BUF_SEQUENTIAL */ MMAP_SEQUENTIAL,
	/* BUF_WILLNEED   */ MMAP_WILLNEED,
	/* BUF_DONTNEED   */ MMAP_DONTNEED
};

int
BATmadvise(BAT *b, int hb, int tb, int hhp, int thp)
{
	BATcheck(b, "BATmadvise");

	/* A varsized string heap never has sequential access, setting it is
	 * no good. */
	assert(!(ATOMstorage(b->htype) == TYPE_str && b->H->vheap && hhp == BUF_SEQUENTIAL));
	assert(!(ATOMstorage(b->ttype) == TYPE_str && b->T->vheap && thp == BUF_SEQUENTIAL));

	/* If the BAT is read-only, set the madvice for the actually used
	 * part of the BAT (e.g. till the free offset), else, apply the
	 * advice to the entire BAT (the size), since writing may extend to
	 * there */
	if (BAThrestricted(b) == BAT_READ) {
		@:madvise(hb,(&b->H->heap),(&b->H->heap)->free)@
		@:madvise(hhp,b->H->vheap,b->H->vheap->free)@
	} else {
		@:madvise(hb,(&b->H->heap),(&b->H->heap)->size)@
		@:madvise(hhp,b->H->vheap,b->H->vheap->size)@
	}
	if (BATtrestricted(b) == BAT_READ) {
		@:madvise(tb,(&b->T->heap),(&b->T->heap)->free)@
		@:madvise(thp,b->T->vheap,b->T->vheap->free)@
	} else {
		@:madvise(tb,(&b->T->heap),(&b->T->heap)->size)@
		@:madvise(thp,b->T->vheap,b->T->vheap->size)@
	}
	return 0;
}

@}
@- Change the BAT access permissions (read, append, write)
@verbatim
Regrettably, BAT access-permissions, persistent status and memory map 
modes, interact in ways that makes one's brain sizzle. This makes 
BATsetaccess and TMcommit (where a change in BAT persistence mode is 
made permanent) points in which the memory map status of bats needs 
to be carefully re-assessed and ensured. 

Another complication is the fact that during commit, concurrent users
may access the heaps, such that the simple solution unmap;re-map is out 
of the question.
Even worse, it is not possible to even rename an open mmap file in
Windows. For this purpose, we dropped the old .priv scheme, which relied
on file moves. Now, the file that is opened with mmap is always the
X file, in case of newstorage=STORE_PRIV, we save in a new file X.new

we must consider the following dimensions:

persistence:   
    not simply the current persistence mode but whether the bat *was*
    present at the last commit point (BBP status & BBPEXISTING).
    The crucial issue is namely whether we must guarantee recovery
    to a previous sane state.

access:    
    whether the BAT is BAT_READ or BAT_WRITE. Note that BAT_APPEND
    is ususally the same as BAT_READ (as our concern are only data pages
    that already existed at the last commit).

storage:
    the current way the heap file X is memory-mapped; 
    STORE_MMAP uses direct mapping (so dirty pages may be flushed
    at any time to disk), STORE_PRIV uses copy-on-write.

newstorage:    
    the current save-regime. STORE_MMAP calls msync() on the heap X,
    whereas STORE_PRIV writes the *entire* heap in a file: X.new
    If a BAT is loaded from disk, the field newstorage is used
    to set storage as well (so before change-access and commit-
    persistence mayhem, we always have newstorage=storage).

change-access: 
    what happens if the bat-access mode is changed from
    BAT_READ into BAT_WRITE (or vice versa).

commit-persistence: 
    what happens during commit if the bat-persistence mode was 
    changed (from TRANSIENT into PERSISTENT, or vice versa).

this is the scheme:

 persistence access    newstorage storage    change-access commit-persistence
 =========== ========= ========== ========== ============= ==================
0 transient  BAT_READ  STORE_MMAP STORE_MMAP =>2           =>4
1 transient  BAT_READ  STORE_PRIV STORE_PRIV =>3           =>5
2 transient  BAT_WRITE STORE_MMAP STORE_MMAP =>0           =>6+
3 transient  BAT_WRITE STORE_PRIV STORE_PRIV =>1           =>7
4 persistent BAT_READ  STORE_MMAP STORE_MMAP =>6+          =>0
5 persistent BAT_READ  STORE_PRIV STORE_PRIV =>7           =>1
6 persistent BAT_WRITE STORE_PRIV STORE_MMAP del X.new=>4+ del X.new;=>2+
7 persistent BAT_WRITE STORE_PRIV STORE_PRIV =>5           =>3

exception states:
a transient  BAT_READ  STORE_PRIV STORE_MMAP =>b           =>c
b transient  BAT_WRITE STORE_PRIV STORE_MMAP =>a           =>6
c persistent BAT_READ  STORE_PRIV STORE_MMAP =>6           =>a

(+) indicates that we must ensure that the heap gets saved in its new mode

Note that we now allow a heap with save-regime STORE_PRIV that was actually
mapped STORE_MMAP. In effect, the potential corruption of the X file 
is compensated by writing out full X.new files that take precedence. 
When transitioning out of this state towards one with both storage 
regime and OS as STORE_MMAP we need to move the X.new files into the
backup directory. Then msync the X file and (on success) remove the X.new; 
see backup_new().

Exception states are only reachable if the commit fails and those new
persistent bats have already been processed (but never become part
of a committed state). In that case a transition 2=>6 may end up 2=>b.
Exception states a and c are reachable from b.

Errors in HEAPchangeaccess() can be handled atomically inside the routine.  
The work on changing mmap modes HEAPcommitpersistence() is done during 
the BBPsync() for all bats that are newly persistent (BBPNEW). After the 
TMcommit(), it is done for those bats that are no longer persistent after 
the commit (BBPDELETED), only if it succeeds. 
Such transient bats cannot be processed before the commit, because the 
commit may fail and then the more unsafe transient mmap modes would be 
present on a persistent bat.

See dirty_bat() in BBPsync() -- gdk_bbp.mx and epilogue() in gdk_tm.mx

Including the exception states, we have 11 of the 16 combinations. As for the
5 avoided states, all four (persistence,access) states with (STORE_MMAP,STORE_PRIV)
are omitted (this would amount to an msync() save regime on a copy-on-write
heap -- which does not work). The remaining avoided state is the patently unsafe 
(persistent,BAT_WRITE,STORE_MMAP,STORE_MMAP).

Note that after a server restart exception states are gone, as on BAT loads 
the saved descriptor is inspected again (which will reproduce the state 
at the last succeeded commit).  

To avoid exception states, a TMsubcommit protocol would need to be used which 
is too heavy for BATsetaccess(). 

Note that this code is not about making heaps mmap-ed in the first place. 
It is just about determining which flavor of mmap should be used. The 
MAL user is oblivious of such details.

The route for making heaps mmapped in the first place (or make them no
longer so) is to request a mode change with BATmmap. The requested modes
are remembered in b->batMap*. At the next re-load of the BAT, they are applied
after a sanity check (DESCsetmodes() in gdk_storage.mx).
@end verbatim
@{
@c
/* rather than deleting X.new, we comply with the commit protocol and move it to backup storage */
static int
backup_new(Heap *hp, int lockbat)
{
	int batret, bakret, xx, ret = 0;
	long_str batpath, bakpath;
	struct stat st;

	/* file actions here interact with the global commits */
	for (xx = 0; xx <= lockbat; xx++)
		gdk_set_lock(GDKtrimLock(xx), "TMsubcommit");

	/* check for an existing X.new in BATDIR, BAKDIR and SUBDIR */
	GDKfilepath(batpath, BATDIR, hp->filename, ".new");
	GDKfilepath(bakpath, BAKDIR, hp->filename, ".new");
	batret = stat(batpath, &st);
	bakret = stat(bakpath, &st);

	if (batret == 0 && bakret) {
		/* no backup yet, so move the existing X.new there out of the way */
		ret = rename(batpath, bakpath);
		IODEBUG THRprintf(GDKout, "#rename(%s,%s) = %d\n", batpath, bakpath, ret);
	} else if (batret == 0) {
		/* there is a backup already; just remove the X.new */
		ret = unlink(batpath);
		IODEBUG THRprintf(GDKout, "#unlink(%s) = %d\n", batpath, ret);
	}
	for (xx = lockbat; xx >= 0; xx--)
		gdk_unset_lock(GDKtrimLock(xx), "TMsubcommit");
	return ret;
}

#define ACCESSMODE(wr,rd) ((wr)?BAT_WRITE:(rd)?BAT_READ:-1)

/* transition heap from readonly to writable */
static int
HEAPchangeaccess(Heap *hp, int dstmode, int existing)
{
	if (hp->storage == STORE_MMAP && hp->size >= MT_MMAP_TILE) {
		MT_mmap_inform(hp->base, hp->size, 0, 0, (dstmode == BAT_READ) ? -1 : 1);	/* inform vmtrim of the new mode */
	}
	if (hp->base == NULL || hp->newstorage == STORE_MEM || !existing || dstmode == -1)
		return hp->newstorage;	/* 0<=>2,1<=>3,a<=>b */

	if (dstmode == BAT_WRITE) {
		if (hp->storage != STORE_PRIV)
			hp->dirty = 1;	/* exception c does not make it dirty */
		return STORE_PRIV;	/* 4=>6,5=>7,c=>6 persistent BAT_WRITE needs STORE_PRIV */
	}
	if (hp->storage == STORE_MMAP) {	/* 6=>4 */
		hp->dirty = 1;
		return backup_new(hp, BBP_THREADMASK) ? -1 : STORE_MMAP;	/* only called for existing bats */
	}
	return hp->storage;	/* 7=>5 */
}

/* heap changes persistence mode (at commit point) */
static int
HEAPcommitpersistence(Heap *hp, int writable, int existing)
{
	if (existing) {		/* existing, ie will become transient */
		if (hp->storage == STORE_MMAP && hp->newstorage == STORE_PRIV && writable) {	/* 6=>2 */
			hp->dirty = 1;
			return backup_new(hp, -1) ? -1 : STORE_MMAP;	/* only called for existing bats */
		}
		return hp->newstorage;	/* 4=>0,5=>1,7=>3,c=>a no change */
	}
	/* !existing, ie will become persistent */
	if (hp->newstorage == STORE_MEM)
		return hp->newstorage;
	if (hp->newstorage == STORE_MMAP && !writable)
		return STORE_MMAP;	/* 0=>4 STORE_MMAP */

	if (hp->newstorage == STORE_MMAP)
		hp->dirty = 1;	/* 2=>6 */
	return STORE_PRIV;	/* 1=>5,2=>6,3=>7,a=>c,b=>6 states */
}


/* change the heap modes at a commit */
int
BATcheckmodes(BAT *b, int existing)
{
	int wr = (b->batRestricted == BAT_WRITE);
	int m0 = 0, m1 = 0, m2 = 0, m3 = 0;
	int dirty = 0;

	BATcheck(b, "BATcheckmodes");

	if (b->htype) {
		m0 = HEAPcommitpersistence(&b->H->heap, wr, existing);
		dirty |= (b->H->heap.newstorage != m0);
	}

	if (b->ttype) {
		m1 = HEAPcommitpersistence(&b->T->heap, wr, existing);
		dirty |= (b->T->heap.newstorage != m1);
	}

	if (b->H->vheap) {
		int ha = (b->batRestricted == BAT_APPEND) && ATOMappendpriv(b->htype, b->H->vheap);
		m2 = HEAPcommitpersistence(b->H->vheap, wr || ha, existing);
		dirty |= (b->H->vheap->newstorage != m2);
	}
	if (b->T->vheap) {
		int ta = (b->batRestricted == BAT_APPEND) && ATOMappendpriv(b->ttype, b->T->vheap);
		m3 = HEAPcommitpersistence(b->T->vheap, wr || ta, existing);
		dirty |= (b->T->vheap->newstorage != m3);
	}
	if (m0 < 0 || m1 < 0 || m2 < 0 || m3 < 0)
		return -1;

	if (dirty) {
		b->batDirtydesc = 1;
		b->H->heap.newstorage = m0;
		b->T->heap.newstorage = m1;
		if (b->H->vheap)
			b->H->vheap->newstorage = m2;
		if (b->T->vheap)
			b->T->vheap->newstorage = m3;
	}
	return 0;
}

@= heap_unshare
	if (@1->copied) {
		Heap hp;

		memset(&hp, 0, sizeof(Heap));
		if (HEAPcopy(&hp, @1) < 0) {
			GDKerror("%s: remapped @2 of %s could not be copied.\n", fcn, BATgetId(b));
			return -1;

		}
		hp.parentid = @3;
		if (@1->parentid == @3)
			HEAPfree(@1);
		else
			BBPunshare(@1->parentid);
		* (@1) = hp;
		@1->copied = 0;
	}
@c
static int
batunshare(BAT *b, str fcn)
{
	if (b->H->heap.base)
		@:heap_unshare((&b->H->heap),head,0)@
	if (b->T->heap.base)
		@:heap_unshare((&b->T->heap),tail,0)@
	if (b->H->vheap)
		@:heap_unshare(b->H->vheap,H->vheap,ABS(b->batCacheid))@
	if (b->T->vheap)
		@:heap_unshare(b->T->vheap,T->vheap,ABS(b->batCacheid))@
	b->P->lview = 0;
	return 0;
}

BAT *
BATsetaccess(BAT *b, int newmode)
{
	int bakmode, bakdirty;
	BATcheck(b, "BATsetaccess");
	if (isVIEW(b) && newmode != BAT_READ) {
		if (VIEWreset(b) == NULL)
			return NULL;
	}
	bakmode = b->batRestricted;
	bakdirty = b->batDirtydesc;
	if (bakmode != newmode) {
		int existing = BBP_status(b->batCacheid) & BBPEXISTING;
		int wr = (newmode == BAT_WRITE);
		int rd = (bakmode == BAT_WRITE);
		int m0, m1, m2 = 0, m3 = 0;
		int b0, b1, b2 = 0, b3 = 0;

		/* copy-on-write isolated bats that change mode should be made independent */
		if (b->P->lview && newmode != BAT_READ && batunshare(b, "BATsetaccess") < 0)
			return NULL;

		if (b->batSharecnt && newmode != BAT_READ) {

			PROPDEBUG THRprintf(GDKout, "#BATsetaccess: %s has %d views; deliver a copy.\n", BATgetId(b), b->batSharecnt);
			b = BATsetaccess(BATcopy(b, b->htype, b->ttype, TRUE), newmode);
			if (b && b->batStamp > 0)
				b->batStamp = -b->batStamp;	/* prevent MIL setaccess */
			return b;
		}

		b0 = b->H->heap.newstorage;
		m0 = HEAPchangeaccess(&b->H->heap, ACCESSMODE(wr, rd), existing);
		b1 = b->T->heap.newstorage;
		m1 = HEAPchangeaccess(&b->T->heap, ACCESSMODE(wr, rd), existing);
		if (b->H->vheap) {
			int ha = (newmode == BAT_APPEND && ATOMappendpriv(b->htype, b->H->vheap));
			b2 = b->H->vheap->newstorage;
			m2 = HEAPchangeaccess(b->H->vheap, ACCESSMODE(wr && ha, rd && ha), existing);
		}
		if (b->T->vheap) {
			int ta = (newmode == BAT_APPEND && ATOMappendpriv(b->ttype, b->T->vheap));
			b3 = b->T->vheap->newstorage;
			m3 = HEAPchangeaccess(b->T->vheap, ACCESSMODE(wr && ta, rd && ta), existing);
		}
		if (m0 < 0 || m1 < 0 || m2 < 0 || m3 < 0)
			return NULL;

		/* set new access mode and mmap modes */
		b->batRestricted = newmode;
		b->batDirtydesc = TRUE;
		b->H->heap.newstorage = m0;
		b->T->heap.newstorage = m1;
		if (b->H->vheap)
			b->H->vheap->newstorage = m2;
		if (b->T->vheap)
			b->T->vheap->newstorage = m3;

		if (existing && BBPsave(b) < 0) {
			/* roll back all changes */
			b->batRestricted = bakmode;
			b->batDirtydesc = bakdirty;
			b->H->heap.newstorage = b0;
			b->T->heap.newstorage = b1;
			if (b->H->vheap)
				b->H->vheap->newstorage = b2;
			if (b->T->vheap)
				b->T->vheap->newstorage = b3;
			return NULL;
		}
	}
	return b;
}

int
BATgetaccess(BAT *b)
{
	BATcheck(b, "BATgetaccess");
	return b->batRestricted;
}

@}
@- change BAT persistency (persistent,session,transient)
In the past, we prevented BATS with certain types from being saved at all:
- BATs of BATs, as having recursive bats creates cascading complexities in commits/aborts. 
- any atom with refcounts, as the BBP has no overview of such user-defined refcounts.
- pointer types, as the values they point to are bound to be transient.

However, nowadays we do allow such saves, as the BBP swapping mechanism was altered
to be able to save transient bats temporarily to disk in order to make room.
Thus, we must be able to save any transient BAT to disk. 

What we don't allow is to make such bats persistent. 

Although the persistent state does influence the allowed mmap modes, this only
goes for the *real* committed persistent state. Making the bat persistent with BATmode 
does not matter for the heap modes until the commit point is reached. So we do not
need to do anything with heap modes yet at this point.
@{
@= check_type
	if (ATOMisdescendant(@1, TYPE_ptr) || ATOMisdescendant(@1, TYPE_bat) ||	
	    BATatoms[@1].atomUnfix || BATatoms[@1].atomFix) {
		GDKerror("BATmode: %s type implies that %s[%s,%s] cannot be made persistent.\n",
			 ATOMname(@1), BATgetId(b),
			 ATOMname(b->htype), ATOMname(b->ttype));
		return NULL;
	}
@c
BAT *
BATmode(BAT *b, int mode)
{
	BATcheck(b, "BATmode");

	if (mode != b->batPersistence) {
		bat bid = ABS(b->batCacheid);

		if (b->P->lview) {
			if (batunshare(b, "BATmode") < 0)
				return NULL;
		}
		if (mode == PERSISTENT) {
			@:check_type(b->htype)@
			@:check_type(b->ttype)@
		}
		BBPdirty(1);

		/* a SESSION bat is a TRANSIENT with one logical reference added */
		if (mode == SESSION) {
			BBPincref(bid, TRUE);
		} else if (b->batPersistence == SESSION) {
			BBPdecref(bid, TRUE);
		}
		if (mode == PERSISTENT && isVIEW(b)) {
			VIEWreset(b);
		}
		/* persistent BATs get a logical reference */
		if (mode == PERSISTENT) {
			BBPincref(bid, TRUE);
		} else if (b->batPersistence == PERSISTENT) {
			BBPdecref(bid, TRUE);
		}
		gdk_set_lock(GDKswapLock(bid & BBP_BATMASK), "BATmode");
		if (mode == PERSISTENT) {
			if (!(BBP_status(bid) & BBPDELETED))
				BBP_status_on(bid, BBPNEW, "BATmode");
			BBP_status_off(bid, BBPDELETED, "BATmode");
		} else if (b->batPersistence == PERSISTENT) {
			if (!(BBP_status(bid) & BBPNEW))
				BBP_status_on(bid, BBPDELETED, "BATmode");
			BBP_status_off(bid, BBPPERSISTENT, "BATmode");
		}
		/* session bats or persistent bats that did not witness a commit yet may have been saved */
		if (b->batCopiedtodisk) {
			if (mode == PERSISTENT) {
				BBP_status_off(bid, BBPTMP, "BATmode");
			} else {
				/* TMcommit must remove it to guarantee free space */
				BBP_status_on(bid, BBPTMP, "BATmode");
			}
		}
		b->batPersistence = mode;
		gdk_unset_lock(GDKswapLock(bid & BBP_BATMASK), "BATmode");
	}
	return b;
}

@}
@+ BATpropcheck

This is a low-cost routine that smartly tries to deduce as 
much properties possible on the head column of its BAT parameter.

with PROPDEBUG (-d8) enabled, it is also a powerful tool
to check whether all properties of a BAT are set correctly.

It uses efficient algorithms to either prove or disprove
the validity of the hkey, hsorted and hdense properties.

If each such property is already set, we know already for certain 
and do not have to check. If in the course of this routine we find 
proof that the property does not hold, we record this proof
using special fields in the BAT descriptor. 
This means that a subsequent execution of this routine 
does not have to check the property exhaustively anymore.

This routine now guarantees that any property that could be set 
on the BAT head column, is set after execution. Hence it can be
used for determining with certainty whether the head column of a 
BAT is sorted, key or dense. 
@{
@c
BAT *
BATpropcheck(BAT *b, int mode)
{
	BATiter bvi, bi = bat_iterator(b), bi2 = bat_iterator(b);
	int disprove_dense, disprove_sorted, disprove_key = TRUE, disprove_nonil = b->H->nonil;
	int dense_bak = 0, key_bak = 0, sorted_bak = 0, nonil_bak = 0;
	oid seq_bak = 0;
	BUN xx, yy;
	int zz, tpe;
	BUN p, q, r;
	ptr last;
	bit isKey = FALSE;
	BAT *parent;

	BATcheck(b, "BATpropcheck");
	if (b->halign == 0) {
		b->batDirtydesc = 1;
		b->halign = OIDnew(1);
	}
	tpe = b->htype;
	yy = BUNfirst(b);
	xx = BUNlast(b);
	disprove_sorted = ATOMlinear(tpe);
@- 
check if duplicated properties are equal
@c
	PROPDEBUG mode |= BATPROPS_CHECK;

	if (mode & BATPROPS_CHECK) {
		BAT *bm = BATmirror(b);

		if (BAThvoid(b) && b->hseqbase != bm->tseqbase) {
			oid o = (b->htype && yy != xx) ? *(oid *) BUNhloc(bi, BUNfirst(b)) : oid_nil;
			GDKerror("BATpropcheck: BAT %s(%d) set inconsistent hseqbase: " OIDFMT " != " OIDFMT " => " OIDFMT "\n", BATgetId(b), b->batCacheid, b->hseqbase, bm->tseqbase, o);
			b->hseqbase = bm->tseqbase = o;

			b->batDirty = TRUE;
		}
		zz = ((b->U != bm->U) << 1) |
		     ((b->P != bm->P) << 2) |
		     ((b->H != bm->T) << 3) |
		     ((b->htype != bm->ttype) << 4) |
		     ((b->H->varsized != bm->T->varsized) << 6) |
		     ((b->T->varsized != bm->H->varsized) << 6) |
		     ((b->H->shift != bm->T->shift) << 7) |
		     ((b->T->shift != bm->H->shift) << 7) |
		     ((b->H->width != bm->T->width) << 8) |
		     ((b->T->width != bm->H->width) << 8) |
		     (((b->H->width != 0 || b->H->shift != 0) && b->H->width != (1 << b->H->shift)) << 9) |
		     (((b->T->width != 0 || b->T->shift != 0) && b->T->width != (1 << b->T->shift)) << 9) |
		     ((b->batFirst < b->batDeleted) << 10) |
		     ((b->batFirst > b->batInserted) << 11) |
		     ((b->H->heap.size > b->H->heap.maxsize) << 13) |
		     (((b->H->heap.free > b->H->heap.size) & (b->htype != TYPE_void)) |
		      ((b->T->heap.free > b->T->heap.size) & (b->ttype != TYPE_void))) << 14 |
		     (((xx - yy) != b->batCount) << 15) |
		     ((b->H->type && (b->U->capacity > (b->H->heap.size >> b->H->shift))) |
		      (b->T->type && (b->U->capacity > (b->T->heap.size >> b->T->shift)))) << 16;

		if (zz) {
			GDKfatal("BATpropcheck: BAT %s(%d) has inconsistent descriptor %d (%o)\n", BATgetId(b), b->batCacheid, zz, zz);

		}
		if (b->H->hash != bm->T->hash) {
			GDKerror("BATpropcheck: BAT %s(%d) has inconsistent accrefs\n", BATgetId(b), b->batCacheid);
			HASHdestroy(b);
			b->batDirty = TRUE;
		}
		if (b->H->key != bm->T->key) {
			GDKerror("BATpropcheck: BAT %s(%d) recovered hkey\n", BATgetId(b), b->batCacheid);
			b->H->key = bm->T->key = b->batDirty = TRUE;
		}
		if (BAThdense(b) && !b->hkey) {
			GDKerror("BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples is dense but not key!?\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);
		}
	}
	if (BAThdense(b) && !b->hkey)
		BATkey(b, TRUE);
@-
quick check on trivial cases (void columns, 0 or 1 tuple bats).
@c
	if (tpe == TYPE_void) {
		return b;
	}
	if (xx > yy /* BATcount(b) > 0 */  &&
	    BAThdense(b) &&
	    b->htype == TYPE_oid &&
	    *(oid *) BUNhloc(bi, BUNfirst(b)) != b->hseqbase) {
		GDKerror("BATpropcheck: BAT %s(%d) with " BUNFMT " tuples seqbase of dense oid bat is wrong! " OIDFMT " != " OIDFMT "\n", BATgetId(b), b->batCacheid, b->batCount, b->hseqbase, *(oid *) BUNhloc(bi, BUNfirst(b)));
	}
	if (xx <= yy + 1) {	/* BATcount(b) <= 1 */
		if (ATOMlinear(tpe) && !(b->hsorted & 1)) {
			XPROPDEBUG THRprintf(GDKout, "#BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples is (h)sorted!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);

			b->batDirtydesc = TRUE;
			b->hsorted = GDK_SORTED;
		}
		if (!b->hkey) {
			XPROPDEBUG THRprintf(GDKout, "#BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples is (h)key!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);

			BATkey(b, TRUE);
		}
		if (tpe == TYPE_oid && !BAThdense(b)) {
			oid hsb = oid_nil;

			if (yy == xx) {	/* BATcount(b) == 0 */
				hsb = 0;	/* does not really matter */
			} else {
				hsb = *(oid *) BUNhloc(bi, BUNfirst(b));
			}
			if (hsb != oid_nil) {
				XPROPDEBUG THRprintf(GDKout, "#BATpropcheck: [oid,?]-BAT %s(%d)[%s,%s] with " BUNFMT " tuples is (h)dense!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);

				b->hdense = b->batDirtydesc = TRUE;
				BATseqbase(b, hsb);
			}
		}
		return b;
	}
@-
first propagate already known properties. that will save some effort.
@c
	if (VIEWparentcol(b) && ALIGNsynced(parent = BBP_cache(VIEWhparent(b)), b)) {
		/* quickly propagate properties from parent to child */
		if (((BAThordered(parent) & 1) && !(BAThordered(b) & 1)) && !b->H->heap.copied) {
			XPROPDEBUG THRprintf(GDKout, "#BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples inherits (h)sorted from BAT %s(%d)!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount, BATgetId(parent), parent->batCacheid);

			b->batDirtydesc = TRUE;
			b->hsorted = GDK_SORTED;
		}
		if (parent->hkey && !b->hkey) {
			XPROPDEBUG THRprintf(GDKout, "#BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples inherits (h)key from BAT %s(%d)!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount, BATgetId(parent), parent->batCacheid);

			BATkey(b, TRUE);
		}
		if (BAThdense(parent) && tpe == TYPE_oid && !BAThdense(b)) {
			XPROPDEBUG THRprintf(GDKout, "#BATpropcheck: [oid,?]-BAT %s(%d)[%s,%s] with " BUNFMT " tuples inherits (h)dense from BAT %s(%d)!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount, BATgetId(parent), parent->batCacheid);

			b->hdense = b->batDirtydesc = TRUE;
			BATseqbase(b, *(oid *) BUNhloc(bi, BUNfirst(b)));
		}
	}
	disprove_dense = (tpe == TYPE_oid);

	if (mode & BATPROPS_CHECK) {
		dense_bak = BAThdense(b);
		seq_bak = b->hseqbase;
		sorted_bak = BAThordered(b) & 1;	/* StM: GDK_SORTED_REV ? */
		key_bak = b->hkey;
		nonil_bak = b->H->nonil;
		BATkey(b, FALSE);
		b->hsorted &= (bit) ~1;	/* FALSE */	/* StM: GDK_SORTED_REV ? */
		b->hdense = FALSE;
		b->H->nonil = FALSE;
	} else if (b->hdense) {
		disprove_dense = FALSE;
	}
@-
check whether whatever we want need to prove was already disproven 
@c
	if (disprove_key) {
		if (b->hkey ||
		    ((b->H->nokey[0] != b->H->nokey[1]) &&
		     (b->H->nokey[0] >= yy) &&
		     (b->H->nokey[0] < xx) &&
		     (b->H->nokey[1] >= yy) &&
		     (b->H->nokey[1] < xx) &&
		     ATOMcmp(tpe, BUNhead(bi, b->H->nokey[0]), BUNhead(bi2, b->H->nokey[1])) == 0)) {
			disprove_key = FALSE;
		} else {
			b->H->nokey[0] = b->H->nokey[1] = 0;
		}
	}
	if (disprove_nonil) {
		if (b->H->nonil || b->H->nil) {
			disprove_nonil = FALSE;
		} else {
			b->H->nil = 0;
		}
	}
	if (disprove_sorted) {	/* StM: GDK_SORTED_REV ? */
		if ((BAThordered(b) & 1) ||
		    ATOMlinear(tpe) == 0 ||
		    (b->H->nosorted > yy &&
		     b->H->nosorted < xx &&
		     ATOMcmp(tpe, BUNhead(bi, b->H->nosorted - 1), BUNhead(bi2, b->H->nosorted)) > 0)) {
			disprove_sorted = FALSE;
		} else {
			b->H->nosorted = 0;	/* StM: nosorted_rev ? */
		}
	}
	if (disprove_dense) {	/* StM: GDK_SORTED_REV ? */
		if (((b->hsorted & 1) == FALSE && disprove_sorted == FALSE) ||
		    (b->H->nodense > yy &&
		     b->H->nodense < xx &&
		     *(oid *) BUNhloc(bi, b->H->nodense - 1) + 1 != *(oid *) BUNhloc(bi2, b->H->nodense))) {
			disprove_dense = FALSE;
		} else {
			b->H->nodense = 0;
		}
	}
@-
still got something to prove? If not, we're done.
@c
	if (!(disprove_sorted || disprove_key || disprove_dense || disprove_nonil)) {
		goto exit;
	}
@-
Prepare to scan.
@c
	p = BUNfirst(b);
	q = BUNlast(b);
	last = BUNhead(bi, p);
@-
disprove_dense is only set for oid columns, as the 'dense' property
is only relevant for this type..
@c
	if (disprove_dense)
		while ((++p) < q) {
			ptr v = BUNhloc(bi, p);

			if ((*(oid *) last + 1) != *(oid *) v) {
				disprove_dense = FALSE;
				b->hdense = FALSE;
				b->H->nodense = p;
				b->batDirtydesc = 1;
				break;
			}
			last = v;
	} else
		p++;
	if (disprove_dense)
		isKey = TRUE;
@-
Merge scan check to see if head values are sorted (&key) 
@c
	switch (ATOMstorage(tpe)) {
#ifndef NOEXPAND_CHR
	case TYPE_chr:
		@:merge_disprove(simple,chr,loc)@
#endif
#ifndef NOEXPAND_BTE
	case TYPE_bte:
		@:merge_disprove(simple,bte,loc)@
#endif
#ifndef NOEXPAND_SHT
	case TYPE_sht:
		@:merge_disprove(simple,sht,loc)@
#endif
#ifndef NOEXPAND_INT
	case TYPE_int:
		@:merge_disprove(simple,int,loc)@
#endif
#ifndef NOEXPAND_FLT
	case TYPE_flt:
		@:merge_disprove(simple,flt,loc)@
#endif
#ifndef NOEXPAND_LNG
	case TYPE_lng:
		@:merge_disprove(simple,lng,loc)@
#endif
#ifndef NOEXPAND_DBL
	case TYPE_dbl:
		@:merge_disprove(simple,dbl,loc)@
#endif
	default:
		@:merge_disprove(atom,tpe,ead)@
	}

@= merge_disprove
	if (disprove_sorted) {	/* StM: GDK_SORTED_REV ? */
		if (disprove_nonil && p < q) {
			ptr v = BUNh@3(bi, p);
			int ret = @1_CMP(v, ATOMnilptr(b->htype), @2);
			if (ret == 0) {
				b->H->nil = 1;
				disprove_nonil = FALSE;
				b->batDirtydesc = 1; 
			}
		}
		while (p < q) {
			ptr v = BUNh@3(bi, p);
			int ret = @1_CMP(v, last, @2);

			if (ret < 0) {
				disprove_sorted = FALSE;
				b->H->nosorted = p;	/* StM: nosorted_rev ? */
				b->batDirtydesc = 1; 
				break;
			} else if (ret == 0 && disprove_key) {
				b->H->nokey[0] = p - 1;
				b->H->nokey[1] = p;
				disprove_key = FALSE;
				b->batDirtydesc = 1; 
			} 
			p++;
			last = v;
		}
	}
	break;
@-
@}
To see if head values are key
we create a view on the bat as the hash table created is 
partial; hence inconsistent (it should also not molest
existing consistent hash tables). On this VIEW we can do a HASHfnd

The code was modified to limit memory consumption in the hash-table.
Basically, unless we really need to determine that a bat is key,
we say that it is not if we cannot determine easily. Easily here means
'with a small hash table'. In the case of a sanity check,
we also do full key derivation (with whatever it takes).

We also insert a debug statement triggered with BATDEBUG (mask 32) 
that displays the size of the hash table used.  We chose BATDEBUG because 
that also gives the best overview of program execution - necessary
for determining which algebra commands set properties sub-optimally.
@{
@c
	if (disprove_key || disprove_nonil) {
		if (p < q) {
			BUN cnt = b->batCount;
			BUN lim = (BUN) ((mode & BATPROPS_ALL) ? GDK_int_max : 16000);

			lim = MIN(cnt, lim);
			q = yy + lim;
			if (p < q) {
				BAT *bv = VIEWcreate(b, b);
				Heap *hp = (Heap *) GDKzalloc(sizeof(Heap));
				str nme = BBP_physical(bv->batCacheid);
				size_t nmelen = strlen(nme);

				hp->filename = GDKmalloc(nmelen + 12);
				if (hp->filename != NULL)
					snprintf(hp->filename, nmelen + 12, "%s.%chash", nme, bv->batCacheid > 0 ? 'h' : 't');
				if (hp->filename == NULL ||
				    (bv->H->hash = HASHnew(hp, tpe, yy + lim, HASHmask(lim))) == NULL) {
					GDKfree(hp->filename);
					GDKfree(hp);
					BATDEBUG THRprintf(GDKout, "#BATpropcheck: BAT %s(%d): could not allocate hash table for key test\n", BATgetId(b), b->batCacheid);
				} else {
					switch (ATOMstorage(tpe)) {
#ifndef NOEXPAND_CHR
					case TYPE_chr:
						@:hash_disprove(_chr,loc)@
#endif
#ifndef NOEXPAND_BTE
					case TYPE_bte:
						@:hash_disprove(_bte,loc)@
#endif
#ifndef NOEXPAND_SHT
					case TYPE_sht:
						@:hash_disprove(_sht,loc)@
#endif
#if !defined(NOEXPAND_INT) || !defined(NOEXPAND_FLT)
					case TYPE_int:
					case TYPE_flt:
						@:hash_disprove(_int,loc)@
#endif
#if !defined(NOEXPAND_LNG) || !defined(NOEXPAND_DBL)
					case TYPE_lng:
					case TYPE_dbl:
						@:hash_disprove(_lng,loc)@
#endif
					case TYPE_str:
						if (b->H->vheap->hashash) {
							@:hash_disprove(_str_hv,var)@
						}
						/* fall through */
					default:
						@:hash_disprove(_any,ead)@
					}
					BATDEBUG THRprintf(GDKout, "#BATpropcheck: BAT %s(%d): used hashtable of size " BUNFMT "\n", BATgetId(b), b->batCacheid, lim);
				}
				BBPreclaim(bv);
			}
		} else {
			isKey = TRUE;
		}
	}

@= hash_disprove
	bvi = bat_iterator(bv);
	for (r = BUNfirst(b); r < p; r++, yy++) {
		ptr v = BUNh@2(bvi, r);
		HASHins@1(bv->H->hash, yy, v);
		if (disprove_nonil && ATOMcmp(b->htype, v, ATOMnilptr(b->htype)) == 0) {
			disprove_nonil = FALSE;
			b->H->nil = 1;
			b->batDirtydesc = 1;
			if (!disprove_key)
				break;
		}
	}
	while (disprove_key && p < q) {
		ptr v = BUNh@2(bvi, p);

		HASHfnd@1(r,bvi,v); /* purify: UMR */
		if (r != BUN_NONE) {
			b->H->nokey[0] = r;
			b->H->nokey[1] = yy;
			disprove_key = FALSE;
			b->batDirtydesc = 1;
			break;
		}
		HASHins@1(bv->H->hash, yy, v);
		yy++;
		p++;
	}
	if (disprove_key && cnt == lim)
		isKey = TRUE;
	break;
@-
failed to disprove on exhaustive check => succeeded to prove
@c
	if (disprove_nonil)
		b->H->nonil = nonil_bak;
	if (disprove_key || disprove_dense) {
		BATkey(b, key_bak | isKey);	/* respect BOUND2BTRUE */
	}
	if (disprove_sorted || disprove_dense) {	/* StM: GDK_SORTED_REV ? */
		b->batDirtydesc = TRUE;
		b->hsorted = GDK_SORTED;
	}
	if (disprove_dense) {
		b->batDirtydesc = b->hdense = TRUE;
		BATseqbase(b, *(oid *) BUNhloc(bi, BUNfirst(b)));
	}
      exit:
	if ((mode & BATPROPS_CHECK) == BATPROPS_CHECK) {
		if ((sorted_bak & 1) && !(BAThordered(b) & 1)) {
			GDKerror("BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples was incorrectly marked sorted!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);
			if (BAThordered(b))
				GDKerror("BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples remains marked radix-clustered on %d bits; not checked!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount, BAThordered(b) >> 1);
		}
		if (key_bak && !b->hkey)
			GDKerror("BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples was incorrectly marked keyed!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);
		if (nonil_bak && !b->H->nonil)
			GDKerror("BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples was incorrectly marked nonil!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);
		if (dense_bak && disprove_dense) {
			if (!BAThdense(b))
				GDKerror("BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples was incorrectly marked dense!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);
			if (seq_bak != b->hseqbase)
				GDKerror("BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples had incorrect seqbase!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);
		}
		XPROPDEBUG {
			if (!(sorted_bak & 1) && (BAThordered(b) & 1))	/* StM: GDK_SORTED_REV ? */
				GDKerror("BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples was not marked sorted!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);
			if (!key_bak && b->hkey)
				GDKerror("BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples was not marked keyed!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);
			if (!dense_bak && disprove_dense) {
				if (BAThdense(b))
					GDKerror("BATpropcheck: BAT %s(%d)[%s,%s] with " BUNFMT " tuples was not marked dense!\n", BATgetId(b), b->batCacheid, ATOMname(b->htype), ATOMname(b->ttype), b->batCount);
			}
		}
	}
	return b;
}

@
@}
