@/
The contents of this file are subject to the MonetDB Public License
Version 1.1 (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html

Software distributed under the License is distributed on an "AS IS"
basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
License for the specific language governing rights and limitations
under the License.

The Original Code is the MonetDB Database System.

The Initial Developer of the Original Code is CWI.
Portions created by CWI are Copyright (C) 1997-July 2008 CWI.
Copyright August 2008-2011 MonetDB B.V.
All Rights Reserved.
@

@f gdk_relop
@a M. L. Kersten, P. Boncz, S. Manegold
@* BAT relational operators
The basic relational operators are implemented for BATs.
Particular attention has been paid to speed-up processing
joins, such that navigational access and object re-assembly
are not being harmed too much.
@{
@c
#include "monetdb_config.h"
#include "gdk.h"

#define SAMPLE_TRESHOLD_LOG 17
#define SAMPLE_SLICE_SIZE 1000
@}
@+ Join Algorithms
All join related operations have the same prelude to check
domain compatibility and to creates the BAT to hold the result.

We do some dynamic effort to estimate the result size. Good
estimates enhance performance and reduce the memory hunger of the join.
Method: we sample on l, and join on the whole r. This macro is called by
the physical join algorithms, hence we already decided on the algorithm
and join method, so the initial costs on r (e.g. hash creation) would have
to be paid anyway, and are reused later in the real join phase.

Sampling was made more robust by using a logarithmic number of slices
taken at equal-spaced intervals across l. The results are then analyzed
and checked for outliers. If outliers are present, a real sample is taken
and executed with the generic join algorithm to obtain an better estimate.

On small joins we just assume 1-N joins with a limited (=3) hit rate.
@{
@= joincheck
	ERRORcheck(l == NULL, "@1: invalid left operand");
	ERRORcheck(r == NULL, "@1: invalid right operand");
	ERRORcheck(TYPEerror(@2, @3), "@1: type conflict\n");
@= joinestimate
	if (@3 == BUN_NONE) {
		BUN _lcount = BATcount(l);
		BUN _rcount = BATcount(r);
		BUN _slices = 0;

		/* limit estimate with simple bounds first; only spend effort if the join result might be big */
		if (@1 == JOIN_EQ) {
			if (l->tkey)
				@3 = r->hkey ? MIN(_rcount, _lcount) : _rcount;
			else if (r->hkey)
				@3 = _lcount;
		}
		if (@3 == BUN_NONE) {
			BUN _heuristic = MIN(_lcount, _rcount);

			if (_heuristic <= BUN_MAX / 3) {
				_heuristic *= 3;
				if (_heuristic <= (1 << SAMPLE_TRESHOLD_LOG))
					@3 = _heuristic;
			}
		}
		if (@3 == BUN_NONE) {
			BUN _idx;

			for (_idx = _lcount; _idx > 0; _idx >>= 1)
				_slices++;
		}
		if (_slices > SAMPLE_TRESHOLD_LOG) {
			/* use cheapo sampling by taking a number of slices and joining those with the algo */
			BUN _idx = 0, _tot = 0, _step, _lo, _avg, _sample, *_cnt;
			BAT *_tmp1 = l, *_tmp2, *_tmp3 = NULL;

			_step = _lcount / (_slices -= SAMPLE_TRESHOLD_LOG);
			_sample = _slices * SAMPLE_SLICE_SIZE;
			_cnt = (BUN *) alloca(_slices * sizeof(BUN));
			for (_lo = 0; _idx < _slices; _lo += _step) {
				BUN _size = 0, _hi = _lo + SAMPLE_SLICE_SIZE;

				l = BATslice(_tmp1, _lo, _hi);	/* slice keeps all parent properties */
				if (l == NULL)
					return NULL;
				_tmp2 = @2;	/* @2 = e.g. BATXjoin(l,r) */
				if (_tmp2) {
					_size = BATcount(_tmp2);
					BBPreclaim(_tmp2);
				}
				_tot += (_cnt[_idx++] = _size);
				BBPreclaim(l);
			}
			/* do outlier detection on sampling results; this guards against skew */
			if (@1 == JOIN_EQ) {
				for (_avg = _tot / _slices, _idx = 0; _idx < _slices; _idx++) {
					BUN _diff = _cnt[_idx] - _avg;

					if (_avg > _cnt[_idx])
						_diff = _avg - _cnt[_idx];
					if (_diff > MAX(SAMPLE_SLICE_SIZE, _avg))
						break;
				}
				if (_idx < _slices) {
					/* outliers detected, compute a real sample on at most 1% of the data */
					_sample = MIN(_lcount / 100, (1 << SAMPLE_TRESHOLD_LOG) / 3);
					_tmp2 = BATsample(_tmp1, _sample);
					if (_tmp2) {
						_tmp3 = BATjoin(_tmp2, r, BUN_NONE);	/* might be expensive */
						if (_tmp3) {
							_tot = BATcount(_tmp3);
							BBPreclaim(_tmp3);
						}
						BBPreclaim(_tmp2);
					}
					if (_tmp3 == NULL)
						return NULL;
				}
			}
			/* overestimate always by 5% */
			{
				double _d = (double) (((lng) _tot) * ((lng) _lcount)) / (0.95 * (double) _sample);
				if (_d < (double) BUN_MAX)
					@3 = (BUN) _d;
				else
					@3 = BUN_MAX;
			}
			l = _tmp1;
		} else {
			BUN _m = MIN(_lcount,_rcount);
			if (_m <= BUN_MAX / 32)
				_m *= 32;
			else
				_m = BUN_MAX;
			@3 = MIN(_m,MAX(_lcount,_rcount));
		}
	}
@= joinbat
	{
		BUN _estimate = @3;

		@:joinestimate(@1, @2, _estimate)@
		bn = BATnew(BAThtype(l), BATttype(r), _estimate);
		if (bn == NULL) 
			return bn;
	}
@}
@- Merge join
In the case that both join columns are ordered, we can do a merging
(@%BATmergejoin@). The merge is opportunistic in that it tries to do
merge between l and r, but if for a long time no matching tuples are
found in r, it uses binary search. It also allows joining of an
unsorted l with a sorted r; in that case it always uses binary search.
@{
@c
#define BATPERC(lfirst,lcur,lend,rfirst,rcur,rend)\
		((((dbl) (lend-lfirst))*((dbl) (rend-rfirst))) / \
		 MAX(1,((lcur-lfirst)*((dbl) (rend-rfirst))+(dbl) (rcur-rfirst))))

#define bunfastins_limit(b, h, t, limit, percdone) {			\
                register BUN _p = BUNlast(b);				\
		if (_p == BUN_MAX) /* reached maximum, can't do more */	\
			goto bunins_done;				\
                if (_p + 1 > BATcapacity(b)) {				\
                        if (limit) {					\
				*limit = (BUN) (b->batCount * (percdone)); \
                              goto bunins_done;				\
			}						\
                        if (BATextend(b, BATgrows(b)) == NULL)		\
                                goto bunins_failed;			\
                }							\
                hfastins_nocheck(b, _p, h, Hsize(b));			\
                tfastins_nocheck(b, _p, t, Tsize(b));			\
                (b)->batCount++;					\
        }
@= mergejoin
	if (((!BATtvoid(l)) || l->tseqbase != oid_nil) &&
	    ((!BAThvoid(r)) || r->hseqbase != oid_nil || nil_on_miss)) {
		assert(r->htype != TYPE_void);
		while (l_start < l_last) {
			ptr v2, v1 = BUNt@2(li, l_start);
			int neq = 1;

			/* lookup range in l */
			l_end = l_start;
			if (l_key) {
				l_end++;
			} else
				do {
					if ((++l_end) >= l_last)
						break;
					v2 = BUNt@2(li, l_end);
				} while (@1_EQ(v1, v2, @4));

			/* lookup value in r (if not nil, that is) */
			if (!@1_EQ(v1, nil, @4)) {
				if (r_scan > 0) {
					/* first try scanning; but give up after a while */
					for (r_lim = MIN(r_last, r_end + r_scan); r_end < r_lim; r_end++) {
						v2 = BUNh@3(ri, r_end);
						neq = @1_CMP(v1, v2, @4);
						if (neq <= 0)
							break;
					}
					r_start = r_end;
				}
				if (neq == 1) {
					/* use binary search after failed scan or if scanning is impossible (l not sorted) */
					if (r_scan < 0 || r_start < r_last) {
						/* if merge not ended (or if no merge at all) */
						r_start = (BUN) SORTfndfirst_@4(rr, v1);
					}
					if (r_start < r_last) {
						v2 = BUNh@3(ri, r_start);
						neq = !@1_EQ(v1, v2, @4);
					} else if (r_scan >= 0) {
						/* r is already at end => break off merge join */
						break;
					}
				}
			}
			if (neq == 0) {
				/* lookup range in r */
				r_end = r_start+1;
				if (r_key == 0)
					while (r_end < r_last) {
						v2 = BUNh@3(ri, r_end);
						if (!@1_EQ(v1, v2, @4))
							break;
						r_end++ ;
					}
				/* generate match-product as join result */
				for (; l_start < l_end; l_start++)
					for (r_cur = r_start; r_cur < r_end; r_cur++)
						bunfastins_limit(bn, BUNhead(li, l_start), BUNtail(ri, r_cur), limit, BATPERC(BUNfirst(l),l_start,BUNlast(l),r_start,r_cur,r_end));
			} else if (nil_on_miss) {
				/* outerjoin inserts nils on a miss */
				hasnils = 1;
				for (; l_start < l_end; l_start++)
					bunfastins_limit(bn, BUNhead(li, l_start), nil_on_miss, limit, BATPERC(BUNfirst(l),l_start,BUNlast(l),0,1,1));
			} else {
				l_start = l_end;	/* no match found in equi-join */
			}
		}
	}
@c
/* serves both normal equi-join (nil_on_miss==NULL) and outerjoin (nil_on_miss=nil) */
static BAT *
mergejoin(BAT *l, BAT *r, BAT *bn, ptr nil_on_miss, BUN estimate, BUN *limit)
{
	ptr nil = ATOMnilptr(r->htype);
	int r_scan = -1;	/* no scanning in r */
	BAT *rr = BATmirror(r);
	BUN l_last, r_last;	/* last BUN of the BAT */
	BUN l_start, r_start;	/* start of current chunk  */
	BUN l_end, r_end;	/* end of current chunk */
	int l_key = l->tkey;
	int r_key = r->hkey;
	BUN r_cur, r_lim;
	int loc, var, hasnils = 0;
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);

	if (BATtordered(l) & 1) {
		BUN i;
		int logr = 4;

		/* 4*log2(r.count) = estimation of the cost of binary search in units of scan comparisons */
		for (i = BATcount(r); i > 0; logr++)
			i >>= 1;
		r_scan = logr;	/* opportunistic scan window in r */
	}
	if (!(BAThordered(r) & 1)) {
		GDKerror("mergejoin: right input is not sorted.\n");
		return NULL;
	}
	BATaccessBegin(l, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10)
		BATaccessBegin(r, USE_HEAD | USE_TAIL, r_scan > 0 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
	if (bn == NULL) {
		@:joinbat(JOIN_EQ,mergejoin(l,r,NULL,nil_on_miss,BUN_NONE,NULL),estimate)@
	}

	/* the algorithm */
	loc = ATOMstorage(l->ttype);

	l_last = BUNlast(l);
	r_last = BUNlast(r);
	l_start = l_end = BUNfirst(l);
	r_start = r_end = BUNfirst(r);

	switch (loc) {
#ifndef NOEXPAND_CHR
	case TYPE_chr:
		@:mergejoin(simple,loc,loc,chr)@
		break;
#endif
#ifndef NOEXPAND_BTE
	case TYPE_bte:
		@:mergejoin(simple,loc,loc,bte)@
		break;
#endif
#ifndef NOEXPAND_SHT
	case TYPE_sht:
		@:mergejoin(simple,loc,loc,sht)@
		break;
#endif
#ifndef NOEXPAND_INT
	case TYPE_int:
		@:mergejoin(simple,loc,loc,int)@
		break;
#endif
#ifndef NOEXPAND_FLT
	case TYPE_flt:
		@:mergejoin(simple,loc,loc,flt)@
		break;
#endif
#ifndef NOEXPAND_LNG
	case TYPE_lng:
		@:mergejoin(simple,loc,loc,lng)@
		break;
#endif
#ifndef NOEXPAND_DBL
	case TYPE_dbl:
		@:mergejoin(simple,loc,loc,dbl)@
		break;
#endif
	default:
		/* watch it: l->tvarsized may be set due to void l */
		if (l->tvarsized) {
			var = ATOMstorage(l->ttype);

			if (r->hvarsized) {
				/* l and r both real varsized types */
				@:mergejoin(atom,var,var,var)@
			} else {
				/* l is void, r is oid */
				loc = ATOMstorage(r->htype);
				@:mergejoin(atom,var,loc,loc)@
			}
		} else {
			/* we can't handle void r anyway, so don't worry about it here */
			loc = ATOMstorage(l->ttype);
			@:mergejoin(atom,loc,loc,loc)@
		}
		break;
	}

	if (nil_on_miss && l_start < l_last) {
		hasnils = 1;
		for (; l_start < l_last; l_start++)
			bunfastins_limit(bn, BUNhead(li, l_start), nil_on_miss, limit, BATPERC(BUNfirst(l), l_start, BUNlast(l), 0, 1, 1));
	}
	/* propagate properties */
      bunins_done:
	BATaccessEnd(l, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10)
		BATaccessEnd(r, USE_HEAD | USE_TAIL, r_scan > 0 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
	bn->hsorted = BAThordered(l);
	if (r->hkey) {
		if (BATcount(bn) == BATcount(l)) {
			ALIGNsetH(bn, l);
		} else if (l->hkey) {
			BATkey(bn, TRUE);
		}
	}
	bn->H->nonil = l->H->nonil;
	bn->tsorted = FALSE;
	if (!hasnils) {
		if (BATtordered(l) & 1) {
			if (l->tkey && BATcount(bn) == BATcount(r)) {
				ALIGNsetT(bn, r);
			} else if (l->tkey || r->hkey) {
				bn->tsorted = BATtordered(r);
			}
		}
		if (l->tkey && r->tkey) {
			BATkey(BATmirror(bn), TRUE);
		}
	}
	bn->T->nonil = r->T->nonil && !hasnils;
	return bn;
      bunins_failed:
	BATaccessEnd(l, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10)
		BATaccessEnd(r, USE_HEAD | USE_TAIL, r_scan > 0 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
	BBPreclaim(bn);
	return NULL;
}

static BAT *batfetchjoin(BAT *l, BAT *r, BUN estimate, bit swap, bit hitalways);

static BAT *
batmergejoin(BAT *l, BAT *r, BUN estimate, bit swap, BUN *limit)
{
	@:joincheck(BATmergejoin,l->ttype,r->htype)@
	if (BAThdense(r) || (swap && BATtdense(l))) {
		/* batmergejoin can't handle void tail columns at all (fetchjoin is better anyway) */
		BAT *left = limit ? BATslice(l, 0, *limit) : l;
		BAT *bn = batfetchjoin(left, r, estimate, swap, FALSE);
		if (limit)
			BBPreclaim(left);
		return bn;
	}
	if (swap && (((BAThordered(r) & 1) == 0) || ((BATtordered(l) & 1) && (BATcount(l) > BATcount(r))))) {
		/* reverse join if required (r not sorted) or if l is larger (quick jump through l with binary search) */
		BAT *bn = mergejoin(BATmirror(r), BATmirror(l), NULL, NULL, estimate, limit);

		return bn ? BATmirror(bn) : NULL;
	}
	return mergejoin(l, r, NULL, NULL, estimate, limit);
}

BAT *
BATmergejoin(BAT *l, BAT *r, BUN estimate)
{
	/* allows swapping of left and right input for faster processing */
	return batmergejoin(l, r, estimate, TRUE, NULL);
}

BAT *
BATleftmergejoin(BAT *l, BAT *r, BUN estimate)
{
	/* do not swap left and right input,
	   and hence maintain order of left head in result */
	return batmergejoin(l, r, estimate, FALSE, NULL);
}

BAT *
BATleftmergejoin_limit(BAT *l, BAT *r, BUN estimate, BUN *limit)
{
	return batmergejoin(l, r, estimate, FALSE, limit);
}

@- hash join
These macros encode the core of the join algorithm. They are
the fast inner loops, optimized towards their type.

@= hashjoin
	{
		BUN yy;

		BATaccessBegin(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
		BATloop(l, p, q) {
			v = BUN@3(li, p);
			if (@1_EQ(v, nil, @4)) {
				continue; /* skip nil */
			}
			HASHloop_@2(ri, r->H->hash, yy, v) {
				bunfastins(bn, BUNhead(li, p), BUNtail(ri, yy));
			}
		}
		BATaccessEnd(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
		/* set sorted flags by hand, because we used BUNfastins() */
		bn->hsorted = BAThordered(l);
		bn->tsorted = FALSE;
		break;
	}
@c
BAT *
BAThashjoin(BAT *l, BAT *r, BUN estimate)
{
	ptr v, nil = ATOMnilptr(r->htype);
	BUN p, q;
	int any;
	BAT *bn = NULL;
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);

	@:joincheck(BAThashjoin,l->ttype,r->htype)@
	@:joinbat(JOIN_EQ,BAThashjoin(l,r,BUN_NONE),estimate)@

	BATaccessBegin(r, USE_HEAD, MMAP_SEQUENTIAL);
	if (BATprepareHash(r)) {
		BATaccessEnd(r, USE_HEAD, MMAP_SEQUENTIAL);
		return NULL;
	}
	BATaccessEnd(r, USE_HEAD, MMAP_SEQUENTIAL);
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10)
		BATaccessBegin(r, USE_HEAD | USE_TAIL | USE_HHASH, MMAP_WILLNEED);
	switch (any = ATOMstorage(l->ttype)) {
#ifndef NOEXPAND_CHR
	case TYPE_chr:
		@:hashjoin(simple,chr,tloc,chr)@
#endif
#ifndef NOEXPAND_BTE
	case TYPE_bte:
		@:hashjoin(simple,bte,tloc,bte)@
#endif
#ifndef NOEXPAND_SHT
	case TYPE_sht:
		@:hashjoin(simple,sht,tloc,sht)@
#endif
#if !defined(NOEXPAND_INT) || !defined(NOEXPAND_FLT)
	case TYPE_int:
	case TYPE_flt:
		@:hashjoin(simple,int,tloc,int)@
#endif
#if !defined(NOEXPAND_DBL) || !defined(NOEXPAND_LNG)
	case TYPE_dbl:
	case TYPE_lng:
		@:hashjoin(simple,lng,tloc,lng)@
#endif
	case TYPE_str:
		if (l->T->vheap->hashash) {
			@:hashjoin(atom,str_hv,tail,any)@
		}
		/* fall through */
	default:
		@:hashjoin(atom,any,tail,any)@
	}
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10)
		BATaccessEnd(r, USE_HEAD | USE_TAIL | USE_HHASH, MMAP_WILLNEED);

	/* propagate alignment info */
	bn->hsorted = BAThordered(l);
	if (BAThkey(r)) {
		if (BATcount(bn) == BATcount(l))
			ALIGNsetH(bn, l);
		if (BAThkey(l))
			BATkey(bn, TRUE);
	}
	bn->H->nonil = l->H->nonil;
	bn->T->nonil = r->T->nonil;
	ESTIDEBUG THRprintf(GDKout, "#BAThashjoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;

}

@}

@- Fetch-join
The @`BATfetchjoin@5(l,r) does a join on the basis of positional lookup.
It looks up index numbers from the second parameter in first parameter BAT.
The right parameter may contain OIDs, in which case their base is
subtracted.

In a typical join(BAT[any::1,oid) L, BATvoid,any::2] R) : BAT[any::1,any::2]
we expect each tuple of L to hit exactly once in R. Now if any::1=void
this void column can be carried over to the result. We do that.

However, it is possible that an tail-oid is out of range with respect
to R; in that case some tuples will be missing and we cannot carry on
producing a void column. In that case, we have to switch back
on-the-fly to the non-dense implementation.

The aftermath -- property setting -- is relatively straightforward here.
@{
@c
#define HLATOMput(bn, dst) ATOMput(bn->htype, bn->H->vheap, dst, BUNhloc(li,l_cur))
#define HVATOMput(bn, dst) Hputvalue(bn, dst, BUNhvar(li,l_cur), 1)
#define TLATOMput(bn, dst) ATOMput(bn->ttype, bn->T->vheap, dst, BUNtloc(ri,r_cur))
#define TVATOMput(bn, dst) Tputvalue(bn, dst, BUNtvar(ri,r_cur), 1)

@= SIMPLEput
#define H@1put(bn,dst)	*(@1*) (dst) = *(@1*) (BUNhloc(li,l_cur))
#define T@1put(bn,dst)	*(@1*) (dst) = *(@1*) (BUNtloc(ri,r_cur))
@c
@:SIMPLEput(chr)@
@:SIMPLEput(bte)@
@:SIMPLEput(sht)@
@:SIMPLEput(int)@
@:SIMPLEput(lng)@

@= bunfastins_nocheck_
	H@1put(bn, BUNhloc(bni, dst));
	T@2put(bn, BUNtloc(bni, dst));
@c
@= fetchjoin
static BAT *
densefetchjoin_@1_@2(BAT *bn, BAT *l, BAT *r)
{
	BUN l_cur, l_end, r_cur, dst;
	ssize_t offset;
	BUN base;
	BAT *ret = NULL;
	BATiter bni = bat_iterator(bn);
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);

	if (bn == NULL)
		return NULL;
	dst = BUNfirst(bn);
	base = BUNfirst(r);
	offset = (ssize_t) base - (ssize_t) r->hseqbase; /* cast first, subtract second */
	r_cur = (BUN) (offset + *(oid *) BUNtail(li, BUNfirst(l)));

	ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: densefetchjoin(@1,@2);\n");

	BATaccessBegin(l, USE_HEAD, MMAP_SEQUENTIAL);
	BATaccessBegin(r, USE_TAIL, MMAP_SEQUENTIAL);
	BATloop(l, l_cur, l_end) {
		@:bunfastins_nocheck_(@1,@2)@
		r_cur++;
		dst++;
	}
	ret = bn;
      goto bunins_failed;
      bunins_failed:
	BATaccessEnd(l, USE_HEAD, MMAP_SEQUENTIAL);
	BATaccessEnd(r, USE_TAIL, MMAP_SEQUENTIAL);
	BATsetcount(bn, dst);
	if (!ret)
		BBPreclaim(bn);
	return ret;
}

static BAT *
orderedfetchjoin_@1_@2(BAT *bn, BAT *l, BAT *r)
{
	BUN l_cur, l_end, r_cur, dst;
	ssize_t offset;
	BUN base, yy;
	BAT *ret = NULL;
	BATiter bni = bat_iterator(bn);
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);

	if (bn == NULL)
		return NULL;
	dst = BUNfirst(bn);
	base = BUNfirst(r);
	offset = (ssize_t) base - (ssize_t) r->hseqbase; /* cast first, subtract second */

	ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: orderedfetchjoin(@1,@2);\n");

	BATaccessBegin(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
	BATaccessBegin(r, USE_TAIL, MMAP_SEQUENTIAL);
	BATloop(l, l_cur, l_end) {
		yy = (BUN) (offset + *(oid *) BUNtail(li, l_cur));
		r_cur = yy;
		@:bunfastins_nocheck_(@1,@2)@
		dst++;
	}
	ret = bn;
      goto bunins_failed;
      bunins_failed:
	BATaccessEnd(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
	BATaccessEnd(r, USE_TAIL, MMAP_SEQUENTIAL);
	BATsetcount(bn, dst);
	if (!ret)
		BBPreclaim(bn);
	return ret;
}

static BAT *
defaultfetchjoin_@1_@2(BAT *bn, BAT *l, BAT *r)
{
	BUN l_cur, l_end, r_cur, dst;
	ssize_t offset;
	BUN yy, base, end;
	BAT *ret = NULL;
	BATiter bni = bat_iterator(bn);
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);


	if (bn == NULL)
		return NULL;
	dst = BUNfirst(bn);
	base = BUNfirst(r);
	offset = (ssize_t) base - (ssize_t) r->hseqbase; /* cast first, subtract second */
	end = base + BATcount(r);

	ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: defaultfetchjoin(@1,@2);\n");

	BATaccessBegin(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10)
		BATaccessBegin(r, USE_TAIL, MMAP_WILLNEED);
	/*BATaccessBegin(bn, MMAP_SEQUENTIAL);*/
	BATloop(l, l_cur, l_end) {
		yy = (BUN) (offset + *(oid *) BUNtail(li, l_cur));
		if (yy < base || yy >= end) {
			continue;
		}
		r_cur = yy;
		@:bunfastins_nocheck_(@1,@2)@
		dst++;
	}
	ret = bn;
      goto bunins_failed;
      bunins_failed:
	BATaccessEnd(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10)
		BATaccessEnd(r, USE_TAIL, MMAP_WILLNEED);
	/*BATaccessEnd(bn, MMAP_SEQUENTIAL);*/
	BATsetcount(bn, dst);
	if (!ret)
		BBPreclaim(bn);
	return ret;
}
@c
@= fetchjoin2
	@:fetchjoin(@1,chr)@
	@:fetchjoin(@1,bte)@
	@:fetchjoin(@1,sht)@
	@:fetchjoin(@1,int)@
	@:fetchjoin(@1,lng)@
	@:fetchjoin(@1,VATOM)@
	@:fetchjoin(@1,LATOM)@
@c
@:fetchjoin2(chr)@
@:fetchjoin2(bte)@
@:fetchjoin2(sht)@
@:fetchjoin2(int)@
@:fetchjoin2(lng)@

@:fetchjoin2(VATOM)@
@:fetchjoin2(LATOM)@
@c

@= fetchjoin_switch_rtt
	if (ATOMstorage(rtt) == TYPE_chr) {
		bn = @1fetchjoin_@2_chr(bn, l, r);
	} else if (ATOMstorage(rtt) == TYPE_bte) {
		bn = @1fetchjoin_@2_bte(bn, l, r);
	} else if (ATOMstorage(rtt) == TYPE_sht) {
		bn = @1fetchjoin_@2_sht(bn, l, r);
	} else if (rtt != TYPE_bat &&
		   (ATOMstorage(rtt) == TYPE_int ||
		    ATOMstorage(rtt) == TYPE_flt
#if SIZEOF_OID == SIZEOF_INT
		    || ATOMstorage(rtt) == TYPE_oid
#endif
			   )) {
		/* ensure use of ATOMput for TYPE_bat */
		bn = @1fetchjoin_@2_int(bn, l, r);
	} else if (ATOMstorage(rtt) == TYPE_lng ||
		   ATOMstorage(rtt) == TYPE_dbl
#if SIZEOF_OID == SIZEOF_LNG
		   || ATOMstorage(lht) == TYPE_oid
#endif
		) {
		bn = @1fetchjoin_@2_lng(bn, l, r);
	} else if (r->tvarsized) {
		bn = @1fetchjoin_@2_VATOM(bn, l, r);
	} else {
		bn = @1fetchjoin_@2_LATOM(bn, l, r);
	}
@c
@= fetchjoin_switch_lht
	if (ATOMstorage(lht) == TYPE_chr) {
		@:fetchjoin_switch_rtt(@1,chr)@
	} else if (ATOMstorage(lht) == TYPE_bte) {
		@:fetchjoin_switch_rtt(@1,bte)@
	} else if (ATOMstorage(lht) == TYPE_sht) {
		@:fetchjoin_switch_rtt(@1,sht)@
	} else if (lht != TYPE_bat &&
		   (ATOMstorage(lht) == TYPE_int ||
		    ATOMstorage(lht) == TYPE_flt
#if SIZEOF_OID == SIZEOF_INT
		    || ATOMstorage(lht) == TYPE_oid
#endif
			   )) {
		/* ensure use of ATOMput for TYPE_bat */
		@:fetchjoin_switch_rtt(@1,int)@
	} else if (ATOMstorage(lht) == TYPE_lng ||
		   ATOMstorage(lht) == TYPE_dbl
#if SIZEOF_OID == SIZEOF_LNG
		   || ATOMstorage(lht) == TYPE_oid
#endif
		) {
		@:fetchjoin_switch_rtt(@1,lng)@
	} else if (l->hvarsized) {
		@:fetchjoin_switch_rtt(@1,VATOM)@
	} else {
		@:fetchjoin_switch_rtt(@1,LATOM)@
	}
@c
@= densevoidfetchjoin
	ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: densevoidfetchjoin(@1);\n");
	r_cur = (BUN) (offset + * (oid *) BUNtloc(li, BUNfirst(l)));
	BATaccessBegin(r, USE_TAIL, MMAP_SEQUENTIAL);
	/*BATaccessBegin(bn, MMAP_SEQUENTIAL);*/
	BATloop(l, l_cur, l_end) {
		@1put(bn, Tloc(bn,dst));
		r_cur++;
		dst++;
	}
	BATaccessEnd(r, USE_TAIL, MMAP_SEQUENTIAL);
	/*BATaccessEnd(bn, MMAP_SEQUENTIAL);*/
@c
@= orderedvoidfetchjoin
	ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: orderedvoidfetchjoin(@1);\n");
	BATaccessBegin(l, USE_TAIL, MMAP_SEQUENTIAL);
	BATaccessBegin(r, USE_TAIL, MMAP_SEQUENTIAL);
	/*BATaccessBegin(bn, MMAP_SEQUENTIAL);*/
	BATloop(l, l_cur, l_end) {
		BUN _yy = (BUN) (offset + * (oid *) BUNtloc(li, l_cur));

		r_cur = _yy;
		@1put(bn, Tloc(bn,dst));
		dst++;
	}
	BATaccessEnd(l, USE_TAIL, MMAP_SEQUENTIAL);
	BATaccessEnd(r, USE_TAIL, MMAP_SEQUENTIAL);
	/*BATaccessEnd(bn, MMAP_SEQUENTIAL);*/
@c
@= defaultvoidfetchjoin
	ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: defaultvoidfetchjoin(@1);\n");
	BATaccessBegin(l, USE_TAIL, MMAP_SEQUENTIAL);
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10) 
		BATaccessBegin(r, USE_TAIL, MMAP_WILLNEED);
	BATloop(l, l_cur, l_end) {
		BUN _yy = (BUN) (offset + * (oid *) BUNtloc(li, l_cur));

		if (_yy < base || _yy >= end) {
			BATsetcount(bn, dst);
			BBPreclaim(bn);
			nondense = 1;
			break;
		}
		r_cur = _yy;
		@1put(bn, Tloc(bn,dst));
		dst++;
	}
	BATaccessEnd(l, USE_TAIL, MMAP_SEQUENTIAL);
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10) 
		BATaccessEnd(r, USE_TAIL, MMAP_WILLNEED);
	if (nondense) {
		BATiter bni; 
		/* not (yet?) completely type-optimized ! */
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: defaultvoidfetchjoin(@1): discovered non-density, resuming with non-void head\n");
		bn = BATnew(BAThtype(l), ATOMtype(tpe), BATcount(l));
		if (bn == NULL)
			return bn;
		dst = BUNfirst(bn);
		bni = bat_iterator(bn);
		BATaccessBegin(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
		BATaccessBegin(r, USE_TAIL, MMAP_WILLNEED);
		/*BATaccessBegin(bn, MMAP_SEQUENTIAL);*/
		BATloop(l, l_cur, l_end) {
			BUN _yy = (BUN) (offset + * (oid *) BUNtail(li, l_cur));

			if (_yy < base || _yy >= end) {
				continue;
			}
			r_cur = _yy;
			Hputvalue(bn, BUNhloc(bni, dst), BUNhead(li, l_cur), 1);
			@1put(bn, BUNtloc(bni, dst));
			dst++;
		}
		BATaccessEnd(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
		BATaccessEnd(r, USE_TAIL, MMAP_WILLNEED);
	}
@c
@= voidfetchjoin
	if (BATtdense(l)) {
		/* dense => ordered, i.e., we did check the bounderies already above */
		/* and we can do a "synchronized walk" through l & r */
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: BAThvoid(l) && !BATtvoid(l) && BATtdense(l)\n");
		@:densevoidfetchjoin(@1)@
	} else if ((BATtordered(l)&1) || hitalways) {
		/* we did check the bounderies already above (BATtordered(l)&1) or simply "trust" hitalways */
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: BAThvoid(l) && !BATtvoid(l) && !BATtdense(l) && ( BATtordered(l)&1 [== %d] || hitalways [== %d] )\n", (int)(BATtordered(l)&1), (int)hitalways);
		@:orderedvoidfetchjoin(@1)@
	} else {
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: BAThvoid(l) && !BATtvoid(l) && !BATtdense(l) && !BATtordered(l)&1 && !hitalways\n");
		@:defaultvoidfetchjoin(@1)@
	}
@c
#define SIMPLEput(tpe,hp,dst,src) *(tpe*) (dst) = *(tpe*) (src)

static BAT *
batfetchjoin(BAT *l, BAT *r, BUN estimate, bit swap, bit hitalways)
{
	int lht, rtt;
	BUN base, end;
	ssize_t offset;
	BUN lcount, rcount;
	BUN r_cur, l_cur, l_end;
	oid seqbase;
	BAT *ret = NULL, *bn = NULL, *l_orig = l;
	bit hitalways_check = FALSE;
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);

	BATcheck(l, "BATfetchjoin: left BAT required");
	BATcheck(r, "BATfetchjoin: right BAT required");

	lcount = BATcount(l);
	rcount = BATcount(r);
	if (estimate == BUN_NONE || estimate < lcount) {
		/* upper bound to avoid size checks in the join loop */
		estimate = lcount;
	}

	if (swap) {
		if (!BAThdense(r)) {
			ERRORcheck(!BATtdense(l), "BATfetchjoin: one join column must be dense");
			ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: BATmirror(BATfetchjoin(BATmirror(r),BATmirror(l)));\n");

			return BATmirror(batfetchjoin(BATmirror(r), BATmirror(l), estimate, FALSE, FALSE));
		}
	} else {
		ERRORcheck(!BAThdense(r), "BATfetchjoin: head column of right input must be dense");
	}
	/* not checking boundaries is very dangerous; use regression tests with debugmask=8 first */
	PROPDEBUG {
		hitalways_check = hitalways;
		hitalways = FALSE;
	}

	if (lcount == 0 || rcount == 0) {
		/* below range checking do not support empty bats. so treat them separately (easy) */
		@:return_empty_join_result(l_orig,r, BATfetchjoin: |l|==0 or |r|==0,1)@
@= return_empty_join_result
		ALGODEBUG THRprintf(GDKout, "#@3 => empty result\n");
#if @4
		if (hitalways|hitalways_check && lcount > 0) {
			GDKerror("BATfetchjoin(%s,%s) does not hit always (|bn|=0 != "BUNFMT"=|l|) => can't use fetchjoin.\n", BATgetId(l), BATgetId(r), lcount);
			return NULL;
		}
#endif
		bn = BATnew(@1->htype, @2->ttype, 0);
		if (bn == NULL)
			return NULL;
		bn->hsorted = bn->tsorted = GDK_SORTED;
		BATkey(bn, TRUE);
		BATkey(BATmirror(bn), TRUE);
		if (bn->htype == TYPE_void || bn->htype == TYPE_oid) {
			bn->hdense = TRUE;
			BATseqbase(bn, @1->htype == TYPE_void ? @1->hseqbase : 0);
		}
		if (bn->ttype == TYPE_void || bn->ttype == TYPE_oid) {
			bn->tdense = TRUE;
			BATseqbase(BATmirror(bn), @2->ttype == TYPE_void ? @2->tseqbase : 0);
		}
		return bn;
@c
	} else if (hitalways && BATtdense(l) && BAThdense(r) && l->tseqbase == r->hseqbase) {
		/* always hit and tail of left is alligned with head of right */
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: BATtdense(l) && BAThdense(r)\n");
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: VIEWcreate(l,r)\n");

		return VIEWcreate(l, r);
	} else if (hitalways && BAThdense(r) && BATtdense(r) && r->hseqbase == r->tseqbase) {
		/* idempotent join: always hit and substitute tail with the same value */
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: BAThdense(r) && BATtdense(r)\n");
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: VIEWcreate(l,l)\n");

		return VIEWcreate(l, l);
	} else if ((BATtordered(l) & 1)) {
		/* optimization to be able to carry over more void head columns */
		/* (only needed if neither operand is empty) */
		oid r_lo = *(oid *) BUNhead(ri, BUNfirst(r));
		oid r_hi = *(oid *) BUNhead(ri, BUNlast(r) - 1);
		oid l_lo = *(oid *) BUNtail(li, BUNfirst(l));
		oid l_hi = *(oid *) BUNtail(li, BUNlast(l) - 1);
		int empty = ATOMcmp(TYPE_oid, &r_lo, &l_hi) > 0 || ATOMcmp(TYPE_oid, &r_hi, &l_lo) < 0;
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: BATtordered(l)&1\n");
		ALGODEBUG THRprintf(GDKout, "#r_lo=" OIDFMT ", r_hi=" OIDFMT ", l_lo=" OIDFMT ", l_hi=" OIDFMT ".\n", r_lo, r_hi, l_lo, l_hi);

		if (!empty &&
		    (ATOMcmp(TYPE_oid, &r_lo, &l_lo) > 0 ||
		     ATOMcmp(TYPE_oid, &r_hi, &l_hi) < 0)) {
			ALGODEBUG THRprintf(GDKout, "#shrinking!\n");
			ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: l = BATselect(l, &r_lo, &r_hi);\n");

			li.b = l = BATselect(l, &r_lo, &r_hi);	/* sorted, so it will be a slice */
			if (l == NULL)
				return NULL;
			if (BATcount(l) == 0) {
				if (l != l_orig) {
					BBPreclaim(l);	/* was created as a temporary (slice) select on l */
				}
				empty = 1;
			}
		}
		if (empty) {
			@:return_empty_join_result(l_orig, r, BATfetchjoin: empty,1)@
		} else if (hitalways | hitalways_check && BATcount(l) < lcount) {
			GDKerror("BATfetchjoin(%s,%s) does not hit always (|bn|=" BUNFMT " != " BUNFMT "=|l|) => can't use fetchjoin.\n", BATgetId(l), BATgetId(r), BATcount(l), lcount);
			return NULL;
		}
		lcount = BATcount(l);
	}
	ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: 1\n");

	base = BUNfirst(r);
	offset = (ssize_t) base - (ssize_t) r->hseqbase;	/* cast first, subtract second */
	end = base + rcount;
	/* only BUNhead crashes on empty bats with TYPE != virtual oid */
	seqbase = l->htype == TYPE_void ?
		l->hseqbase :
		(lcount ?
		 (l->htype == TYPE_int ?
		  (oid) *(int *) BUNhead(li, BUNfirst(l)) :
		  (l->htype == TYPE_oid ?
		   *(oid *) BUNhead(li, BUNfirst(l)) :
		   (l->htype == TYPE_lng ?
		    (oid) *(lng *) BUNhead(li, BUNfirst(l)) :
		    oid_nil))) :
		 oid_nil);

	ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: 2\n");

	if (!BAThvoid(l)) {
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: !BAThvoid(l)\n");

		/* default case: no void column to propagate */
		lht = l->htype;
		rtt = r->ttype;

		if (ATOMstorage(rtt) == TYPE_str &&
		    estimate > batcache_maxbuckets * BATTINY &&
		    ((BATtordered(l) & 1) || r->T->vheap->free < MT_MMAP_TILE) &&
		    (!rcount || (lcount << 3) > rcount)) {
			/* insert as ints and copy/share the string heap */
			rtt = r->T->width == 1 ? TYPE_bte : (r->T->width == 2 ? TYPE_sht : (r->T->width == 4 ? TYPE_int : TYPE_lng));
		}
		bn = BATnew(BAThtype(l), ATOMtype(rtt), estimate);
		if (bn == NULL)
			goto ready;
		ESTIDEBUG THRprintf(GDKout, "#BATfetchjoin: estimated resultsize: " BUNFMT "\n", lcount);

		/* TODO: apply the "string trick" (see below) here too */
		if (BATtdense(l)) {
			/* dense => ordered, i.e., we did check the bounderies already above */
			/* and we can do a "synchronized walk" through l & r */
			ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: !BAThvoid(l) && BATtdense(l)\n");
			@:fetchjoin_switch_lht(dense)@
		} else if ((BATtordered(l) & 1) || hitalways) {
			/* we did check the bounderies already above (BATtordered(l)&1) or simply "trust" hitalways */
			ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: !BAThvoid(l) && !BATtdense(l) && ( BATtordered(l)&1 [== %d] || hitalways [== %d] )\n", (int) (BATtordered(l) & 1), (int) hitalways);
			@:fetchjoin_switch_lht(ordered)@
		} else {
			ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: !BAThvoid(l) && !BATtdense(l) && !BATtordered(l)&1 && !hitalways\n");

			@:fetchjoin_switch_lht(default)@
		}
		/* handle string trick */
		if (rtt != r->ttype && ATOMstorage(r->ttype) == TYPE_str) {
			if (r->batRestricted == BAT_READ) {
				assert(r->T->vheap->parentid > 0);
				BBPshare(r->T->vheap->parentid);
				bn->T->vheap = r->T->vheap;
			} else {
				bn->T->vheap = (Heap *) GDKzalloc(sizeof(Heap));
				if (bn->T->vheap == NULL) {
					BBPreclaim(bn);
					goto ready;
				}
				bn->T->vheap->parentid = bn->batCacheid;
				if (r->T->vheap->filename) {
					char *nme = BBP_physical(bn->batCacheid);

					bn->T->vheap->filename = (str) GDKmalloc(strlen(nme) + 12);
					if (bn->T->vheap->filename == NULL) {
						BBPreclaim(bn);
						goto ready;
					}
					GDKfilepath(bn->T->vheap->filename, NULL, nme, "theap");
				}
				if (HEAPcopy(bn->T->vheap, r->T->vheap) < 0) {
					BBPreclaim(bn);
					goto ready;
				}
			}
			bn->ttype = r->ttype;
			bn->tvarsized = 1;
			bn->T->width = r->T->width;
			bn->T->shift = r->T->shift;
		}
		bn->hsorted = (BATtordered(l) & BAThordered(r) & 1) ? BAThordered(l) : 0;
	} else if (!BATtvoid(l)) {
		/* propagation of void columns in the result */
		int nondense = 0;
		int tpe = r->ttype;
		BUN dst;

		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: BAThvoid(l) && !BATtvoid(l)\n");

		if (ATOMstorage(tpe) == TYPE_str && estimate > batcache_maxbuckets * BATTINY &&
		    /* GDK_ELIMDOUBLES(r->T->vheap) && */
		    (!rcount || (lcount << 3) > rcount)) {
			/* insert double-eliminated strings as ints */
			tpe = r->T->width == 1 ? TYPE_bte : (r->T->width == 2 ? TYPE_sht : (r->T->width == 4 ? TYPE_int : TYPE_lng));
		}
		bn = BATnew(TYPE_void, ATOMtype(tpe), estimate);
		if (bn == NULL)
			goto ready;
		ESTIDEBUG THRprintf(GDKout, "#BATfetchjoin: estimated resultsize: " BUNFMT "\n", lcount);

		dst = BUNfirst(bn);

		if (ATOMstorage(tpe) == TYPE_chr) {
			@:voidfetchjoin(Tchr)@
		} else if (ATOMstorage(tpe) == TYPE_bte) {
			@:voidfetchjoin(Tbte)@
		} else if (ATOMstorage(tpe) == TYPE_sht) {
			@:voidfetchjoin(Tsht)@
		} else if (tpe != TYPE_bat &&
			   (ATOMstorage(tpe) == TYPE_int ||
			    ATOMstorage(tpe) == TYPE_flt)) {
			/* ensure use of ATOMput for TYPE_bat */
			@:voidfetchjoin(Tint)@
		} else if (ATOMstorage(tpe) == TYPE_lng ||
			   ATOMstorage(tpe) == TYPE_dbl) {
			@:voidfetchjoin(Tlng)@
		} else if (r->tvarsized) {
			@:voidfetchjoin(TVATOM)@
		} else {
			@:voidfetchjoin(TLATOM)@
		}
		ret = bn;
		goto bunins_failed;
	      bunins_failed:
		BATsetcount(bn, dst);
		if (ret == NULL) {
			BBPreclaim(bn);
			goto ready;
		}
		/* handle string trick */
		if (tpe != r->ttype && ATOMstorage(r->ttype) == TYPE_str) {
			bn->T->vheap = (Heap *) GDKzalloc(sizeof(Heap));
			if (bn->T->vheap == NULL) {
				BBPreclaim(bn);
				ret = NULL;
				goto ready;
			}
			bn->T->vheap->parentid = bn->batCacheid;
			if (r->T->vheap->filename) {
				char *nme = BBP_physical(bn->batCacheid);

				bn->T->vheap->filename = (str) GDKmalloc(strlen(nme) + 12);
				if (bn->T->vheap->filename == NULL) {
					BBPreclaim(bn);
					ret = NULL;
					goto ready;
				}
				GDKfilepath(bn->T->vheap->filename, NULL, nme, "theap");
			}
			if (HEAPcopy(bn->T->vheap, r->T->vheap) < 0) {
				BBPreclaim(bn);
				ret = NULL;
				goto ready;
			}
			bn->ttype = r->ttype;
			bn->tvarsized = 1;
			bn->T->width = r->T->width;
			bn->T->shift = r->T->shift;
		}
		if (nondense) {
			bn->hsorted = (BATtordered(l) & BAThordered(r) & 1) ? BAThordered(l) : 0;
		} else {
			BATseqbase(bn, seqbase);
			if (seqbase != oid_nil)
				BATkey(bn, TRUE);
			bn->hsorted = GDK_SORTED;
		}
	} else if (l->tseqbase != oid_nil) {
		/* execute using slice */
		BAT *v = BATmirror(VIEWhead(BATmirror(r)));
		oid lo_val = MAX(l->tseqbase, r->hseqbase);
		oid hi_val = MIN(l->tseqbase + lcount, r->hseqbase + rcount);
		BUN lo_pos = lo_val - r->hseqbase;
		BUN hi_pos = hi_val;

		if (hi_pos > r->hseqbase)
			hi_pos -= r->hseqbase;
		else
			hi_pos = 0;
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: BAThvoid(l) && BATtvoid(l) && l->tseqbase != oid_nil  =>  bn = BATslice(BATmirror(VIEWhead(BATmirror(r))), lo_pos=" BUNFMT ", hi_pos=" BUNFMT ");\n", lo_pos, hi_pos);

		bn = BATslice(v, lo_pos, hi_pos);
		if (seqbase != oid_nil)
			seqbase += lo_val - l->tseqbase;
		BATseqbase(bn, seqbase);
		BBPunfix(v->batCacheid);
	} else {
		/* nil join column => empty result */
		ALGODEBUG THRprintf(GDKout, "#BATfetchjoin: BAThvoid(l) && BATtvoid(l) && l->tseqbase == oid_nil\n");

		bn = BATnew(ATOMtype(l->htype), ATOMtype(r->ttype), 10);
		if (bn == NULL)
			goto ready;
		ESTIDEBUG THRprintf(GDKout, "#BATfetchjoin: estimated resultsize: %d\n", 10);
	}
	/* property propagation */
	if (BATcount(bn) == lcount) {
		ALIGNsetH(bn, l);	/* BAThkey(r), remember? */
	} else {
		if (hitalways | hitalways_check) {
			GDKerror("BATfetchjoin(%s,%s) does not hit always (|bn|=" BUNFMT " != " BUNFMT "=|l|) => can't use fetchjoin.\n", BATgetId(l), BATgetId(r), BATcount(bn), lcount);
			BBPreclaim(bn);
			ret = NULL;
			goto ready;
		}
		bn->hsorted = l->hsorted;
	}
	bn->tsorted = (BATtordered(l) & BATtordered(r) & 1) ? GDK_SORTED : 0;
	if (BATtkey(l)) {
		/* if BATtkey(l) elements of r match at most once */
		if ((BATtordered(l) & 1) && BATcount(bn) == rcount) {
			ALIGNsetT(bn, r);
		} else {
			BATkey(BATmirror(bn), BATtkey(r));
		}
	}
	bn->H->nonil = l->H->nonil;
	bn->T->nonil = r->T->nonil;
	ret = bn;
      ready:
	if (l != l_orig) {
		BBPreclaim(l);	/* was created as a temporary (slice) select on l */
	}
	ESTIDEBUG THRprintf(GDKout, "#BATfetchjoin: actual resultsize: " BUNFMT "\n", ret ? BATcount(ret) : 0);
	return ret;
}

BAT *
BATfetchjoin(BAT *l, BAT *r, BUN estimate)
{
	/* fetchjoin now implies that you assure no fetch misses (hitalways) */
	/* allows swapping of left and right input for faster processing */
	return batfetchjoin(l, r, estimate, TRUE, TRUE);
}

BAT *
BATleftfetchjoin(BAT *l, BAT *r, BUN estimate)
{
	/* fetchjoin now implies that you assure no fetch misses (hitalways) */
	/* do not swap left and right input,
	   and hence maintain order of left head in result */
	return batfetchjoin(l, r, estimate, FALSE, TRUE);
}

@-
This routine does the join optimization. 
@c
static BAT *
batjoin(BAT *l, BAT *r, BUN estimate, bit swap)
{
	size_t lsize, rsize, mem_size = MT_npages() * MT_pagesize() / (GDKnr_threads ? GDKnr_threads : 1);
	BUN i, lcount, rcount;
	bit lfetch, rfetch, must_hash;
	lng logr, logl;

	ERRORcheck(l == NULL, "BATjoin: invalid left operand");
	ERRORcheck(r == NULL, "BATjoin: invalid right operand");
	ERRORcheck(TYPEerror(l->ttype, r->htype), "BATjoin: type conflict\n");
	lcount = BATcount(l);
	rcount = BATcount(r);

	if (lcount == 0 || rcount == 0 ||
	    (l->ttype == TYPE_void && l->tseqbase == oid_nil) ||
	    (r->htype == TYPE_void && r->hseqbase == oid_nil)) {
		BAT *bn;

		@:return_empty_join_result(l,r, BATjoin: |l|==0 or |r|==0 or tail(l)==NIL or head(r)==NIL,0)@
	}
@-
collect statistics that help us decide what to do
@c
	lsize = lcount * (Hsize(l) + Tsize(l)) + (l->H->vheap ? l->H->vheap->size : 0) + (l->T->vheap ? l->T->vheap->size : 0) + 2 * lcount * sizeof(BUN);
	rsize = rcount * (Hsize(r) + Tsize(r)) + (r->H->vheap ? r->H->vheap->size : 0) + (r->T->vheap ? r->T->vheap->size : 0) + 2 * rcount * sizeof(BUN);
	for (logr = 4, i = rcount; i > 0; logr++)
		i >>= 1;
	for (logl = 4, i = lcount; i > 0; logl++)
		i >>= 1;

	rfetch = BAThdense(r);
	lfetch = BATtdense(l);
	/* in case of fetchjoin, make sure we propagate a non-join
	   void column */
	if (lfetch && rfetch) {
		if (BAThvoid(l) && !BATtvoid(r))
			lfetch = 0;
		if (swap && BATtvoid(r) && !BAThvoid(l))
			rfetch = 0;
	}
	/* in case of fetchjoin, make sure we exploit sortedness for
	   sequential access */
	if (lfetch && rfetch) {
		if (BATtordered(l) & 1 && !(BAThordered(r) & 1))
			lfetch = 0;
		if (swap && BAThordered(r) & 1 && !(BATtordered(l) & 1))
			rfetch = 0;
	}
	must_hash = swap && rsize > lsize ? l->T->hash == NULL : r->H->hash == NULL;
@-
Inner input out of memory => sort-merge-join performs better than hash-join or even random-access fetch-join.
@c
	if (((swap && MIN(lsize, rsize) > mem_size) ||
	     (!swap && rsize > mem_size)) &&
	    !(BATtordered(l) & BAThordered(r) & 1)) {
		/* inner input out of memory, but not both sorted
		   (sequential-access fetch/merge handled by special
		   cases below) */
		if (BATtordered(l) & 1 || swap) {
			/* left tail already sorted (i.e., no re-order
			   required) or left-order-preserving not
			   required (i.e., re-order allowed) */
			BAT *ls, *rs, *j;

			/* if not yet sorted on tail, sort left input on tail */
			ls = BATtordered(l) & 1 ? l : BATmirror(BATsort(BATmirror(l)));
			ERRORcheck(ls == NULL, "BATjoin: BATmirror(BATsort(BATmirror(l))) failed");
			/* if not yet sorted on head, sort right input on head */
			rs = BAThordered(r) & 1 ? r : BATsort(r);
			ERRORcheck(rs == NULL, "BATjoin: BATsort(r) failed");
			if (swap && rsize > lsize) {
				/* left-order-preserving not required: user smaller input as inner (right) */
				/* (not sure, though, whether this makes a difference with merge-join ...) */
				ALGODEBUG THRprintf(GDKout, "#BATjoin: BATmirror(BATmergejoin(BATmirror(BATsort(r)), BATsort(BATmirror(l)), " BUNFMT "));\n", estimate);
				j = BATmirror(batmergejoin(BATmirror(rs), BATmirror(ls), estimate, swap, NULL));
				ERRORcheck(j == NULL, "BATjoin: BATmirror(batmergejoin(BATmirror(rs), BATmirror(ls), estimate, swap, NULL)) failed");
			} else {
				/* left-order-preserving required, or inner (right) input is smaller one */
				ALGODEBUG THRprintf(GDKout, "#BATjoin: BATmergejoin(BATmirror(BATsort(BATmirror(l))), BATsort(r), " BUNFMT "));\n", estimate);
				j = batmergejoin(ls, rs, estimate, swap, NULL);
				ERRORcheck(j == NULL, "BATjoin: batmergejoin(ls, rs, estimate, swap, NULL) failed");
			}
			if (ls != l) {
				/* release temp. tail-ordered copy of left input */
				BBPunfix(ls->batCacheid);
			}
			if (rs != r) {
				/* release temp. head-ordered copy of right input */
				BBPunfix(rs->batCacheid);
			}
			return j;
		} else
			/* as of here, left order must be preserved /
			   restored */
		if (BAThordered(l) & 1 && l->htype < TYPE_str) {
			/* left head sorted (i.e., left order can be
			   restored with simple (stable) sort of join
			   result), provided the sort is fast (i.e.,
			   not on varsized types) */
			BAT *ls, *rs, *jj, *j;

			ALGODEBUG THRprintf(GDKout, "#BATjoin: BAT[s]sort(BATmergejoin(BATmirror(BAT[s]sort(BATmirror(l))), BATsort(r), " BUNFMT "));\n", estimate);
			/* sort left input on tail, use stable sort to maintain original order of duplicate head values */
			ls = BAThkey(l) ? BATmirror(BATsort(BATmirror(l))) : BATmirror(BATssort(BATmirror(l)));
			ERRORcheck(ls == NULL, "BATjoin: BATmirror(BAT[s]sort(BATmirror(l))) failed");
			/* if not yet sorted on head, sort right input on head */
			rs = BAThordered(r) & 1 ? r : BATsort(r);
			ERRORcheck(rs == NULL, "BATjoin: BATsort(r) failed");
			/* perform merge join */
			jj = batmergejoin(ls, rs, estimate, swap, NULL);
			ERRORcheck(jj == NULL, "BATjoin: batmergejoin(ls, rs, estimate, swap, NULL) failed");
			/* release temp. tail-ordered copy of left input */
			BBPunfix(ls->batCacheid);
			ls = NULL;
			if (rs != r) {
				/* release temp. head-ordered copy of right input */
				BBPunfix(rs->batCacheid);
				rs = NULL;
			}
			/* sort join result on head to restore physical left-input-order;
			 * use stable sort to maintain original order of duplicate head values */
			j = BAThkey(l) ? BATsort(jj) : BATssort(jj);
			ERRORcheck(j == NULL, "BATjoin: BAT[s]sort(jj) failed");
			/* release temp. unordered join result */
			BBPunfix(jj->batCacheid);
			jj = NULL;
			return j;
		} else {
			/* - separate left head & tail using BATmark
			 * - sort left tail
			 * - sort right head
			 * - merge-join left (tail) & right (head)
			 * - sort join result on BATmark-generated left OIDs to restore left order
			 * - re-add left head with seq. access fetchjoin
			 */
			BAT *lh, *lt, *ls, *rs, *jj, *js, *j;

			ALGODEBUG THRprintf(GDKout, "#BATjoin: BATmirror(batfetchjoin(BATmirror(BATsort(BATmergejoin(BATmirror(BATsort(BATmark(BATmirror(l),0))), BATsort(r), " BUNFMT "))), BATmirror(BATmark(l,0))));\n", estimate);
			/* separate left head & tail using BATmark */
			lh = BATmark(l, 0);
			ERRORcheck(lh == NULL, "BATjoin: BATmark(l,0) failed");
			lt = BATmirror(BATmark(BATmirror(l), 0));
			ERRORcheck(lt == NULL, "BATjoin: BATmirror(BATmark(BATmirror(l),0)) failed");
			/* sort left tail */
			ls = BATmirror(BATsort(BATmirror(lt)));
			ERRORcheck(ls == NULL, "BATjoin: BATmirror(BATsort(BATmirror(lt))) failed");
			/* release temp. unsorted left tail */
			BBPunfix(lt->batCacheid);
			lt = NULL;
			/* if not yet sorted on head, sort right input on head */
			rs = BAThordered(r) & 1 ? r : BATsort(r);
			ERRORcheck(rs == NULL, "BATjoin: BATsort(r) failed");
			/* perform merge join */
			jj = batmergejoin(ls, rs, estimate, swap, NULL);
			ERRORcheck(jj == NULL, "BATjoin: batmergejoin(ls, rs, estimate, swap, NULL) failed");
			/* release temp. ordered copy of left tail */
			BBPunfix(ls->batCacheid);
			ls = NULL;
			if (rs != r) {
				/* release temp. head-ordered copy of right input */
				BBPunfix(rs->batCacheid);
				rs = NULL;
			}
			/* sort join result on head to restore physical left-input-order */
			js = BATsort(jj);
			ERRORcheck(js == NULL, "BATjoin: BATsort(jj) failed");
			/* release temp. unordered join result */
			BBPunfix(jj->batCacheid);
			jj = NULL;
			/* restore original left head values */
			j = BATmirror(batfetchjoin(BATmirror(js), BATmirror(lh), BATcount(js), swap, TRUE));
			ERRORcheck(j == NULL, "BATjoin: BATmirror(batfetchjoin(BATmirror(js), BATmirror(lh), BATcount(js), swap, TRUE)) failed");
			/* release temp.sorted join result */ 
			BBPunfix(js->batCacheid);
			js = NULL;
			/* release temp. copy of left head */
			BBPunfix(lh->batCacheid);
			lh = NULL;
			return j;
		}
	}
@-
In special cases (equal join columns, void join columns, or ordered
join columns), we take special action.
@c
	if (swap && lfetch && !(rfetch && lcount <= rcount)) {
		ALGODEBUG THRprintf(GDKout, "#BATjoin: BATmirror(BATfetchjoin(BATmirror(r), BATmirror(l), " BUNFMT "));\n", estimate);

		return BATmirror(batfetchjoin(BATmirror(r), BATmirror(l), estimate, TRUE, FALSE));
	} else if (rfetch) {
		ALGODEBUG THRprintf(GDKout, "#BATjoin: BATfetchjoin(l, r, " BUNFMT ");\n", estimate);

		return batfetchjoin(l, r, estimate, swap, FALSE);
	}
@-
If both are ordered we do merge-join, or if hash-join is not possible right
away and one input is ordered and the other is much smaller, we do nested
loop binary search (both implemented by BATmergejoin).
@c
	if ((BATtordered(l) & BAThordered(r) & 1) ||
	    (must_hash &&
	     (((BATtordered(l) & 1) &&
	       ((lng) lcount > logl * (lng) rcount) &&
	       swap) ||
	      ((BAThordered(r) & 1) &&
	       ((lng) rcount > logr * (lng) lcount))))) {
		ALGODEBUG THRprintf(GDKout, "#BATjoin: BATmergejoin(l,r," BUNFMT ");\n", estimate);

		return batmergejoin(l, r, estimate, swap, NULL);
	}
@-
hash join: the bread&butter join of monet
@c
	/* Simple rule, always build hash on the smallest */
	if (swap && rsize > lsize) {
		ALGODEBUG THRprintf(GDKout, "#BATjoin: BATmirror(BAThashjoin(BATmirror(r), BATmirror(l)," BUNFMT "));\n", estimate);

		return BATmirror(BAThashjoin(BATmirror(r), BATmirror(l), estimate));
	}
	ALGODEBUG THRprintf(GDKout, "#BATjoin: BAThashjoin(l,r," BUNFMT ");\n", estimate);

	return BAThashjoin(l, r, estimate);
}

BAT *
BATjoin(BAT *l, BAT *r, BUN estimate)
{
	/* allows swapping of left and right input for faster processing */
	BAT *b = batjoin(l, r, estimate, TRUE);

	/* invest in property check, since we cannot easily derive the result properties,
	 * but later operations might benefit from / depend on them
	 * Disable via command line option  --debug=16777216
	 */
	JOINPROPCHK {
		if (b) {
			BATpropcheck(b, BATPROPS_QUICK);
			if (b->H != b->T)
				BATpropcheck(BATmirror(b), BATPROPS_QUICK);
		}
	}

	return b;
}

BAT *
BATleftjoin(BAT *l, BAT *r, BUN estimate)
{
	/* do not swap left and right input,
	   and hence maintain order of left head in result */
	BAT *b = batjoin(l, r, estimate, FALSE);

	/* invest in property check, since we cannot easily derive the result properties,
	 * but later operations might benefit from / depend on them
	 * Disable via command line option  --debug=16777216
	 */
	JOINPROPCHK {
		if (b) {
			BATpropcheck(b, BATPROPS_QUICK);
			if (b->H != b->T)
				BATpropcheck(BATmirror(b), BATPROPS_QUICK);
		}
	}
	return b;
}

@
@}
@+  Outerjoin
The left outerjoin between two BAT is also supported. The code is
identical to the hashjoin algorithm with the extension to insert a BUN
if no match can be found.
@{
@= outerjoinloop
{
	ptr v, nilh = ATOMnilptr(r->htype), nilt = ATOMnilptr(r->ttype);
	BUN xx;
	BUN p, q;
	@4

	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10)
		BATaccessBegin(r, USE_HEAD|USE_TAIL|USE_HHASH, MMAP_WILLNEED);
	BATloop(l, p, q) {
		BUN i = 0;

		v = (ptr) BUNtail(li, p);
		if (!@1_EQ(v, nilh, @5))
			HASHloop_@2(ri, r->H->hash, xx, v) {
				@3(bn, s, BUNhead(li, p), BUNtail(ri, xx));
				i++;
			}
		if (i == 0) {
			@3(bn, s, BUNhead(li, p), nilt);
		}
	}
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10)
		BATaccessEnd(r, USE_HEAD|USE_TAIL|USE_HHASH, MMAP_WILLNEED);
}
break;
@
@-
The baseline join algorithm creates a hash on the smallest element and
probes it using the larger one. [TODO]
@c
BAT *
BATouterjoin(BAT *l, BAT *r, BUN estimate)
{
	BAT *bn = NULL;
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);

	@:joincheck(BATouterjoin,l->ttype,r->htype)@
	if (BAThkey(r) && (estimate == BUN_NONE || estimate < BATcount(l)))
		estimate = BATcount(l);
	if (BAThdense(l) && BAThkey(r)) {
		bn = BATnew(TYPE_void, ATOMtype(r->ttype), estimate);
		if (bn == NULL)
			return bn;
		ESTIDEBUG THRprintf(GDKout, "#BATouterjoin: estimated resultsize: " BUNFMT "\n", estimate);

		BATseqbase(bn, l->hseqbase);
	}
	if (BAThdense(r) == FALSE && BAThordered(r) & 1) {
		/* use the merge-join; it takes care of the rest */
		ALGODEBUG THRprintf(GDKout, "#BATouterjoin: mergejoin(l, r, bn, ATOMnilptr(r->ttype), estimate);\n");

		bn = mergejoin(l, r, bn, ATOMnilptr(r->ttype), estimate, NULL);
		ESTIDEBUG THRprintf(GDKout, "#BATouterjoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

		/* invest in property check, since we cannot easily derive the result properties,
		 * but later operations might benefit from / depend on them
		 * Disable via command line option  --debug=16777216
		 */
		JOINPROPCHK {
			if (bn)
				BATpropcheck(bn, BATPROPS_QUICK);
		}

		return bn;
	} else if (bn == NULL) {
		@:joinbat(JOIN_EQ,BATouterjoin(l,r,BUN_NONE),estimate)@
	}

	/* Just to silence compilers (Intel's icc) that otherwise might
	 * complain about "declared but never referenced" labels
	 * (condition should never be true).
	 * (A "dead" goto between the return and the label makes (other)
	 * compilers (Sun) complain about never reached code...)
	 */
	if (!bn)
		goto bunins_failed;

	BATaccessBegin(l, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
	if (BAThdense(r)) {
		/* positional algorithm: hash on void column would give error and is stupid */
		ptr nilt = ATOMnilptr(r->ttype);
		bit nonil = TRUE;
		BUN p, q, w, s = BUNfirst(bn);

		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(l) > BATcount(r)/10)
			BATaccessBegin(r, USE_TAIL, BATtordered(l) & 1 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
		BATloop(l, p, q) {
			oid v = *(oid *) BUNtail(li, p);
			ptr t = nilt;

			if (v != oid_nil) {
				BUNfndVOID(w, ri, &v);
				if (w != BUN_NONE)
					t = BUNtail(ri, w);
			}
			nonil &= (t != nilt);
			bunfastins_nocheck(bn, s, BUNhead(li, p), t, Hsize(bn), Tsize(bn));
			s++;
		}
		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(l) > BATcount(r)/10)
			BATaccessEnd(r, USE_TAIL, BATtordered(l) & 1 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
		bn->tsorted = ((BATtordered(l) & BATtordered(r) & 1) && nonil) ? GDK_SORTED : 0;
	} else {
		/* hash based algorithm (default) */
		int any = ATOMstorage(r->htype);

		if (BATprepareHash(r)) {
			BBPreclaim(bn);
			return NULL;
		}
		if (BAThkey(r)) {
			@:outerjoinswitch(bunfastins_nocheck_inc, BUN s = BUNfirst(bn);)@
		} else {
			@:outerjoinswitch(bunfastins_check,)@
		}
@= outerjoinswitch
		switch (any) {
#ifndef NOEXPAND_CHR
		case TYPE_chr:
			@:outerjoinloop(simple,chr,@1,@2,chr)@
#endif
#ifndef NOEXPAND_BTE
		case TYPE_bte:
			@:outerjoinloop(simple,bte,@1,@2,bte)@
#endif
#ifndef NOEXPAND_SHT
		case TYPE_sht:
			@:outerjoinloop(simple,sht,@1,@2,sht)@
#endif
#if !defined(NOEXPAND_INT) || !defined(NOEXPAND_FLT)
		case TYPE_int:
		case TYPE_flt:
			@:outerjoinloop(simple,int,@1,@2,int)@
#endif
#if !defined(NOEXPAND_DBL) || !defined(NOEXPAND_LNG)
		case TYPE_dbl:
		case TYPE_lng:
			@:outerjoinloop(simple,lng,@1,@2,lng)@
#endif
		case TYPE_str:
			if (l->T->vheap->hashash) {
				@:outerjoinloop(atom,str_hv,@1,@2,any)@
			}
			/* fall through */
		default:
			@:outerjoinloop(atom,any,@1,@2,any)@
		}
@c
		bn->tsorted = 0;
	}
	BATaccessEnd(l, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
	/* set sorted flags by hand, because we used BUNfastins() */
	if (r->hkey) {
		ALIGNsetH(bn, l);	/* always 1 hit, so columns are equal */
	} else {
		bn->hsorted = BAThordered(l);
	}
	bn->H->nonil = l->H->nonil;
	bn->T->nonil = FALSE;
	ESTIDEBUG THRprintf(GDKout, "#BATouterjoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

	/* invest in property check, since we cannot easily derive the result properties,
	 * but later operations might benefit from / depend on them
	 * Disable via command line option  --debug=16777216
	 */
	JOINPROPCHK {
		if (bn)
			BATpropcheck(bn, BATPROPS_QUICK);
	}

	return bn;

      bunins_failed:
	BATaccessEnd(l, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
	BBPreclaim(bn);
	return NULL;
}

@
@}

@+ ThetaJoin
Current predicates supported are: JOIN_EQ, JOIN_LT,
JOIN_GE, JOIN_LE and JOIN_GT. The JOIN_EQ will pass the control to the
normal @:BATjoin@ equijoin. The is and index-based join: if an index
is not present, it will be created on the smallest relation.

We do lots of code-inlining: first of all on join type (4), and
furthermore on left-tail (equal right-head) type (5), which are the
join columns.  We factor out more by splitting on storage strategy
(variable-sized/fixed-size) of both the left-head, and right tail
columns (2*2).

In the end, this results in 4*5*2*2 = 80 different inner loops.
@{
@c
BAT *
BATthetajoin(BAT *l, BAT *r, int op, BUN estimate)
{
	BUN _lcount = BATcount(l);
	BUN _rcount = BATcount(r);
	BUN _estimate = (BUN) MIN((lng) _lcount * _rcount, BUN_MAX);

	assert(_estimate <= BUN_MAX);
	@:joincheck(BATthetajoin,l->ttype,r->htype)@
	if (estimate < _estimate)
		_estimate = estimate;
	if (op == JOIN_EQ) {
		/* exploit all equi-join optimizations */
		ALGODEBUG THRprintf(GDKout, "#BATthetajoin(l,r,JOIN_EQ): BATjoin(l, r);\n");

		return BATjoin(l, r, _estimate);
	}
	return BATnlthetajoin(l, r, op, _estimate);
}

BAT *
BATleftthetajoin(BAT *l, BAT *r, int op, BUN estimate)
{
	BUN _lcount = BATcount(l);
	BUN _rcount = BATcount(r);
	BUN _estimate = (BUN) MIN((lng) _lcount * _rcount, BUN_MAX);

	assert(_estimate <= BUN_MAX);
	@:joincheck(BATleftthetajoin,l->ttype,r->htype)@
	if (estimate < _estimate)
		_estimate = estimate;
	if (op == JOIN_EQ) {
		/* exploit all equi-join optimizations */
		ALGODEBUG THRprintf(GDKout, "#BATleftthetajoin(l,r,JOIN_EQ): BATleftjoin(l, r);\n");

		return BATleftjoin(l, r, _estimate);
	}
	return BATnlthetajoin(l, r, op, _estimate);
}

/* nested loop join; finally MonetDB can enjoy the virtues of this algorithm as well! */
@= nlthetajoin_unroll8
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
@= nlthetajoin_void
	{
		tdst[cur] = off++;
		cur += v @1 ra[ri];
	} 
@= nlthetajoin_oid
	{
		tdst[cur] = rt[ri];
		cur += v @1 ra[ri];
	}
@= nlthetajoin_impl
static int
nlthetajoin_@2_@1(BAT *bn, BAT *l, BAT *r)
{
	BATiter lbi = bat_iterator(l);
	BATiter rbi = bat_iterator(r);
	oid *hdst = (oid *) Hloc(bn, BUNfirst(bn)), *tdst = (oid *) Tloc(bn, BUNfirst(bn));
	BUN cur = BUNfirst(bn);
	BUN lim = BATcapacity(bn);
	BUN li = BUNfirst(l), lhi = BUNlast(l);
	BUN ri = BUNfirst(r), rhi = MAX(ri + 8, BUNlast(r)) - 8;
	@1 *la = (@1 *) BUNtloc(lbi, li);
	@1 *ra = (@1 *) BUNhloc(rbi, ri);
	oid *rt = (oid *) (r->ttype == TYPE_void ? 0 : BUNtloc(rbi, ri));

	for (ri = li = 0; li < lhi; li++, ri = 0) {
		oid off = r->ttype == TYPE_void ? r->tseqbase : 0;
		BUN len = cur;
		@1 v = la[li];
		oid o;

		if (v == @1_nil)
			continue;

		/* unroll 8 times, factor out cur->l and memory re-allocation checking */
		while (1) {
			if (cur + 8 >= lim) {
				BATsetcount(bn, cur);
				if (BATextend(bn, 8 + (BUN) (BATcount(bn) * (((dbl) lhi) / (li + 1)))) == NULL)
					return 1;
				lim = BATcapacity(bn);
				hdst = (oid *) Hloc(bn, BUNfirst(bn));
				tdst = (oid *) Tloc(bn, BUNfirst(bn));
			}
			if (ri >= rhi)
				break;
			if (r->ttype == TYPE_void) {
				@:nlthetajoin_unroll8(@3,void)@
			} else {
				@:nlthetajoin_unroll8(@3,oid)@
			}
		}
		/* do rest in more expensive loop */
		if (r->ttype == TYPE_void) {
			BUN cnt = BATcount(r);

			for (; ri < cnt; ri++)
				@:nlthetajoin_void(@3)@
		} else {
			BUN cnt = BATcount(r);

			for (; ri < cnt; ri++)
				@:nlthetajoin_oid(@3)@
		}

		/* fill in the left oids for the generated result tuples */
 		o = * (oid *) BUNhead(lbi, li);
		while (len < cur)
			hdst[len++] = o;
	}
	BATsetcount(bn, cur);
	return 0;
}
@= nlthetajoin_call
	case TYPE_@1:
		if (nlthetajoin_@2_@1(bn, l, r))
			goto bunins_failed;
		break;
@= nlthetajoin_tpe
#ifndef NOEXPAND_CHR
	@:nlthetajoin_@1(chr,@2,@3)@
#endif
#ifndef NOEXPAND_BTE
	@:nlthetajoin_@1(bte,@2,@3)@
#endif
#ifndef NOEXPAND_SHT
	@:nlthetajoin_@1(sht,@2,@3)@
#endif
#ifndef NOEXPAND_INT
	@:nlthetajoin_@1(int,@2,@3)@
#endif
#ifndef NOEXPAND_LNG
	@:nlthetajoin_@1(lng,@2,@3)@
#endif
#ifndef NOEXPAND_FLT
	@:nlthetajoin_@1(flt,@2,@3)@
#endif
#ifndef NOEXPAND_DBL
	@:nlthetajoin_@1(dbl,@2,@3)@
#endif
@c
@:nlthetajoin_tpe(impl,gt,>)@
@:nlthetajoin_tpe(impl,ge,>=)@
@:nlthetajoin_tpe(impl,lt,<)@
@:nlthetajoin_tpe(impl,le,<=)@
@:nlthetajoin_tpe(impl,eq,==)@
BAT *
BATnlthetajoin(BAT *l, BAT *r, int op, BUN estimate)
{
	int optimize = (l->htype == TYPE_oid || BAThdense(l)) && (r->ttype == TYPE_oid || BATtdense(r))
	    /* the follwoing might be trivial cases,
	     * but the "optimized" nlthetajoin implementation cannot handle them, yet ... */
	    && l->ttype != TYPE_void && r->htype != TYPE_void;
	BAT *bn = BATnew(ATOMtype(l->htype), ATOMtype(r->ttype), estimate >= BUN_MAX - 128 ? BUN_MAX : estimate + 128);
	int lo = 0, hi = 0;

	if (bn == NULL)
		return NULL;

	if (op == JOIN_GT) {
		lo = 1;
		hi = GDK_int_max;
		if (optimize)
			switch (ATOMstorage(l->ttype)) {
				@:nlthetajoin_tpe(call,gt)@
			default:
				optimize = 0;
			}
	} else if (op == JOIN_GE) {
		lo = 0;
		hi = GDK_int_max;
		if (optimize)
			switch (ATOMstorage(l->ttype)) {
				@:nlthetajoin_tpe(call,ge)@
			default:
				optimize = 0;
			}
	} else if (op == JOIN_LT) {
		lo = GDK_int_min;
		hi = -1;
		if (optimize)
			switch (ATOMstorage(l->ttype)) {
				@:nlthetajoin_tpe(call,lt)@
			default:
				optimize = 0;
			}
	} else if (op == JOIN_LE) {
		lo = GDK_int_min;
		hi = 0;
		if (optimize)
			switch (ATOMstorage(l->ttype)) {
				@:nlthetajoin_tpe(call,le)@
			default:
				optimize = 0;
			}
	} else if (op == JOIN_EQ) {
		if (optimize)
			switch (ATOMstorage(l->ttype)) {
				@:nlthetajoin_tpe(call,eq)@
			default:
				optimize = 0;
			}

	}
	if (!optimize) {
		BATiter li = bat_iterator(l);
		BATiter ri = bat_iterator(r);
		int (*cmp) (ptr, ptr) = BATatoms[l->ttype].atomCmp;
		ptr nil = ATOMnilptr(l->ttype);
		BUN rp, rq, lp, lq;

		BATaccessBegin(l, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
		BATaccessBegin(r, USE_HEAD | USE_TAIL, BATcount(l) <= 1 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
		BATloop(l, lp, lq) {
			ptr v = (ptr) BUNtail(li, lp);

			if ((*cmp) (v, nil) == 0) {
				continue;
			}
			BATloop(r, rp, rq) {
				ptr w = (ptr) BUNhead(ri, rp);
				int c = (*cmp) (v, w);

				if ((c >= lo) & (c <= hi)) {
					bunfastins(bn, BUNhead(li, lp), BUNtail(ri, rp));
				}
			}
		}
		BATaccessEnd(l, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
		BATaccessEnd(r, USE_HEAD | USE_TAIL, BATcount(l) <= 1 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
	}
	bn->hsorted = l->hsorted;
	bn->tsorted = 0;
	bn->H->nonil = l->H->nonil;
	bn->T->nonil = r->T->nonil;
	return bn;
      bunins_failed:
	if (!optimize) {
		BATaccessEnd(l, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
		BATaccessEnd(r, USE_HEAD | USE_TAIL, BATcount(l) <= 1 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
	}
	BBPreclaim(bn);
	return NULL;
}

@}

@+ Semijoin

The @%BATsemijoin@ performs a semijoin over @%l@ and @%r@. It returns
a subset of @%l@ that matches at least one element in @%r@.
The result inherits the integrity properties.

Various algorithms exist. The main one BATkintersect() resides
outside this file, in the set-operations implementation (gdk_setop).
Other variants for the semijoin include the fetch-semijoin
(for dense join columns), the reverse semijoin that loops over r
instead of l, and semijoin using binary search in r.
@{
@= semijoinbat
	bn = BATnew(BAThtype(@1), BATttype(@1), MAX(BATTINY, MIN(BATcount(l), BATcount(r))));
	ESTIDEBUG THRprintf(GDKout, "#%s.semijoinbat: estimated resultsize: " BUNFMT "\n",@4,MAX(BATTINY, MIN(BATcount(l), BATcount(r))));
	if (bn == NULL) 
		return bn;
	BATkey(bn, BAThkey(@1));
	BATkey(BATmirror(bn), BATtkey(@1));
	bn->hsorted = @2;
	bn->tsorted = @3;
@}
@-
In the sorted cases with a low semijoin hit-rate, we do lookup using
probe-based binary search, instead of a full merge scan.
Normal merge-semijoin with a full scan on both is handled by kintersect
(default exit) if both relations are large or if their sizes do not
differ significantly.
@{
@= binsemijoin
{
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	BUN lp, lq;
	ptr nil = ATOMnilptr(l->htype);

	if (cpy == l) {
		BATaccessBegin(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(l) > BATcount(r)/10)
			BATaccessBegin(r, USE_HEAD, MMAP_WILLNEED);
		BATloop(l, lp, lq) {
			ptr v = BUNh@1(li, lp);

			if (!@3_EQ(v, nil, @2) && SORTfnd_@2(r, v) != BUN_NONE) {
				bunfastins(bn, v, BUNtail(li, lp));
			}
		}
		BATaccessEnd(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(l) > BATcount(r)/10)
			BATaccessEnd(r, USE_HEAD, MMAP_WILLNEED);
	} else {
		BATaccessBegin(l, USE_HEAD, MMAP_SEQUENTIAL);
		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(l) > BATcount(r)/10)
			BATaccessBegin(r, USE_HEAD|USE_TAIL, MMAP_WILLNEED);
		BATloop(l, lp, lq) {
			BUN rp, rq;
			ptr v = BUNh@1(li, lp);

			if (!@3_EQ(v, nil, @2)) {
				SORTloop_@2(BATmirror(r), rp, rq, v, v) {
					bunfastins(bn, v, BUNtail(ri, rp));
				}
			}
		}
		BATaccessEnd(l, USE_HEAD, MMAP_SEQUENTIAL);
		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(l) > BATcount(r)/10)
			BATaccessEnd(r, USE_HEAD|USE_TAIL, MMAP_WILLNEED);
	}
}
break;
@c
static BAT *
BATbinsemijoin(BAT *l, BAT *r, BAT *cpy)
{
	BAT *bn, *del = NULL;
	int loc, var;

	@:joincheck(BATbinsemijoin,l->htype,r->htype)@
	@:semijoinbat(cpy,TRUE,(l==cpy&&(BATtordered(l)&1)),"BATbinsemijoin")@

	if (!(BAThordered(r) & 1)) {
		del = r = BATsort(r);
		if (del == NULL)
			return NULL;
	}

	switch (loc = var = ATOMstorage(l->htype)) {
#ifndef NOEXPAND_CHR
	case TYPE_chr:
		@:binsemijoin(loc,chr,simple)@
#endif
#ifndef NOEXPAND_BTE
	case TYPE_bte:
		@:binsemijoin(loc,bte,simple)@
#endif
#ifndef NOEXPAND_SHT
	case TYPE_sht:
		@:binsemijoin(loc,sht,simple)@
#endif
#ifndef NOEXPAND_INT
	case TYPE_int:
		@:binsemijoin(loc,int,simple)@
#endif
#ifndef NOEXPAND_FLT
	case TYPE_flt:
		@:binsemijoin(loc,flt,simple)@
#endif
#ifndef NOEXPAND_DBL
	case TYPE_dbl:
		@:binsemijoin(loc,dbl,simple)@
#endif
#ifndef NOEXPAND_LNG
	case TYPE_lng:
		@:binsemijoin(loc,lng,simple)@
#endif
	default:
		if (l->hvarsized) {
			if (r->hvarsized) {
				@:binsemijoin(var,var,atom)@
			} else {
				@:binsemijoin(var,loc,atom)@
			}
		} else {
			if (r->hvarsized) {
				@:binsemijoin(loc,var,atom)@
			} else {
				@:binsemijoin(loc,loc,atom)@
			}
		}
	}

	/* propagate properties */
	bn->hsorted = l->hsorted;
	bn->tsorted = 0;
	if (BATcount(bn) == BATcount(l)) {
		if (l == cpy) {
			ALIGNset(bn, l);
		} else if (BAThkey(l) && BAThkey(r)) {
			ALIGNsetH(bn, l);
		}
	}
	bn->H->nonil = l->H->nonil & r->H->nonil;
	bn->T->nonil = l->T->nonil;
	if (del)
		BBPreclaim(del);
	ESTIDEBUG THRprintf(GDKout, "#BATbinsemijoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;
}

@-
The reverse semijoin is only better if the other side (r) is much
smaller than l, and iff you already have the hash table on l. It uses hash tables on
both relations: on r to check that no item is processed twice (not necessary to check
iff BAThkey(r) and one on l to find the matching tuples.
@{
@= revsemijoin
{
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	BUN yy;
	BUN rp = 0, rq = 0;
	ptr nil = ATOMnilptr(l->htype);
	ptr v;

	if (merge) {
		ALGODEBUG THRprintf(GDKout, "#BATrevsemijoin: merge\n");
		BATaccessBegin(r, USE_HEAD, MMAP_SEQUENTIAL);
		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(r) > BATcount(l)/10)
			BATaccessBegin(l, USE_HEAD|USE_TAIL|USE_HHASH, MMAP_WILLNEED);
		BATloop(r, rp, rq) {
			v = BUN@3(ri, rp);

			yy = rp+1;
			if (yy < rq && @1_EQ(v, BUN@3(ri, yy), @4))
				continue;
			if (!@1_EQ(v, nil, @4)) {
				HASHloop_@2(li, l->H->hash, yy, v)
					bunfastins(bn, v, BUNtail(li, yy));
			}
		}
		BATaccessEnd(r, USE_HEAD, MMAP_SEQUENTIAL);
		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(r) > BATcount(l)/10)
			BATaccessEnd(l, USE_HEAD|USE_TAIL|USE_HHASH, MMAP_WILLNEED);
	} else if (rdoubles) {
		ALGODEBUG THRprintf(GDKout, "#BATrevsemijoin: rdoubles\n");
		BATaccessBegin(r, USE_HEAD, MMAP_SEQUENTIAL);
		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(r) > BATcount(l)/10)
			BATaccessBegin(l, USE_HEAD|USE_TAIL|USE_HHASH, MMAP_WILLNEED);
		BATloop(r, rp, rq) {
			v = BUN@3(ri, rp);

			HASHloop_@2(ri, r->H->hash, yy, v)
				break;
			if (yy != rp)
				continue;
			if (!@1_EQ(v, nil, @4)) {
				HASHloop_@2(li, l->H->hash, yy, v)
					bunfastins(bn, v, BUNtail(li, yy));
			}
		}
		BATaccessEnd(r, USE_HEAD, MMAP_SEQUENTIAL);
		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(r) > BATcount(l)/10)
			BATaccessEnd(l, USE_HEAD|USE_TAIL|USE_HHASH, MMAP_WILLNEED);
	} else {
		BATaccessBegin(r, USE_HEAD, MMAP_SEQUENTIAL);
		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(r) > BATcount(l)/10)
			BATaccessBegin(l, USE_HEAD|USE_TAIL|USE_HHASH, MMAP_WILLNEED);
		BATloop(r, rp, rq) {
			v = BUN@3(ri, rp);
			if (!@1_EQ(v, nil, @4)) {
				HASHloop_@2(li, l->H->hash, yy, v)
					bunfastins(bn, v, BUNtail(li, yy));
			}
		}
		BATaccessEnd(r, USE_HEAD, MMAP_SEQUENTIAL);
		/* use MMAP_WILLNEED only if random access is not too scattered, *
		 * i.e., only if number of lookups is more than 10% of inner BAT */
		if (BATcount(r) > BATcount(l)/10)
			BATaccessEnd(l, USE_HEAD|USE_TAIL|USE_HHASH, MMAP_WILLNEED);
	}
}
break;
@c
static BAT *
BATrevsemijoin(BAT *l, BAT *r)
{
	int any, rdoubles = (BAThkey(r) == 0), merge = rdoubles & BAThordered(r);
	BAT *bn;

	@:joincheck(BATrevsemijoin,l->htype,r->htype)@
	@:semijoinbat(l,FALSE,FALSE,"BATrevsemijoin")@
	if (BATprepareHash(l))
		return NULL;
	if (rdoubles && BATprepareHash(r))
		return NULL;

	switch (any = ATOMstorage(l->htype)) {
#ifndef NOEXPAND_CHR
	case TYPE_chr:
		@:revsemijoin(simple,chr,hloc,chr)@
#endif
#ifndef NOEXPAND_BTE
	case TYPE_bte:
		@:revsemijoin(simple,bte,hloc,bte)@
#endif
#ifndef NOEXPAND_SHT
	case TYPE_sht:
		@:revsemijoin(simple,sht,hloc,sht)@
#endif
#if !defined(NOEXPAND_INT) || !defined(NOEXPAND_FLT)
	case TYPE_int:
	case TYPE_flt:
		@:revsemijoin(simple,int,hloc,int)@
#endif
#if !defined(NOEXPAND_DBL) || !defined(NOEXPAND_LNG)
	case TYPE_dbl:
	case TYPE_lng:
		@:revsemijoin(simple,lng,hloc,lng)@
#endif
	case TYPE_str:
		if (r->H->vheap->hashash) {
			@:revsemijoin(atom,str_hv,head,any)@
		}
		/* fall through */
	default:
		@:revsemijoin(atom,any,head,any)@
	}
	/* propagate properties */
	bn->hsorted = bn->tsorted = 0;
	if (BAThkey(r) && BATtkey(l) && BATcount(bn) == BATcount(r)) {
		ALIGNsetH(bn, r);
	}
	bn->H->nonil = l->H->nonil & r->H->nonil;
	bn->T->nonil = l->T->nonil;
	ESTIDEBUG THRprintf(GDKout, "#BATrevsemijoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;
}

@}
@-
The positional semijoin performs a semijoin using positional lookup.
This implementation is dirty as it also allows fetches with
hard integer positions, rather than oid matching on a dense-oid column.
@{
@c
static BAT *
BATfetchsemijoin(BAT *l, BAT *r, BAT *cpy, int denselookup)
{
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	BUN base, end, yy;
	ssize_t offset;
	BUN l_cur, l_end, r_cur;
	BAT *bn;

	BATcheck(l, "BATfetchsemijoin: left BAT required");
	BATcheck(r, "BATfetchsemijoin: right BAT required");

	if (denselookup) {
		if (!BAThdense(r)) {
			GDKerror("BATfetchsemijoin: left column must be dense.\n");
			return NULL;
		} else if (BATcount(l) && ATOMstorage(l->htype) != ATOMstorage(TYPE_oid)) {
			GDKerror("BATfetchsemijoin: illegal index type %s.\n", ATOMname(l->htype));
			return NULL;
		}
	}
	if (BATcount(l) && BAThvoid(l)) {
		/* redirect semijoin on two dense regions to a select (and hence to BATslice) */
		oid min = l->hseqbase, max = min;

		if (min != oid_nil)
			max += BATcount(l);
		if (denselookup) {
			min -= r->hseqbase;
			max -= r->hseqbase;
		}
		return BATslice(cpy, min, max);
	}
	base = BUNfirst(r);
	end = base + BATcount(r);
	bn = BATnew(BAThtype(cpy), BATttype(cpy), MIN(BATcount(r), BATcount(l)));
	if (bn == NULL)
		return bn;
	ESTIDEBUG THRprintf(GDKout, "#BATfetchsemijoin: estimated resultsize: " BUNFMT "\n", MIN(BATcount(r), BATcount(l)));

	if (bn == NULL) {
		return NULL;
	}
	if (denselookup) {
		offset = (ssize_t) base - (ssize_t) r->hseqbase;	/* translate oid to BUN position */
	} else {
		offset = (ssize_t) base;	/* fetch by hard BUNindex */
	}

	/* iterate l; positional fetch in r */
	BATaccessBegin(l, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10)
		BATaccessBegin(r, USE_HEAD | USE_TAIL, BAThordered(l) & 1 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
	BATloop(l, l_cur, l_end) {
		yy = (BUN) (offset + *(oid *) BUNhloc(li, l_cur));
		if (yy < base || yy >= end) {
			continue;
		}
		r_cur = yy;
		if (cpy == r) {
			bunfastins(bn, BUNhead(ri, r_cur), BUNtail(ri, r_cur));
		} else {
			bunfastins(bn, BUNhead(ri, r_cur), BUNtail(li, l_cur));
		}
	}
	BATaccessEnd(l, USE_HEAD | USE_TAIL, MMAP_SEQUENTIAL);
	/* use MMAP_WILLNEED only if random access is not too scattered, *
	 * i.e., only if number of lookups is more than 10% of inner BAT */
	if (BATcount(l) > BATcount(r)/10)
		BATaccessEnd(r, USE_HEAD | USE_TAIL, BAThordered(l) & 1 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);

	/* property propagation */
	bn->hsorted = (BAThordered(l) & BAThordered(r) & 1 ? GDK_SORTED : FALSE);
	bn->tsorted = (bn->hsorted & BATtordered(cpy) & 1 ? GDK_SORTED : FALSE);
	bn->H->nonil = l->H->nonil & r->H->nonil;
	bn->T->nonil = cpy->T->nonil;

	if (denselookup && BATcount(bn) == BATcount(l)) {
		ALIGNsetH(bn, l);
	} else {
		BATkey(bn, BAThkey(l) && BAThkey(r));
	}
	if (BAThkey(l)) {
		if (BATcount(bn) == BATcount(cpy) && (BAThordered(r) & BAThordered(l) & 1)) {
			ALIGNsetT(bn, cpy);
		} else {
			BATkey(BATmirror(bn), BATtkey(cpy));
		}
	}
	ESTIDEBUG THRprintf(GDKout, "#BATfetchsemijoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;
}

BAT *
BATfetch(BAT *l, BAT *r)
{
	return BATfetchsemijoin(r, l, l, FALSE);
}

@-
The BATsemijoin chooses between various alternatives.
@c

BAT *
BATsemijoin(BAT *l, BAT *r)
{
	int reverse1, reverse2;
	BUN countr, countl, i;
	lng logr, logl;
	BAT *bn, *tmp = NULL;

	ERRORcheck(l == NULL, "BATsemijoin");
	ERRORcheck(r == NULL, "BATsemijoin");
	ERRORcheck(TYPEerror(l->htype, r->htype), "BATsemijoin: type conflict\n");

@- algorithm selection
We have 10 algorithms implementing semijoin. Their conditions are checked in order
of efficiency. Some algorithms reverse the semijoin (loop over r, lookup in l).
To do that r should be unique. To that end, doubles may sometimes be eliminated from r.
@c
	for (logr = 4, i = countr = BATcount(r); i > 0; logr++)
		i >>= 1;
	for (logl = 4, i = countl = BATcount(l); i > 0; logl++)
		i >>= 1;
	reverse1 = countr < countl && (BAThkey(r) || (lng) countr * 8 < (lng) countl);
	reverse2 = (lng) countr *logl < (lng) countl && (BAThkey(r)
							 || (lng) countr * (logl + 8) < (lng) countl);

	if (ALIGNsynced(l, r)) {
		ALGODEBUG THRprintf(GDKout, "#BATsemijoin: BATcopy(l);\n");

		bn = BATcopy(l, l->htype, l->ttype, FALSE);
	} else if ((BAThordered(l) & 1) && BAThdense(r)) {
		oid lo = r->hseqbase;
		oid hi = r->hseqbase + countr - 1;
		ALGODEBUG THRprintf(GDKout, "#BATsemijoin: BATmirror(BATselect(BATmirror(l), &lo, &hi));\n");

		bn = BATmirror(BATselect(BATmirror(l), &lo, &hi));
	} else if (BAThdense(r)) {
		ALGODEBUG THRprintf(GDKout, "#BATsemijoin: BATfetchsemijoin(l, r, l);\n");

		bn = BATfetchsemijoin(l, r, l, TRUE);
	} else if (BAThdense(l) && reverse1) {
		if (!BAThkey(r)) {
			BAT *v = VIEWhead_(r, BAT_WRITE);

			tmp = r = BATkunique(v);
			BBPreclaim(v);
		}
		ALGODEBUG THRprintf(GDKout, "#BATsemijoin: BATfetchsemijoin(r, l, l);\n");

		bn = BATfetchsemijoin(r, l, l, TRUE);
	} else if (l->H->hash && reverse1) {
		ALGODEBUG THRprintf(GDKout, "#BATsemijoin: BATrevsemijoin(l,r);\n");

		bn = BATrevsemijoin(l, r);
	} else if ((BAThordered(r) & 1) && countl * logr < countr) {
		ALGODEBUG THRprintf(GDKout, "#BATsemijoin: BATbinsemijoin(l, r, l);\n");

		bn = BATbinsemijoin(l, r, l);
	} else if ((BAThordered(l) & 1) & reverse2) {
		if (!BAThkey(r)) {
			BAT *v = VIEWhead_(r, BAT_WRITE);

			tmp = r = BATkunique(v);
			BBPreclaim(v);
		}
		ALGODEBUG THRprintf(GDKout, "#BATsemijoin: BATbinsemijoin(r, l, l);\n");

		bn = BATbinsemijoin(r, l, l);
	} else {
		ALGODEBUG THRprintf(GDKout, "#BATsemijoin: BATkintersect(l, r);\n");

		bn = BATkintersect(l, r);	/* merge-semijoin or nested hashlookup in r */
	}
	if (tmp) {
		BBPreclaim(tmp);
	}
	/* invest in property check, since we cannot easily derive the result properties,
	 * but later operations might benefit from / depend on them
	 * Disable via command line option  --debug=16777216
	 */
	JOINPROPCHK {
		if (bn)
			BATpropcheck(BATmirror(bn), BATPROPS_QUICK);
	}
	return bn;
}

@}
@+ AntiJoin
This operation computes the cross product of two BATs, returning only the
head-value from the 'left' operand and then tail-value from the 'right'
provided the tail-head pair do not (!) match.
@{
@= antijoin2
static BAT *
antijoin_@1_@2(BAT *bn, BAT *l, BAT *r)
{
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	BATiter bni;
	BUN l_cur, l_end, r_cur, r_end, dst;
	int (*cmp) (ptr, ptr) = BATatoms[l->ttype].atomCmp;
	ptr nil = ATOMnilptr(l->ttype);

	/* Just to silence compilers (Intel's icc) that otherwise might
	 * complain about "declared but never referenced" labels
	 * (condition should never be true).
	 * (A "dead" goto between the return and the label makes (other)
	 * compilers (Sun) complain about never reached code...)
	 */
	if (!bn)
		goto bunins_failed;

	bni = bat_iterator(bn);
	dst = BUNfirst(bn);
	ALGODEBUG THRprintf(GDKout, "#BATantijoin: antijoin_@1_@2();\n");
	BATaccessBegin(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
	BATaccessBegin(r, USE_HEAD|USE_TAIL, BATcount(l) <= 1 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
	BATloop(l, l_cur, l_end) {
		ptr v = (ptr) BUNtail(li, l_cur);
		BATloop(r, r_cur, r_end) {
			ptr w = (ptr) BUNhead(ri, r_cur);
			int c = (*cmp)(v, w);
			if ((*cmp)(v, nil) != 0 && (*cmp)(w, nil) != 0 && c != 0 ) {
				@:bunfastins_nocheck_(@1,@2)@
				dst++;
			}
		}
	}
	BATsetcount(bn, dst);
	BATaccessEnd(l, USE_HEAD|USE_TAIL, MMAP_SEQUENTIAL);
	BATaccessEnd(r, USE_HEAD|USE_TAIL, BATcount(l) <= 1 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);

	return bn;

bunins_failed:
	BBPreclaim(bn);
	return NULL;
}
@= antijoin1
	@:antijoin2(@1,chr)@
	@:antijoin2(@1,bte)@
	@:antijoin2(@1,sht)@
	@:antijoin2(@1,int)@
	@:antijoin2(@1,lng)@
	@:antijoin2(@1,VATOM)@
	@:antijoin2(@1,LATOM)@
@c
@:antijoin1(chr)@
@:antijoin1(bte)@
@:antijoin1(sht)@
@:antijoin1(int)@
@:antijoin1(lng)@

@:antijoin1(VATOM)@
@:antijoin1(LATOM)@
@c

@= antijoin_switch_rtt
{
	int rtt = r->ttype;
	int rts = ATOMstorage(rtt);

	if (rts == TYPE_chr) {
		bn = antijoin_@1_chr(bn, l, r);
	} else if (rts == TYPE_bte) {
		bn = antijoin_@1_bte(bn, l, r);
	} else if (rts == TYPE_sht) {
		bn = antijoin_@1_sht(bn, l, r);
	} else if (rtt != TYPE_bat &&
		   (rts == TYPE_int || rts == TYPE_flt
#if SIZEOF_OID == SIZEOF_INT
		    || rts == TYPE_oid
#endif
		   )) {
		/* ensure use of ATOMput for TYPE_bat */
		bn = antijoin_@1_int(bn, l, r);
	} else if (rts == TYPE_lng || rts == TYPE_dbl
#if SIZEOF_OID == SIZEOF_LNG
		   || ATOMstorage(lht) == TYPE_oid
#endif
) {
		bn = antijoin_@1_lng(bn, l, r);
	} else if (r->tvarsized) {
		bn = antijoin_@1_VATOM(bn, l, r);
	} else {
		bn = antijoin_@1_LATOM(bn, l, r);
	}
}
@c
@= antijoin_switch_lht
{
	int lht = l->htype;
	int lhs = ATOMstorage(lht);

	if (lhs == TYPE_chr) {
		@:antijoin_switch_rtt(chr)@
	} else if (lhs == TYPE_bte) {
		@:antijoin_switch_rtt(bte)@
	} else if (lhs == TYPE_sht) {
		@:antijoin_switch_rtt(sht)@
	} else if (lht != TYPE_bat &&
		   (lhs == TYPE_int || lhs == TYPE_flt
#if SIZEOF_OID == SIZEOF_INT
		    || lhs == TYPE_oid
#endif
		   )) {
		/* ensure use of ATOMput for TYPE_bat */
		@:antijoin_switch_rtt(int)@
	} else if (lhs == TYPE_lng || lhs == TYPE_dbl
#if SIZEOF_OID == SIZEOF_LNG
		   || lhs == TYPE_oid
#endif
		   ) {
		@:antijoin_switch_rtt(lng)@
	} else if (l->hvarsized) {
		@:antijoin_switch_rtt(VATOM)@
	} else {
		@:antijoin_switch_rtt(LATOM)@
	}
}
@c
BAT *
BATantijoin(BAT *l, BAT *r)
{
	BAT *bn;
	BUN lc, rc, sz;

	ERRORcheck(l == NULL, "BATantijoin: invalid left operand");
	ERRORcheck(r == NULL, "BATantijoin: invalid right operand");
	lc = BATcount(l);
	rc = BATcount(r);
	sz = (BUN) MIN((lng) lc * rc, BUN_MAX);

	assert(sz <= BUN_MAX);
	if (sz > 0) {
		BATiter li = bat_iterator(l);
		BATiter ri = bat_iterator(r);

		/* try to keep void columns where possible */
		if (rc == 1)
			return BATconst(l, BATttype(r), BUNtail(ri, BUNfirst(r)));
		if (lc == 1)
			return BATmirror(BATconst(BATmirror(r), BAThtype(l), BUNhead(li, BUNfirst(l))));
	}

	bn = BATnew(BAThtype(l), BATttype(r), sz);
	if (bn == NULL)
		return bn;
	if (sz == 0)
		return bn;

	@:antijoin_switch_lht@

	if (bn) {
		bn->hsorted = l->hsorted;
		bn->tsorted = (lc == 1 ? r->tsorted : FALSE);
		bn->hdense = (rc == 1 ? l->hdense : FALSE);
		bn->tdense = (lc == 1 ? r->tdense : FALSE);
		BATkey(bn, (rc == 1 ? BAThkey(l) : FALSE));
		BATkey(BATmirror(bn), (lc == 1 ? BATtkey(r) : FALSE));
		bn->H->nonil = l->H->nonil;
		bn->T->nonil = r->T->nonil;
		if (!bn->batDirty)
			bn->batDirty = TRUE;
	}

	return bn;
}

@+ Cross Product
This operation computes the cross product of two BATs, returning only the
head-value from the 'left' operand and then tail-value from the 'right'
operand.
@{
@= cross2
static BAT *
cross_@1_@2(BAT *bn, BAT *l, BAT *r)
{
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	BATiter bni;
	BUN l_cur, l_end, r_cur, r_end, dst;

	/* Just to silence compilers (Intel's icc) that otherwise might
	 * complain about "declared but never referenced" labels
	 * (condition should never be true).
	 * (A "dead" goto between the return and the label makes (other)
	 * compilers (Sun) complain about never reached code...)
	 */
	if (!bn)
		goto bunins_failed;

	bni = bat_iterator(bn);
	dst = BUNfirst(bn);
	ALGODEBUG THRprintf(GDKout, "#BATcross: cross_@1_@2();\n");
	BATaccessBegin(l, USE_HEAD, MMAP_SEQUENTIAL);
	BATaccessBegin(r, USE_TAIL, BATcount(l) <= 1 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
	BATloop(l, l_cur, l_end) {
		BATloop(r, r_cur, r_end) {
			@:bunfastins_nocheck_(@1,@2)@
			dst++;
		}
	}
	BATaccessEnd(l, USE_HEAD, MMAP_SEQUENTIAL);
	BATaccessEnd(r, USE_TAIL, BATcount(l) <= 1 ? MMAP_SEQUENTIAL : MMAP_WILLNEED);
	BATsetcount(bn, dst);

	return bn;
 	     
bunins_failed:
	BBPreclaim(bn);
	return NULL;
}
@= cross1
	@:cross2(@1,chr)@
	@:cross2(@1,bte)@
	@:cross2(@1,sht)@
	@:cross2(@1,int)@
	@:cross2(@1,lng)@
	@:cross2(@1,VATOM)@
	@:cross2(@1,LATOM)@
@c
@:cross1(chr)@
@:cross1(bte)@
@:cross1(sht)@
@:cross1(int)@
@:cross1(lng)@

@:cross1(VATOM)@
@:cross1(LATOM)@
@c

@= cross_switch_rtt
{
	int rtt = r->ttype;
	int rts = ATOMstorage(rtt);

	if (rts == TYPE_chr) {
		bn = cross_@1_chr(bn, l, r);
	} else if (rts == TYPE_bte) {
		bn = cross_@1_bte(bn, l, r);
	} else if (rts == TYPE_sht) {
		bn = cross_@1_sht(bn, l, r);
	} else if (rtt != TYPE_bat &&
		   (rts == TYPE_int || rts == TYPE_flt
#if SIZEOF_OID == SIZEOF_INT
		    || rts == TYPE_oid
#endif
		   )) {
		/* ensure use of ATOMput for TYPE_bat */
		bn = cross_@1_int(bn, l, r);
	} else if (rts == TYPE_lng || rts == TYPE_dbl
#if SIZEOF_OID == SIZEOF_LNG
		   || ATOMstorage(lht) == TYPE_oid
#endif
) {
		bn = cross_@1_lng(bn, l, r);
	} else if (r->tvarsized) {
		bn = cross_@1_VATOM(bn, l, r);
	} else {
		bn = cross_@1_LATOM(bn, l, r);
	}
}
@c
@= cross_switch_lht
{
	int lht = l->htype;
	int lhs = ATOMstorage(lht);

	if (lhs == TYPE_chr) {
		@:cross_switch_rtt(chr)@
	} else if (lhs == TYPE_bte) {
		@:cross_switch_rtt(bte)@
	} else if (lhs == TYPE_sht) {
		@:cross_switch_rtt(sht)@
	} else if (lht != TYPE_bat &&
		   (lhs == TYPE_int || lhs == TYPE_flt
#if SIZEOF_OID == SIZEOF_INT
		    || lhs == TYPE_oid
#endif
		   )) {
		/* ensure use of ATOMput for TYPE_bat */
		@:cross_switch_rtt(int)@
	} else if (lhs == TYPE_lng || lhs == TYPE_dbl
#if SIZEOF_OID == SIZEOF_LNG
		   || lhs == TYPE_oid
#endif
		   ) {
		@:cross_switch_rtt(lng)@
	} else if (l->hvarsized) {
		@:cross_switch_rtt(VATOM)@
	} else {
		@:cross_switch_rtt(LATOM)@
	}
}
@c
BAT *
BATcross(BAT *l, BAT *r)
{
	BAT *bn;
	BUN lc, rc, sz;

	ERRORcheck(l == NULL, "BATcross: invalid left operand");
	ERRORcheck(r == NULL, "BATcross: invalid right operand");
	lc = BATcount(l);
	rc = BATcount(r);
	sz = (BUN) MIN((lng) lc * rc, BUN_MAX);
	assert(sz <= BUN_MAX);

	if (sz > 0) {
		BATiter li = bat_iterator(l);
		BATiter ri = bat_iterator(r);

		/* try to keep void columns where possible */
		if (rc == 1)
			return BATconst(l, BATttype(r), BUNtail(ri, BUNfirst(r)));
		if (lc == 1)
			return BATmirror(BATconst(BATmirror(r), BAThtype(l), BUNhead(li, BUNfirst(l))));
	}

	bn = BATnew(BAThtype(l), BATttype(r), sz);
	if (bn == NULL)
		return bn;
	if (sz == 0)
		return bn;

	@:cross_switch_lht@

	if (bn) {
		bn->hsorted = l->hsorted;
		bn->tsorted = (lc == 1 ? r->tsorted : FALSE);
		bn->hdense = (rc == 1 ? l->hdense : FALSE);
		bn->tdense = (lc == 1 ? r->tdense : FALSE);
		BATkey(bn, (rc == 1 ? BAThkey(l) : FALSE));
		BATkey(BATmirror(bn), (lc == 1 ? BATtkey(r) : FALSE));
		if (!bn->batDirty)
			bn->batDirty = TRUE;
		bn->H->nonil = l->H->nonil;
		bn->T->nonil = r->T->nonil;
	}

	return bn;
}

@}
@+ Cartesian product
The matching algorithms tries to construct non-empty matches on all head
columns. Each time this succeeds, it calls the Cartesian routine to
construct a join result that consists of the Cartesian product of these
matches.

The matching tuples can be encoded in two ways:
@table @samp
@item clustered
 here we have two BUN pointers 'hi' and 'lo' that point
to a consecutive range of BUNs in a BAT that match.
@item nonclustered here we have a hit pointer that points to an array
of BUN  pointers that match.
@end table
@{
The below structures are used for keeping track of the matching process.
@c
typedef struct _column_t {
	BAT *b;			/* BAT of this column */
	BATiter bi;
	BUN cur;		/* current BUN in b */
	BUN nhits;		/* number of matched BUNs */

	/* clustered */
	BUN lo;			/* first BUN that matches */
	BUN hi;			/* past last BUN that matches */
	/* nonclustered */
	BUN *hit;		/* BUN array pointer */
	size_t hitsize;		/* size of hit array */

	/* properties */
/* I'm not sure whether offset can become negative, so to be on the
 * save side, use a signed type.  However the magnitude should be
 * within the range allowed by BUN, so the casts associated with this
 * value should be OK. */
	ssize_t offset;		/* BUNindex of BUNfirst  */
	struct _column_t *sync;	/* iff > 0: column with synchronous BAT */
	BUN size;		/* size of the BAT */
	char binsearch;		/* sparse matching expected? */
	char ordered;		/* merge matching */
} column_t;

typedef struct {
	RowFcn tuple_fcn;	/* function to invoke per match */
	ptr tuple_data;		/* application-specific data */
	ColFcn *value_fcn;	/* for each col: function to invoke per value */
	ptr *value_data;	/* for each col: application-specific data */
	column_t *c;		/* array of columns */
	int argc;		/* size of c */
} table_t;

static void
column_result(table_t *t, int i)
{
	if (++i > t->argc) {
		/* end of recursion: invoke tuple-match routine */
		t->tuple_fcn(t->tuple_data, t->value_data);
	} else {
		/* recurse over all matches on this column */
		column_t *c = t->c + (i - 1);
		BUN q, *p = c->hit;
		BUN j;

		if (p == NULL) {	/* clustered */
			for (q = c->lo; q < c->hi; q++) {
				t->value_fcn[i] (t->value_data[i], BUNtail(c->bi, q));
				column_result(t, i);
			}
		} else {
			for (j = 0; j < c->nhits; j++, p++) {
				t->value_fcn[i] (t->value_data[i], BUNtail(c->bi, *p));
				column_result(t, i);
			}
		}
	}
}

@}
@* MultiColumn Joins
Computes the n-ary equijoin over the head columns of multiple BATs.
This function is complex, and uses nested functions calls,
for the specific stuff, it uses the stack for generating the
Cartesian product on each hit tuple. Most of all, it emits tuples one
at a time, in a pipeline rather than bulk fashion. For all these reasons,
it is not main-memory efficient. It does things that MonetDB actually
specifically was designed to avoid.

USE THIS FUNCTION ONLY WHEN YOU REALLY REALLY HAVE TO:
@table @code
@item  -
printing a multicolumn table to a watching end-user is one such example
@end table
@+ multijoin entry routine
The multijoin will cause a cascade of value_fcn() calls putting
values in to place, rounded off each time by a tuple_fcn() that is
executed on each produced tuple. If this corresponds 1-1 with
the elements of one of the parameter BAT, the 'result' of the
operation would be aligned with it.

The return value of this operation contains this status information.
It is an integer, of which all 4 bytes are used:
@table @code
@item ret[0] == 1,
if a mergejoin was used, 0 otherwise
@item ret[1] == 1,
if all bats had the key property set, 0 otherwise
@item ret[2] == 1
if there was a 1-1 join, 0 otherwise
@item ret[3] ==
the parameter number of the BAT which was used as leader
@end table
@{
@c
#define COLSIZE(c)\
	(((c)->b->htype!=TYPE_void || (c)->b->hseqbase!=oid_nil)?(c)->size:0)
#define REALLOCBUNS(c,n) if (c->hitsize <= n)\
	c->hit = (BUN*) GDKrealloc(c->hit, (c->hitsize+=n)*sizeof(BUN))

#define LEAD_INTERRUPT_END  1
#define LEAD_TRAVERSE_SSK   3	/* seq, sorted, key */
#define LEAD_TRAVERSE_SNK   4	/* seq, nonsorted, key */
#define LEAD_TRAVERSE_SEQ   6	/* enforced seq (for order purposes) */
#define LEAD_TRAVERSE_SRT   9	/* traverse by sorted chunk */

int
BATmultijoin(int argc, BAT *argv[], RowFcn tuple_fcn, ptr tuple_data, ColFcn value_fcn[], ptr value_data[], int orderby)
{
	column_t *lead_col, *c = (column_t *) alloca(argc * (int) sizeof(column_t));
	column_t **reorder = (column_t **) alloca(argc * (int) sizeof(column_t *));
	int status = 0, algo = LEAD_TRAVERSE_SEQ;
	int i, k;
	BUN p, q;
	table_t t;

@-
Init the table descriptor.
@c
	memset(c, 0, argc * sizeof(column_t));
	t.tuple_data = tuple_data;
	t.value_data = value_data;
	t.tuple_fcn = tuple_fcn;
	t.value_fcn = value_fcn;
	t.argc = argc;
	t.c = c;
@-
order columns by their size (smallest first)
@c
	for (i = 0; i < argc; i++) {
		int j;

		c[i].b = argv[i];
		c[i].bi = bat_iterator(c[i].b);
		c[i].nhits = 1;	/* default value */
		c[i].offset = (ssize_t) BUNfirst(c[i].b);
		c[i].size = BATcount(c[i].b);

		/* positional lookup possible => ignore other alternatives */
		if (!BAThdense(c[i].b))
			c[i].ordered = BAThordered(c[i].b) & 1;

		/* insertion sort on size */
		for (j = 0; j < i; j++) {
			if (COLSIZE(reorder[j]) > COLSIZE(c + i) ||
			    /* in case of equal size, we prefer dense over non-dense */
			    (COLSIZE(reorder[j]) == COLSIZE(c + i) && !BAThdense(reorder[j]->b) && BAThdense((c + i)->b))) {
				for (k = i; k > j; k--) {
					reorder[k] = reorder[k - 1];
				}
				break;
			}
		}
		reorder[j] = c + i;
	}
@}
@- handle explicit ordering requests
An 'orderby' specification tells that the multijoin should match in the
order of one specific BAT parameter.

Notice that we *respect* the ordering of the orderby column rather than we
sort it explicitly (ie; you should order the most significant column beforehand).
This allows for both for join results ordered on some tail column as results
ordered on head column, or even 'reverse' or other specific orderings.
One such specific ordering is the SQL ORDER BY multi-column ordering that
can be obtained with the CTorderby command from the xtables module.
@{
@c
	if (orderby) {		/* order on tail of some column */
		int lead = orderby - 1;

		for (i = 0; i < argc; i++)
			if (reorder[i] == c + lead)
				break;
		while (--i >= 0) {
			reorder[i + 1] = reorder[i];
		}
		reorder[0] = c + lead;
	}
	lead_col = reorder[0];
@}
@- lead column traversal mode
The default action is to do LEAD_TRAVERSE_SEQ: 1-by-1 traversal of the lead_col,
and for each head value use the best possible matching algorithm.
A local optimization is to signal a sorted head column in the lead column,
so we can switch to LEAD_TRAVERSE_SRT; if double lead values occur we do them
in one match iteration.

We record in MULTIJOIN_SORTED(status) whether the chosen traversal method
visits the head values in the lead column in order. This is important
for the matching algorithms of the other columns (only if the head
values are visited in order, merge algorithms may be employed).
@{
@c
	if (BAThordered(lead_col->b) & 1) {
		if (!BAThkey(lead_col->b)) {
			algo = LEAD_TRAVERSE_SRT;
		}
		MULTIJOIN_SORTED(status) = TRUE;
	}
	lead_col->hi = lead_col->cur = BUNfirst(lead_col->b);
	q = BUNlast(lead_col->b);
	MULTIJOIN_KEY(status) = (char) BAThkey(lead_col->b);
	MULTIJOIN_LEAD(status) = (char) (lead_col - c);
	MULTIJOIN_SYNCED(status) = 1;
	if (algo == LEAD_TRAVERSE_SEQ && BAThkey(lead_col->b)) {
		algo = (BAThordered(lead_col->b) & 1) ? LEAD_TRAVERSE_SSK : LEAD_TRAVERSE_SNK;
	}
@}

@- matching algorithms for the other columns
Finally, the issue of choosing matching-algorithms for the other columns
is treated. There are a number of possibilities. If a column is
synced with a previous column, this is registered, so it can copy the
matching results of that previous column. If not, we use the fact that a
column is ordered and if not, has an binary index on it. Both cases
fall into two sub cases: merge-lookup or binary-search; depending on
whether we visit the head elements in order (MULTIJOIN_SORTED(status)).
If none of this is the case, we do hash-lookup using an on-the-fly hash-table.
@{
@c
	for (k = 1; k < argc; k++) {
		column_t *n = reorder[k];
		int j;

		for (j = (algo == LEAD_TRAVERSE_SEQ); j < k; j++) {
			if (ALIGNsynced(reorder[j]->b, n->b)) {
				n->sync = (struct _column_t *) reorder[j];
				n->offset -= reorder[j]->offset;
			}
		}
		if (!BAThkey(n->b)) {
			MULTIJOIN_KEY(status) = 0;
			MULTIJOIN_SYNCED(status) = 0;
		}
		if (!MULTIJOIN_SORTED(status)) {
			if (n->size < 4 * lead_col->size) {
				n->ordered = FALSE;
			} else {
				n->binsearch = TRUE;
			}
		} else if (n->size > 40 * lead_col->size) {
			n->binsearch = TRUE;
		}
		if (n->ordered) {
			n->cur = BUNfirst(n->b);
		} else if (!BAThkey(n->b) && n->sync == NULL) {
			if (BATprepareHash(n->b)) {
				GDKerror("BATmultijoin: could not hash '%s'\n", BATgetId(n->b));
				return 0;
			}
			n->hitsize = 20;
			n->hit = (BUN *) GDKmalloc(n->hitsize * sizeof(BUN));
			if (n->hit == NULL) {
				return 0;
			}
		}
	}

@- the matching phase
We optimize in the case that the head-columns are OID. Below
macro's help to separate the two cases cleanly.
@c
#if (SIZEOF_OID == SIZEOF_INT)
#define OIDcmp(v1,v2)	simple_CMP(v1,v2,int)
#else
#define OIDcmp(v1,v2)	simple_CMP(v1,v2,lng)
#endif
#define STDcmp(v1,v2)	(*cmp)(v1,v2)

	if (ATOMstorage(lead_col->b->htype) == ATOMstorage(TYPE_oid)) {
		@:multijoin(hloc,OID,_oid,_oid)@
	} else {
		int (*cmp) (ptr, ptr) = BATatoms[lead_col->b->htype].atomCmp;

		@:multijoin(head,STD,_any)@
	}
@-
Cleanup & exit.
@c
	for (i = 0; i < argc; i++) {
		if (c[i].hitsize)
			GDKfree(c[i].hit);
	}
	return status;
}

@}
@+ The Matching Algorithm
In multi-column join, all MonetDB accelerators are put to use when
equi-lookup is done on a number of head columns.  In order of
preference, it:

@itemize
@item
    does positional lookup on @emph{ virtual oid} columns (void).
@item
    reuses lookup info on @emph{ synced columns}.
@item
    uses merge scan on @emph{ ordered columns}.
@item
    uses binary tree leaf scan on @emph{ indexed columns}.
@item
    uses hash lookup in other cases. If a hash-table does not
exist; it is created on the fly.
@end itemize

The algorithm goes one by one, for unique head values in the smallest-sized
BAT. The strategy is for each column to find a range of BUNs that match it.

The algorithm is intelligent in that it processes the columns in order
of cardinality. If a column has no matches, you can cut off the matching
process for the current ID (head value) and go to the next. Smallest BATs
first means highest miss probability first.

Another optimization is that when a column has a cardinality much larger
than the smallest column, you can expect sparse matching (e.g. you selected
1% tuples out of a 1M tuple BAT, and re-joins both with this routine). In
those cases the merge algorithms use binary search instead of mergescan.

In non-empty matching ranges are found in all head columns, a recursive
routine is used to go over all combinations of matching BUNs. This recursive
routine calls for every match (the Cartesian product) a special-purpose
routine that is passed all matching BUN pointers. This sequence of calls
represents the result of the multijoin.

Normally you want to perform an action on each value (like formatting or
copying), but many values reoccur in the same place when the Cartesian product
over all columns is formed.  For instance, when we have 5 attributes in which
each has 2 matches on the current id, we have 2*2*2*2*2=32 result tuples for
this one id. A simple-minded strategy would then do 32*5 value actions, when
processing these result tuples. This multijoin reduces that to just 32, by
calling whenever a value is 'changed' in the result-tuple-under-construction,
a value specific function, provided by the user. Since each column can have
a different value function, this also allows for factoring out type-checking
overhead.
@{
@= multijoin
	for (i = 0; i < argc; i++)
		BATaccessBegin(reorder[i]->b, USE_HEAD|USE_TAIL|USE_HHASH, reorder[i]->sync?MMAP_SEQUENTIAL:MMAP_WILLNEED);
	while (algo) {
		ptr h;		/* points to current ID */

		/*
		 * find the next leader bun
		 */
		p = lead_col->hi;
		if (p >= q)
			break;
		h = BUNhead(lead_col->bi, p);

		/* FIND MATCHING COLUMN RANGES
		 * For each column, find all matches for this head value
		 */
		for (i = 0; i < argc; i++) {
			column_t *m, *n = reorder[i];	/* use BATcount() order */
			BAT *b = n->b;
			BATiter bi = n->bi;

			/* one-by-one traversal of the lead column? => no matching done.
			 */
			if (n == lead_col) {
				if (argc > 1 && ATOMcmp(b->htype, h, ATOMnilptr(b->htype)) == 0) {
					n->lo = n->hi = p+1;
					break;
				} else if (algo <= LEAD_TRAVERSE_SEQ) {
					n->lo = p;
					n->hi = p+1;
					continue;
				}
			}
			/* Synced lookup
			 * If some BAT is synced with a BAT we already handled ('parent'),
			 * we can simply copy and convert the BUNlists of the parent.
			 */
			if ((m = n->sync) != NULL) {
				if (m->hit) {
					BUN j;

					REALLOCBUNS(n, m->nhits);
					for (j = 0; j < m->nhits; j++) {
						n->hit[j] = (BUN) (n->offset + m->hit[j]);
					}
					n->nhits = m->nhits;
				} else {
					n->lo = (BUN) (n->offset + m->lo);
					n->hi = (BUN) (n->offset + m->hi);
				}
				/* Sorted lookup
				 * We perform a merge scan over the tail column.
				 */
			} else if (n->ordered) {
				BUN last = BUNlast(b);

				if (n->binsearch) {
					n->cur = (BUN) SORTfndfirst@4(BATmirror(b), h);
					if (n->cur >= last)
						break;	/* NOT FOUND */
				} else {
					int yy = 1;

					for (; n->cur < last; n->cur++)
						if ((yy = @2cmp(BUN@1(bi, n->cur), h)) >= 0)
							 break;

					if (yy != 0)
						break;	/* NOT FOUND */
				}
				n->lo = n->cur;
				for (n->nhits = 1; (++n->cur) < last; n->nhits++) {
					if (@2cmp(BUN@1(bi, n->cur), h))
						 break;
				}
				if (n->cur >= last && (algo & LEAD_INTERRUPT_END))
					algo = 0;
				n->hi = n->cur;
				/* Single Hash lookup
				 */
			} else if (BAThkey(n->b)) {
				BUNfnd@2(n->cur, bi, h);
				if (n->cur == BUN_NONE)
					break;	/* NOT FOUND */
				n->lo = n->cur;
				n->hi = n->cur+1;
				/* Multiple Hash lookup
				 */
			} else {
				BUN j;

				n->nhits = 0;
				HASHloop@3(bi, b->H->hash, j, h) {
					REALLOCBUNS(n, n->nhits + 1);
					n->hit[n->nhits++] = j;
				}
				if (n->nhits == 0)
					break;	/* NOT FOUND */
			}
		}
		/* Recursively print the Cartesian product of all match collections of h.
		 */
		if (i >= argc) {
			t.value_fcn[0] (t.value_data[0], h);
			column_result(&t, 0);
		} else {
			MULTIJOIN_SYNCED(status) = 0;	/* a miss occurred somewhere! */
		}
	}
	if (lead_col->hi < q) {
		MULTIJOIN_SYNCED(status) = 0;	/* an interrupt occurred! */
	}
	for (i = 0; i < argc; i++)
		BATaccessEnd(reorder[i]->b, USE_HEAD|USE_TAIL|USE_HHASH, reorder[i]->sync?MMAP_SEQUENTIAL:MMAP_WILLNEED);
@}
