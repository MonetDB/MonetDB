@/
The contents of this file are subject to the MonetDB Public License
Version 1.1 (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
http://www.monetdb.org/Legal/MonetDBLicense

Software distributed under the License is distributed on an "AS IS"
basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
License for the specific language governing rights and limitations
under the License.

The Original Code is the MonetDB Database System.

The Initial Developer of the Original Code is CWI.
Portions created by CWI are Copyright (C) 1997-July 2008 CWI.
Copyright August 2008-2014 MonetDB B.V.
All Rights Reserved.
@

@f gdk_relop

@c
/*
 * @a M. L. Kersten, P. Boncz, S. Manegold
 * @* BAT relational operators
 * The basic relational operators are implemented for BATs.
 * Particular attention has been paid to speed-up processing
 * joins, such that navigational access and object re-assembly
 * are not being harmed too much.
 */
#include "monetdb_config.h"
#include "gdk.h"
#include "gdk_private.h"

#define SAMPLE_TRESHOLD_LOG 17
#define SAMPLE_SLICE_SIZE 1000

static BAT *BATnlthetajoin(BAT *l, BAT *r, int op, BUN estimate);

/*
 * @+ Join Algorithms
 * All join related operations have the same prelude to check
 * domain compatibility and to creates the BAT to hold the result.
 *
 * We do some dynamic effort to estimate the result size. Good
 * estimates enhance performance and reduce the memory hunger of the join.
 * Method: we sample on l, and join on the whole r. This macro is called by
 * the physical join algorithms, hence we already decided on the algorithm
 * and join method, so the initial costs on r (e.g. hash creation) would have
 * to be paid anyway, and are reused later in the real join phase.
 *
 * Sampling was made more robust by using a logarithmic number of slices
 * taken at equal-spaced intervals across l. The results are then analyzed
 * and checked for outliers. If outliers are present, a real sample is taken
 * and executed with the generic join algorithm to obtain an better estimate.
 *
 * On small joins we just assume 1-N joins with a limited (=3) hit rate.
 */
@= joincheck
	ERRORcheck(l == NULL, "@1: invalid left operand");
	ERRORcheck(r == NULL, "@1: invalid right operand");
	ERRORcheck(TYPEerror(@2, @3), "@1: type conflict\n");
@= joinestimate
	if (@3 == BUN_NONE) {
		BUN _lcount = BATcount(l);
		BUN _rcount = BATcount(r);
		BUN _slices = 0;

		/* limit estimate with simple bounds first; only spend
		 * effort if the join result might be big */
		if (@1 == JOIN_EQ) {
			if (l->tkey)
				@3 = r->hkey ? MIN(_rcount, _lcount) : _rcount;
			else if (r->hkey)
				@3 = _lcount;
		}
		if (@3 == BUN_NONE) {
			BUN _heuristic = MIN(_lcount, _rcount);

			if (_heuristic <= BUN_MAX / 3) {
				_heuristic *= 3;
				if (_heuristic <= (1 << SAMPLE_TRESHOLD_LOG))
					@3 = _heuristic;
			}
		}
		if (@3 == BUN_NONE) {
			BUN _idx;

			for (_idx = _lcount; _idx > 0; _idx >>= 1)
				_slices++;
		}
		if (_slices > SAMPLE_TRESHOLD_LOG) {
			/* use cheapo sampling by taking a number of
			 * slices and joining those with the algo */
			BUN _idx = 0, _tot = 0, _step, _lo, _avg, _sample, *_cnt;
			BAT *_tmp1 = l, *_tmp2, *_tmp3 = NULL;

			_step = _lcount / (_slices -= SAMPLE_TRESHOLD_LOG);
			_sample = _slices * SAMPLE_SLICE_SIZE;
			_cnt = GDKmalloc(_slices * sizeof(BUN));
			if (_cnt == NULL)
				return NULL;
			for (_lo = 0; _idx < _slices; _lo += _step) {
				BUN _size = 0, _hi = _lo + SAMPLE_SLICE_SIZE;

				l = BATslice(_tmp1, _lo, _hi);	/* slice keeps all parent properties */
				if (l == NULL) {
					GDKfree(_cnt);
					return NULL;
				}
				_tmp2 = @2;	/* @2 = e.g. BATXjoin(l,r) */
				if (_tmp2) {
					_size = BATcount(_tmp2);
					BBPreclaim(_tmp2);
				}
				_tot += (_cnt[_idx++] = _size);
				BBPreclaim(l);
			}
			/* do outlier detection on sampling results;
			 * this guards against skew */
			if (@1 == JOIN_EQ) {
				for (_avg = _tot / _slices, _idx = 0; _idx < _slices; _idx++) {
					BUN _diff = _cnt[_idx] - _avg;

					if (_avg > _cnt[_idx])
						_diff = _avg - _cnt[_idx];
					if (_diff > MAX(SAMPLE_SLICE_SIZE, _avg))
						break;
				}
				if (_idx < _slices) {
					/* outliers detected, compute
					 * a real sample on at most 1%
					 * of the data */
					_sample = MIN(_lcount / 100, (1 << SAMPLE_TRESHOLD_LOG) / 3);
					_tmp2 = BATsample(_tmp1, _sample);
					if (_tmp2) {
						_tmp3 = BATjoin(_tmp2, r, BUN_NONE);	/* might be expensive */
						if (_tmp3) {
							_tot = BATcount(_tmp3);
							BBPreclaim(_tmp3);
						}
						BBPreclaim(_tmp2);
					}
					if (_tmp3 == NULL) {
						GDKfree(_cnt);
						return NULL;
					}
				}
			}
			GDKfree(_cnt);
			/* overestimate always by 5% */
			{
				double _d = (double) (((lng) _tot) * ((lng) _lcount)) / (0.95 * (double) _sample);
				if (_d < (double) BUN_MAX)
					@3 = (BUN) _d;
				else
					@3 = BUN_MAX;
			}
			l = _tmp1;
		} else {
			BUN _m = MIN(_lcount,_rcount);
			if (_m <= BUN_MAX / 32)
				_m *= 32;
			else
				_m = BUN_MAX;
			@3 = MIN(_m,MAX(_lcount,_rcount));
		}
	}
@= joinbat
	{
		BUN _estimate = @3;

		@:joinestimate(@1, @2, _estimate)@
		bn = BATnew(BAThtype(l), BATttype(r), _estimate);
		if (bn == NULL)
			return bn;
	}
@
@c
/*
 * @- Merge join
 * In the case that both join columns are ordered, we can do a merging
 * (BATmergejoin). The merge is opportunistic in that it tries to do
 * merge between l and r, but if for a long time no matching tuples are
 * found in r, it uses binary search. It also allows joining of an
 * unsorted l with a sorted r; in that case it always uses binary search.
 */
#define BATPERC(lfirst,lcur,lend,rfirst,rcur,rend)\
		((((dbl) (lend-lfirst))*((dbl) (rend-rfirst))) / \
		 MAX(1,((lcur-lfirst)*((dbl) (rend-rfirst))+(dbl) (rcur-rfirst))))

#define bunfastins_limit(b, h, t, limit, percdone)			\
	do {								\
                register BUN _p = BUNlast(b);				\
		if (_p == BUN_MAX) /* reached maximum, can't do more */	\
			goto bunins_done;				\
                if (_p + 1 > BATcapacity(b)) {				\
                        if (limit) {					\
				*limit = (BUN) (b->batCount * (percdone)); \
                              goto bunins_done;				\
			}						\
                        if (BATextend(b, BATgrows(b)) == NULL)		\
                                goto bunins_failed;			\
                }							\
                hfastins_nocheck(b, _p, h, Hsize(b));			\
                tfastins_nocheck(b, _p, t, Tsize(b));			\
                (b)->batCount++;					\
        } while (0)
@= mergejoin
	if (((!BATtvoid(l)) || l->tseqbase != oid_nil) &&
	    ((!BAThvoid(r)) || r->hseqbase != oid_nil || nil_on_miss)) {
		assert(r->htype != TYPE_void);
		while (l_start < l_last) {
			ptr v2, v1 = BUNt@2(li, l_start);
			int neq = 1;

			/* lookup range in l */
			l_end = l_start;
			if (l_key) {
				l_end++;
			} else
				do {
					if ((++l_end) >= l_last)
						break;
					v2 = BUNt@2(li, l_end);
				} while (@1_EQ(v1, v2, @4));

			/* lookup value in r (if not nil, that is) */
			if (!@1_EQ(v1, nil, @4)) {
				if (r_scan > 0) {
					/* first try scanning; but
					 * give up after a while */
					for (r_lim = MIN(r_last, r_end + r_scan); r_end < r_lim; r_end++) {
						v2 = BUNh@3(ri, r_end);
						neq = @1_CMP(v1, v2, @4);
						if (neq <= 0)
							break;
					}
					r_start = r_end;
				}
				if (neq == 1) {
					/* use binary search after
					 * failed scan or if scanning
					 * is impossible (l not
					 * sorted) */
					if (r_scan < 0 || r_start < r_last) {
						/* if merge not ended
						 * (or if no merge at
						 * all) */
						r_start = SORTfndfirst(rr, v1);
					}
					if (r_start < r_last) {
						v2 = BUNh@3(ri, r_start);
						neq = !@1_EQ(v1, v2, @4);
					} else if (r_scan >= 0) {
						/* r is already at end
						 * => break off merge
						 * join */
						break;
					}
				}
			}
			if (neq == 0) {
				/* lookup range in r */
				r_end = r_start+1;
				if (r_key == 0)
					while (r_end < r_last) {
						v2 = BUNh@3(ri, r_end);
						if (!@1_EQ(v1, v2, @4))
							break;
						r_end++ ;
					}
				/* generate match-product as join result */
				for (; l_start < l_end; l_start++)
					for (r_cur = r_start; r_cur < r_end; r_cur++)
						bunfastins_limit(bn, BUNhead(li, l_start), BUNtail(ri, r_cur), limit, BATPERC(BUNfirst(l),l_start,BUNlast(l),r_start,r_cur,r_end));
			} else if (nil_on_miss) {
				/* outerjoin inserts nils on a miss */
				hasnils = 1;
				for (; l_start < l_end; l_start++)
					bunfastins_limit(bn, BUNhead(li, l_start), nil_on_miss, limit, BATPERC(BUNfirst(l),l_start,BUNlast(l),0,1,1));
			} else {
				l_start = l_end;	/* no match found in equi-join */
			}
		}
	}
@
@c
/* serves both normal equi-join (nil_on_miss==NULL) and outerjoin
 * (nil_on_miss=nil) */
static BAT *
mergejoin(BAT *l, BAT *r, BAT *bn, ptr nil_on_miss, BUN estimate, BUN *limit)
{
	ptr nil = ATOMnilptr(r->htype);
	int r_scan = -1;	/* no scanning in r */
	BAT *rr = BATmirror(r);
	BUN l_last, r_last;	/* last BUN of the BAT */
	BUN l_start, r_start;	/* start of current chunk  */
	BUN l_end, r_end;	/* end of current chunk */
	int l_key = l->tkey;
	int r_key = r->hkey;
	BUN r_cur, r_lim;
	int loc, var, hasnils = 0;
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);

	if (BATtordered(l)) {
		BUN i;
		int logr = 4;

		/* 4*log2(r.count) = estimation of the cost of binary
		 * search in units of scan comparisons */
		for (i = BATcount(r); i > 0; logr++)
			i >>= 1;
		r_scan = logr;	/* opportunistic scan window in r */
	}
	if (!BAThordered(r)) {
		GDKerror("mergejoin: right input is not sorted.\n");
		return NULL;
	}
	if (bn == NULL) {
		@:joinbat(JOIN_EQ,mergejoin(l,r,NULL,nil_on_miss,BUN_NONE,NULL),estimate)@
	}

	/* the algorithm */
	loc = ATOMstorage(l->ttype);

	l_last = BUNlast(l);
	r_last = BUNlast(r);
	l_start = l_end = BUNfirst(l);
	r_start = r_end = BUNfirst(r);

	switch (loc) {
	case TYPE_bte:
		@:mergejoin(simple,loc,loc,bte)@
		break;
	case TYPE_sht:
		@:mergejoin(simple,loc,loc,sht)@
		break;
	case TYPE_int:
		@:mergejoin(simple,loc,loc,int)@
		break;
	case TYPE_flt:
		@:mergejoin(simple,loc,loc,flt)@
		break;
	case TYPE_lng:
		@:mergejoin(simple,loc,loc,lng)@
		break;
	case TYPE_dbl:
		@:mergejoin(simple,loc,loc,dbl)@
		break;
	default:
		/* watch it: l->tvarsized may be set due to void l */
		if (l->tvarsized) {
			var = ATOMstorage(l->ttype);

			if (r->hvarsized) {
				/* l and r both real varsized types */
				@:mergejoin(atom,var,var,var)@
			} else {
				/* l is void, r is oid */
				loc = ATOMstorage(r->htype);
				@:mergejoin(atom,var,loc,loc)@
			}
		} else {
			/* we can't handle void r anyway, so don't
			 * worry about it here */
			loc = ATOMstorage(l->ttype);
			@:mergejoin(atom,loc,loc,loc)@
		}
		break;
	}

	if (nil_on_miss && l_start < l_last) {
		hasnils = 1;
		for (; l_start < l_last; l_start++)
			bunfastins_limit(bn, BUNhead(li, l_start), nil_on_miss, limit, BATPERC(BUNfirst(l), l_start, BUNlast(l), 0, 1, 1));
	}
	/* propagate properties */
      bunins_done:
	bn->hsorted = BAThordered(l);
	bn->hrevsorted = BAThrevordered(l);
	if (r->hkey) {
		if (BATcount(bn) == BATcount(l)) {
			ALIGNsetH(bn, l);
		} else if (l->hkey) {
			BATkey(bn, TRUE);
		}
	}
	bn->H->nonil = l->H->nonil;
	bn->tsorted = FALSE;
	bn->trevsorted = FALSE;
	if (!hasnils) {
		if (BATtordered(l)) {
			if (l->tkey && BATcount(bn) == BATcount(r)) {
				ALIGNsetT(bn, r);
			} else if (l->tkey || r->hkey) {
				bn->tsorted = BATtordered(r);
				bn->trevsorted = BATtrevordered(r);
			}
		}
		if (l->tkey && r->tkey) {
			BATkey(BATmirror(bn), TRUE);
		}
	}
	bn->T->nonil = r->T->nonil && !hasnils;
	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;
}

static BAT *batfetchjoin(BAT *l, BAT *r, BUN estimate, bit swap, bit hitalways);

static BAT *
batmergejoin(BAT *l, BAT *r, BUN estimate, bit swap, BUN *limit)
{
	@:joincheck(BATmergejoin,l->ttype,r->htype)@
	if (BAThdense(r) || (swap && BATtdense(l))) {
		/* batmergejoin can't handle void tail columns at all
		 * (fetchjoin is better anyway) */
		BAT *left = limit ? BATslice(l, 0, *limit) : l;
		BAT *bn = batfetchjoin(left, r, estimate, swap, FALSE);
		if (limit)
			BBPreclaim(left);
		return bn;
	}
	if (swap && (!BAThordered(r) || (BATtordered(l) && BATcount(l) > BATcount(r)))) {
		/* reverse join if required (r not sorted) or if l is
		 * larger (quick jump through l with binary search) */
		BAT *bn = mergejoin(BATmirror(r), BATmirror(l), NULL, NULL, estimate, limit);

		return bn ? BATmirror(bn) : NULL;
	}
	return mergejoin(l, r, NULL, NULL, estimate, limit);
}

BAT *
BATmergejoin(BAT *l, BAT *r, BUN estimate)
{
	/* allows swapping of left and right input for faster processing */
	return batmergejoin(l, r, estimate, TRUE, NULL);
}

/*
 * @- hash join
 * These macros encode the core of the join algorithm. They are
 * the fast inner loops, optimized towards their type.
 */
@= hashjoin
	{
		BUN yy;

		BATloop(l, p, q) {
			v = BUN@3(li, p);
			if (@1_EQ(v, nil, @4)) {
				continue; /* skip nil */
			}
			HASHloop_@2(ri, r->H->hash, yy, v) {
				bunfastins(bn, BUNhead(li, p), BUNtail(ri, yy));
			}
		}
		/* set sorted flags by hand, because we used BUNfastins() */
		bn->hsorted = BAThordered(l);
		bn->hrevsorted = BAThrevordered(l);
		bn->tsorted = FALSE;
		bn->trevsorted = FALSE;
		break;
	}
@
@c
BAT *
BAThashjoin(BAT *l, BAT *r, BUN estimate)
{
	ptr v, nil = ATOMnilptr(r->htype);
	BUN p, q;
	int any;
	BAT *bn = NULL;
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);

	@:joincheck(BAThashjoin,l->ttype,r->htype)@
	@:joinbat(JOIN_EQ,BAThashjoin(l,r,BUN_NONE),estimate)@

	if (BATprepareHash(r)) {
		return NULL;
	}
	switch (any = ATOMstorage(l->ttype)) {
	case TYPE_bte:
		@:hashjoin(simple,bte,tloc,bte)@
	case TYPE_sht:
		@:hashjoin(simple,sht,tloc,sht)@
	case TYPE_int:
	case TYPE_flt:
		@:hashjoin(simple,int,tloc,int)@
	case TYPE_dbl:
	case TYPE_lng:
		@:hashjoin(simple,lng,tloc,lng)@
	case TYPE_str:
		if (l->T->vheap->hashash) {
			@:hashjoin(atom,str_hv,tail,any)@
		}
		/* fall through */
	default:
		@:hashjoin(atom,any,tail,any)@
	}

	/* propagate alignment info */
	bn->hsorted = BAThordered(l);
	bn->hrevsorted = BAThrevordered(l);
	if (BAThkey(r)) {
		if (BATcount(bn) == BATcount(l))
			ALIGNsetH(bn, l);
		if (BAThkey(l))
			BATkey(bn, TRUE);
	}
	bn->H->nonil = l->H->nonil;
	bn->T->nonil = r->T->nonil;
	ESTIDEBUG THRprintf(GDKout, "#BAThashjoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;

}


/*
 * @- Fetch-join
 * The @`BATfetchjoin@5(l,r) does a join on the basis of positional lookup.
 * It looks up index numbers from the second parameter in first parameter BAT.
 * The right parameter may contain OIDs, in which case their base is
 * subtracted.
 *
 * In a typical join(BAT[any::1,oid) L, BATvoid,any::2] R) : BAT[any::1,any::2]
 * we expect each tuple of L to hit exactly once in R. Now if any::1=void
 * this void column can be carried over to the result. We do that.
 *
 * However, it is possible that an tail-oid is out of range with respect
 * to R; in that case some tuples will be missing and we cannot carry on
 * producing a void column. In that case, we have to switch back
 * on-the-fly to the non-dense implementation.
 *
 * The aftermath -- property setting -- is relatively straightforward here.
 */
#define HLATOMput(bn, dst) ATOMput(bn->htype, bn->H->vheap, dst, BUNhloc(li,l_cur))
#define HVATOMput(bn, dst) Hputvalue(bn, dst, BUNhvar(li,l_cur), 1)
#define TLATOMput(bn, dst) ATOMput(bn->ttype, bn->T->vheap, dst, BUNtloc(ri,r_cur))
#define TVATOMput(bn, dst) Tputvalue(bn, dst, BUNtvar(ri,r_cur), 1)
#define LATOM_cmp(bn, p,n) atom_CMP(p, n, bn->ttype)
#define VATOM_cmp(bn, p,n) atom_CMP(p, n, bn->ttype)

@= SIMPLEput
#define H@1put(bn,dst)	*(@1*) (dst) = *(@1*) (BUNhloc(li,l_cur))
#define T@1put(bn,dst)	*(@1*) (dst) = *(@1*) (BUNtloc(ri,r_cur))
#define @1_cmp(bn,p,n)  simple_CMP(p, n, @1)
@
@c
@:SIMPLEput(bte)@
@:SIMPLEput(sht)@
@:SIMPLEput(int)@
@:SIMPLEput(flt)@
@:SIMPLEput(lng)@
@:SIMPLEput(dbl)@

@= bunfastins_nocheck_
	H@1put(bn, BUNhloc(bni, dst));
	T@2put(bn, BUNtloc(bni, dst));
@
@c
@= fetchjoin
static BAT *
densefetchjoin_@1_@2(BAT *bn, BAT *l, BAT *r)
{
	BUN l_cur, l_end, r_cur, dst;
	ssize_t offset;
	BUN base;
	BAT *ret = NULL;
	BATiter bni = bat_iterator(bn);
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	void *prev = NULL, *next = NULL;

	if (bn == NULL)
		return NULL;
	dst = BUNfirst(bn);
	base = BUNfirst(r);
	offset = (ssize_t) base - (ssize_t) r->hseqbase; /* cast first, subtract second */
	r_cur = (BUN) (offset + *(oid *) BUNtail(li, BUNfirst(l)));

	ALGODEBUG fprintf(stderr, "#BATfetchjoin: densefetchjoin(@1,@2,@3);\n");

	BATloop(l, l_cur, l_end) {
		@:bunfastins_nocheck_(@1,@2)@
		if (bn->tsorted || bn->trevsorted) {
			next = BUNt@3(bni,dst);
			if (bn->tsorted && prev && @2_cmp(bn,prev,next) > 0) {
				bn->tsorted = 0;
			}
			if (bn->trevsorted && prev && @2_cmp(bn,prev,next) < 0) {
				bn->trevsorted = 0;
			}
			prev = next;
		}
		r_cur++;
		dst++;
	}
	BATsetcount(bn, dst);
	ret = bn;
      goto bunins_failed;
      bunins_failed:
	if (!ret)
		BBPreclaim(bn);
	return ret;
}

static BAT *
orderedfetchjoin_@1_@2(BAT *bn, BAT *l, BAT *r)
{
	BUN l_cur, l_end, r_cur, dst;
	ssize_t offset;
	BUN base, yy;
	BAT *ret = NULL;
	BATiter bni = bat_iterator(bn);
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	void *prev = NULL, *next = NULL;

	if (bn == NULL)
		return NULL;
	dst = BUNfirst(bn);
	base = BUNfirst(r);
	offset = (ssize_t) base - (ssize_t) r->hseqbase; /* cast first, subtract second */

	ALGODEBUG fprintf(stderr, "#BATfetchjoin: orderedfetchjoin(@1,@2,@3);\n");

	BATloop(l, l_cur, l_end) {
		yy = (BUN) (offset + *(oid *) BUNtail(li, l_cur));
		r_cur = yy;
		@:bunfastins_nocheck_(@1,@2)@
		if (bn->tsorted || bn->trevsorted) {
			next = BUNt@3(bni,dst);
			if (bn->tsorted && prev && @2_cmp(bn,prev,next) > 0) {
				bn->tsorted = 0;
			}
			if (bn->trevsorted && prev && @2_cmp(bn,prev,next) < 0) {
				bn->trevsorted = 0;
			}
			prev = next;
		}
		dst++;
	}
	BATsetcount(bn, dst);
	ret = bn;
      goto bunins_failed;
      bunins_failed:
	if (!ret)
		BBPreclaim(bn);
	return ret;
}

static BAT *
defaultfetchjoin_@1_@2(BAT *bn, BAT *l, BAT *r)
{
	BUN l_cur, l_end, r_cur, dst;
	ssize_t offset;
	BUN yy, base, end;
	BAT *ret = NULL;
	BATiter bni = bat_iterator(bn);
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	void *prev = NULL, *next = NULL;

	if (bn == NULL)
		return NULL;
	dst = BUNfirst(bn);
	base = BUNfirst(r);
	offset = (ssize_t) base - (ssize_t) r->hseqbase; /* cast first, subtract second */
	end = base + BATcount(r);

	ALGODEBUG fprintf(stderr, "#BATfetchjoin: defaultfetchjoin(@1,@2,@3);\n");

	BATloop(l, l_cur, l_end) {
		yy = (BUN) (offset + *(oid *) BUNtail(li, l_cur));
		if (yy < base || yy >= end) {
			continue;
		}
		r_cur = yy;
		@:bunfastins_nocheck_(@1,@2)@
		if (bn->tsorted || bn->trevsorted) {
			next = BUNt@3(bni,dst);
			if (bn->tsorted && prev && @2_cmp(bn,prev,next) > 0) {
				bn->tsorted = 0;
			}
			if (bn->trevsorted && prev && @2_cmp(bn,prev,next) < 0) {
				bn->trevsorted = 0;
			}
			prev = next;
		}
		dst++;
	}
	BATsetcount(bn, dst);
	ret = bn;
      goto bunins_failed;
      bunins_failed:
	if (!ret)
		BBPreclaim(bn);
	return ret;
}
@
@c
@= fetchjoin2
	@:fetchjoin(@1,bte,loc)@
	@:fetchjoin(@1,sht,loc)@
	@:fetchjoin(@1,int,loc)@
	@:fetchjoin(@1,flt,loc)@
	@:fetchjoin(@1,lng,loc)@
	@:fetchjoin(@1,dbl,loc)@
	@:fetchjoin(@1,VATOM,var)@
	@:fetchjoin(@1,LATOM,loc)@
@
@c
@:fetchjoin2(bte)@
@:fetchjoin2(sht)@
@:fetchjoin2(int)@
@:fetchjoin2(lng)@

@:fetchjoin2(VATOM)@
@:fetchjoin2(LATOM)@

@= fetchjoin_switch_rtt
	if (ATOMstorage(rtt) == TYPE_bte) {
		bn = @1fetchjoin_@2_bte(bn, l, r);
	} else if (ATOMstorage(rtt) == TYPE_sht) {
		bn = @1fetchjoin_@2_sht(bn, l, r);
	} else if (ATOMstorage(rtt) == TYPE_int) {
		bn = @1fetchjoin_@2_int(bn, l, r);
	} else if (ATOMstorage(rtt) == TYPE_flt) {
		bn = @1fetchjoin_@2_flt(bn, l, r);
	} else if (ATOMstorage(rtt) == TYPE_lng) {
		bn = @1fetchjoin_@2_lng(bn, l, r);
	} else if (ATOMstorage(rtt) == TYPE_dbl) {
		bn = @1fetchjoin_@2_dbl(bn, l, r);
	} else if (r->tvarsized) {
		bn = @1fetchjoin_@2_VATOM(bn, l, r);
	} else {
		bn = @1fetchjoin_@2_LATOM(bn, l, r);
	}
@
@c
@= fetchjoin_switch_lht
	if (ATOMstorage(lht) == TYPE_bte) {
		@:fetchjoin_switch_rtt(@1,bte)@
	} else if (ATOMstorage(lht) == TYPE_sht) {
		@:fetchjoin_switch_rtt(@1,sht)@
	} else if (ATOMstorage(lht) == TYPE_int ||
		   ATOMstorage(lht) == TYPE_flt) {
		@:fetchjoin_switch_rtt(@1,int)@
	} else if (ATOMstorage(lht) == TYPE_lng ||
		   ATOMstorage(lht) == TYPE_dbl) {
		@:fetchjoin_switch_rtt(@1,lng)@
	} else if (l->hvarsized) {
		@:fetchjoin_switch_rtt(@1,VATOM)@
	} else {
		@:fetchjoin_switch_rtt(@1,LATOM)@
	}
@
@c
@= densevoidfetchjoin
	ALGODEBUG fprintf(stderr, "#BATfetchjoin: densevoidfetchjoin(@1,@2);\n");
	r_cur = (BUN) (offset + * (oid *) BUNtloc(li, BUNfirst(l)));
	BATloop(l, l_cur, l_end) {
		T@1put(bn, Tloc(bn,dst));
		if (bn->tsorted || bn->trevsorted) {
			next = BUNt@2(bni,dst);
			if (bn->tsorted && prev && @1_cmp(bn,prev,next) > 0) {
				bn->tsorted = 0;
			}
			if (bn->trevsorted && prev && @1_cmp(bn,prev,next) < 0) {
				bn->trevsorted = 0;
			}
			prev = next;
		}
		r_cur++;
		dst++;
	}
@
@c
@= orderedvoidfetchjoin
	ALGODEBUG fprintf(stderr, "#BATfetchjoin: orderedvoidfetchjoin(@1,@2);\n");
	BATloop(l, l_cur, l_end) {
		BUN _yy = (BUN) (offset + * (oid *) BUNtloc(li, l_cur));

		r_cur = _yy;
		T@1put(bn, Tloc(bn,dst));
		if (bn->tsorted || bn->trevsorted) {
			next = BUNt@2(bni,dst);
			if (bn->tsorted && prev && @1_cmp(bn,prev,next) > 0) {
				bn->tsorted = 0;
			}
			if (bn->trevsorted && prev && @1_cmp(bn,prev,next) < 0) {
				bn->trevsorted = 0;
			}
			prev = next;
		}
		dst++;
	}
@
@c
@= defaultvoidfetchjoin
	ALGODEBUG fprintf(stderr, "#BATfetchjoin: defaultvoidfetchjoin(@1,@2);\n");
	BATloop(l, l_cur, l_end) {
		BUN _yy = (BUN) (offset + * (oid *) BUNtloc(li, l_cur));

		if (_yy < base || _yy >= end) {
			bntsorted = bn->tsorted;
			bntrevsorted = bn->trevsorted;
			BBPreclaim(bn);
			bn = NULL;
			nondense = 1;
			prev = next = NULL;
			break;
		}
		r_cur = _yy;
		T@1put(bn, Tloc(bn,dst));
		if (bn->tsorted || bn->trevsorted) {
			next = BUNt@2(bni,dst);
			if (bn->tsorted && prev && @1_cmp(bn,prev,next) > 0) {
				bn->tsorted = 0;
			}
			if (bn->trevsorted && prev && @1_cmp(bn,prev,next) < 0) {
				bn->trevsorted = 0;
			}
			prev = next;
		}
		dst++;
	}
	if (nondense) {
		/* not (yet?) completely type-optimized ! */
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: defaultvoidfetchjoin(@1,@2): discovered non-density, resuming with non-void head\n");
		bn = BATnew(BAThtype(l), ATOMtype(tpe), BATcount(l));
		if (bn == NULL)
			return bn;
		dst = BUNfirst(bn);
		bni = bat_iterator(bn);
		bn->tsorted = bntsorted;
		bn->trevsorted = bntrevsorted;
		BATloop(l, l_cur, l_end) {
			BUN _yy = (BUN) (offset + * (oid *) BUNtail(li, l_cur));

			if (_yy < base || _yy >= end) {
				continue;
			}
			r_cur = _yy;
			Hputvalue(bn, BUNhloc(bni, dst), BUNhead(li, l_cur), 1);
			T@1put(bn, BUNtloc(bni, dst));
			if (bn->tsorted || bn->trevsorted) {
				next = BUNt@2(bni,dst);
				if (bn->tsorted && prev && @1_cmp(bn,prev,next) > 0) {
					bn->tsorted = 0;
				}
				if (bn->trevsorted && prev && @1_cmp(bn,prev,next) < 0) {
					bn->trevsorted = 0;
				}
				prev = next;
			}
			dst++;
		}
	}
@
@c
@= voidfetchjoin
	if ((BATtordered(l) & BATtordered(r)) || \
	    (BATtordered(l) & BATtrevordered(r)) || \
	    (BATtrevordered(l) & BATtordered(r)) || \
	    (BATtrevordered(l) & BATtrevordered(r))) {
		/* will be set correctly once we're done */
		bn->tsorted = bn->trevsorted = 0;
	} else if (ATOMstorage(r->ttype) == TYPE_str) {
		/* either: "string trick" => cannot compare on the fly
		 * or: "real string" => cannot (yet?) cope with 
		 *     heap extend or index width extend
		 */
		bn->tsorted = bn->trevsorted = 0;
		derive_tail_properties = TRUE;
	} else if (r->ttype == TYPE_void) {
		/* cannot compare on the fly */
		bn->tsorted = bn->trevsorted = 0;
		derive_tail_properties = TRUE;
	} else {
		/* start optimistic & check on the fly */
		bn->tsorted = bn->trevsorted = 1;
	}
	if (BATtdense(l)) {
		/* dense => ordered, i.e., we did check the bounderies
		 * already above and we can do a "synchronized walk"
		 * through l & r */
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: BAThvoid(l) && !BATtvoid(l) && BATtdense(l)\n");
		@:densevoidfetchjoin(@1,@2)@
	} else if (BATtordered(l) || hitalways) {
		/* we did check the bounderies already above
		 * BATtordered(l) or simply "trust" hitalways */
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: BAThvoid(l) && !BATtvoid(l) && !BATtdense(l) && ( BATtordered(l) [== %d] || hitalways [== %d] )\n", BATtordered(l), (int)hitalways);
		@:orderedvoidfetchjoin(@1,@2)@
	} else {
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: BAThvoid(l) && !BATtvoid(l) && !BATtdense(l) && !BATtordered(l) && !hitalways\n");
		@:defaultvoidfetchjoin(@1,@2)@
	}
@
@c
#define SIMPLEput(tpe,hp,dst,src) *(tpe*) (dst) = *(tpe*) (src)

static BAT *
batfetchjoin(BAT *l, BAT *r, BUN estimate, bit swap, bit hitalways)
{
	int lht, rtt;
	BUN base, end;
	ssize_t offset;
	BUN lcount, rcount;
	BUN r_cur, l_cur, l_end;
	oid seqbase;
	BAT *ret = NULL, *bn = NULL, *l_orig = l;
	bit hitalways_check = FALSE;
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	bit derive_tail_properties = FALSE;

	BATcheck(l, "BATfetchjoin: left BAT required");
	BATcheck(r, "BATfetchjoin: right BAT required");

	lcount = BATcount(l);
	rcount = BATcount(r);
	if (estimate == BUN_NONE || estimate < lcount) {
		/* upper bound to avoid size checks in the join loop */
		estimate = lcount;
	}

	if (swap) {
		if (!BAThdense(r)) {
			ERRORcheck(!BATtdense(l), "BATfetchjoin: one join column must be dense");
			ALGODEBUG fprintf(stderr, "#BATfetchjoin: BATmirror(BATfetchjoin(BATmirror(r),BATmirror(l)));\n");

			return BATmirror(batfetchjoin(BATmirror(r), BATmirror(l), estimate, FALSE, FALSE));
		}
	} else {
		ERRORcheck(!BAThdense(r), "BATfetchjoin: head column of right input must be dense");
	}
	/* not checking boundaries is very dangerous; use regression
	 * tests with debugmask=8 first */
	PROPDEBUG {
		hitalways_check = hitalways;
		hitalways = FALSE;
	}

	if (lcount == 0 || rcount == 0) {
		/* below range checking do not support empty bats. so
		 * treat them separately (easy) */
		@:return_empty_join_result(l_orig,r, BATfetchjoin: |l|==0 or |r|==0,1)@
@= return_empty_join_result
		ALGODEBUG fprintf(stderr, "#@3 => empty result\n");
#if @4
		if (hitalways|hitalways_check && lcount > 0) {
			GDKerror("BATfetchjoin(%s,%s) does not hit always (|bn|=0 != "BUNFMT"=|l|) => can't use fetchjoin.\n", BATgetId(l), BATgetId(r), lcount);
			return NULL;
		}
#endif
		bn = BATnew(@1->htype, @2->ttype, 0);
		if (bn == NULL)
			return NULL;
		BATkey(bn, TRUE);
		BATkey(BATmirror(bn), TRUE);
		if (bn->htype == TYPE_void || bn->htype == TYPE_oid) {
			BATseqbase(bn, @1->htype == TYPE_void ? @1->hseqbase : 0);
			bn->hdense = bn->hseqbase != oid_nil;
		}
		if (bn->ttype == TYPE_void || bn->ttype == TYPE_oid) {
			BATseqbase(BATmirror(bn), @2->ttype == TYPE_void ? @2->tseqbase : 0);
			bn->tdense = bn->tseqbase != oid_nil;
		}
		return bn;
@
@c
	} else if (BATtdense(l) && BAThdense(r) && l->tseqbase == r->hseqbase && BATcount(l) <= BATcount(r)) {
		/* always hit and tail of left is alligned with head
		 * of right */
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: BATtdense(l) && BAThdense(r)\n");
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: VIEWcreate(l,r)\n");

		return VIEWcreate(l, r);
	} else if (hitalways && BAThdense(r) && BATtdense(r) && r->hseqbase == r->tseqbase && BATcount(l) <= BATcount(r)) {
		/* idempotent join: always hit and substitute tail with the same value */
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: BAThdense(r) && BATtdense(r)\n");
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: VIEWcreate(l,l)\n");

		return VIEWcreate(l, l);
	} else if (BATtordered(l)) {
		/* optimization to be able to carry over more void
		 * head columns */
		/* (only needed if neither operand is empty) */
		oid r_lo = *(oid *) BUNhead(ri, BUNfirst(r));
		oid r_hi = *(oid *) BUNhead(ri, BUNlast(r) - 1);
		oid l_lo = *(oid *) BUNtail(li, BUNfirst(l));
		oid l_hi = *(oid *) BUNtail(li, BUNlast(l) - 1);
		int empty = r_lo > l_hi || r_hi < l_lo;
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: BATtordered(l)\n");
		ALGODEBUG fprintf(stderr, "#r_lo=" OIDFMT ", r_hi=" OIDFMT ", l_lo=" OIDFMT ", l_hi=" OIDFMT ".\n", r_lo, r_hi, l_lo, l_hi);

		if (!empty && (r_lo > l_lo || r_hi < l_hi)) {
			ALGODEBUG fprintf(stderr, "#shrinking!\n");
			ALGODEBUG fprintf(stderr, "#BATfetchjoin: l = BATselect(l, &r_lo, &r_hi);\n");

			li.b = l = BATselect(l, &r_lo, &r_hi);	/* sorted, so it will be a slice */
			if (l == NULL)
				return NULL;
			if (BATcount(l) == 0) {
				if (l != l_orig) {
					BBPreclaim(l);	/* was created as a temporary (slice) select on l */
				}
				empty = 1;
			}
		}
		if (empty) {
			@:return_empty_join_result(l_orig, r, BATfetchjoin: empty,1)@
		} else if (hitalways | hitalways_check && BATcount(l) < lcount) {
			GDKerror("BATfetchjoin(%s,%s) does not hit always (|bn|=" BUNFMT " != " BUNFMT "=|l|) => can't use fetchjoin.\n", BATgetId(l), BATgetId(r), BATcount(l), lcount);
			return NULL;
		}
		lcount = BATcount(l);
	}
	ALGODEBUG fprintf(stderr, "#BATfetchjoin: 1\n");

	base = BUNfirst(r);
	offset = (ssize_t) base - (ssize_t) r->hseqbase;	/* cast first, subtract second */
	end = base + rcount;
	/* only BUNhead crashes on empty bats with TYPE != virtual oid */
	seqbase = l->htype == TYPE_void ?
		l->hseqbase :
		(lcount ?
		 (l->htype == TYPE_int ?
		  (oid) *(int *) BUNhead(li, BUNfirst(l)) :
		  (l->htype == TYPE_oid ?
		   *(oid *) BUNhead(li, BUNfirst(l)) :
		   (l->htype == TYPE_lng ?
		    (oid) *(lng *) BUNhead(li, BUNfirst(l)) :
		    oid_nil))) :
		 oid_nil);

	ALGODEBUG fprintf(stderr, "#BATfetchjoin: 2\n");

	if (!BAThvoid(l)) {
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: !BAThvoid(l)\n");

		/* default case: no void column to propagate */
		lht = l->htype;
		rtt = r->ttype;

		if (ATOMstorage(rtt) == TYPE_str &&
		    (BATtordered(l) || r->T->vheap->free < MT_MMAP_TILE) &&
		    (!rcount || (lcount << 3) > rcount)) {
			/* insert as ints and copy/share the string heap */
			rtt = r->T->width == 1 ? TYPE_bte : (r->T->width == 2 ? TYPE_sht : (r->T->width == 4 ? TYPE_int : TYPE_lng));
		}
		bn = BATnew(BAThtype(l), ATOMtype(rtt), estimate);
		if (bn == NULL)
			goto ready;
		ESTIDEBUG THRprintf(GDKout, "#BATfetchjoin: estimated resultsize: " BUNFMT "\n", lcount);

		if ((BATtordered(l) & BATtordered(r)) || \
		    (BATtordered(l) & BATtrevordered(r)) || \
		    (BATtrevordered(l) & BATtordered(r)) || \
		    (BATtrevordered(l) & BATtrevordered(r))) {
			/* will be set correctly once we're done */
			bn->tsorted = bn->trevsorted = 0;
		} else if (ATOMstorage(r->ttype) == TYPE_str) {
			/* either: "string trick" => cannot compare on the fly
			 * or: "real string" => cannot (yet?) cope with 
			 *     heap extend or index width extend
			 */
			bn->tsorted = bn->trevsorted = 0;
			derive_tail_properties = TRUE;
		} else if (r->ttype == TYPE_void) {
			/* cannot compare on the fly */
			bn->tsorted = bn->trevsorted = 0;
			derive_tail_properties = TRUE;
		} else {
			/* start optimistic & check on the fly */
			bn->tsorted = bn->trevsorted = 1;
		}
		/* TODO: apply the "string trick" (see below) here too */
		if (BATtdense(l)) {
			/* dense => ordered, i.e., we did check the
			 * bounderies already above and we can do a
			 * "synchronized walk" through l & r */
			ALGODEBUG fprintf(stderr, "#BATfetchjoin: !BAThvoid(l) && BATtdense(l)\n");
			@:fetchjoin_switch_lht(dense)@
		} else if (BATtordered(l) || hitalways) {
			/* we did check the bounderies already above
			 * BATtordered(l) or simply "trust"
			 * hitalways */
			ALGODEBUG fprintf(stderr, "#BATfetchjoin: !BAThvoid(l) && !BATtdense(l) && ( BATtordered(l) [== %d] || hitalways [== %d] )\n", BATtordered(l), (int) hitalways);
			@:fetchjoin_switch_lht(ordered)@
		} else {
			ALGODEBUG fprintf(stderr, "#BATfetchjoin: !BAThvoid(l) && !BATtdense(l) && !BATtordered(l) && !hitalways\n");
			@:fetchjoin_switch_lht(default)@
		}
		/* handle string trick */
		if (rtt != r->ttype && ATOMstorage(r->ttype) == TYPE_str) {
			if (r->batRestricted == BAT_READ) {
				assert(r->T->vheap->parentid > 0);
				BBPshare(r->T->vheap->parentid);
				bn->T->vheap = r->T->vheap;
			} else {
				bn->T->vheap = (Heap *) GDKzalloc(sizeof(Heap));
				if (bn->T->vheap == NULL) {
					BBPreclaim(bn);
					goto ready;
				}
				bn->T->vheap->parentid = bn->batCacheid;
				if (r->T->vheap->filename) {
					char *nme = BBP_physical(bn->batCacheid);

					bn->T->vheap->filename = (str) GDKmalloc(strlen(nme) + 12);
					if (bn->T->vheap->filename == NULL) {
						BBPreclaim(bn);
						goto ready;
					}
					GDKfilepath(bn->T->vheap->filename, NULL, nme, "theap");
				}
				if (HEAPcopy(bn->T->vheap, r->T->vheap) < 0) {
					BBPreclaim(bn);
					goto ready;
				}
			}
			bn->ttype = r->ttype;
			bn->tvarsized = 1;
			bn->T->width = r->T->width;
			bn->T->shift = r->T->shift;
		}
		/* if join columns are ordered, head inherits ordering */
		bn->hsorted = BATtordered(l) & BAThordered(r) & BAThordered(l);
		bn->hrevsorted = BATtordered(l) & BAThordered(r) & BAThrevordered(l);
	} else if (!BATtvoid(l)) {
		/* propagation of void columns in the result */
		int nondense = 0;
		int tpe = r->ttype;
		BUN dst;
		void *prev = NULL, *next = NULL;
		bit bntsorted = 0, bntrevsorted = 0;
		BATiter bni;

		ALGODEBUG fprintf(stderr, "#BATfetchjoin: BAThvoid(l) && !BATtvoid(l)\n");

		if (ATOMstorage(tpe) == TYPE_str &&
		    /* GDK_ELIMDOUBLES(r->T->vheap) && */
		    (!rcount || (lcount << 3) > rcount)) {
			/* insert double-eliminated strings as ints */
			tpe = r->T->width == 1 ? TYPE_bte : (r->T->width == 2 ? TYPE_sht : (r->T->width == 4 ? TYPE_int : TYPE_lng));
		}
		bn = BATnew(TYPE_void, ATOMtype(tpe), estimate);
		if (bn == NULL)
			goto ready;
		ESTIDEBUG THRprintf(GDKout, "#BATfetchjoin: estimated resultsize: " BUNFMT "\n", lcount);

		bni = bat_iterator(bn);
		dst = BUNfirst(bn);

		if (ATOMstorage(tpe) == TYPE_bte) {
			@:voidfetchjoin(bte,loc)@
		} else if (ATOMstorage(tpe) == TYPE_sht) {
			@:voidfetchjoin(sht,loc)@
		} else if (ATOMstorage(tpe) == TYPE_int) {
			@:voidfetchjoin(int,loc)@
		} else if (ATOMstorage(tpe) == TYPE_flt) {
			@:voidfetchjoin(flt,loc)@
		} else if (ATOMstorage(tpe) == TYPE_lng) {
			@:voidfetchjoin(lng,loc)@
		} else if (ATOMstorage(tpe) == TYPE_dbl) {
			@:voidfetchjoin(dbl,loc)@
		} else if (r->tvarsized) {
			@:voidfetchjoin(VATOM,var)@
		} else {
			@:voidfetchjoin(LATOM,loc)@
		}
		BATsetcount(bn, dst);
		ret = bn;
		goto bunins_failed;
	      bunins_failed:
		if (ret == NULL) {
			BBPreclaim(bn);
			goto ready;
		}
		/* handle string trick */
		if (tpe != r->ttype && ATOMstorage(r->ttype) == TYPE_str) {
			if (r->batRestricted == BAT_READ) {
				assert(r->T->vheap->parentid > 0);
				BBPshare(r->T->vheap->parentid);
				bn->T->vheap = r->T->vheap;
			} else {
				bn->T->vheap = (Heap *) GDKzalloc(sizeof(Heap));
				if (bn->T->vheap == NULL) {
					BBPreclaim(bn);
					ret = NULL;
					goto ready;
				}
				bn->T->vheap->parentid = bn->batCacheid;
				if (r->T->vheap->filename) {
					char *nme = BBP_physical(bn->batCacheid);

					bn->T->vheap->filename = (str) GDKmalloc(strlen(nme) + 12);
					if (bn->T->vheap->filename == NULL) {
						BBPreclaim(bn);
						ret = NULL;
						goto ready;
					}
					GDKfilepath(bn->T->vheap->filename, NULL, nme, "theap");
				}
				if (HEAPcopy(bn->T->vheap, r->T->vheap) < 0) {
					BBPreclaim(bn);
					ret = NULL;
					goto ready;
				}
			}
			bn->ttype = r->ttype;
			bn->tvarsized = 1;
			bn->T->width = r->T->width;
			bn->T->shift = r->T->shift;
		}
		if (nondense) {
			/* if join columns are ordered, head inherits
			 * ordering */
			bn->hsorted = BATtordered(l) & BAThordered(r) & BAThordered(l);
			bn->hrevsorted = BATtordered(l) & BAThordered(r) & BAThrevordered(l);
		} else {
			BATseqbase(bn, seqbase);
			if (seqbase != oid_nil)
				BATkey(bn, TRUE);
			bn->hsorted = 1;
			bn->hrevsorted = BATcount(bn) <= 1;
		}
	} else if (l->tseqbase != oid_nil) {
		/* execute using slice */
		BAT *v = r;
		oid lo_val = MAX(l->tseqbase, r->hseqbase);
		oid hi_val = MIN(l->tseqbase + lcount, r->hseqbase + rcount);
		BUN lo_pos = lo_val - r->hseqbase;
		BUN hi_pos = hi_val;

		if (v->H->type != TYPE_void) /* only create view when needed */
			v = BATmirror(VIEWhead(BATmirror(r)));
		if (hi_pos > r->hseqbase)
			hi_pos -= r->hseqbase;
		else
			hi_pos = 0;
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: BAThvoid(l) && BATtvoid(l) && l->tseqbase != oid_nil  =>  bn = BATslice(BATmirror(VIEWhead(BATmirror(r))), lo_pos=" BUNFMT ", hi_pos=" BUNFMT ");\n", lo_pos, hi_pos);

		bn = BATslice(v, lo_pos, hi_pos);
		if (seqbase != oid_nil)
			seqbase += lo_val - l->tseqbase;
		BATseqbase(bn, seqbase);
		if (v != r)
			BBPunfix(v->batCacheid);
	} else {
		/* nil join column => empty result */
		ALGODEBUG fprintf(stderr, "#BATfetchjoin: BAThvoid(l) && BATtvoid(l) && l->tseqbase == oid_nil\n");

		bn = BATnew(ATOMtype(l->htype), ATOMtype(r->ttype), 10);
		if (bn == NULL)
			goto ready;
		ESTIDEBUG THRprintf(GDKout, "#BATfetchjoin: estimated resultsize: %d\n", 10);
	}
	/* property propagation */
	if (BATcount(bn) == lcount) {
		ALIGNsetH(bn, l);	/* BAThkey(r), remember? */
	} else {
		if (hitalways | hitalways_check) {
			GDKerror("BATfetchjoin(%s,%s) does not hit always (|bn|=" BUNFMT " != " BUNFMT "=|l|) => can't use fetchjoin.\n", BATgetId(l), BATgetId(r), BATcount(bn), lcount);
			BBPreclaim(bn);
			ret = NULL;
			goto ready;
		}
		bn->hsorted = (BATcount(bn) <= 1) || l->hsorted;
		bn->hrevsorted = (BATcount(bn) <= 1) || l->hrevsorted;
	}
	bn->tsorted = bn->tsorted || \
	              (BATcount(bn) <= 1) || \
	              (BATtordered(l) & BATtordered(r)) || \
	              (BATtrevordered(l) & BATtrevordered(r));
	bn->trevsorted = bn->trevsorted || \
	                 (BATcount(bn) <= 1) || \
	                 (BATtordered(l) & BATtrevordered(r)) || \
	                 (BATtrevordered(l) & BATtordered(r));
	if (BATtkey(l)) {
		/* if BATtkey(l) elements of r match at most once */
		if (BATtordered(l) && BATcount(bn) == rcount) {
			ALIGNsetT(bn, r);
		} else {
			BATkey(BATmirror(bn), BATtkey(r));
		}
	}
	bn->H->nonil = l->H->nonil;
	bn->T->nonil = r->T->nonil;

	if (derive_tail_properties) {
		/* invest in property check, since we cannot easily derive the
		 * result properties, but later operations might benefit from
		 * / depend on them
		 * Disable via command line option --debug=16777216
		 */
		JOINPROPCHK {
			if (bn) {
				BATderiveHeadProps(BATmirror(bn), 0);
			}
		}
	}
	ret = bn;
      ready:
	if (l != l_orig) {
		BBPreclaim(l);	/* was created as a temporary (slice) select on l */
	}
	ESTIDEBUG THRprintf(GDKout, "#BATfetchjoin: actual resultsize: " BUNFMT "\n", ret ? BATcount(ret) : 0);
	return ret;
}

BAT *
BATfetchjoin(BAT *l, BAT *r, BUN estimate)
{
	/* fetchjoin now implies that you assure no fetch misses (hitalways) */
	/* allows swapping of left and right input for faster processing */
	return batfetchjoin(l, r, estimate, TRUE, TRUE);
}

BAT *
BATleftfetchjoin(BAT *l, BAT *r, BUN estimate)
{
	/* fetchjoin now implies that you assure no fetch misses (hitalways) */
	/* do not swap left and right input, and hence maintain order
	 * of left head in result */
	return batfetchjoin(l, r, estimate, FALSE, TRUE);
}

/*
 * This routine does the join optimization.
 */
static BAT *
batjoin(BAT *l, BAT *r, BUN estimate, bit swap)
{
	size_t lsize, rsize, mem_size = MT_npages() * MT_pagesize() / (GDKnr_threads ? GDKnr_threads : 1);
	BUN i, lcount, rcount;
	bit lfetch, rfetch, must_hash;
	lng logr, logl;

	ERRORcheck(l == NULL, "BATjoin: invalid left operand");
	ERRORcheck(r == NULL, "BATjoin: invalid right operand");
	ERRORcheck(TYPEerror(l->ttype, r->htype), "BATjoin: type conflict\n");
	lcount = BATcount(l);
	rcount = BATcount(r);

	if (lcount == 0 || rcount == 0 ||
	    (l->ttype == TYPE_void && l->tseqbase == oid_nil) ||
	    (r->htype == TYPE_void && r->hseqbase == oid_nil)) {
		BAT *bn;

		@:return_empty_join_result(l,r, BATjoin: |l|==0 or |r|==0 or tail(l)==NIL or head(r)==NIL,0)@
	}
	if (BATtdense(l) && BAThdense(r) && l->tseqbase == r->hseqbase &&
	    lcount == rcount &&
	    l->batRestricted == BAT_READ && r->batRestricted == BAT_READ)
		return VIEWcreate(l, r);
	/*
	 * collect statistics that help us decide what to do
	 */
	lsize = lcount * (Hsize(l) + Tsize(l)) + (l->H->vheap ? l->H->vheap->size : 0) + (l->T->vheap ? l->T->vheap->size : 0) + 2 * lcount * sizeof(BUN);
	rsize = rcount * (Hsize(r) + Tsize(r)) + (r->H->vheap ? r->H->vheap->size : 0) + (r->T->vheap ? r->T->vheap->size : 0) + 2 * rcount * sizeof(BUN);
	for (logr = 4, i = rcount; i > 0; logr++)
		i >>= 1;
	for (logl = 4, i = lcount; i > 0; logl++)
		i >>= 1;

	rfetch = BAThdense(r);
	lfetch = BATtdense(l);
	/* in case of fetchjoin, make sure we propagate a non-join
	 * void column */
	if (lfetch && rfetch) {
		if (BAThvoid(l) && !BATtvoid(r))
			lfetch = 0;
		if (swap && BATtvoid(r) && !BAThvoid(l))
			rfetch = 0;
	}
	/* in case of fetchjoin, make sure we exploit sortedness for
	 * sequential access */
	if (lfetch && rfetch) {
		if (BATtordered(l) && !BAThordered(r))
			lfetch = 0;
		if (swap && BAThordered(r) && !BATtordered(l))
			rfetch = 0;
	}
	must_hash = swap && rsize > lsize ? l->T->hash == NULL : r->H->hash == NULL;
	/*
	 * Inner input out of memory => sort-merge-join performs
	 * better than hash-join or even random-access fetch-join.
	 */
	if (((swap && MIN(lsize, rsize) > mem_size) ||
	     (!swap && rsize > mem_size)) &&
	    !(BATtordered(l) & BAThordered(r))) {
		/* inner input out of memory, but not both sorted
		 * (sequential-access fetch/merge handled by special
		 * cases below) */
		if (BATtordered(l) || swap) {
			/* left tail already sorted (i.e., no re-order
			 * required) or left-order-preserving not
			 * required (i.e., re-order allowed) */
			BAT *ls, *rs, *j;

			/* if not yet sorted on tail, sort left input on tail */
			ls = BATtordered(l) ? l : BATmirror(BATsort(BATmirror(l)));
			ERRORcheck(ls == NULL, "BATjoin: BATmirror(BATsort(BATmirror(l))) failed");
			/* if not yet sorted on head, sort right input
			 * on head */
			rs = BAThordered(r) ? r : BATsort(r);
			ERRORcheck(rs == NULL, "BATjoin: BATsort(r) failed");
			if (swap && rsize > lsize) {
				/* left-order-preserving not required:
				 * user smaller input as inner
				 * (right) */
				/* (not sure, though, whether this
				 * makes a difference with merge-join
				 * ...) */
				ALGODEBUG fprintf(stderr, "#BATjoin: BATmirror(BATmergejoin(BATmirror(BATsort(r)), BATsort(BATmirror(l)), " BUNFMT "));\n", estimate);
				j = BATmirror(batmergejoin(BATmirror(rs), BATmirror(ls), estimate, swap, NULL));
				ERRORcheck(j == NULL, "BATjoin: BATmirror(batmergejoin(BATmirror(rs), BATmirror(ls), estimate, swap, NULL)) failed");
			} else {
				/* left-order-preserving required, or
				 * inner (right) input is smaller
				 * one */
				ALGODEBUG fprintf(stderr, "#BATjoin: BATmergejoin(BATmirror(BATsort(BATmirror(l))), BATsort(r), " BUNFMT "));\n", estimate);
				j = batmergejoin(ls, rs, estimate, swap, NULL);
				ERRORcheck(j == NULL, "BATjoin: batmergejoin(ls, rs, estimate, swap, NULL) failed");
			}
			if (ls != l) {
				/* release temp. tail-ordered copy of
				 * left input */
				BBPunfix(ls->batCacheid);
			}
			if (rs != r) {
				/* release temp. head-ordered copy of
				 * right input */
				BBPunfix(rs->batCacheid);
			}
			return j;
		} else
			/* as of here, left order must be preserved /
			 * restored */
		if (BAThordered(l) && l->htype < TYPE_str) {
			/* left head sorted (i.e., left order can be
			 * restored with simple (stable) sort of join
			 * result), provided the sort is fast (i.e.,
			 * not on varsized types) */
			BAT *ls, *rs, *jj, *j;

			ALGODEBUG fprintf(stderr, "#BATjoin: BAT[s]sort(BATmergejoin(BATmirror(BAT[s]sort(BATmirror(l))), BATsort(r), " BUNFMT "));\n", estimate);
			/* sort left input on tail, use stable sort to
			 * maintain original order of duplicate head
			 * values */
			ls = BAThkey(l) ? BATmirror(BATsort(BATmirror(l))) : BATmirror(BATssort(BATmirror(l)));
			ERRORcheck(ls == NULL, "BATjoin: BATmirror(BAT[s]sort(BATmirror(l))) failed");
			/* if not yet sorted on head, sort right input
			 * on head */
			rs = BAThordered(r) ? r : BATsort(r);
			ERRORcheck(rs == NULL, "BATjoin: BATsort(r) failed");
			/* perform merge join */
			jj = batmergejoin(ls, rs, estimate, swap, NULL);
			ERRORcheck(jj == NULL, "BATjoin: batmergejoin(ls, rs, estimate, swap, NULL) failed");
			/* release temp. tail-ordered copy of left input */
			BBPunfix(ls->batCacheid);
			ls = NULL;
			if (rs != r) {
				/* release temp. head-ordered copy of
				 * right input */
				BBPunfix(rs->batCacheid);
				rs = NULL;
			}
			/* sort join result on head to restore
			 * physical left-input-order; use stable sort
			 * to maintain original order of duplicate
			 * head values */
			j = BAThkey(l) ? BATsort(jj) : BATssort(jj);
			ERRORcheck(j == NULL, "BATjoin: BAT[s]sort(jj) failed");
			/* release temp. unordered join result */
			BBPunfix(jj->batCacheid);
			jj = NULL;
			return j;
		} else {
			/* - separate left head & tail using BATmark
			 * - sort left tail
			 * - sort right head
			 * - merge-join left (tail) & right (head)
			 * - sort join result on BATmark-generated
			 *   left OIDs to restore left order
			 * - re-add left head with seq. access fetchjoin
			 */
			BAT *lh, *lt, *ls, *rs, *jj, *js, *j;

			ALGODEBUG fprintf(stderr, "#BATjoin: BATmirror(batfetchjoin(BATmirror(BATsort(BATmergejoin(BATmirror(BATsort(BATmark(BATmirror(l),0))), BATsort(r), " BUNFMT "))), BATmirror(BATmark(l,0))));\n", estimate);
			/* separate left head & tail using BATmark */
			lh = BATmark(l, 0);
			ERRORcheck(lh == NULL, "BATjoin: BATmark(l,0) failed");
			lt = BATmirror(BATmark(BATmirror(l), 0));
			ERRORcheck(lt == NULL, "BATjoin: BATmirror(BATmark(BATmirror(l),0)) failed");
			/* sort left tail */
			ls = BATmirror(BATsort(BATmirror(lt)));
			ERRORcheck(ls == NULL, "BATjoin: BATmirror(BATsort(BATmirror(lt))) failed");
			/* release temp. unsorted left tail */
			BBPunfix(lt->batCacheid);
			lt = NULL;
			/* if not yet sorted on head, sort right input on head */
			rs = BAThordered(r) ? r : BATsort(r);
			ERRORcheck(rs == NULL, "BATjoin: BATsort(r) failed");
			/* perform merge join */
			jj = batmergejoin(ls, rs, estimate, swap, NULL);
			ERRORcheck(jj == NULL, "BATjoin: batmergejoin(ls, rs, estimate, swap, NULL) failed");
			/* release temp. ordered copy of left tail */
			BBPunfix(ls->batCacheid);
			ls = NULL;
			if (rs != r) {
				/* release temp. head-ordered copy of
				 * right input */
				BBPunfix(rs->batCacheid);
				rs = NULL;
			}
			/* sort join result on head to restore
			 * physical left-input-order */
			js = BATsort(jj);
			ERRORcheck(js == NULL, "BATjoin: BATsort(jj) failed");
			/* release temp. unordered join result */
			BBPunfix(jj->batCacheid);
			jj = NULL;
			/* restore original left head values */
			j = BATmirror(batfetchjoin(BATmirror(js), BATmirror(lh), BATcount(js), swap, TRUE));
			ERRORcheck(j == NULL, "BATjoin: BATmirror(batfetchjoin(BATmirror(js), BATmirror(lh), BATcount(js), swap, TRUE)) failed");
			/* release temp.sorted join result */
			BBPunfix(js->batCacheid);
			js = NULL;
			/* release temp. copy of left head */
			BBPunfix(lh->batCacheid);
			lh = NULL;
			return j;
		}
	}
	/*
	 * In special cases (equal join columns, void join columns, or
	 * ordered join columns), we take special action.
	 */
	if (swap && lfetch && !(rfetch && lcount <= rcount)) {
		ALGODEBUG fprintf(stderr, "#BATjoin: BATmirror(BATfetchjoin(BATmirror(r), BATmirror(l), " BUNFMT "));\n", estimate);

		return BATmirror(batfetchjoin(BATmirror(r), BATmirror(l), estimate, TRUE, FALSE));
	} else if (rfetch) {
		ALGODEBUG fprintf(stderr, "#BATjoin: BATfetchjoin(l, r, " BUNFMT ");\n", estimate);

		return batfetchjoin(l, r, estimate, swap, FALSE);
	}
	/*
	 * If both are ordered we do merge-join, or if hash-join is
	 * not possible right away and one input is ordered and the
	 * other is much smaller, we do nested loop binary search
	 * (both implemented by BATmergejoin).
	 */
	if ((BATtordered(l) & BAThordered(r)) ||
	    (must_hash &&
	     ((BATtordered(l) &&
	       ((lng) lcount > logl * (lng) rcount) &&
	       swap) ||
	      (BAThordered(r) &&
	       ((lng) rcount > logr * (lng) lcount))))) {
		ALGODEBUG fprintf(stderr, "#BATjoin: BATmergejoin(l,r," BUNFMT ");\n", estimate);

		return batmergejoin(l, r, estimate, swap, NULL);
	}
	/*
	 * hash join: the bread&butter join of monet
	 */
	/* Simple rule, always build hash on the smallest */
	if (swap && rsize > lsize) {
		ALGODEBUG fprintf(stderr, "#BATjoin: BATmirror(BAThashjoin(BATmirror(r), BATmirror(l)," BUNFMT "));\n", estimate);

		return BATmirror(BAThashjoin(BATmirror(r), BATmirror(l), estimate));
	}
	ALGODEBUG fprintf(stderr, "#BATjoin: BAThashjoin(l,r," BUNFMT ");\n", estimate);

	return BAThashjoin(l, r, estimate);
}

BAT *
BATjoin(BAT *l, BAT *r, BUN estimate)
{
	/* allows swapping of left and right input for faster processing */
	BAT *b = batjoin(l, r, estimate, TRUE);

	/* invest in property check, since we cannot easily derive the
	 * result properties, but later operations might benefit from
	 * / depend on them
	 * Disable via command line option --debug=16777216
	 */
	JOINPROPCHK {
		if (b) {
			BATderiveProps(b, 0);
		}
	}

	return b;
}

BAT *
BATleftjoin(BAT *l, BAT *r, BUN estimate)
{
	/* do not swap left and right input, and hence maintain order
	 * of left head in result */
	BAT *b = batjoin(l, r, estimate, FALSE);

	/* invest in property check, since we cannot easily derive the
	 * result properties, but later operations might benefit from
	 * / depend on them
	 * Disable via command line option --debug=16777216
	 */
	JOINPROPCHK {
		if (b) {
			BATderiveProps(b, 0);
		}
	}
	return b;
}

/*
 * @+  Outerjoin
 * The left outerjoin between two BAT is also supported. The code is
 * identical to the hashjoin algorithm with the extension to insert a BUN
 * if no match can be found.
 */
@= outerjoinloop
{
	ptr v, nilh = ATOMnilptr(r->htype), nilt = ATOMnilptr(r->ttype);
	BUN xx;
	BUN p, q;
	@4

	BATloop(l, p, q) {
		BUN i = 0;

		v = (ptr) BUNtail(li, p);
		if (!@1_EQ(v, nilh, @5))
			HASHloop_@2(ri, r->H->hash, xx, v) {
				@3(bn, s, BUNhead(li, p), BUNtail(ri, xx));
				i++;
			}
		if (i == 0) {
			@3(bn, s, BUNhead(li, p), nilt);
		}
	}
}
break;
@
@c
/*
 * The baseline join algorithm creates a hash on the smallest element and
 * probes it using the larger one. [TODO]
 */
BAT *
BATouterjoin(BAT *l, BAT *r, BUN estimate)
{
	BAT *bn = NULL;
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);

	@:joincheck(BATouterjoin,l->ttype,r->htype)@
	if (BAThkey(r) && (estimate == BUN_NONE || estimate < BATcount(l)))
		estimate = BATcount(l);
	if (BAThdense(l) && BAThkey(r)) {
		bn = BATnew(TYPE_void, ATOMtype(r->ttype), estimate);
		if (bn == NULL)
			return bn;
		ESTIDEBUG THRprintf(GDKout, "#BATouterjoin: estimated resultsize: " BUNFMT "\n", estimate);

		BATseqbase(bn, l->hseqbase);
	}
	if (BAThdense(r) == FALSE && BAThordered(r)) {
		/* use the merge-join; it takes care of the rest */
		ALGODEBUG fprintf(stderr, "#BATouterjoin: mergejoin(l, r, bn, ATOMnilptr(r->ttype), estimate);\n");

		bn = mergejoin(l, r, bn, ATOMnilptr(r->ttype), estimate, NULL);
		ESTIDEBUG THRprintf(GDKout, "#BATouterjoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

		/* invest in property check, since we cannot easily
		 * derive the result properties, but later operations
		 * might benefit from / depend on them
		 * Disable via command line option --debug=16777216
		 */
		JOINPROPCHK {
			if (bn)
				BATderiveProps(bn, 0);
		}

		return bn;
	} else if (bn == NULL) {
		@:joinbat(JOIN_EQ,BATouterjoin(l,r,BUN_NONE),estimate)@
	}

	/* Just to silence compilers (Intel's icc) that otherwise might
	 * complain about "declared but never referenced" labels
	 * (condition should never be true).
	 * (A "dead" goto between the return and the label makes (other)
	 * compilers (Sun) complain about never reached code...)
	 */
	if (!bn)
		goto bunins_failed;

	if (BAThdense(r)) {
		/* positional algorithm: hash on void column would
		 * give error and is stupid */
		ptr nilt = ATOMnilptr(r->ttype);
		bit nonil = TRUE;
		BUN p, q, w, s = BUNfirst(bn);

		BATloop(l, p, q) {
			oid v = *(oid *) BUNtail(li, p);
			ptr t = nilt;

			if (v != oid_nil) {
				BUNfndVOID(w, ri, &v);
				if (w != BUN_NONE)
					t = BUNtail(ri, w);
			}
			nonil &= (t != nilt);
			bunfastins_nocheck(bn, s, BUNhead(li, p), t, Hsize(bn), Tsize(bn));
			s++;
		}
		bn->tsorted = BATtordered(l) && BATtordered(r) && nonil;
		bn->trevsorted = BATcount(bn) <= 1;
	} else {
		/* hash based algorithm (default) */
		int any = ATOMstorage(r->htype);

		if (BATprepareHash(r)) {
			BBPreclaim(bn);
			return NULL;
		}
		if (BAThkey(r)) {
			@:outerjoinswitch(bunfastins_nocheck_inc, BUN s = BUNfirst(bn);)@
		} else {
			@:outerjoinswitch(bunfastins_check,)@
		}
@= outerjoinswitch
		switch (any) {
		case TYPE_bte:
			@:outerjoinloop(simple,bte,@1,@2,bte)@
		case TYPE_sht:
			@:outerjoinloop(simple,sht,@1,@2,sht)@
		case TYPE_int:
		case TYPE_flt:
			@:outerjoinloop(simple,int,@1,@2,int)@
		case TYPE_dbl:
		case TYPE_lng:
			@:outerjoinloop(simple,lng,@1,@2,lng)@
		case TYPE_str:
			if (l->T->vheap->hashash) {
				@:outerjoinloop(atom,str_hv,@1,@2,any)@
			}
			/* fall through */
		default:
			@:outerjoinloop(atom,any,@1,@2,any)@
		}
@
@c
		bn->tsorted = BATcount(bn) <= 1;
		bn->trevsorted = BATcount(bn) <= 1;
	}
	/* set sorted flags by hand, because we used BUNfastins() */
	if (r->hkey) {
		ALIGNsetH(bn, l);	/* always 1 hit, so columns are equal */
	} else {
		bn->hsorted = BAThordered(l);
		bn->hrevsorted = BAThrevordered(l);
	}
	bn->H->nonil = l->H->nonil;
	bn->T->nonil = FALSE;
	ESTIDEBUG THRprintf(GDKout, "#BATouterjoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

	/* invest in property check, since we cannot easily derive the
	 * result properties, but later operations might benefit from
	 * / depend on them
	 * Disable via command line option --debug=16777216
	 */
	JOINPROPCHK {
		if (bn)
			BATderiveHeadProps(bn, 0);
	}

	return bn;

      bunins_failed:
	BBPreclaim(bn);
	return NULL;
}

/*
 * @+ ThetaJoin
 * Current predicates supported are: JOIN_EQ, JOIN_LT,
 * JOIN_GE, JOIN_LE and JOIN_GT. The JOIN_EQ will pass the control to the
 * normal BATjoin equijoin. The is and index-based join: if an index
 * is not present, it will be created on the smallest relation.
 *
 * We do lots of code-inlining: first of all on join type (4), and
 * furthermore on left-tail (equal right-head) type (5), which are the
 * join columns.  We factor out more by splitting on storage strategy
 * (variable-sized/fixed-size) of both the left-head, and right tail
 * columns (2*2).
 *
 * In the end, this results in 4*5*2*2 = 80 different inner loops.
 */
BAT *
BATthetajoin(BAT *l, BAT *r, int op, BUN estimate)
{
	BUN _lcount = BATcount(l);
	BUN _rcount = BATcount(r);
	BUN _estimate = (BUN) MIN((lng) _lcount * _rcount, BUN_MAX);

	assert(_estimate <= BUN_MAX);
	@:joincheck(BATthetajoin,l->ttype,r->htype)@
	if (estimate < _estimate)
		_estimate = estimate;
	if (op == JOIN_EQ) {
		/* exploit all equi-join optimizations */
		ALGODEBUG fprintf(stderr, "#BATthetajoin(l,r,JOIN_EQ): BATjoin(l, r);\n");

		return BATjoin(l, r, _estimate);
	}
	return BATnlthetajoin(l, r, op, _estimate);
}

/* nested loop join; finally MonetDB can enjoy the virtues of this
 * algorithm as well! */
@= nlthetajoin_unroll8
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
	@:nlthetajoin_@2(@1)@
	ri++;
@= nlthetajoin_void
	{
		tdst[cur] = off++;
		cur += v @1 ra[ri];
	}
@= nlthetajoin_oid
	{
		tdst[cur] = rt[ri];
		cur += v @1 ra[ri];
	}
@= nlthetajoin_impl
static int
nlthetajoin_@2_@1(BAT *bn, BAT *l, BAT *r)
{
	BATiter lbi = bat_iterator(l);
	BATiter rbi = bat_iterator(r);
	oid *hdst = (oid *) Hloc(bn, BUNfirst(bn)), *tdst = (oid *) Tloc(bn, BUNfirst(bn));
	BUN cur = BUNfirst(bn);
	BUN lim = BATcapacity(bn);
	BUN li = BUNfirst(l), lhi = BUNlast(l);
	BUN ri = BUNfirst(r), rhi = MAX(ri + 8, BUNlast(r)) - 8;
	@1 *la = (@1 *) BUNtloc(lbi, li);
	@1 *ra = (@1 *) BUNhloc(rbi, ri);
	oid *rt = (oid *) (r->ttype == TYPE_void ? 0 : BUNtloc(rbi, ri));

	for (ri = li = 0; li < lhi; li++, ri = 0) {
		oid off = r->ttype == TYPE_void ? r->tseqbase : 0;
		BUN len = cur;
		@1 v = la[li];
		oid o;

		if (v == @1_nil)
			continue;

		/* unroll 8 times, factor out cur->l and memory
		 * re-allocation checking */
		while (1) {
			if (cur + 8 >= lim) {
				BATsetcount(bn, cur);
				if (BATextend(bn, 8 + (BUN) (BATcount(bn) * (((dbl) lhi) / (li + 1)))) == NULL)
					return 1;
				lim = BATcapacity(bn);
				hdst = (oid *) Hloc(bn, BUNfirst(bn));
				tdst = (oid *) Tloc(bn, BUNfirst(bn));
			}
			if (ri >= rhi)
				break;
			if (r->ttype == TYPE_void) {
				@:nlthetajoin_unroll8(@3,void)@
			} else {
				@:nlthetajoin_unroll8(@3,oid)@
			}
		}
		/* do rest in more expensive loop */
		if (r->ttype == TYPE_void) {
			BUN cnt = BATcount(r);

			for (; ri < cnt; ri++)
				@:nlthetajoin_void(@3)@
		} else {
			BUN cnt = BATcount(r);

			for (; ri < cnt; ri++)
				@:nlthetajoin_oid(@3)@
		}

		/* fill in the left oids for the generated result tuples */
 		o = * (oid *) BUNhead(lbi, li);
		while (len < cur)
			hdst[len++] = o;
	}
	BATsetcount(bn, cur);
	return 0;
}
@= nlthetajoin_call
	case TYPE_@1:
		if (nlthetajoin_@2_@1(bn, l, r))
			goto bunins_failed;
		break;
@= nlthetajoin_tpe
	@:nlthetajoin_@1(bte,@2,@3)@
	@:nlthetajoin_@1(sht,@2,@3)@
	@:nlthetajoin_@1(int,@2,@3)@
	@:nlthetajoin_@1(lng,@2,@3)@
	@:nlthetajoin_@1(flt,@2,@3)@
	@:nlthetajoin_@1(dbl,@2,@3)@
@
@c
@:nlthetajoin_tpe(impl,gt,>)@
@:nlthetajoin_tpe(impl,ge,>=)@
@:nlthetajoin_tpe(impl,lt,<)@
@:nlthetajoin_tpe(impl,le,<=)@
@:nlthetajoin_tpe(impl,eq,==)@
static BAT *
BATnlthetajoin(BAT *l, BAT *r, int op, BUN estimate)
{
	int optimize = (l->htype == TYPE_oid || BAThdense(l)) && (r->ttype == TYPE_oid || BATtdense(r))
	    /* the follwoing might be trivial cases, but the
	     * "optimized" nlthetajoin implementation cannot handle
	     * them, yet ... */
	    && l->ttype != TYPE_void && r->htype != TYPE_void;
	BAT *bn = BATnew(ATOMtype(l->htype), ATOMtype(r->ttype), estimate >= BUN_MAX - 128 ? BUN_MAX : estimate + 128);
	int lo = 0, hi = 0;

	if (bn == NULL)
		return NULL;

	if (op == JOIN_GT) {
		lo = 1;
		hi = GDK_int_max;
		if (optimize)
			switch (ATOMstorage(l->ttype)) {
				@:nlthetajoin_tpe(call,gt)@
			default:
				optimize = 0;
			}
	} else if (op == JOIN_GE) {
		lo = 0;
		hi = GDK_int_max;
		if (optimize)
			switch (ATOMstorage(l->ttype)) {
				@:nlthetajoin_tpe(call,ge)@
			default:
				optimize = 0;
			}
	} else if (op == JOIN_LT) {
		lo = GDK_int_min;
		hi = -1;
		if (optimize)
			switch (ATOMstorage(l->ttype)) {
				@:nlthetajoin_tpe(call,lt)@
			default:
				optimize = 0;
			}
	} else if (op == JOIN_LE) {
		lo = GDK_int_min;
		hi = 0;
		if (optimize)
			switch (ATOMstorage(l->ttype)) {
				@:nlthetajoin_tpe(call,le)@
			default:
				optimize = 0;
			}
	} else if (op == JOIN_EQ) {
		if (optimize)
			switch (ATOMstorage(l->ttype)) {
				@:nlthetajoin_tpe(call,eq)@
			default:
				optimize = 0;
			}

	}
	if (!optimize) {
		BATiter li = bat_iterator(l);
		BATiter ri = bat_iterator(r);
		int (*cmp) (const void *, const void *) = BATatoms[l->ttype].atomCmp;
		ptr nil = ATOMnilptr(l->ttype);
		BUN rp, rq, lp, lq;

		BATloop(l, lp, lq) {
			ptr v = (ptr) BUNtail(li, lp);

			if ((*cmp) (v, nil) == 0) {
				continue;
			}
			BATloop(r, rp, rq) {
				ptr w = (ptr) BUNhead(ri, rp);
				int c = (*cmp) (v, w);

				if ((c >= lo) & (c <= hi)) {
					bunfastins(bn, BUNhead(li, lp), BUNtail(ri, rp));
				}
			}
		}
	}
	bn->hsorted = l->hsorted || BATcount(bn) <= 1;
	bn->hrevsorted = l->hrevsorted || BATcount(bn) <= 1;
	bn->tsorted = BATcount(bn) <= 1;
	bn->trevsorted = BATcount(bn) <= 1;
	bn->H->nonil = l->H->nonil;
	bn->T->nonil = r->T->nonil;
	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;
}


/*
 * @+ Semijoin
 *
 * The BATsemijoin performs a semijoin over l and r. It returns
 * a subset of l that matches at least one element in r.
 * The result inherits the integrity properties.
 *
 * Various algorithms exist. The main one BATkintersect() resides
 * outside this file, in the set-operations implementation (gdk_setop).
 * Other variants for the semijoin include the fetch-semijoin
 * (for dense join columns), the reverse semijoin that loops over r
 * instead of l, and semijoin using binary search in r.
 */
#define semijoinbat(b, hs, ts, func)					\
	do {								\
		bn = BATnew(BAThtype(b), BATttype(b),			\
			    MAX(BATTINY, MIN(BATcount(l), BATcount(r)))); \
		ESTIDEBUG THRprintf(GDKout, "#%s.semijoinbat: estimated resultsize: " BUNFMT "\n", func, MAX(BATTINY, MIN(BATcount(l), BATcount(r)))); \
		if (bn == NULL)						\
			return bn;					\
		BATkey(bn, BAThkey(b));					\
		BATkey(BATmirror(bn), BATtkey(b));			\
		bn->hsorted = hs;					\
		bn->tsorted = ts;					\
	} while (0)
@
/*
 * In the sorted cases with a low semijoin hit-rate, we do lookup
 * using probe-based binary search, instead of a full merge scan.
 * Normal merge-semijoin with a full scan on both is handled by
 * kintersect (default exit) if both relations are large or if their
 * sizes do not differ significantly.
 */
@= binsemijoin
{
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	BUN lp, lq;
	ptr nil = ATOMnilptr(l->htype);

	if (cpy == l) {
		BATloop(l, lp, lq) {
			ptr v = BUNh@1(li, lp);

			if (!@3_EQ(v, nil, @2) && SORTfnd(r, v) != BUN_NONE) {
				bunfastins(bn, v, BUNtail(li, lp));
			}
		}
	} else {
		BATloop(l, lp, lq) {
			BUN rp, rq;
			ptr v = BUNh@1(li, lp);

			if (!@3_EQ(v, nil, @2)) {
				SORTloop_@2(BATmirror(r), rp, rq, v, v) {
					bunfastins(bn, v, BUNtail(ri, rp));
				}
			}
		}
	}
}
break;
@
@c
static BAT *
BATbinsemijoin(BAT *l, BAT *r, BAT *cpy)
{
	BAT *bn, *del = NULL;
	int loc, var;

	@:joincheck(BATbinsemijoin,l->htype,r->htype)@
	semijoinbat(cpy, TRUE, l == cpy && BATtordered(l), "BATbinsemijoin");

	if (!BAThordered(r)) {
		del = r = BATsort(r);
		if (del == NULL)
			goto bunins_failed;
	}

	switch (loc = var = ATOMstorage(l->htype)) {
	case TYPE_bte:
		@:binsemijoin(loc,bte,simple)@
	case TYPE_sht:
		@:binsemijoin(loc,sht,simple)@
	case TYPE_int:
		@:binsemijoin(loc,int,simple)@
	case TYPE_flt:
		@:binsemijoin(loc,flt,simple)@
	case TYPE_dbl:
		@:binsemijoin(loc,dbl,simple)@
	case TYPE_lng:
		@:binsemijoin(loc,lng,simple)@
	default:
		if (l->hvarsized) {
			if (r->hvarsized) {
				@:binsemijoin(var,var,atom)@
			} else {
				@:binsemijoin(var,loc,atom)@
			}
		} else {
			if (r->hvarsized) {
				@:binsemijoin(loc,var,atom)@
			} else {
				@:binsemijoin(loc,loc,atom)@
			}
		}
	}

	/* propagate properties */
	bn->hsorted = l->hsorted || BATcount(bn) <= 1;
	bn->hrevsorted = l->hrevsorted || BATcount(bn) <= 1;
	bn->tsorted = BATcount(bn) <= 1;
	bn->trevsorted = BATcount(bn) <= 1;
	if (BATcount(bn) == BATcount(l)) {
		if (l == cpy) {
			ALIGNset(bn, l);
		} else if (BAThkey(l) && BAThkey(r)) {
			ALIGNsetH(bn, l);
		}
	}
	bn->H->nonil = l->H->nonil & r->H->nonil;
	bn->T->nonil = l->T->nonil;
	if (del)
		BBPreclaim(del);
	ESTIDEBUG THRprintf(GDKout, "#BATbinsemijoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;
}

/*
 * The reverse semijoin is only better if the other side (r) is much
 * smaller than l, and iff you already have the hash table on l. It
 * uses hash tables on both relations: on r to check that no item is
 * processed twice (not necessary to check iff BAThkey(r) and one on l
 * to find the matching tuples.
 */
@= revsemijoin
{
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	BUN yy;
	BUN rp = 0, rq = 0;
	ptr nil = ATOMnilptr(l->htype);
	ptr v;

	if (merge) {
		ALGODEBUG fprintf(stderr, "#BATrevsemijoin: merge\n");
		BATloop(r, rp, rq) {
			v = BUN@3(ri, rp);

			yy = rp+1;
			if (yy < rq && @1_EQ(v, BUN@3(ri, yy), @4))
				continue;
			if (!@1_EQ(v, nil, @4)) {
				HASHloop_@2(li, l->H->hash, yy, v)
					bunfastins(bn, v, BUNtail(li, yy));
			}
		}
	} else if (rdoubles) {
		ALGODEBUG fprintf(stderr, "#BATrevsemijoin: rdoubles\n");
		BATloop(r, rp, rq) {
			v = BUN@3(ri, rp);

			HASHloop_@2(ri, r->H->hash, yy, v)
				break;
			if (yy != rp)
				continue;
			if (!@1_EQ(v, nil, @4)) {
				HASHloop_@2(li, l->H->hash, yy, v)
					bunfastins(bn, v, BUNtail(li, yy));
			}
		}
	} else {
		BATloop(r, rp, rq) {
			v = BUN@3(ri, rp);
			if (!@1_EQ(v, nil, @4)) {
				HASHloop_@2(li, l->H->hash, yy, v)
					bunfastins(bn, v, BUNtail(li, yy));
			}
		}
	}
}
break;
@
@c
static BAT *
BATrevsemijoin(BAT *l, BAT *r)
{
	int any, rdoubles = (BAThkey(r) == 0), merge = rdoubles & BAThordered(r);
	BAT *bn;

	@:joincheck(BATrevsemijoin,l->htype,r->htype)@
	semijoinbat(l, FALSE, FALSE, "BATrevsemijoin");
	if (BATprepareHash(l))
		goto bunins_failed;
	if (rdoubles && BATprepareHash(r))
		goto bunins_failed;

	switch (any = ATOMstorage(l->htype)) {
	case TYPE_bte:
		@:revsemijoin(simple,bte,hloc,bte)@
	case TYPE_sht:
		@:revsemijoin(simple,sht,hloc,sht)@
	case TYPE_int:
	case TYPE_flt:
		@:revsemijoin(simple,int,hloc,int)@
	case TYPE_dbl:
	case TYPE_lng:
		@:revsemijoin(simple,lng,hloc,lng)@
	case TYPE_str:
		if (r->H->vheap->hashash) {
			@:revsemijoin(atom,str_hv,head,any)@
		}
		/* fall through */
	default:
		@:revsemijoin(atom,any,head,any)@
	}
	/* propagate properties */
	bn->hsorted = bn->hrevsorted = BATcount(bn) <= 1;
	bn->tsorted = bn->trevsorted = BATcount(bn) <= 1;
	if (BAThkey(r) && BATtkey(l) && BATcount(bn) == BATcount(r)) {
		ALIGNsetH(bn, r);
	}
	bn->H->nonil = l->H->nonil & r->H->nonil;
	bn->T->nonil = l->T->nonil;
	ESTIDEBUG THRprintf(GDKout, "#BATrevsemijoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;
}

/*
 * The positional semijoin performs a semijoin using positional
 * lookup.  This implementation is dirty as it also allows fetches
 * with hard integer positions, rather than oid matching on a
 * dense-oid column.
 */
static BAT *
BATfetchsemijoin(BAT *l, BAT *r, BAT *cpy, int denselookup)
{
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	BUN base, end, yy;
	ssize_t offset;
	BUN l_cur, l_end, r_cur;
	BAT *bn;

	BATcheck(l, "BATfetchsemijoin: left BAT required");
	BATcheck(r, "BATfetchsemijoin: right BAT required");

	if (denselookup) {
		if (!BAThdense(r)) {
			GDKerror("BATfetchsemijoin: left column must be dense.\n");
			return NULL;
		} else if (BATcount(l) && ATOMstorage(l->htype) != ATOMstorage(TYPE_oid)) {
			GDKerror("BATfetchsemijoin: illegal index type %s.\n", ATOMname(l->htype));
			return NULL;
		}
	}
	if (BATcount(l) && BAThvoid(l)) {
		/* redirect semijoin on two dense regions to a select
		 * (and hence to BATslice) */
		oid min = l->hseqbase, max = min;

		if (min != oid_nil)
			max += BATcount(l);
		if (denselookup) {
			min -= r->hseqbase;
			max -= r->hseqbase;
		}
		return BATslice(cpy, min, max);
	}
	base = BUNfirst(r);
	end = base + BATcount(r);
	bn = BATnew(BAThtype(cpy), BATttype(cpy), MIN(BATcount(r), BATcount(l)));
	if (bn == NULL)
		return bn;
	ESTIDEBUG THRprintf(GDKout, "#BATfetchsemijoin: estimated resultsize: " BUNFMT "\n", MIN(BATcount(r), BATcount(l)));

	if (bn == NULL) {
		return NULL;
	}
	if (denselookup) {
		offset = (ssize_t) base - (ssize_t) r->hseqbase;	/* translate oid to BUN position */
	} else {
		offset = (ssize_t) base;	/* fetch by hard BUNindex */
	}

	/* iterate l; positional fetch in r */
	BATloop(l, l_cur, l_end) {
		yy = (BUN) (offset + *(oid *) BUNhloc(li, l_cur));
		if (yy < base || yy >= end) {
			continue;
		}
		r_cur = yy;
		if (cpy == r) {
			bunfastins(bn, BUNhead(ri, r_cur), BUNtail(ri, r_cur));
		} else {
			bunfastins(bn, BUNhead(ri, r_cur), BUNtail(li, l_cur));
		}
	}

	/* property propagation */
	bn->hsorted = BATcount(bn) <= 1 ||
		BAThordered(l) & BAThordered(r) ||
		BAThrevordered(l) & BAThrevordered(r);
	bn->hrevsorted = BATcount(bn) <= 1 ||
		BAThordered(l) & BAThrevordered(r) ||
		BAThrevordered(l) & BAThordered(r);
	if (cpy == r) {
		bn->tsorted = BATcount(bn) <= 1 ||
			BAThordered(l) & BATtordered(r) ||
			BAThrevordered(l) & BATtrevordered(r);
		bn->trevsorted = BATcount(bn) <= 1 ||
			BAThordered(l) & BATtrevordered(r) ||
			BAThrevordered(l) & BATtordered(r);
	} else {
		bn->tsorted = BATcount(bn) <= 1 || BATtordered(l);
		bn->trevsorted = BATcount(bn) <= 1 || BATtrevordered(l);
	}
	bn->H->nonil = l->H->nonil & r->H->nonil;
	bn->T->nonil = cpy->T->nonil;

	if (denselookup && BATcount(bn) == BATcount(l)) {
		ALIGNsetH(bn, l);
	} else {
		BATkey(bn, BAThkey(l) && BAThkey(r));
	}
	if (BAThkey(l)) {
		if (BATcount(bn) == BATcount(cpy) && (BAThordered(r) & BAThordered(l))) {
			ALIGNsetT(bn, cpy);
		} else {
			BATkey(BATmirror(bn), BATtkey(cpy));
		}
	}
	ESTIDEBUG THRprintf(GDKout, "#BATfetchsemijoin: actual resultsize: " BUNFMT "\n", BATcount(bn));

	return bn;
      bunins_failed:
	BBPreclaim(bn);
	return NULL;
}

BAT *
BATfetch(BAT *l, BAT *r)
{
	return BATfetchsemijoin(r, l, l, FALSE);
}

/*
 * The BATsemijoin chooses between various alternatives.
 */

BAT *
BATsemijoin(BAT *l, BAT *r)
{
	int reverse1, reverse2;
	BUN countr, countl, i;
	lng logr, logl;
	BAT *bn, *tmp = NULL;

	ERRORcheck(l == NULL, "BATsemijoin");
	ERRORcheck(r == NULL, "BATsemijoin");
	ERRORcheck(TYPEerror(l->htype, r->htype), "BATsemijoin: type conflict\n");

	/*
	 * @- algorithm selection
	 * We have 10 algorithms implementing semijoin. Their
	 * conditions are checked in order of efficiency. Some
	 * algorithms reverse the semijoin (loop over r, lookup in l).
	 * To do that r should be unique. To that end, doubles may
	 * sometimes be eliminated from r.
	 */
	for (logr = 4, i = countr = BATcount(r); i > 0; logr++)
		i >>= 1;
	for (logl = 4, i = countl = BATcount(l); i > 0; logl++)
		i >>= 1;
	reverse1 = countr < countl && (BAThkey(r) || (lng) countr * 8 < (lng) countl);
	reverse2 = (lng) countr *logl < (lng) countl && (BAThkey(r)
							 || (lng) countr * (logl + 8) < (lng) countl);

	if (ALIGNsynced(l, r)) {
		ALGODEBUG fprintf(stderr, "#BATsemijoin: BATcopy(l);\n");

		bn = BATcopy(l, l->htype, l->ttype, FALSE);
	} else if (BAThordered(l) && BAThdense(r)) {
		oid lo = r->hseqbase;
		oid hi = r->hseqbase + countr - 1;
		ALGODEBUG fprintf(stderr, "#BATsemijoin: BATmirror(BATselect(BATmirror(l), &lo, &hi));\n");

		bn = BATmirror(BATselect(BATmirror(l), &lo, &hi));
	} else if (BAThdense(r)) {
		ALGODEBUG fprintf(stderr, "#BATsemijoin: BATfetchsemijoin(l, r, l);\n");

		bn = BATfetchsemijoin(l, r, l, TRUE);
	} else if (BAThdense(l) && reverse1) {
		if (!BAThkey(r)) {
			BAT *v = VIEWhead_(r, BAT_WRITE);

			tmp = r = BATkunique(v);
			BBPreclaim(v);
		}
		ALGODEBUG fprintf(stderr, "#BATsemijoin: BATfetchsemijoin(r, l, l);\n");

		bn = BATfetchsemijoin(r, l, l, TRUE);
	} else if (l->H->hash && reverse1) {
		ALGODEBUG fprintf(stderr, "#BATsemijoin: BATrevsemijoin(l,r);\n");

		bn = BATrevsemijoin(l, r);
	} else if (BAThordered(r) && countl * logr < countr) {
		ALGODEBUG fprintf(stderr, "#BATsemijoin: BATbinsemijoin(l, r, l);\n");

		bn = BATbinsemijoin(l, r, l);
	} else if (BAThordered(l) & reverse2) {
		if (!BAThkey(r)) {
			BAT *v = VIEWhead_(r, BAT_WRITE);

			tmp = r = BATkunique(v);
			BBPreclaim(v);
		}
		ALGODEBUG fprintf(stderr, "#BATsemijoin: BATbinsemijoin(r, l, l);\n");

		bn = BATbinsemijoin(r, l, l);
	} else {
		ALGODEBUG fprintf(stderr, "#BATsemijoin: BATkintersect(l, r);\n");

		bn = BATkintersect(l, r);	/* merge-semijoin or nested hashlookup in r */
	}
	if (tmp) {
		BBPreclaim(tmp);
	}
	/* invest in property check, since we cannot easily derive the
	 * result properties, but later operations might benefit from
	 * / depend on them
	 * Disable via command line option --debug=16777216
	 */
	JOINPROPCHK {
		if (bn)
			BATderiveHeadProps(BATmirror(bn), 0);
	}
	return bn;
}

/*
 * @+ AntiJoin
 * This operation computes the cross product of two BATs, returning only the
 * head-value from the 'left' operand and then tail-value from the 'right'
 * provided the tail-head pair do not (!) match.
 */
@= antijoin2
static BAT *
antijoin_@1_@2(BAT *bn, BAT *l, BAT *r)
{
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	BATiter bni;
	BUN l_cur, l_end, r_cur, r_end, dst;
	int (*cmp) (const void *, const void *) = BATatoms[l->ttype].atomCmp;
	ptr nil = ATOMnilptr(l->ttype);

	/* Just to silence compilers (Intel's icc) that otherwise might
	 * complain about "declared but never referenced" labels
	 * (condition should never be true).
	 * (A "dead" goto between the return and the label makes (other)
	 * compilers (Sun) complain about never reached code...)
	 */
	if (!bn)
		goto bunins_failed;

	bni = bat_iterator(bn);
	dst = BUNfirst(bn);
	ALGODEBUG fprintf(stderr, "#BATantijoin: antijoin_@1_@2();\n");
	BATloop(l, l_cur, l_end) {
		ptr v = (ptr) BUNtail(li, l_cur);
		BATloop(r, r_cur, r_end) {
			ptr w = (ptr) BUNhead(ri, r_cur);
			int c = (*cmp)(v, w);
			if ((*cmp)(v, nil) != 0 && (*cmp)(w, nil) != 0 && c != 0 ) {
				@:bunfastins_nocheck_(@1,@2)@
				dst++;
			}
		}
	}
	BATsetcount(bn, dst);

	return bn;

bunins_failed:
	BBPreclaim(bn);
	return NULL;
}
@= antijoin1
	@:antijoin2(@1,bte)@
	@:antijoin2(@1,sht)@
	@:antijoin2(@1,int)@
	@:antijoin2(@1,lng)@
	@:antijoin2(@1,VATOM)@
	@:antijoin2(@1,LATOM)@
@
@c
@:antijoin1(bte)@
@:antijoin1(sht)@
@:antijoin1(int)@
@:antijoin1(lng)@

@:antijoin1(VATOM)@
@:antijoin1(LATOM)@

@= antijoin_switch_rtt
{
	int rtt = r->ttype;
	int rts = ATOMstorage(rtt);

	if (rts == TYPE_bte) {
		bn = antijoin_@1_bte(bn, l, r);
	} else if (rts == TYPE_sht) {
		bn = antijoin_@1_sht(bn, l, r);
	} else if (rts == TYPE_int || rts == TYPE_flt
#if SIZEOF_OID == SIZEOF_INT
		   || rts == TYPE_oid
#endif
		) {
		bn = antijoin_@1_int(bn, l, r);
	} else if (rts == TYPE_lng || rts == TYPE_dbl
#if SIZEOF_OID == SIZEOF_LNG
		   || ATOMstorage(lht) == TYPE_oid
#endif
) {
		bn = antijoin_@1_lng(bn, l, r);
	} else if (r->tvarsized) {
		bn = antijoin_@1_VATOM(bn, l, r);
	} else {
		bn = antijoin_@1_LATOM(bn, l, r);
	}
}
@
@c
@= antijoin_switch_lht
{
	int lht = l->htype;
	int lhs = ATOMstorage(lht);

	if (lhs == TYPE_bte) {
		@:antijoin_switch_rtt(bte)@
	} else if (lhs == TYPE_sht) {
		@:antijoin_switch_rtt(sht)@
	} else if (lhs == TYPE_int || lhs == TYPE_flt
#if SIZEOF_OID == SIZEOF_INT
		   || lhs == TYPE_oid
#endif
		) {
		@:antijoin_switch_rtt(int)@
	} else if (lhs == TYPE_lng || lhs == TYPE_dbl
#if SIZEOF_OID == SIZEOF_LNG
		   || lhs == TYPE_oid
#endif
		   ) {
		@:antijoin_switch_rtt(lng)@
	} else if (l->hvarsized) {
		@:antijoin_switch_rtt(VATOM)@
	} else {
		@:antijoin_switch_rtt(LATOM)@
	}
}
@
@c
BAT *
BATantijoin(BAT *l, BAT *r)
{
	BAT *bn;
	BUN lc, rc, sz;

	ERRORcheck(l == NULL, "BATantijoin: invalid left operand");
	ERRORcheck(r == NULL, "BATantijoin: invalid right operand");
	lc = BATcount(l);
	rc = BATcount(r);
	sz = (BUN) MIN((lng) lc * rc, BUN_MAX);

	assert(sz <= BUN_MAX);
	if (sz > 0) {
		BATiter li = bat_iterator(l);
		BATiter ri = bat_iterator(r);

		if (rc == 1) {
			l = BATantiuselect_(l, BUNhead(ri, BUNfirst(r)), NULL, 1, 1);
			bn = BATconst(l, BATttype(r), BUNtail(ri, BUNfirst(r)));
			BBPunfix(l->batCacheid);
			return bn;
		}
		if (lc == 1) {
			r = BATantiuselect_(BATmirror(r), BUNtail(li, BUNfirst(l)), NULL, 1, 1);
			bn = BATmirror(BATconst(r, BAThtype(l), BUNhead(li, BUNfirst(l))));
			BBPunfix(r->batCacheid);
			return bn;
		}
	}

	bn = BATnew(BAThtype(l), BATttype(r), sz);
	if (bn == NULL)
		return bn;
	if (sz == 0)
		return bn;

	@:antijoin_switch_lht@

	if (bn) {
		bn->hsorted = l->hsorted || BATcount(bn) <= 1;
		bn->hrevsorted = l->hrevsorted || BATcount(bn) <= 1;
		bn->tsorted = (lc == 1 && r->tsorted) || BATcount(bn) <= 1;
		bn->trevsorted = (lc == 1 && r->trevsorted) || BATcount(bn) <= 1;
		bn->hdense = rc == 1 && l->hdense;
		bn->tdense = lc == 1 && r->tdense;
		BATkey(bn, rc == 1 && BAThkey(l));
		BATkey(BATmirror(bn), lc == 1 && BATtkey(r));
		bn->H->nonil = l->H->nonil;
		bn->T->nonil = r->T->nonil;
		if (!bn->batDirty)
			bn->batDirty = TRUE;
	}

	return bn;
}

/*
 * @+ Cross Product
 * This operation computes the cross product of two BATs, returning only the
 * head-value from the 'left' operand and then tail-value from the 'right'
 * operand.
 */
@= cross2
static BAT *
cross_@1_@2(BAT *bn, BAT *l, BAT *r)
{
	BATiter li = bat_iterator(l);
	BATiter ri = bat_iterator(r);
	BATiter bni;
	BUN l_cur, l_end, r_cur, r_end, dst;

	/* Just to silence compilers (Intel's icc) that otherwise might
	 * complain about "declared but never referenced" labels
	 * (condition should never be true).
	 * (A "dead" goto between the return and the label makes (other)
	 * compilers (Sun) complain about never reached code...)
	 */
	if (!bn)
		goto bunins_failed;

	bni = bat_iterator(bn);
	dst = BUNfirst(bn);
	ALGODEBUG fprintf(stderr, "#BATcross: cross_@1_@2();\n");
	BATloop(l, l_cur, l_end) {
		BATloop(r, r_cur, r_end) {
			@:bunfastins_nocheck_(@1,@2)@
			dst++;
		}
	}
	BATsetcount(bn, dst);

	return bn;

bunins_failed:
	BBPreclaim(bn);
	return NULL;
}
@= cross1
	@:cross2(@1,bte)@
	@:cross2(@1,sht)@
	@:cross2(@1,int)@
	@:cross2(@1,lng)@
	@:cross2(@1,VATOM)@
	@:cross2(@1,LATOM)@
@
@c
@:cross1(bte)@
@:cross1(sht)@
@:cross1(int)@
@:cross1(lng)@

@:cross1(VATOM)@
@:cross1(LATOM)@

@= cross_switch_rtt
{
	int rtt = r->ttype;
	int rts = ATOMstorage(rtt);

	if (rts == TYPE_bte) {
		bn = cross_@1_bte(bn, l, r);
	} else if (rts == TYPE_sht) {
		bn = cross_@1_sht(bn, l, r);
	} else if (rts == TYPE_int || rts == TYPE_flt
#if SIZEOF_OID == SIZEOF_INT
		   || rts == TYPE_oid
#endif
		) {
		bn = cross_@1_int(bn, l, r);
	} else if (rts == TYPE_lng || rts == TYPE_dbl
#if SIZEOF_OID == SIZEOF_LNG
		   || ATOMstorage(lht) == TYPE_oid
#endif
) {
		bn = cross_@1_lng(bn, l, r);
	} else if (r->tvarsized) {
		bn = cross_@1_VATOM(bn, l, r);
	} else {
		bn = cross_@1_LATOM(bn, l, r);
	}
}
@
@c
@= cross_switch_lht
{
	int lht = l->htype;
	int lhs = ATOMstorage(lht);

	if (lhs == TYPE_bte) {
		@:cross_switch_rtt(bte)@
	} else if (lhs == TYPE_sht) {
		@:cross_switch_rtt(sht)@
	} else if (lhs == TYPE_int || lhs == TYPE_flt
#if SIZEOF_OID == SIZEOF_INT
		   || lhs == TYPE_oid
#endif
		) {
		@:cross_switch_rtt(int)@
	} else if (lhs == TYPE_lng || lhs == TYPE_dbl
#if SIZEOF_OID == SIZEOF_LNG
		   || lhs == TYPE_oid
#endif
		   ) {
		@:cross_switch_rtt(lng)@
	} else if (l->hvarsized) {
		@:cross_switch_rtt(VATOM)@
	} else {
		@:cross_switch_rtt(LATOM)@
	}
}
@
@c
BAT *
BATcross(BAT *l, BAT *r)
{
	BAT *bn;
	BUN lc, rc, sz;

	ERRORcheck(l == NULL, "BATcross: invalid left operand");
	ERRORcheck(r == NULL, "BATcross: invalid right operand");
	lc = BATcount(l);
	rc = BATcount(r);
	sz = (BUN) MIN((lng) lc * rc, BUN_MAX);
	assert(sz <= BUN_MAX);

	if (sz > 0) {
		BATiter li = bat_iterator(l);
		BATiter ri = bat_iterator(r);

		/* try to keep void columns where possible */
		if (rc == 1)
			return BATconst(l, BATttype(r), BUNtail(ri, BUNfirst(r)));
		if (lc == 1)
			return BATmirror(BATconst(BATmirror(r), BAThtype(l), BUNhead(li, BUNfirst(l))));
	}

	bn = BATnew(BAThtype(l), BATttype(r), sz);
	if (bn == NULL)
		return bn;
	if (sz == 0)
		return bn;

	@:cross_switch_lht@

	if (bn) {
		bn->hsorted = l->hsorted;
		bn->hrevsorted = l->hrevsorted;
		bn->tsorted = lc == 1 && r->tsorted;
		bn->trevsorted = lc == 1 && r->trevsorted;
		bn->hdense = rc == 1 && l->hdense;
		bn->tdense = lc == 1 && r->tdense;
		BATkey(bn, rc == 1 && BAThkey(l));
		BATkey(BATmirror(bn), lc == 1 && BATtkey(r));
		if (!bn->batDirty)
			bn->batDirty = TRUE;
		bn->H->nonil = l->H->nonil;
		bn->T->nonil = r->T->nonil;
	}

	return bn;
}

/*
 * @+ Cartesian product
 * The matching algorithms tries to construct non-empty matches on all head
 * columns. Each time this succeeds, it calls the Cartesian routine to
 * construct a join result that consists of the Cartesian product of these
 * matches.
 *
 * The matching tuples can be encoded in two ways:
 * @table @samp
 * @item clustered
 *  here we have two BUN pointers 'hi' and 'lo' that point
 * to a consecutive range of BUNs in a BAT that match.
 * @item nonclustered here we have a hit pointer that points to an array
 * of BUN  pointers that match.
 * @end table
 * The below structures are used for keeping track of the matching process.
 */
typedef struct _column_t {
	BAT *b;			/* BAT of this column */
	BATiter bi;
	BUN cur;		/* current BUN in b */
	BUN nhits;		/* number of matched BUNs */

	/* clustered */
	BUN lo;			/* first BUN that matches */
	BUN hi;			/* past last BUN that matches */
	/* nonclustered */
	BUN *hit;		/* BUN array pointer */
	size_t hitsize;		/* size of hit array */

	/* properties */
/* I'm not sure whether offset can become negative, so to be on the
 * save side, use a signed type.  However the magnitude should be
 * within the range allowed by BUN, so the casts associated with this
 * value should be OK. */
	ssize_t offset;		/* BUNindex of BUNfirst  */
	struct _column_t *sync;	/* iff > 0: column with synchronous BAT */
	BUN size;		/* size of the BAT */
	char binsearch;		/* sparse matching expected? */
	char ordered;		/* merge matching */
} column_t;

typedef struct {
	RowFcn tuple_fcn;	/* function to invoke per match */
	ptr tuple_data;		/* application-specific data */
	ColFcn *value_fcn;	/* for each col: function to invoke per value */
	ptr *value_data;	/* for each col: application-specific data */
	column_t *c;		/* array of columns */
	int argc;		/* size of c */
} table_t;

static void
column_result(table_t *t, int i)
{
	if (++i > t->argc) {
		/* end of recursion: invoke tuple-match routine */
		t->tuple_fcn(t->tuple_data, t->value_data);
	} else {
		/* recurse over all matches on this column */
		column_t *c = t->c + (i - 1);
		BUN q, *p = c->hit;
		BUN j;

		if (p == NULL) {	/* clustered */
			for (q = c->lo; q < c->hi; q++) {
				t->value_fcn[i] (t->value_data[i], BUNtail(c->bi, q));
				column_result(t, i);
			}
		} else {
			for (j = 0; j < c->nhits; j++, p++) {
				t->value_fcn[i] (t->value_data[i], BUNtail(c->bi, *p));
				column_result(t, i);
			}
		}
	}
}

/*
 * @* MultiColumn Joins
 * Computes the n-ary equijoin over the head columns of multiple BATs.
 * This function is complex, and uses nested functions calls,
 * for the specific stuff, it uses the stack for generating the
 * Cartesian product on each hit tuple. Most of all, it emits tuples one
 * at a time, in a pipeline rather than bulk fashion. For all these reasons,
 * it is not main-memory efficient. It does things that MonetDB actually
 * specifically was designed to avoid.
 *
 * USE THIS FUNCTION ONLY WHEN YOU REALLY REALLY HAVE TO:
 * @table @code
 * @item  -
 * printing a multicolumn table to a watching end-user is one such example
 * @end table
 * @+ multijoin entry routine
 * The multijoin will cause a cascade of value_fcn() calls putting
 * values in to place, rounded off each time by a tuple_fcn() that is
 * executed on each produced tuple. If this corresponds 1-1 with
 * the elements of one of the parameter BAT, the 'result' of the
 * operation would be aligned with it.
 *
 * The return value of this operation contains this status information.
 * It is an integer, of which all 4 bytes are used:
 * @table @code
 * @item ret[0] == 1,
 * if a mergejoin was used, 0 otherwise
 * @item ret[1] == 1,
 * if all bats had the key property set, 0 otherwise
 * @item ret[2] == 1
 * if there was a 1-1 join, 0 otherwise
 * @item ret[3] ==
 * the parameter number of the BAT which was used as leader
 * @end table
 */
#define COLSIZE(c)\
	(((c)->b->htype!=TYPE_void || (c)->b->hseqbase!=oid_nil)?(c)->size:0)
#define REALLOCBUNS(c,n) if (c->hitsize <= n)\
	c->hit = (BUN*) GDKrealloc(c->hit, (c->hitsize+=n)*sizeof(BUN))

#define LEAD_INTERRUPT_END  1
#define LEAD_TRAVERSE_SSK   3	/* seq, sorted, key */
#define LEAD_TRAVERSE_SNK   4	/* seq, nonsorted, key */
#define LEAD_TRAVERSE_SEQ   6	/* enforced seq (for order purposes) */
#define LEAD_TRAVERSE_SRT   9	/* traverse by sorted chunk */

int
BATmultijoin(int argc, BAT *argv[], RowFcn tuple_fcn, ptr tuple_data, ColFcn value_fcn[], ptr value_data[], int orderby)
{
	column_t *lead_col, *c = (column_t *) GDKzalloc(argc * (int) sizeof(column_t));
	column_t **reorder = (column_t **) GDKmalloc(argc * (int) sizeof(column_t *));
	int status = 0, algo = LEAD_TRAVERSE_SEQ;
	int i, k;
	BUN p, q;
	table_t t;

	/*
	 * Init the table descriptor.
	 */
	if (c == NULL || reorder == NULL) {
		GDKfree(c);
		GDKfree(reorder);
		return 0;
	}
	t.tuple_data = tuple_data;
	t.value_data = value_data;
	t.tuple_fcn = tuple_fcn;
	t.value_fcn = value_fcn;
	t.argc = argc;
	t.c = c;
	/*
	 * order columns by their size (smallest first)
	 */
	for (i = 0; i < argc; i++) {
		int j;

		c[i].b = argv[i];
		c[i].bi = bat_iterator(c[i].b);
		c[i].nhits = 1;	/* default value */
		c[i].offset = (ssize_t) BUNfirst(c[i].b);
		c[i].size = BATcount(c[i].b);

		/* positional lookup possible => ignore other alternatives */
		if (!BAThdense(c[i].b))
			c[i].ordered = BAThordered(c[i].b);

		/* insertion sort on size */
		for (j = 0; j < i; j++) {
			if (COLSIZE(reorder[j]) > COLSIZE(c + i) ||
			    /* in case of equal size, we prefer dense over non-dense */
			    (COLSIZE(reorder[j]) == COLSIZE(c + i) && !BAThdense(reorder[j]->b) && BAThdense((c + i)->b))) {
				for (k = i; k > j; k--) {
					reorder[k] = reorder[k - 1];
				}
				break;
			}
		}
		reorder[j] = c + i;
	}
	/*
	 * @- handle explicit ordering requests
	 * An 'orderby' specification tells that the multijoin should
	 * match in the order of one specific BAT parameter.
	 *
	 * Notice that we *respect* the ordering of the orderby column
	 * rather than we sort it explicitly (ie; you should order the
	 * most significant column beforehand).  This allows for both
	 * for join results ordered on some tail column as results
	 * ordered on head column, or even 'reverse' or other specific
	 * orderings.  One such specific ordering is the SQL ORDER BY
	 * multi-column ordering that can be obtained with the
	 * CTorderby command from the xtables module.
	 */
	if (orderby) {		/* order on tail of some column */
		int lead = orderby - 1;

		for (i = 0; i < argc; i++)
			if (reorder[i] == c + lead)
				break;
		while (--i >= 0) {
			reorder[i + 1] = reorder[i];
		}
		reorder[0] = c + lead;
	}
	lead_col = reorder[0];
	/*
	 * @- lead column traversal mode
	 * The default action is to do LEAD_TRAVERSE_SEQ: 1-by-1
	 * traversal of the lead_col, and for each head value use the
	 * best possible matching algorithm.  A local optimization is
	 * to signal a sorted head column in the lead column, so we
	 * can switch to LEAD_TRAVERSE_SRT; if double lead values
	 * occur we do them in one match iteration.
	 *
	 * We record in MULTIJOIN_SORTED(status) whether the chosen
	 * traversal method visits the head values in the lead column
	 * in order. This is important for the matching algorithms of
	 * the other columns (only if the head values are visited in
	 * order, merge algorithms may be employed).
	 */
	if (BAThordered(lead_col->b)) {
		if (!BAThkey(lead_col->b)) {
			algo = LEAD_TRAVERSE_SRT;
		}
		MULTIJOIN_SORTED(status) = TRUE;
	}
	lead_col->hi = lead_col->cur = BUNfirst(lead_col->b);
	q = BUNlast(lead_col->b);
	MULTIJOIN_KEY(status) = (char) BAThkey(lead_col->b);
	MULTIJOIN_LEAD(status) = (char) (lead_col - c);
	MULTIJOIN_SYNCED(status) = 1;
	if (algo == LEAD_TRAVERSE_SEQ && BAThkey(lead_col->b)) {
		algo = BAThordered(lead_col->b) ? LEAD_TRAVERSE_SSK : LEAD_TRAVERSE_SNK;
	}

	/*
	 * @- matching algorithms for the other columns
	 * Finally, the issue of choosing matching-algorithms for the
	 * other columns is treated. There are a number of
	 * possibilities. If a column is synced with a previous
	 * column, this is registered, so it can copy the matching
	 * results of that previous column. If not, we use the fact
	 * that a column is ordered and if not, has an binary index on
	 * it. Both cases fall into two sub cases: merge-lookup or
	 * binary-search; depending on whether we visit the head
	 * elements in order (MULTIJOIN_SORTED(status)).  If none of
	 * this is the case, we do hash-lookup using an on-the-fly
	 * hash-table.
	 */
	for (k = 1; k < argc; k++) {
		column_t *n = reorder[k];
		int j;

		for (j = (algo == LEAD_TRAVERSE_SEQ); j < k; j++) {
			if (ALIGNsynced(reorder[j]->b, n->b)) {
				n->sync = (struct _column_t *) reorder[j];
				n->offset -= reorder[j]->offset;
			}
		}
		if (!BAThkey(n->b)) {
			MULTIJOIN_KEY(status) = 0;
			MULTIJOIN_SYNCED(status) = 0;
		}
		if (!MULTIJOIN_SORTED(status)) {
			if (n->size < 4 * lead_col->size) {
				n->ordered = FALSE;
			} else {
				n->binsearch = TRUE;
			}
		} else if (n->size > 40 * lead_col->size) {
			n->binsearch = TRUE;
		}
		if (n->ordered) {
			n->cur = BUNfirst(n->b);
		} else if (!BAThkey(n->b) && n->sync == NULL) {
			if (BATprepareHash(n->b)) {
				GDKerror("BATmultijoin: could not hash '%s'\n", BATgetId(n->b));
				GDKfree(c);
				GDKfree(reorder);
				return 0;
			}
			n->hitsize = 20;
			n->hit = (BUN *) GDKmalloc(n->hitsize * sizeof(BUN));
			if (n->hit == NULL) {
				GDKfree(c);
				GDKfree(reorder);
				return 0;
			}
		}
	}

/*
 * @- the matching phase
 * We optimize in the case that the head-columns are OID. Below
 * macro's help to separate the two cases cleanly.
 */
#if (SIZEOF_OID == SIZEOF_INT)
#define OIDcmp(v1,v2)	simple_CMP(v1,v2,int)
#else
#define OIDcmp(v1,v2)	simple_CMP(v1,v2,lng)
#endif
#define STDcmp(v1,v2)	(*cmp)(v1,v2)

	if (ATOMstorage(lead_col->b->htype) == ATOMstorage(TYPE_oid)) {
		@:multijoin(hloc,OID,_oid)@
	} else {
		int (*cmp) (const void *, const void *) = BATatoms[lead_col->b->htype].atomCmp;

		@:multijoin(head,STD,_any)@
	}
	/*
	 * Cleanup & exit.
	 */
	for (i = 0; i < argc; i++) {
		if (c[i].hitsize)
			GDKfree(c[i].hit);
	}
	GDKfree(c);
	GDKfree(reorder);
	return status;
}

/*
 * @+ The Matching Algorithm
 * In multi-column join, all MonetDB accelerators are put to use when
 * equi-lookup is done on a number of head columns.  In order of
 * preference, it:
 *
 * @itemize
 * @item
 *     does positional lookup on @emph{ virtual oid} columns (void).
 * @item
 *     reuses lookup info on @emph{ synced columns}.
 * @item
 *     uses merge scan on @emph{ ordered columns}.
 * @item
 *     uses binary tree leaf scan on @emph{ indexed columns}.
 * @item
 *     uses hash lookup in other cases. If a hash-table does not
 * exist; it is created on the fly.
 * @end itemize
 *
 * The algorithm goes one by one, for unique head values in the
 * smallest-sized BAT. The strategy is for each column to find a range
 * of BUNs that match it.
 *
 * The algorithm is intelligent in that it processes the columns in
 * order of cardinality. If a column has no matches, you can cut off
 * the matching process for the current ID (head value) and go to the
 * next. Smallest BATs first means highest miss probability first.
 *
 * Another optimization is that when a column has a cardinality much
 * larger than the smallest column, you can expect sparse matching
 * (e.g. you selected 1% tuples out of a 1M tuple BAT, and re-joins
 * both with this routine). In those cases the merge algorithms use
 * binary search instead of mergescan.
 *
 * In non-empty matching ranges are found in all head columns, a
 * recursive routine is used to go over all combinations of matching
 * BUNs. This recursive routine calls for every match (the Cartesian
 * product) a special-purpose routine that is passed all matching BUN
 * pointers. This sequence of calls represents the result of the
 * multijoin.
 *
 * Normally you want to perform an action on each value (like
 * formatting or copying), but many values reoccur in the same place
 * when the Cartesian product over all columns is formed.  For
 * instance, when we have 5 attributes in which each has 2 matches on
 * the current id, we have 2*2*2*2*2=32 result tuples for this one
 * id. A simple-minded strategy would then do 32*5 value actions, when
 * processing these result tuples. This multijoin reduces that to just
 * 32, by calling whenever a value is 'changed' in the
 * result-tuple-under-construction, a value specific function,
 * provided by the user. Since each column can have a different value
 * function, this also allows for factoring out type-checking
 * overhead.
 */
@= multijoin
	while (algo) {
		ptr h;		/* points to current ID */

		/*
		 * find the next leader bun
		 */
		p = lead_col->hi;
		if (p >= q)
			break;
		h = BUNhead(lead_col->bi, p);

		/* FIND MATCHING COLUMN RANGES
		 * For each column, find all matches for this head value
		 */
		for (i = 0; i < argc; i++) {
			column_t *m, *n = reorder[i];	/* use BATcount() order */
			BAT *b = n->b;
			BATiter bi = n->bi;

			/* one-by-one traversal of the lead column? => no matching done.
			 */
			if (n == lead_col) {
				if (argc > 1 && ATOMcmp(b->htype, h, ATOMnilptr(b->htype)) == 0) {
					n->lo = n->hi = p+1;
					break;
				} else if (algo <= LEAD_TRAVERSE_SEQ) {
					n->lo = p;
					n->hi = p+1;
					continue;
				}
			}
			/* Synced lookup
			 * If some BAT is synced with a BAT we already
			 * handled ('parent'), we can simply copy and
			 * convert the BUNlists of the parent.
			 */
			if ((m = n->sync) != NULL) {
				if (m->hit) {
					BUN j;

					REALLOCBUNS(n, m->nhits);
					for (j = 0; j < m->nhits; j++) {
						n->hit[j] = (BUN) (n->offset + m->hit[j]);
					}
					n->nhits = m->nhits;
				} else {
					n->lo = (BUN) (n->offset + m->lo);
					n->hi = (BUN) (n->offset + m->hi);
				}
				/* Sorted lookup
				 * We perform a merge scan over the tail column.
				 */
			} else if (n->ordered) {
				BUN last = BUNlast(b);

				if (n->binsearch) {
					n->cur = SORTfndfirst(BATmirror(b), h);
					if (n->cur >= last)
						break;	/* NOT FOUND */
				} else {
					int yy = 1;

					for (; n->cur < last; n->cur++)
						if ((yy = @2cmp(BUN@1(bi, n->cur), h)) >= 0)
							 break;

					if (yy != 0)
						break;	/* NOT FOUND */
				}
				n->lo = n->cur;
				for (n->nhits = 1; (++n->cur) < last; n->nhits++) {
					if (@2cmp(BUN@1(bi, n->cur), h))
						 break;
				}
				if (n->cur >= last && (algo & LEAD_INTERRUPT_END))
					algo = 0;
				n->hi = n->cur;
				/* Single Hash lookup
				 */
			} else if (BAThkey(n->b)) {
				BUNfnd@2(n->cur, bi, h);
				if (n->cur == BUN_NONE)
					break;	/* NOT FOUND */
				n->lo = n->cur;
				n->hi = n->cur+1;
				/* Multiple Hash lookup
				 */
			} else {
				BUN j;

				n->nhits = 0;
				HASHloop@3(bi, b->H->hash, j, h) {
					REALLOCBUNS(n, n->nhits + 1);
					n->hit[n->nhits++] = j;
				}
				if (n->nhits == 0)
					break;	/* NOT FOUND */
			}
		}
		/* Recursively print the Cartesian product of all
		 * match collections of h.
		 */
		if (i >= argc) {
			t.value_fcn[0] (t.value_data[0], h);
			column_result(&t, 0);
		} else {
			MULTIJOIN_SYNCED(status) = 0;	/* a miss occurred somewhere! */
		}
	}
	if (lead_col->hi < q) {
		MULTIJOIN_SYNCED(status) = 0;	/* an interrupt occurred! */
	}
@
