@' The contents of this file are subject to the MonetDB Public
@' License Version 1.0 (the "License"); you may not use this file
@' except in compliance with the License. You may obtain a copy of
@' the License at
@' http://monetdb.cwi.nl/Legal/MonetDBLicense-1.0.html
@'
@' Software distributed under the License is distributed on an "AS
@' IS" basis, WITHOUT WARRANTY OF ANY KIND, either express or
@' implied. See the License for the specific language governing
@' rights and limitations under the License.
@'
@' The Original Code is the Monet Database System.
@'
@' The Initial Developer of the Original Code is CWI.
@' Portions created by CWI are Copyright (C) 1997-2005 CWI.
@' All Rights Reserved.

@f mal_optimizer
@a M. Kersten
@* The Optimizer Landscape
One of the prime reasons to design the MAL intermediate language is to have
a high-level description for database queries, which is easy to generate by
a front-end compiler and easy to decode, optimize and interpret.

An optimizer needs several mechanisms to be effective. It should be able to
perform a symbolic evaluation of a code fragment and collect the result in
properties for further decision making. The prototypical case is where an 
optimizer estimates the result size of a selection.

Another major issue is to be able to generate and explore a space of 
alternative evaluation plans. This exploration may take place up front, 
but can also be ran at runtime for query fragments.

@menu
* Optimizer landscape::
@menu
* What optimizers to consider?::
* Optimization Dependencies::
* Optimizer Building Blocks::
* Query Optimizer Framework::
@end menu
* Optimizer toolkit::
@end menu

@node What optimizers to consider?, Optimization Dependencies ,Optimizer landscape, Optimizer landscape
@+ What optimizers to consider?
A query optimizer is often a large and complex piece of code, which
enumerates alternative evaluation plans from which 'the best' plan
is selected for evaluation. Limited progress has been made sofar to
decompose the optimizer into (orthogonal) components, because it is 
a common believe in research that a holistic view on the problem is 
a prerequisite to find the best plan. 
Conversely, commercial optimizers use a cost-model driven approach, which
explores part of the space using a limited (up to 300) rewriting rules.

Our hypothesis is that query optimization should be realized with
a collection of query optimizer transformers (QOT),
each dedicated to a specific task.
Furthermore, they are assembled in scenarios to support specific application
domains or achieve a desired behavior. Such scenarios are selected on a
session basis, a query basis, or dynamically at
runtime; they are part of the query plan.

The query transformer list below is under consideration for development.
For each we consider its goal, approach, and expected impact.
Moreover, the minimal prerequisites identify the essential optimizers that 
should have done their work already. For example, it doesn;t make sense
to perform a static evaluation unless you have already propagated the
constants using Alias Removal.

@emph{Scalar expressions (SXoptimizer)}
Goal: to remove scalar expressions which need be evaluated once during the
query lifetime.
Rationale: static expressions appear 
when variables used denote literal constants (e.g. 1+1),
when catalog information can be merged with the plan (e.g. max(B.salary)), 
when session variables are used which are initialized once (e.g. user()).
Early evaluation aids subsequent optimization.
Approach: inspect all instructions to locate static expressions. 
Whether they should be removed depends on the expected re-use,
which in most cases call for an explicit request upon query registration 
to do so. The result of a static evaluation provides a ground for AR.
Impact: relevant for stored queries (MAL functions)
Prereq: AR, CX

@emph{Relational Expression Optimizer (RXoptimizer)}
Goal: to evaluate a relational plan using properties of BATs,
such as being empty or forming an aligned group.
These optimizations assume that the code generator can detect properties
while compiling e.g. an SQL query.
Impact: high
Prereq:

@emph{Alias Removal (ARoptimizer)}
Goal: to reduce the number of  variables referenceing the same value,
thereby reducing the analysis complexity.
Rationale: query transformations often result in replacing
the right-hand side expression with a result variable. This pollutes the
code block with simple assignments e.g. V:=T. Within the descendant flow the
occurrence of V could be replaced by T, provided V is never assigned a new
value.
Approach: literal constants within a MAL block are already recognized and
replaced by a single variable. 
Impact: medium


@emph{Common Expression Optimizer (CXoptimizer)}
Goal: to reduce the amount of work by avoiding calculation of the same
operation twice.
Rationale: to simplify code generation for front-ends, they do not have
to remember the subexpressions already evaluated. It is much easier to 
detect at the MAL level.
Approach: simply walk through the instruction sequence and locate identical
patterns.  (Enhance is with semantic equivalent instructions)
Impact: High
Prereq: AR

@emph{Access Mode Optimizer (AMoptimizer)}
Goal: the default access mode for BATs is readonly.
When updates are needed, it is switched to WriteMode,
which needs to be done only once.
Approach: remove duplicate calls
Impact: low

@emph{Dead Code Removal (DCoptimizer)}
Goal: to remove all instructions whose result is not used
Rationale: due to sloppy coding or alternative execution paths
dead code may appear. Als XML Pathfinder is expected to produce
a large number of simple assignments.
Approach: Every instruction should produce a value used somewhere else.
Impact: low

@emph{Heuristic Rule Rewrites (HRoptimizer)}
Goal: to reduce the volume as quick as possible.
Rationale: most queries are focussed on a small part of the database.
To avoid carrying too many intermediates, the selection should be performed as
early as possible in the process. This assumes that selectivity factors are
known upfront, which in turn depends on histogram of the value distribution.
Approach: locate selections and push them back/forth through the flow graph.
Impact: high

@emph{Join Path Optimizer (JPoptimizer)}
Goal: to reduce the volume produced by a join sequence
Rationale: join paths are potentially expensive operations. Ideally the join
path is evaluated starting at the smallest component, so as to reduce the
size of the intermediate results.
Approach: to successfully reduce the volume we need to estimate their processing
cost. This calls for statistics over the value distribution, in particular,
correlation histograms. If statistics are not available upfront, we have to 
restore to an incremental algorithm, which decides on the steps using the
size of the relations.
Impact: high

@emph{Operator Sort (OSoptimizer)}
Goal: to sort the dataflow graph in such a way as to reduce the
cost, or to assure locality of access for operands.
Rationale: A simple optimizer is to order the instructions for
execution by permutation of the query components 
Approach:
Impact:

@emph{Singleton Set (SSoptimizer)}
Goal: to replace sets that are known to produce precisely
one tuple.
Rationale: Singleton sets can be represented by value pairs in the
MAL program, which reduces to a scalar expression.
Approach: Identify a set variable for replacement.
Impact:

@emph{Result Cacher (RCoptimizer)}
Goal: to reduce the processing cost by keeping track of expensive to
compute intermediate results
Rationale: 
Approach: result caching becomes active after an instruction has been 
evaluated. The result can be cached as long as its underlying operands
remain unchanged. Result caching can be made transparent to the user, but
affects the other QOTs
Impact: high

@emph{Vector Execution (VEoptimizer)}
Goal: to rewrite a query to use a cache-optimal vector implementation
Rationale: processing in the cache is by far the best you can get.
However, the operands may far exceed the cache size and should be broken
into pieces followed by a staged execution of the fragments involved.
Approach: replace the query plan with fragment streamers
Impact:

@emph{Staged Execution (SEoptimizer)}
Goal: to split a query plan into a number of steps, such that the first
response set is delivered as quickly as possible. The remainder is only
produced upon request.
Rationale: interactive queries call for quick response and an indication
of the processing time involved to run it too completion. 
Approach: staged execution can be realized using a fragmentation scheme
over the database, e.g. each table is replaced by a union of fragments.
This fragmentation could be determined upfront by the user or is derived
from the query and database statistics.
impact: high

@emph{Code Parallizer (CPoptimizer)}
Goal: to exploit parallel IO and cpu processing in both SMP and MPP settings.
Rationale: throwing more resources to solve a complex query helps, provided
it is easy to determine that parallel processing recovers the administrative
overhead
Approach: every flow path segment can be handled by an independent process thread.
Impact: high

@emph{Query Evaluation Maps (QEMoptimizer)}
Goal: to avoid touching any tuple that is not relevant for answering a query.
Rationale: the majority of work in solving a query is to disgard tuples of
no interest and to find correlated tuples through join conditions. Ideally,
the database learns these properties over time and re-organizes (or builts
a map) to replace disgarding by map lookup.
Approach: piggyback selection and joins as database fragmentation instructions
Impact: high

@emph{MAL Compiler (MCcompiler) (tactics)}
Goal: to avoid interpretation of functional expressions
Rationale: interpretation of arithmetic expressions with an interpreter
is always expensive. Replacing a complex arithmetic expressin with a
simple dynamically compiled C-functions often pays off. Especially for
cached (MAL) queries
Approach:
Impact: high

@emph{Dynamic Query Scheduler (DQscheduler) (tactics)}
Goal: to organize the work in a way so as to optimize resource usage
Rationale: straight interpretation of a query plan may not lead to the best
use of the underlying resources. For example, the content of the runtime
cache may provide an opportunity to safe time by accessing a cached source
Approach: query scheduling is the last step before a relation algebra interpreter
takes over control. The scheduling step involves a re-ordering of the 
instructions within the boundaries imposed by the flow graph.
impact: medium

@emph{Aggregate Groups (AGoptimizer)}
Goal: to reduce the cost of computing aggregate expressions over times
Rationale: many of our applications call for calculation of aggregates
over dynamically defined groupings. They call for lengtly scans and it pays
to piggyback all aggregate calculates, leaving their result in the cache for
later consumption (eg the optimizers)
Approach:
Impact: High

@emph{Data Cube optimizer (DCoptimizer)}
Goal: to recognize data cube operations
Rationale: 
Approach:
Impact:


@emph{Demand Driven Interpreter (DDoptimizer) (tactics)}
Goal: to use the best interpreter and libraries geared at the task at hand
Rationale: Interpretation of a query plan can be based on different
computational models. A demand driven interpretation starts at the intended 
output and 'walks' backward through the flow graph to collect the pieces,
possibly in a pipelined fashion. (Vulcano model)
Approach: merely calls for a different implementation of the core operators
Impact: high

@emph{Iterator Strength Reduction (SRoptimizer)}
Goal: to reduce the cost of iterator execution by moving instructions
out of the loop.
Rationale: although iteration at the MAL level should be avoided due to
the inherent low performance compared to built-in operators, it is not
forbidden. In that case we should confine the iterator block to the minimal
work needed.
Approach: inspect the flowgraph for each iterator and move instructions around.
Impact: low

@emph{Accumulator Evaliations (AEoptimizer)}
Goal: to replace operators with cheaper ones.
Rationale: based on the actual state of the computation and the richness of
the supporting libraries there may exists alternative routes to solve a query.
Approach: Operator rewriting depends on properties. No general technique.
The first implementation looks at calculator expressions such as they
appear frequently in the RAM compiler.
Impact: high
Prerequisite: should be called after CXoptimizer to avoid clashes.

@emph{Code Inliner (CIoptimizer)}
Goal: to reduce the calling depth of the interpreter and to obtain
a better starting point for code squeezing
Rationale: substitution of code blocks (or macro expansion) leads to
longer linear code sequences. This provides opportunities for squeezing.
Moreover, at runtime building and managing a stackframe is rather expensive.
This should be avoided for functions called repeatedly.
Approach: called explicity to inline a module (or symbol)
Impact: medium

@emph{Code Outliner (COoptimizer)}
Goal: to reduce the program size by replacing a group with a single
instruction
Rationale: inverse macro expansion leads to
shorter linear code sequences. This provides opportunities for less interpreter
overhead, and to optimize complex, but repetative instruction sequences
with a single hardwired call
Approach: called explicitly to outline a module (or symbol)
Impact: medium


@emph{Garbage Collector (GCoptimizer)}
Goal: to release resources as quickly as possible
Rationale: BATs referenced from a MAL program keep resources locked.
Approach: In cooperation with a resource scheduler we should identify those
that can be released quickly. It requires a forced gargabe collection call
at the end of the BAT's lifespan.
Impact: large

@emph{Foreign Key replacements (FKoptimizer)}
Goal: to improve multi-attribute joins over foreign key constraints
Rationale: the code produced by the SQL frontend involves foreign key 
constraints, which provides many opportunities for speedy code.
Impact: large

@node Optimization Dependencies, Optimizer Building Blocks, What optimizers to consider?, Optimizer landscape
@section What is the dependency between optimizers?
The optimizers are highly targeted to a particular problem.
Aside from the resources available to invest in plan optimization,
optimizers are partly dependent and may interfere.

To aid selection of the components of interest, we have grouped
them in a preferred order of deployment.

@multitable @columnfractions .12 .8
@item Group A:
@tab    Code Inliner (CIoptimizer)
@item 
@tab    Static expression evaluator. (SXoptimizer)
@item 
@tab    Relational Expression Evaluator. (RXoptimizer)
@item 
@tab    Strength Reduction (SRoptimizer)

@item Group B:
@tab    Common Expression Optimizer (CXoptimizer)
@item 
@tab    Query Evaluation Maps (QMoptimizer)

@item Group C:
@tab    Join Path Optimizer (JPoptimizer)
@item 
@tab    Operator Cost Reduction (OCoptimizer)
@item 
@tab    Operator Sort (OSoptimizer)
@item 
@tab    Foreign Key handling (FKoptimizer)
@item 
@tab    Aggregate Groups (AGoptimizer)
@item 
@tab    Data Cube optimizer (DCoptimizer)
@item 
@tab    Heuristic Rule Rewrite (HRoptimizer)

@item group D:
@tab    Code Parallizer (CPoptimizer)
@item 
@tab    Accumulator Evaliations (AEoptimizer)
@item 
@tab    Result Cacher (RCoptimizer)
@item
@tab	Replication Manager (RManager)

@item group E:
@tab    MAL Compiler (MCcompiler)
@item 
@tab    Dynamic Query Scheduler (DQscheduler)
@item 
@tab    Vector Execution (VEoptimizer)
@item 
@tab    Staged Execution (SEoptimizer)

@item group F:
@tab    Alias Removal (ARoptimizer)
@item 
@tab    Access Mode Optimizer (AMoptimizer)
@item 
@tab    Dead Code Removal (DCoptimizer)
@item 
@tab    Garbage Collector (GCoptimizer)
@end multitable
@-
Alias removal can be applied after each other optimization step.
@node Optimizer Building Blocks, Query Optimizer Framework, Optimization Dependencies, Optimizer landscape
@+ Optimizer building blocks

Some instructions are independent of the execution context. In particular,
expressions over side-effect free functions with constant parameters could
be evaluated before the program block is considered further.

A major task for an optimizer is to select instruction (sequences) which
can and should be replaced with cheaper ones. The cost model underlying
this decision depends on the processing stage and the overall objective.
For example, based on a symbolic analysis their may exist better 
implementations within the interpreter to perform the job (e.g. hashjoin vs
mergejoin). Alternative, expensive intermediates may be cached for later use.

Plan enumeration is often implemented as a Memo structure, which
designates alternative sub-plans based on a cost metric.
Perhaps we can combine these memo structures into a large table
for all possible combinations encountered for a user.

The MAL language does not imply a specific optimizer to be used. Its programs
are merely a sequence of specifications, which is interpreted by an engine
specific to a given task. Activation of the engine is controlled by a 
scenario, which currently includes two hooks for optimization; a 
strategic optimizer and a tactical optimizer.
Both engines take a MAL program and produce a (new/modified) MAL program for 
execution by the lower layers. 

MAL programs end-up in the symbol table linked to a user session.
An optimizer has the freedom to change the code, provided it is known that
the plan derived is invariant to changes in the environment.
All others lead to alternative plans, which should be collected as a trail of
MAL program blocks. These trails can be inspected for a
posteriori analysis, at least in terms of some statistics on the properties
of the MAL program structures automatically.
Alternatively, the trail may be pruned and re-optimized when appropriate
from changes in the environment.

Breaking up the optimizer into different components and
grouping them together in arbitrary sequences calls for
careful programming.

The rule applied for all optimizers is to not-return
before checking the state of the MAL program,
and to assure the dataflow and variable scopes are properly set.
It costs some performance, but the difficulties
that arise from optimizer interference are very hard to debug.
One of the easiest pitfalls is to derive an optimized
version of a MAL function while it is already referenced by or
when polymorphic typechecking is required afterwards.
For example,
@{
@h
#include "mal.h"
#include "mal_function.h"
#include "mal_client.h"
#include "mal_scenario.h"

/* #define DEBUG_MAL_OPTIMIZER     show partial result */

#define isAlife(M,I,X)          ( (M)->var[I]->beginLifespan<=X && \
                                  (M)->var[I]->endLifespan>=X)
#define isSinglepoint(M,I)  ( (M)->var[I]->beginLifespan== \
                  (M)->var[I]->endLifespan)

#ifdef _MSC_VER
#ifndef LIBOPTIMIZER
#define opt_export extern __declspec(dllimport)
#else
#define opt_export extern __declspec(dllexport)
#endif
#else
#define opt_export extern
#endif

opt_export str MALoptimizer(Client c);
opt_export int optimizerCheck(MalBlkPtr mb, str name, int actions, lng usec);
opt_export void resetOptimizerDebugger();
opt_export str optimizeMALBlock(MalBlkPtr mb);
opt_export void showOptimizerStep(int i, int flg);
opt_export void showOptimizerHistory();
opt_export str debugOptimizers(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
opt_export str ARoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
opt_export int ARoptimizerStep(MalBlkPtr mb, int pc);
opt_export void ARreplaceAlias(MalBlkPtr mb, int pc, int pcl, int src, int alias);
opt_export str AMoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
opt_export str DCoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
opt_export str SRoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
opt_export str CXoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
opt_export str AEoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
opt_export str HRoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
opt_export str RXemptyBAT(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);
opt_export str RXalignedBATs(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci);

opt_export void setLifespan(MalBlkPtr mb);
opt_export void debugLifespan(MalBlkPtr mb);
opt_export void showFlowGraph(MalBlkPtr mb, MalStkPtr stk, str fname);
opt_export int isUnsafeInstruction(InstrPtr q);
opt_export int isUnsafeFunction(MalBlkPtr mb, InstrPtr q);
opt_export int isInvariant(MalBlkPtr mb, int pcf, int pcl, int varid);
opt_export int safetyBarrier(MalBlkPtr mb, InstrPtr p, InstrPtr q);
opt_export int hasSameSignature(InstrPtr p, InstrPtr q);
opt_export int hasSameArguments(MalBlkPtr mb, InstrPtr p, InstrPtr q);
opt_export int isUpdated(MalBlkPtr mb, int pc);
opt_export int hasCommonResults(InstrPtr p, InstrPtr q);
opt_export int hasSideEffects(InstrPtr p, int strict);
opt_export int allArgumentsVisible(MalBlkPtr mb, int pc,int qc);

@}
@-
@node Query Optimizer Framework, Optimizer toolkit, Optimizer Building Blocks, Optimizer landscape
@+ Optimizer framework
The large number of query transformers calls for a flexible scheme for
the deploy them. The approach taken is to make all optimizers visible
at the language level as a MAL pattern. Then (semantic) optimizer merely
inspects a MAL block for their occurrences and activitates it.

Furthermore, the default optimizer scheme can be associated with
a client record. The strategic optimizer merely prepends each query with 
this scheme before it searches/activates the optimizer routines.

The optimizer routines have access to the client context, the MAL block,
and the program counter where optimizer call was found. Each query
transformer should remove itself from the MAL block;

The optimizer terminates when no optimizer transformer call remains.
[Some of the optimizers above should be moved to the tactic level]

Note, all optimizer instructions are executed only once. This means that the
instruction can be removed from further consideration. However, in the case
that a designated function is selected for optimization (e.g. 
CXoptimizer(user,qry)) the pc is assumed 0. The first instruction always
denotes the signature and can not be removed.
@{
@c
#include "mal_optimizer.h"
#include "mal_interpreter.h"
#include "mal_debugger.h"
#include "mal_namespace.h"

int
optimizerCheck(MalBlkPtr mb, str name, int actions, lng usec)
{
	chkFlow(mb);
	chkTypes(getClient()->nspace, mb);
	chkDeclarations(mb, TRUE);
	setLifespan(mb);
	/* debugLifespan(mb); */
	if (mb->errors) {
		showErrors();
		stream_printf(GDKout, "Optimizer %s failed\n", name);
		printFunction(GDKout, mb, LIST_MAL_ALL);
	}
	optimizerDebug(mb, name, actions, usec);
	return mb->errors;
}

@-
Limit the loop count in the optimizer.
@c
str
optimizeMALBlock(MalBlkPtr mb)
{
	InstrPtr p;
	int pc, qot = 0;
	str msg = NULL;
	int cnt = 0;

#ifdef DEBUG_MAL_OPTIMIZER
	int oldstop = mb->stop;
#endif

	do {
		qot = 0;
		for (pc = 0; pc < mb->stop; pc++) {
			p = getInstrPtr(mb, pc);
			if (moduleId(p) && idcmp(moduleId(p), "optimizer") == 0) {
				qot++;
				if (p->fcn)
					/* all optimizers should behave like patterns */
					/* However, we don;t have a stack now */
					msg = (str) (*p->fcn) (mb, 0, p);
				else
					msg = throwMessage("optimizer", "Implementation missing");
				if (msg) {
					GDKerror(msg);
					showErrors();
					return msg;
				}
				pc--;
			}
		}
	} while (qot && cnt++ < 64);
#ifdef DEBUG_MAL_OPTIMIZER
	if (getClient()->debugOptimizer && oldstop != mb->stop) {
		stream_printf(GDKout, "Optimizer effect %d -> %d instructions\n", oldstop, mb->stop);
	}
#endif
	if (cnt >= 64)
		return throwMessage("optimizer.MALoptimizer", "too many optimization cycles\n");
	return 0;
}

str
MALoptimizer(Client c)
{
	return optimizeMALBlock(c->curprg->def);
}

@}
@{
int hasSameSignature(InstrPtr p, InstrPtr q){   
    if( q->retc != p->retc || q->argc != p->argc) return FALSE;
    if( functionId(q)==0 && functionId(p)!=0 ) return FALSE;
    if( functionId(q)!=0 && functionId(p)==0 ) return FALSE;
    if( functionId(q) && functionId(p) && idcmp(functionName(q),functionName(p)) ) 
        return FALSE;
    if( moduleId(q)==0 && moduleId(p)!=0 ) return FALSE;
    if( moduleId(q)!=0 && moduleId(p)==0 ) return FALSE;
    if( moduleId(q) && moduleId(p) && idcmp(moduleName(q),moduleName(p)))
        return FALSE;
    /* actually also check their types */
    return TRUE;
}

int hasSameArguments(MalBlkPtr mb, InstrPtr p, InstrPtr q)
{   int k;
    for(k=p->retc; k<p->argc;k++)
    if( q->argv[k]!= p->argv[k] ) {
		if( isConstant(mb,p->argv[k]) && isConstant(mb,q->argv[k]) &&
			strcmp(getVarLiteral(mb,p->argv[k]), getVarLiteral(mb,q->argv[k])) == 0)
			continue;
		return FALSE;
	}
    return TRUE;
}
@-
If two instructions have elements in common in their target list,
it means a variable is re-initialized and should not be considered
an alias.
@c
int
hasCommonResults(InstrPtr p, InstrPtr q)
{
	int k, l;

	for (k = 0; k < p->retc; k++)
		for (l = 0; l < q->retc; l++)
			if (p->argv[k] == q->argv[l])
				return TRUE;
	return FALSE;
}
@-
See is all arguments mentioned in the instruction at point pc
are still visible at instruction qc.
@c
int
allArgumentsVisible(MalBlkPtr mb, int pc,int qc){
	int i;
	InstrPtr p;

	p= getInstrPtr(mb,pc);
	for(i=p->retc; i< p->argc; i++){
		VarPtr v = getVar(mb, getArg(p,i));
		if( ! (v->beginLifespan <= qc && qc<=v->endLifespan))
			return FALSE;
	}
	return TRUE;
}
@}
@-
For each function it should be relatively easy to determine its
safety property. This calls for accessing the function MAL block
and to inspect the arguments of the signature.
@{
@c
int
isUnsafeFunction(MalBlkPtr mb, InstrPtr q)
{
	Symbol s = 0;
	Client c;

	(void) mb;
	if (q->fcn == 0 || functionId(q) == 0)
		return FALSE;
	c = getClient();
	if (c)
		s = getFunctionSymbol(c->nspace, q);
	(void) s;		/* simulated some action */
	/* check arguments for 'unsafe' property */
	return FALSE;
}

@-
Instructions are unsafe is one of the arguments is also mentioned
in the result list. Alternatively, the 'unsafe' property is set
for the function call itself.
@c
int
isUnsafeInstruction(InstrPtr q)
{
	int j, k;

	for (j = 0; j < q->retc; j++)
		for (k = q->retc; k < q->argc; k++)
			if (q->argv[k] == q->argv[j])
				return TRUE;
	return FALSE;
}

@-
The routine isInvariant determines if the variable V is not
changed in the instruction sequence identified by the range [pcf,pcl].
@c
int
isInvariant(MalBlkPtr mb, int pcf, int pcl, int varid)
{
	(void) mb;
	(void) pcf;
	(void) pcl;
	(void) varid;		/*fool compiler */
	return TRUE;
}

@}
@-
Any instruction may block identification of a common
subexpression. It suffices to stumble upon an unsafe function 
whose parameter lists has a non-empty intersection with the
targeted instruction.
To illustrate, consider the sequence
@example
L1 := f(A,B,C);
...
G1 := g(D,E,F);
...
l2:= f(A,B,C);
...
L2:= h()
@end example

The instruction G1:=g(D,E,F) is blocking if G1 is an alias 
for @verb{ { }A,B,C@verb{ } }.
Alternatively, function g() may be unsafe and @verb{ { }D,E,F@verb{ } }
has a non-empty intersection with @verb{ { }A,B,C@verb{ } }. 
An alias can only be used later on for readonly (and not be used for a function with sideeffects)
@{
@c
int
safetyBarrier(MalBlkPtr mb, InstrPtr p, InstrPtr q)
{
	int i, j;

	for (j = 0; j < q->retc; j++)
		for (i = p->retc; i < p->argc; i++)
			if (p->argv[i] == q->argv[j]) {
#ifdef DEBUG_MAL_OPTIMIZER2
				if (getClient()->debugOptimizer) {
					stream_printf(GDKout, "Found assignment barrier for \n");
					printInstruction(GDKout, mb, p, LIST_MAL_ALL);
					printInstruction(GDKout, mb, q, LIST_MAL_ALL);
				}
#endif
				return TRUE;
			}

	if (isUnsafeFunction(mb, q)) {
		for (i = p->retc; i < p->argc; i++)
			for (j = q->retc; j < q->argc; j++)
				if (p->argv[i] == q->argv[j]) {
#ifdef DEBUG_MAL_OPTIMIZER
					if (getClient()->debugOptimizer) {
						stream_printf(GDKout, "Found overlapping assignment barrier for \n");
						printInstruction(GDKout, mb, q, LIST_MAL_ALL);
					}
#endif
					/* TODO check safety property of the argument */
					return TRUE;
				}
	}
	return FALSE;
}

int
isUpdated(MalBlkPtr mb, int pc)
{
	InstrPtr p, q;
	int j, k;

	p = getInstrPtr(mb, pc);
	for (pc++; pc < mb->stop; pc++) {
		q = getInstrPtr(mb, pc);
		/* target is later assigned a new value */
		for (j = 0; j < p->retc; j++)
			for (k = 0; k < q->retc; k++)
				if (p->argv[j] == q->argv[k]) {
					int c = 0;

					if (p->argc != q->argc)
						return TRUE;

					/* instruction q may not be a common expression */
					/* TO WEAK, test stability of its arguments */
					for (j = 0; j < p->argc; j++)
						if (p->argv[j] == q->argv[k] && isInvariant(mb, 0, pc, q->argv[k]))
							c++;
					return c != p->argc;
				}

		/* result is used in an unsafe function */
		for (j = 0; j < p->retc; j++)
			for (k = q->retc; k < q->argc; k++)
				if (p->argv[j] == q->argv[k] && hasSideEffects(q, TRUE))
					return TRUE;
	}
	return FALSE;
}

@}
@- Lifespan analysis
The variables have a lifespan in the code blocks, denoted by properties
beginLifespan,endLifespan. The beginLifespan denotes the intruction where
it receives its first value, the endLifespan the last instruction in which 
it was used as operand or target.

If, however, the last use lies within a BARRIER block, we can not be sure
about its end of life status, because a block redo may implictly
revive it. For these situations we associate the endLifespan with
the block exit.

In many cases, we have to determine if the lifespan interferes with 
a optimization decision being prepared.
The lifespan is calculated once at the beginning of the optimizer sequence.
It should either be maintained to reflect the most accurate situation while
optimizing the code base. In particular it means that any move/remove/addition
of an instruction calls for either a recalculation or delta propagation.
Unclear what will be the best strategy. For the time being we just recalc.

@{
Also take care of the nested block structure. Because the span should
fall within a single block. This is handled by the chkflow already.
@c
void
debugLifespan(MalBlkPtr mb)
{
	int i;

	for (i = 0; i < mb->vtop; i++) {
		VarPtr v = getVar(mb, i);

		if (isTmpVar(mb, i))
			printf("%c%d %d - %d scope=%d,%d\n", TMPMARKER, v->tmpindex, v->beginLifespan, v->endLifespan, v->scope, v->depth);

		else
			printf("%s %d - %d scope= %d,%d\n", v->name, v->beginLifespan, v->endLifespan, v->scope, v->depth);
	}
}
void
setLifespan(MalBlkPtr mb)
{
	int pc, k;
	InstrPtr p;

	for (k = 0; k < mb->vtop; k++) {
		VarPtr v = getVar(mb, k);

		v->updLifespan = v->beginLifespan = v->endLifespan = 0;
	}
	for (pc = 0; pc < mb->stop; pc++) {
		p = getInstrPtr(mb, pc);
		for (k = 0; k < p->argc; k++) {
			VarPtr v = getVar(mb, p->argv[k]);

			if (v->beginLifespan == 0)
				v->beginLifespan = pc;
			if (k < p->retc)
				v->updLifespan++;
			if (pc > v->endLifespan) {
				/* end only if the beginLifspan falls in the same blk */
				/* otherwise it is the corresponding exit. */
				v->endLifespan = pc;
			}
		}
	}
	/* debugLifespan(mb); */
}

@-
In many cases we should be assured that a variable is not used in
the instruction range identified. For, we may exchange some instructions that
might change its content.
@c
int
isTouched(MalBlkPtr mb, int varid, int p1, int p2)
{
	int i, k;

	for (i = p1; i < p2; i++) {
		InstrPtr p = getInstrPtr(mb, i);

		for (k = 0; k < p->argc; k++)
			if (p->argv[k] == varid)
				return TRUE;
	}
	return FALSE;
}

@}
@- Flow analysis
In many optimization rules, the data flow dependency between statements is
of crucial importance. The MAL language encodes a multi-source, multi-sink
dataflow network. Optimizers typically extract part of the workflow and use
the language properties to enumerate semantic equivalent solutions, which
under a given cost model turns out to result in better performance.

The flow graph plays a crucial role in many optimization steps.
It is unclear as yet what primitives and what storage structure is
most adequate. For the time being we introduce the operations needed and
evaluate them directly against the program

The routine flowStep(pca,pcb) checks whether the output of instruction
pca flows directly into pcb, without its parameters being changed inbetween.
This calls for checking assignments as well as operators that use any of
the targets of pca, but which also change them (e.g. insert/delete bat)
TODO, now more restrictive then needed.
@{
@c
int
flowStep(MalBlkPtr mb, int pca, int pcb)
{
	InstrPtr pa, pb;
	int i, k, l;

	if (pca > pcb)
		return FALSE;
	if (pca + 1 == pcb)
		return TRUE;

	pa = getInstrPtr(mb, pca);
	for (i = pca + 1; i < pcb; i++) {
		pb = getInstrPtr(mb, i);
		if (hasCommonResults(pa, pb))
			return FALSE;

		/* also be aware of operators with side effects */
		for (k = 0; k < pa->retc; k++)
			for (l = pb->retc; l < pb->argc; l++)
				if (pa->argv[k] == pb->argv[l])
					return FALSE;
	}
	return TRUE;
}

@}
@-
For each variable we should determine its scope of stability.
End-points in the flow graph are illustrative as dead-code,
that do not produce persistent data. It can be removed when
you know there are no side-effect.

Side-effect free evaluation is a property that should be known upfront.
For the time being, we assume it for all operations known to the system.
The property `unsafe` is reserved to identify cases where this does not hold.
Typically, a bun-insert operation is unsafe, as it changes one of the parameters.
@{
@c
int
showOutFlow(MalBlkPtr mb, int pc, int varid, stream *f)
{
	InstrPtr p;
	int i, k;

	for (i = pc + 1; i < mb->stop - 1; i++) {
		p = getInstrPtr(mb, i);
		for (k = p->retc; k < p->argc; k++)
			if (p->argv[k] == varid) {
				stream_printf(f, "n%d -> n%d\n", pc, i);
			}
	}
	return 0;
}

@-
At a later stage we could extend the flow details with the status
of crucial properties, e.g. processing time, cost, size
@c
void
showFlowDetails(MalBlkPtr mb, MalStkPtr stk, InstrPtr p, int pc, stream *f)
{
	str s, msg;

	(void) stk;		/* fool the compiler */
	msg = instruction2str(mb, p, 0);
	stream_printf(f, "n%d [fontsize=8, shape=box, label=\"", pc);
	for (s = msg; *s; s++)
		if (*s == '"')
			stream_printf(f, "\\\"");
		else
			stream_printf(f, "%c", *s);
	stream_printf(f, "\"];\n");
	GDKfree(msg);
}

void
showFlowGraph(MalBlkPtr mb, MalStkPtr stk, str fname)
{
	stream *f;
	InstrPtr p;
	int i, k;

	(void) stk;		/* fool the compiler */

	if (idcmp(fname, "stdout") == 0)
		f = GDKout;
	else
		f = open_wastream(fname);
	p = getInstrPtr(mb, 0);
	stream_printf(f, "digraph %s{\n", functionName(p));
	p = getInstrPtr(mb, 0);
	showFlowDetails(mb, stk, p, 0, f);
	for (k = p->retc; k < p->argc; k++) {
		showOutFlow(mb, 0, p->argv[k], f);
	}
	for (i = 1; i < mb->stop - 1; i++) {
		p = getInstrPtr(mb, i);
		showFlowDetails(mb, stk, p, i, f);
		for (k = 0; k < p->retc; k++) {
			showOutFlow(mb, i, p->argv[k], f);
		}
	}
	stream_printf(f, "}\n");
	if (f != GDKout)
		stream_close(f);
}

@
Summarization of the data flow dependencies can be modelled as a dependency graph.
It can be made explicit or kept implicit using the operators needed.
We start with the latter. The primary steps to deal with is dead code removal.
@c
int
removeDeadSink(MalBlkPtr mb, int pc, InstrPtr p)
{
	/* detect if the destination variable is not used anymor */
	/* return if it worked out */
	(void) mb;
	(void) pc;
	(void) p;		/* fool the compiler */
	return FALSE;
}

int
removeDeadSource(MalBlkPtr mb, int pc, InstrPtr p)
{
	/* detect if the source variable is not used anymor */
	/* return if it worked out */
	(void) mb;
	(void) pc;
	(void) p;		/* fool the compiler */
	return FALSE;
}

@}
@- Basic Algebraic Blocks
Many code snippets produced by e.g. the SQL compiler is just 
a linear representation of an algebra tree/graph. Its detection
makes a number of optimization decisions more easy, because
the operations are known to be side-effect free within the tree/graph.
This can be used to re-order the plan without concern on impact of the outcome.
It suffice to respect the flow graph.
[unclear as what we need]

@node Optimizer toolkit, Alias Removal, Query Optimizer Framework , Optimizer landscape

@* The Optimizer Toolkit
In this section we introduce the collection of MAL optimizers 
included in the code base. The tool kit is incrementally built, triggered
by experimentation and curiousity. Several optimizers require
further development to cope with the many features making up the MonetDB system.
Such limitations on the implementation are indicated where appropriate.

@menu
* Alias Removal::
* Dead Code Removal::
* Accumulator Evaluations::
* Heuristic Rewrite Rules::
* Common Sub-Expression Removal::
* Empty Set Reduction::
* Singleton Set Replacement::
* Peephole Optimization::
* Multiplex Compiler::
* Garbage Collector::
* Code Factorization::
* Partitioned Database Optimizer::
* Strength Reduction::
* Costmodels::
* Variable Stack Reduction::
* Query Execution Plans::
@end menu

@node Alias Removal, Dead Code Removal, Optimizer toolkit, Optimizer toolkit
@+ Alias Removal
The routine @code{optimizer.aliasRemoval()}
walks through the program looking for simple
assignment statements, e.g. V:=W. It replaces all subsequent
occurrences of V by W, provided V is assigned a value once and
W does not change in the remainder of the code.
Special care should be taken for iterator blocks as illustrated in
the case below:
@verbatim
	i:=0;
	b:= "done";
barrier go:= true;
	c:=i+1;
	d:="step";
	v:=d;
	io.print(v);
	i:=c;
redo go:= i<2;
exit go;
	io.print(b);
	optimizer.aliasRemoval();
@end verbatim
The constant strings are propagated to the @code{print()} routine, while
the initial assigment @code{i:=0} should be retained. The code block becomes:
@verbatim
	i:=0;
barrier go:= true;
	c:=i+1;
	io.print("step");
	i:=c;
redo go:= i<2;
exit go;
	io.print("done");
@end verbatim
@{
The key decision is to find the next statement that
changes the candidate. 
Beware that parameters could be changed as part of a call.
They are marked as unsafe.
@c
int
ARnxtAssignment(MalBlkPtr mb, int pc, int varid)
{
	int i, k, blkcount = 0, used = 0;
	InstrPtr q;

	for (i = pc; i < mb->stop && isAlife(mb, varid, i); i++) {
		q = getInstrPtr(mb, i);
		for (k = 0; k < q->retc; k++)
			if (q->argv[k] == varid)
				goto ARfound;
		for (; k < q->argc; k++)
			if (q->argv[k] == varid) {
				used++;
				if (!isInvariant(mb, pc, i, varid))
					goto ARfound;
			}
		if (blockStart(q))
			blkcount++;
		if (blockExit(q))
			blkcount--;
		if (blockCntrl(q))
			blkcount--;
		if (blkcount < 0)
			break;	/* it is part of a block */
		if (blockCntrl(q))
			blkcount++;
	}
      ARfound:
	if (blkcount || !used)
		return pc - 1;
	return i;
}

@-
When you propagate an alias through the program, the properties
maintained should also be updated. In particular, the lifespan
of the alias changes as part of the move.
@c
void
ARreplaceAlias(MalBlkPtr mb, int pc, int pcl, int src, int alias)
{
	InstrPtr p;
	VarPtr v;
	int k;

	v = getVar(mb, alias);
	for (; pc < pcl; pc++) {
		p = getInstrPtr(mb, pc);
		for (k = p->retc; k < p->argc; k++)
			if (p->argv[k] == src) {
				p->argv[k] = alias;
				if (pc > v->endLifespan)
					v->endLifespan = pc;
			}
	}
}

@-
Alias removal is targeted at simple assignments only,
because MAL does not allow for nested expressions.
Instructions changing the flow of control should also be ignored.
In all other cases the target variables are potential candidates
for alias removal.
@c
int
ARoptimizerStep(MalBlkPtr mb, int pc)
{
	int k, kn = 0;
	InstrPtr p;

	p = getInstrPtr(mb, pc);
	if (p == 0 || moduleId(p) || functionId(p))
		return pc;
	if (p->token != ASSIGNsymbol)
		return pc;
	if (blockStart(p) || blockExit(p) || blockCntrl(p))
		return pc;

	for (k = 0; k < p->retc; k++) {
		int m;

		m = ARnxtAssignment(mb, pc + 1, p->argv[k]);
		if (m != pc) {
			ARreplaceAlias(mb, pc + 1, m, p->argv[k], p->argv[p->retc + k]);
			kn++;
#ifdef DEBUG_MAL_OPTIMIZER
			if (getClient()->debugOptimizer) {
				stream_printf(GDKout, "Delete alias assignment\n");
				printInstruction(GDKout, mb, p, LIST_MAL_ALL);
			}
#endif
		}
	}
	/* delete the instruction if all targets have been replaced */
	if (kn == p->retc && kn) {
		/* all target variables pushed through */
		removeInstruction(mb, p);
		setLifespan(mb);
		return pc - 1;
	}
	return pc;
}

str
ARoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	int i;
	lng clk = GDKusec();

	(void) stk;
#ifdef DEBUG_MAL_OPTIMIZER
	if (getClient()->debugOptimizer) {
		stream_printf(GDKout, "start alias removal\n");
		printFunction(GDKout, mb, LIST_MAL_ALL);
	}
#endif
	setLifespan(mb);
	for (i = 1; i < mb->stop; i++)
		i = ARoptimizerStep(mb, i);
	/* remove the ARoptimizer request */
	if (pci)
		removeInstruction(mb, pci);
	optimizerCheck(mb, "aliasRemoval", 1, GDKusec() - clk);
	return NULL;
}

@}
@-
@node Dead Code Removal, Accumulator Evaluations, Alias Removal, Optimizer toolkit
@+ Dead Code Removal
Dead code fragments are recognized by assignments to variables
whose value is not consumed any more. 
It can be detected  by marking all variables used as 
arguments as being relevant. 
In parallel, we built a list of instructions that should appear 
in the final result.
The new code block is than built in one scan, discarding the
superflous instructions.

Instructions that produce side effects to the environment, 
e.g. printing and BAT updates, should be taken into account. 
Such (possibly recursive) functions should be marked with a property 
(@code{unsafe}) For now we recognize a few important ones
Likewise instructions marked as control flow instructions should be retained.

An illustrative example is the following MAL snippet:
@verbatim
	V7 := bat.new(:void,:int);
	V10 := bat.new(:int,:void);
	V16 := algebra.markH(V7);
	V17 := algebra.join(V16,V7);
	V19 := bat.new(:void,:int);
	V22 := bat.new(:void,:int);
	V23 := algebra.join(V16,V22);
	io.print("done");
	optimizer.deadCodeRemoval();
@end verbatim
The dead code removal trims this program to the following short block:
@verbatim
    io.print("done");
@end verbatim

@{
The dead code remover should
not be used for testing, because it will trim most programs to
an empty list.
@c
int
hasSideEffects(InstrPtr p, int strict)
{
	if (blockStart(p) || blockExit(p) || blockCntrl(p))
		return TRUE;
	if (functionId(p) && strncmp("print", functionName(p), 5) == 0)
		return TRUE;
	if (functionId(p) && idcmp("deposit", functionName(p)) == 0)
		return TRUE;
	if (functionId(p) && idcmp("insert", functionName(p)) == 0)
		return TRUE;
	if (strict && functionId(p) && idcmp("new", functionName(p)) == 0)
		return TRUE;
	if (functionId(p) && idcmp("append", functionName(p)) == 0)
		return TRUE;
	if (functionId(p) && idcmp("delete", functionName(p)) == 0)
		return TRUE;
	if (functionId(p) && idcmp("destroy", functionName(p)) == 0)
		return TRUE;
	if (functionId(p) && idcmp("prelude", functionName(p)) == 0)
		return TRUE;
	if (functionId(p) && idcmp("decimal_prelude", functionName(p)) == 0)
		return TRUE;
	if (functionId(p) && idcmp("keep", functionName(p)) == 0)
		return TRUE;
	return FALSE;
}

str
DCoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	int i, j, k, dc = 0, se;
	InstrPtr p;
	int *varused;
	int *pcused;
	int actions = 0;
	lng clk = GDKusec();

	(void) pci;
	(void) stk;		/* to fool compilers */

	varused = GDKmalloc(mb->vtop * sizeof(int));
	for (i = 0; i < mb->vtop; i++)
		varused[i] = 0;

	pcused = GDKmalloc(mb->stop * sizeof(int));
	for (i = 0; i < mb->stop; i++)
		pcused[i] = 0;

	for (i = mb->stop - 1; i >= 0; i--) {
		p = getInstrPtr(mb, i);
		switch (p->token) {
		case FUNCTIONsymbol:
		case COMMANDsymbol:
		case FACTORYsymbol:
		case ENDsymbol:
			pcused[i] = 1;
			for (k = 0; k < p->retc; k++)
				varused[p->argv[k]] = 1;
			break;
		case EXITsymbol:
			/*     stream_printf(getClient()->fdout,"#Handle DCR in iterator\n"); */
		case RETURNsymbol:
			pcused[i] = 1;
			for (k = 0; k < p->retc; k++)
				varused[p->argv[k]] = !isTypeVar(mb, p->argv[k]);
			break;
		default:
			se = 0;
			for (k = 0; k < p->argc; k++)
				if (varused[p->argv[k]])
					se++;
			/* do not deal with dead barrier blocks */
			if (blockCntrl(p) || hasSideEffects(p, FALSE) || se) {
				for (k = 0; k < p->argc; k++)
					varused[p->argv[k]] = !isTypeVar(mb, p->argv[k]);
				pcused[i] = 1;
			} else
				dc++;
		}
	}
#ifdef DEBUG_MAL_OPTIMIZER
	{
		Client cntxt = getClient();

		stream_printf(GDKout, "Dead code variables \n");
		for (i = 0; i < mb->vtop; i++)
			if (varused[i] == 0)
				stream_printf(cntxt->fdout, "%s,", getVarName(mb, i));
		stream_printf(getClient()->fdout, "\nDead code instructions \n");
		for (i = 1; i < mb->stop; i++)
			if (pcused[i] == 0)
				printInstruction(cntxt->fdout, mb, getInstrPtr(mb, i), LIST_MAL_ALL);
		stream_printf(cntxt->fdout, "End of DCoptimizer\n");
	}
#endif
	/* compress the code block */
	for (i = j = 1; i < mb->stop; i++) {
		if (pcused[i]) {
			mb->stmt[j] = mb->stmt[i];

			j++;
		} else {
			p = getInstrPtr(mb, i);
			freeInstruction(p);
			actions++;
		}
	}
	mb->stop = j;
	GDKfree(varused);
	GDKfree(pcused);
	optimizerCheck(mb, "deadCodeRemoval", actions, GDKusec() - clk);
	/* remove the DCoptimizer request */
	return NULL;
}

@}

@-
@node Accumulator Evaluations, Heuristic Rewrite Rules, Dead Code Removal, Optimizer toolkit
@+ Accumulator Evaluations
Bulk arithmetic calculations are pretty expensive,
because new @code{BAT}s are created for each expression. 
This memory hunger can be reduced
by detecting opportunities for accummulator processing, i.e.
where a (temporary) variable is overwritten.
For example, consider the program snippet
@example
	t3:= batcalc.*(64,t2);
	t4:= batcalc,+(t1,t3);
	optimizer.expressionAccumulation();
@end example
If variable t2 is not used any further and retains its type throughout
the program block, we can re-use its storage space
and propagate its alias through the remainder of the code.
@example
	batcalc.*(t2,64,t2);
	t4:= batcalc.+(t2,t1,t2);
@end example
The implementation is straight forward. It only deals with the
arithmetic operations available in @code{batcalc} right now.
This set will be gradually be extended.
The key decision is to determine whether we may overwrite
any of the arguments. We assume this is permissible if the argument
was produced by an operator from the @code{algebra, algebra2, group, aggrX3}
modules.
@{
@c
int
AEvalidSource(MalBlkPtr mb, int v, int pc, int stop)
{
	InstrPtr p;
	int i, j;

	for (i = pc - 1; i >= stop; i--) {
		p = getInstrPtr(mb, i);
		if (p->barrier)
			return 0;
		switch (p->token) {
		case FUNCTIONsymbol:
		case FACTORYsymbol:
		case COMMANDsymbol:
		case THREADsymbol:
		case EXITsymbol:
		case CATCHsymbol:
		case RAISEsymbol:
		case RETURNsymbol:
		case YIELDsymbol:
		case ENDsymbol:
			return 0;
		}
		for (j = 0; j < p->retc; j++)
			if (getArg(p, j) == v) {
				if (moduleId(p) && strcmp(moduleId(p), "batcalc") == 0)
					return 1;
				if (moduleId(p) && strcmp(moduleId(p), "algebra") == 0)
					return 1;
				if (moduleId(p) && strcmp(moduleId(p), "aggrX3") == 0)
					return 1;
				if (moduleId(p) && strcmp(moduleId(p), "group") == 0)
					return 1;
				if (moduleId(p) && strcmp(moduleId(p), "array") == 0)
					return 1;
			}
	}
	return 1;
}

void
AEcoercionOptimizer(MalBlkPtr mb, int i, InstrPtr p)
{
	int t, a, b;

	a = getArg(p, 0);
	b = getArg(p, 1);
	t = getVarType(mb, b);
	if (strcmp(functionName(p), "int") == 0 && t == TYPE_int) {
		removeInstruction(mb, p);
		ARreplaceAlias(mb, i, mb->stop, a, b);
		return;
	}
	if (strcmp(functionName(p), "str") == 0 && t == TYPE_str) {
		removeInstruction(mb, p);
		ARreplaceAlias(mb, i, mb->stop, a, b);
		return;
	}
	if (strcmp(functionName(p), "oid") == 0 && t == TYPE_oid) {
		removeInstruction(mb, p);
		ARreplaceAlias(mb, i, mb->stop, a, b);
		return;
	}
	if (strcmp(functionName(p), "lng") == 0 && t == TYPE_lng) {
		removeInstruction(mb, p);
		ARreplaceAlias(mb, i, mb->stop, a, b);
		return;
	}
	if (strcmp(functionName(p), "sht") == 0 && t == TYPE_sht) {
		removeInstruction(mb, p);
		ARreplaceAlias(mb, i, mb->stop, a, b);
		return;
	}
	if (strcmp(functionName(p), "bit") == 0 && t == TYPE_bit) {
		removeInstruction(mb, p);
		ARreplaceAlias(mb, i, mb->stop, a, b);
		return;
	}
	if (strcmp(functionName(p), "dbl") == 0 && t == TYPE_dbl) {
		removeInstruction(mb, p);
		ARreplaceAlias(mb, i, mb->stop, a, b);
		return;
	}
	if (strcmp(functionName(p), "flt") == 0 && t == TYPE_flt) {
		removeInstruction(mb, p);
		ARreplaceAlias(mb, i, mb->stop, a, b);
		return;
	}
}
str
AEoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	int i, j, a, b, depth;
	InstrPtr p;
	Client cntxt = getClient();
	Module scope = cntxt->nspace;
	char *olderr;
	int errlen, actions = 0;
	lng clk = GDKusec();

	(void) pci;
	(void) stk;		/* to fool compilers */
@-
Safe the errors encountered sofar. They have to be reset
at the end of the optimization attempt.
@c
	errlen = strlen(cntxt->errbuf) + 1;
	olderr = alloca(errlen);
	if (errlen)
		strncpy(olderr, cntxt->errbuf, errlen);
	if (errlen)
		strncpy(cntxt->errbuf, olderr, errlen);

	for (i = 1; i < mb->stop; i++) {
		VarPtr v;

		p = getInstrPtr(mb, i);
		if (moduleId(p) == NULL)
			continue;
		if (strcmp(moduleId(p), "calc") == 0) {
			AEcoercionOptimizer(mb, i, p);
			continue;
		}
		if (strcmp(moduleId(p), "batcalc"))
			continue;

		depth = getVarDepth(mb, getArg(p, 0));
		if (p->argc == 3) {
			/* binary/unary operation, check first argument */
			v = getVar(mb, a = getArg(p, 1));
			b = getArg(p, 0);

#ifdef DEBUG_MAL_OPTIMIZER
			stream_printf(GDKout, "Found binary OR candidate \n");
			stream_printf(GDKout, "pc=%d valid=%d \n", i, AEvalidSource(mb, a, i, v->beginLifespan));
			stream_printf(GDKout, "target %d %d-%d\n", b, getVar(mb, b)->beginLifespan, getVar(mb, b)->endLifespan);
			stream_printf(GDKout, "arg 1 %d %d-%d\n", a, v->beginLifespan, v->endLifespan);
			stream_printf(GDKout, "arg 2 %d %d-%d\n", getArg(p, 2), getVar(mb, getArg(p, 2))->beginLifespan, getVar(mb, getArg(p, 2))->endLifespan);
			printInstruction(GDKout, mb, p, LIST_MAL_ALL);
#endif
			if (isaBatType(v->type) && (v->endLifespan == i || a == b) && v->depth <= depth) {
				if (AEvalidSource(mb, a, i, v->beginLifespan) || a == b) {
					pushArgument(mb, p, a);
					for (j = p->argc - 1; j > p->retc; j--)
						p->argv[j] = p->argv[j - 1];
					p->argv[p->retc] = p->argv[0] = a;
					typeChecker(scope, mb, p, TRUE);

					if (a != b)
						ARreplaceAlias(mb, i + 1, mb->stop, b, a);
#ifdef DEBUG_MAL_OPTIMIZER
					stream_printf(GDKout, "FIRST\n");
					printInstruction(GDKout, mb, p, LIST_MAL_ALL);
#endif
					actions++;
					continue;
				}
			}
			/* continue with binary version */
			v = getVar(mb, a = getArg(p, 2));
			if (isaBatType(v->type) && (v->endLifespan == i || a == b) && v->depth <= depth) {
				if (AEvalidSource(mb, a, i, v->beginLifespan) || a == b) {
					pushArgument(mb, p, a);
					for (j = p->argc - 1; j > p->retc; j--)
						p->argv[j] = p->argv[j - 1];
					p->argv[0] = p->argv[p->retc] = a;
					typeChecker(scope, mb, p, TRUE);

					if (a != b)
						ARreplaceAlias(mb, i + 1, mb->stop, b, a);
#ifdef DEBUG_MAL_OPTIMIZER
					stream_printf(GDKout, "SECOND\n");
					printInstruction(GDKout, mb, p, LIST_MAL_ALL);
#endif
					actions++;
					continue;
				}
			}
		} else if (p->argc == 2) {
			/* binary/unary operation, check first argument  and return type */
			int olderr = mb->errors;

			v = getVar(mb, a = getArg(p, 1));
			b = getArg(p, 0);

			if (isaBatType(v->type) && (v->endLifespan == i || a == b) && v->depth <= depth) {
				if (AEvalidSource(mb, a, i, v->beginLifespan) || a == b) {
#ifdef DEBUG_MAL_OPTIMIZER
					stream_printf(GDKout, "Found unary OR candidate\n");
					printInstruction(GDKout, mb, p, LIST_MAL_ALL);
#endif
					mb->errors = 0;
					p->argv[0] = a;
					typeChecker(scope, mb, p, TRUE);

					if (p->typechk == TYPE_UNKNOWN) {
						mb->errors = olderr;
						p->argv[0] = b;
						typeChecker(scope, mb, p, TRUE);
					} else if (a != b)
						ARreplaceAlias(mb, i + 1, mb->stop, b, a);
					actions++;
				}
			}
		}
	}
	if (errlen)
		strncpy(cntxt->errbuf, olderr, errlen);
	/* remove the AEoptimizer request */
	optimizerCheck(mb, "expressionAccumulation", actions, GDKusec() - clk);
	if (mb->errors) {
		showErrors();
		return throwMessage("AEoptimizer", "Optimization raised errors");
	}
	return MAL_SUCCEED;
}

@}
@-
@node Heuristic Rewrite Rules, Common Sub-Expression Removal, Accumulator Evaluations,  Optimizer toolkit
@+ Heuristic rewrites rules
One of the oldest optimizer tricks in relational query processing is
to apply heuristic rules to reduce the processing cost. For example,
a selection predicate is pushed through another operator to reduce
the number of tuples to consider.
Heuristic rewrites are relatively easy to apply in a context where 
the expression is still close to a relational algebra tree.
Therefore, many of the standard rewrite rules are already applied by the SQL
front-end as part of its strategic optimization decisions.

Finding rewrite opportunities within a linear MAL program may
be more difficult. For, the pattern should respect the flow
of control that may already be introduced.
The last resort for the optimizer builder is to write a
C-function to look for a pattern of interest and transform it.
The code base contains an example how to built such 
user specific optimizer routines.
It translates the pattern:
@example
y:= reverse(R);
z:= select(y,l,h);          
@end example
into the statement:
@example
z:= selectHead(x,R,l,h) 
@end example

@{
@-
During a final pass through the program, we can convert all combinators 
back into their elementary steps.
@= fndOperator
    (( moduleId(@1)==0 || (@2 && idcmp(moduleName(@1),@2)==0) ) &&
         (functionId(@1)==0 || (@3 && idcmp(functionName(@1),@3)==0) ))
@-
A more complete implementation should als push the selection through
multiple operators. In particular, a reverse operator may obscure
the opportunity to perform the select push through. 
@c
int
SPcombi000(MalBlkPtr mb, int pc1, int pc2)
{
	InstrPtr p, q;

	p = getInstrPtr(mb, pc1);
	q = getInstrPtr(mb, pc2);
	if (@:fndOperator(p, "bat", "reverse")@) {
		if (@:fndOperator(q, "algebra", "select")@) {
			if (p->argv[0] == q->argv[1]) {
				setModuleId(p, putName("algebra", 7));
				setFunctionId(p, putName("reverse_select", 14));
				p = pushArgument(mb, p, q->argv[1]);
				p = pushArgument(mb, p, q->argv[2]);
				p = pushArgument(mb, p, q->argv[3]);
				removeInstruction(mb, q);
				chkFlow(mb);
				chkDeclarations(mb, TRUE);
				return 1;
			}
		}
	}
	return 0;
}

int
SPsqueezer000(MalBlkPtr mb, int pc1, int pc2)
{
	InstrPtr p, q;

	p = getInstrPtr(mb, pc1);
	q = getInstrPtr(mb, pc2);
	(void) p;
	(void) q;		/* do something useful later on */
	return 0;
}

str
HRoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	int i, k, combis = 0, squeeze = 0;
	InstrPtr p;
	lng clk = GDKusec();

	(void) stk;		/* fool compilers */

	/* process the combinators */
	for (i = 0; i < mb->stop - 1; i++) {
		p = getInstrPtr(mb, i);
		for (k = i + 1; k < mb->stop && isAlife(mb, p->argv[0], k); k++)
			if (SPcombi000(mb, i, k)) {
#ifdef DEBUG_MAL_OPTIMIZER
				if (getClient()->debugOptimizer) {
					stream_printf(GDKout, "Combinator found\n");
					printInstruction(GDKout, mb, getInstrPtr(mb, i), LIST_MAL_ALL);
				}
#endif
				combis++;
				k--;	/* an instruction has been removed */
				setLifespan(mb);	/* expensive but needed */
			}
	}
	/* process the squeezers */
	for (i = 0; i < mb->stop - 1; i++) {
		p = getInstrPtr(mb, i);
		for (k = i + 1; k < mb->stop && isAlife(mb, p->argv[0], k); k++)
			if (SPsqueezer000(mb, i, k)) {
#ifdef DEBUG_MAL_OPTIMIZER
				if (getClient()->debugOptimizer) {
					stream_printf(GDKout, "Squeezer found\n");
					printInstruction(GDKout, mb, getInstrPtr(mb, i), LIST_MAL_ALL);
				}
#endif
				squeeze++;
				k--;	/* an instruction has been removed */
			}
	}

	/* remove the HRoptimizer request */
	if (pci)
		removeInstruction(mb, pci);
	optimizerCheck(mb, "selectPushDown", squeeze, GDKusec() - clk);
	return NULL;
}

@-
Pushing a selection geared at the left operand through the join operator
is more complex, because you can only recognize those instances when later
on the semijoin is recognized. The pattern we are looking for
@T
\begin{verbatim}
AD := join (AB, CD);
ZZ := semijoin (AB, AD);
Za := select(ZZ, l,h);
\end{verbatim}
@-
Note that this operation depends on HRoptimizer, because it already
pushes down the selection through the semijoin.
Should be done differently

@+ Access Mode optimizer
Another example of a heuristic optimizer, which was used 
at one point in the SQL optimizer.
Walk through the program code searching for setWriteMode
and make sure it is done once per basic block. It assumes
that instructions do not change the access mode as a side
effect.
@c
static MALfcn AMsetWriteMode;

int
AMoptimizerStep(MalBlkPtr mb, int pc)
{
	int k, kn = 0;
	InstrPtr p;
	lng clk = GDKusec();
	int actions = 0;

	p = getInstrPtr(mb, pc);
	if (p->fcn != AMsetWriteMode)
		return pc;
	kn = getArg(p, 1);

	for (k = pc - 1; k > 1; k--) {
		p = getInstrPtr(mb, k);
		if (p->barrier)
			return pc;
		if (p->fcn != AMsetWriteMode)
			continue;
		if (getArg(p, 1) == kn) {
			if (p)
				removeInstruction(mb, p);
			actions++;
			return pc - 1;
		}
	}
	optimizerCheck(mb, "accessMode", actions, GDKusec() - clk);
	return pc;
}

str
AMoptimizer(MalBlkPtr mb, MalStkPtr stk, InstrPtr pci)
{
	int i;
	Symbol s;

	(void) stk;
	s = findMALSymbol("bat", "setWriteMode");
	if (s == 0)
		return throwMessage("AMoptimizer", "bat.setWriteMode missing\n");
	AMsetWriteMode = getSignature(s)->fcn;
	for (i = 1; i < mb->stop; i++)
		i = AMoptimizerStep(mb, i);
	/* remove the AMoptimizer request */
	if (pci)
		removeInstruction(mb, pci);
	return MAL_SUCCEED;
}

@}
