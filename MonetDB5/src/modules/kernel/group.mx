@' The contents of this file are subject to the MonetDB Public License
@' Version 1.1 (the "License"); you may not use this file except in
@' compliance with the License. You may obtain a copy of the License at
@' http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html
@'
@' Software distributed under the License is distributed on an "AS IS"
@' basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the
@' License for the specific language governing rights and limitations
@' under the License.
@'
@' The Original Code is the MonetDB Database System.
@'
@' The Initial Developer of the Original Code is CWI.
@' Portions created by CWI are Copyright (C) 1997-2006 CWI.
@' All Rights Reserved.

@f group
@a M.L. Kersten, P. Boncz, A.P. de Vries, N.J. Nes
@v 2.3
@* The group module
This module contains the primitives to construct, derive, and
perform statistical operations on BATs representing groups.
The default scheme in Monet is to assume the head to represent
the group identifier and the tail an element in the group.

Groups play an important role in datamining, where they are used
to construct cross-tables. Such cross tables over a single
BAT are already supported by the histogram function.
This module provides extensions to support identification of groups in a
(multi-)dimensional space.

The module implementation has a long history. The first implementation
provided several alternatives to produce/derive the grouping.
A more complete (and complex) scheme was derived during its
extensive use in the context of the Data Distilleries  product.
The current implementation is partly a cleanup of this code-base,
but also enables provides better access to the intermediate
structures produced in the process, i.e. the histogram and
the sub-group mapping. They can be used for various optimization
schemes at the MAL level.

The prime limitation of the current implementation is that an
underlying database of @{oid->any@} BATs is assumed.
This enables representation of each group using an oid,
and the value representation of the group can be accordingly be
retrieved easily. An optimized implementation in which we use positional
integer id's (as embodied by Monet's void type) is also available.

This limitation on (v)oid-headers is marginal. The primitive GRPsplit
produces for any BAT two copies with both a (v)oid header.
@+ Algorithms
There are several approaches to build a cross table. The one chosen here
is aimed at incremental construction, such that re-use of intermediates
becomes possible. Starting with the first dimension, a BAT is derived to
represent the various groups, called a @emph{GRP BAT} or cross-table BAT.

@- Cross Table (GRP)
A cross table is an <oid,oid> BAT where the first (head) denotes a tuple in
the cross table and the second (tail) marks all identical lists.
The tail-oids contain group identifiers; that is, @emph{this value is equal
@strong{iff} two tuples belong to the same group}. The group identifiers are
chosen from the domain of the tuple-identifiers. This simplifies
getting back to the original tuples, when talking about a group.
If the tuple-oid of 'John' is chosen as a group-id, you might view this
as saying that each member of the group is 'like John' with respect
to the grouping-criterion.

@- 
Successively the subgroups can be identified by modifying the GRP BAT or
to derive a new GRP BAT for the subgroups. After all groups have been
identified this way, a BAT histogram operation can be used to obtain
the counts of each data cube. Other aggregation operations using the MIL
set aggregate construct @{X@}(bat) (see the
@[<a href="../../../FrontEnds/mil/mil.html#mod_3_2_0">MIL Reference Manual</a>@) 
can be used as well; note for instance that histogram == @{count@}(b.reverse()).

The Monet interface module specification is shown below.
Ideally we should defined stronger type constraints, e.g.
command group.new(attr:bat[@{void,oid@},:any_1]

@mal
module group;

command new(b:bat[:any_1,:any_2], start:int, incr:int, grpsize:int)
			:bat[:any_1,:int] 
address GRPgroup0
comment "Produces a new BAT with identical head column, and in the tail 
		column groups of equally valued integers within each group. 
		Parameters: a start group -value, -number increment, -size.";

command new(attr:bat[:any_1,:any_2] )
	(histo:bat[:any_1,:int], grp:bat[:any_1,:void]) 
address GRPgroup;

command new(attr:bat[:any_1,:any_2] )
	(histo:bat[:any_1,:int], grp:bat[:any_1,:oid]) 
address GRPgroup;

command new(attr:bat[:any_1,:any_2], N:int, rng:int)
	(histo:bat[:any_1,:int],grp:bat[:any_1,:oid]) 
address GRPgroup_custom
comment "Cross tabulation group initialization like GRPgroup, but with 
		user provided #bits in hashmask and #distinct values in range.";

command derive(hist:bat[:any_1,:int], map:bat[:any_1,:oid], attr:bat[:any_1,:any_2])
	(histo:bat[:any_1,:int],grp:bat[:any_1,:oid]) 
address GRPderive
comment "Cross tabulation group extension step.  Returned head values are 
		identical as in 'ct'. Tail values are from the same domain and 
		indicate further refinement of the groups in 'ct', taking into 
		account also the tail-values in 'attr'.";
command derive(histo:bat[:void,:int], map:bat[:void,:oid], attr:bat[:oid,:any_2])
	(hist:bat[:oid,:int],grp:bat[:oid,:oid]) 
address GRPderive;

command refine(b:bat[:any_2,:any_3], a:bat[:any_2,:any_1]) :bat[:any_2,:oid] 
address GRPrefine
comment "refine the ordering of a tail-ordered BAT by sub-ordering on the 
		values of a second bat 'a' (where the heads of a and b match 1-1).
		The effect of this is similar to (hash-based) GRPderive, with the 
		distinction that the group ids respect the ordering of the group 
		values.";

command refine(b:bat[:oid,:any_3], a:bat[:void,:any_1]) :bat[:oid,:oid] 
address GRPrefine;
command refine(b:bat[:void,:any_3], a:bat[:oid,:any_1]) :bat[:oid,:oid] 
address GRPrefine;

command refine_reverse(b:bat[:any_2,:any_3], a:bat[:any_2,:any_1]) :bat[:any_2,:oid] 
address GRPrefine_rev
comment "refine the ordering of a tail-ordered BAT by sub-ordering on the 
		values of a second bat 'a' (where the heads of a and b match 1-1).
		The effect of this is similar to (hash-based) GRPderive, with the 
		distinction that the group ids respect the ordering of the group 
		values.";
@-
@+ Group Aggregate operations

This module also contains some efficient aggregate functions over
groups that compute their result in one scan.

For the groups we assume a bat structure where the head indicates the group
and the tail contains the group elements. This leads to the situation that
most value-based operators work on the tail, while counting groups
is focussed on the head.
@= grpSignature
command sum(b:bat[:any_2,:@1], e:bat[:any_2,:any_1]) :bat[:any_2,:@1] 
address GRPsum_@1
comment "grouped tail sum";

command sum(b:bat[:any_2,:@1], size:int) :bat[:any_2,:@1] 
address GRPwindowsum_@1
comment "Tail sum of groups of a fixed size";

command sum(b:bat[:any_2,:@1], size:int, shift:int) :bat[:any_2,:@1] 
address GRPslidingsum_@1
comment "Tail sum of groups of a sliding window of fixed size";

command avg(b:bat[:any_2,:@1], e:bat[:any_2,:any_1]) :bat[:any_2,:@1] 
address GRPavg_@1
comment "grouped tail average";

@-
Not used yet
#command min(b:bat[:any_2,:@1], size:int) :bat[:any_2,:@1] 
#address GRPwindowmin@1
#comment "Tail minimum of groups of a fixed size";
#command max(b:bat[:any_2,:@1], size:int) :bat[:any_2,:@1] 
#address GRPwindowmax@1
#comment "Tail minimum of groups of a fixed size";
@mal
	@:grpSignature(sht)@
	@:grpSignature(int)@
	@:grpSignature(lng)@
	@:grpSignature(flt)@
	@:grpSignature(dbl)@

command min(b:bat[:any_2,:any_1], e:bat[:any_2,:any_3]) :bat[:any_2,:any_1] 
address GRPmin
comment "Grouped tail minimum";
command max(b:bat[:any_2,:any_1], e:bat[:any_2,:any_3]) :bat[:any_2,:any_1] 
address GRPmax
comment "Grouped tail maximum";

command count(b:bat[:any_2,:any_1], e:bat[:any_2,:any_3], nonils:bit) :bat[:any_2,:int] 
address GRPaggr_count
comment "Grouped count";
command size(b:bat[:any_2,:bit], e:bat[:any_2,:any_1]) :bat[:any_2,:int] 
address GRPsize
comment "Grouped count of true values";

@{
@-
We need a few routines to support MonetDB/XQ implementation.
They are focussed on edge BATs [:oid,:oid] where the tail is
assumed a sequence and the head denotes a group.
Finding the first and last element maps into finding
the min/max oid within a group.
@= xqMinMaxDef
command min(b:bat[:oid,:@1]):bat[:oid,:@1]
address GRPmin_oid_@1
comment "Select the minimum element of each group";

command max(b:bat[:oid,:@1]):bat[:oid,:@1]
address GRPmax_oid_@1
comment "Select the minimum element of each group";

@mal
 @:xqMinMaxDef(oid)@
 @:xqMinMaxDef(sht)@
 @:xqMinMaxDef(int)@
 @:xqMinMaxDef(lng)@
 @:xqMinMaxDef(flt)@
 @:xqMinMaxDef(dbl)@

command prelude()
address GRPprelude;

group.prelude();
@* Implementation Code
Inclusion of the xtables requires some preliminary definitions
and als renaming :group by something else, because Mx can;t handle
macros identical to file names.
@h
#ifndef _GROUP_H_
#define _GROUP_H_
#include "gdk.h"

extern int CTderive(BAT **B, BAT **H, BAT *ct_hist, BAT *ct_map, BAT *b);
extern int CTgroup(BAT **B, BAT **H, BAT *b);

#endif /* _GROUP_H_ */
@c
#include "group.h"
#include "algebra.h"
static int TYPE_mapentry;
static int TYPE_idxentry;


int
grp_new(BAT *b, BAT *h)
{
	if (h) {
		BATkey(h, TRUE);
		BATkey(BATmirror(h), FALSE);
		h->tsorted = 0;
		if ((h->hsorted = BAThordered(b)) & 1) {
			if (BATcount(h) == BATcount(b)) {
				ALIGNsetH(h, BATmirror(b));
			}
		} else if (BATorder(h) == NULL) {
			BBPreclaim(h);
			if (b) BBPreclaim(b);
			return GDK_FAIL;
		}
		BBPkeepref(h->batCacheid);
	} else {
		assert(h);
	}
	BBPkeepref(b->batCacheid);
	return GDK_SUCCEED;
}


@+ Core Grouping Algorithms
We use hash-grouping all the way. This implementation employs
a simple sequential scan through the operands, adding group
values to a hash-table. This hash-table gives access to the group
identifiers, which are always OIDs.

This strategy is also followed on binary groupings; here
we construct a special integer consisting of the XORed hashnumber
of both columns. In such a way, we can build a hash table on
map_entries (instead of simple atomic values -- the unary case).

In the unary group case, we optimized processing on 1-byte
and 2-byte values by using direct mapping in an array instead of
hashing.
@c
#define HASH_chr(p) ((hash_t) (*(unsigned char*) (p)))
#define HASH_sht(p) ((hash_t) (*(unsigned short*) (p)))
#define HASH_int(p) ((hash_t) *(unsigned int*) (p))
#define HASH_lng(p) ((hash_t)(((unsigned int*)(p))[0]^((unsigned int*)(p))[1]))
#define HASH_any(p) ((*hashfcn)(p))

#define match_sync(b,p,r) r += yy
#define match_hash(b,p,r) BUNfndOID(r,b,p); if (r == NULL) continue;

#define declare_atom int any = b->ttype; hash_t (*hashfcn)(ptr) = BATatoms[any].atomHash;
#define declare_simple	/* any and hash would otherwise give unused variable warning */

#define htype_sync(b) BAThdense(b)?TYPE_void:TYPE_oid
#define htype_hash(b) TYPE_oid

#define ttype_simple(b,t) t
#define ttype_atom(b,t) b->ttype

#define STANDARD_MASK ((hash_t) 1023)

/*
   Note:
	following macros take advantage of clustered property;
	if b is clustered, then we can stop early traversing collision lists.

	BTW, simply stopping possibly breaks chain construction, so the resulting
	map is not directly reuseable as a hash table; the current Monet cannot
	however handle multiple accellerators, so this ain't a real problem for now :)
 */

#define declare_unclustered	/* avoid warning */
#define declare_clustered   int samecluster = TRUE;

#define chain_unclustered   for (zz = hash[c]; zz != HASH_MAX; zz = e->link)
#define chain_clustered     for (zz = hash[c]; (zz != HASH_MAX) && (samecluster); zz = e->link)

#define tst_grp_unclustered(eq,p,t)    (eq(p, tcur, t))
#define tst_grp_clustered(eq,p,t)      (samecluster = eq(p, tcur, t))

#define tst_derive_unclustered(eq,p,t) (e->hcur == hcur && eq(p, tcur, t))
#define tst_derive_clustered(eq,p,t)   ((samecluster = e->hcur == hcur) && eq(p, tcur, t))

/* NOTE: the first two fields of idxentry_t and mapentry_t MUST be the
   same */
typedef struct {
	oid hcur;		/* old group id */
	hash_t link;		/* hash link */
} idxentry_t;

typedef struct {
	oid hcur;		/* old group id */
	hash_t link;		/* hash link */
	oid gid;		/* new group id */
	int cnt;		/* histogram count */
} mapentry_t;

typedef struct {
	BAT *map;		/* [mapentry,value] elements */
	hash_t *hash, mask;	/* hash buckets and mask */
	Heap hp;		/* storage for hash buckets */
} map_T;

@:map_init_def(STANDARD,STANDARD_MASK,4096)@
@:map_init_def(CUSTOM,custom_MASK,custom_rng)@

@= map_init_def
#define map_init_@1(map,hash,mask,entry,mapsize)			\
	if (m) {							\
		map = m->map; hash = m->hash; mask = m->mask;		\
	} else {							\
		hash_t yy;						\
		map = BATnew(TYPE_mapentry, tailtype(b,TRUE), @3);	\
		hash = (hash_t*) GDKmalloc((int)(sizeof(hash_t)*((mask=@2)+1))); \
		for (yy=0; yy<=@2; yy++) {				\
			hash[yy] = HASH_MAX;				\
		}							\
	}								\
	entry.cnt = 1;							\
	mapsize = BUNindex(map, BUNlast(map));
@c
void
map_free(map_T m)
{
	BBPreclaim(m.map);
	HEAPfree(&m.hp);
}

#ifndef offsetof
#define offsetof(type, member)	((size_t) &((type *) 0)->member)
#endif

BAT *
map2histo(BAT *map)
{
	if (map == NULL || map->htype != TYPE_mapentry || VIEWparent(map) || map->batSharecnt > 1 || BATgetaccess(map) != BAT_WRITE) {
		if (map)
			BBPreclaim(map);
		return NULL;
	}
	/* trickily transform a bat[mapentry,any] into bat[oid,int] */
	map->htype = BATmirror(map)->ttype = TYPE_oid;
	map->ttype = BATmirror(map)->htype = TYPE_int;
	if (map->tvarsized && map->theap) {
		HEAPfree(map->theap);
		GDKfree(map->theap);
		map->theap = NULL;
	}
	BATmirror(map)->hvarsized = map->tvarsized = 0;
	/* do these in the right order: map->dims.headloc is used, so
	 * change it at end
	 */
	BATmirror(map)->dims.headloc = map->dims.tailloc = map->dims.headloc + (int) offsetof(mapentry_t, cnt);
	BATmirror(map)->dims.tailloc = map->dims.headloc = map->dims.headloc + (int) offsetof(mapentry_t, gid);

	return map;
}

@-
The group macro is split along three dimensions:
@table
@item [type:] 
Type specific implementation for selecting the right
hash function and data size etc.;
@item [clustered:] 
The @{clustered and unclustered@} select the
appropriate algorithm, i.e., with or without taking advantage of 
an order of values in the parent groups;
@item [physical properties:] 
Values @{standard and custom@}, 
choosing between a fixed predefined and a custom hashmask. Custom
allows the user to determine the size of the hashmask (and indirectly
the estimated size of the result). The hashmask is $2^n - 1$ where $n$
is given by the user, or 1023 otherwise, and the derived result
size is $4 \cdot 2^n$.
@end table

Further research should point out whether fitting a simple statistical
model (possibly a simple mixture model) can help choose these parameters
automatically; the current idea is that the user (which could be a
domain-specific extension of the higher-level language) knows the
properties of the data, especially for IR in which the standard grouping
settings differ significantly from the original datamining application.
@c
#define group_params_STANDARD	/* fixed */
#define group_params_CUSTOM   hash_t custom_MASK, int custom_rng,

@= groupAll
BAT *
CTgroup_@1_@4_@5(group_params_@5 BAT *b, BAT *bn, map_T *m)
{
	oid *dst = (oid*) BUNfirst(bn);
	hash_t xx=0, *hash, mask;
	size_t zz, mapsize;
	mapentry_t entry, *e;
	BUN p, q, r;
	BAT *map = NULL;
	declare_@3
#ifdef MKspeedup
	size_t idx;
#endif

	map_init_@5(map,hash,mask,entry,mapsize);
	if (map == NULL)
		return NULL;

	/* core hash grouping algorithm */
#ifdef MKspeedup
/* MK: Experimental code. Should be triggered when you attempt
to consume a lot of your physical memory. First indication, a factor 2.
*/
		(void) q;

        if( BATprepareHash(BATmirror(b))){
            stream_printf(GDKout,"#M5 IO group join\n");
            for( idx=0; idx< b->thash->mask; idx++)
            for( xx=b->thash->hash[idx]; xx != HASH_MAX; xx= b->thash->link[xx]){
		declare_@4
		ptr tcur;
		p= BUNptr(b,xx);
		tcur = BUN@2(b,p);

#else
	BATloopFast(b, p, q, xx) {
		declare_@4
		ptr tcur = BUN@2(b,p);
#endif

		/* hash-lookup of 'tcur' in map */
		hash_t c = HASH_@1(tcur);
		c = mix_int(c) & mask;
		chain_@4 {
			r = BUNptr(map,zz);
			e = (mapentry_t*) BUNhloc(map,r);
			if (tst_grp_@4(@3_EQ, BUN@2(map,r), @1)) {
				if (m == NULL)
					e->cnt++;
				goto found;
			}
		}

		/* not found-> insert new element in map (and hash) */
		if (m) {
			zz = mapsize;
		} else {
			entry.gid = *(oid*) BUNhead(b,p);
		}
		entry.link = hash[c];
		hash[c] = mapsize++;
		bunfastins(map, &entry, tcur);
		e = &entry;

found:		/* ultra-fast 'insert' of [oid,gid] into ct */
		if (bn->htype)
			*dst++ = *(oid*) BUNhead(b,p);
		*dst++ = m?zz:e->gid;
	}
#ifdef MKspeedup
	BATsort(BATmirror(bn));
	}
#endif
	bn->batBuns->free = ((BUN) dst) - bn->batBuns->base;
	BATsetcount(bn, bn->batBuns->free/BUNsize(bn));
	bn->tsorted = 0;
	if (!(bn->batDirty&2)) bn = BATsetaccess(bn, BAT_READ);
	ALIGNsetH(bn,b);
	if (hash && !m)
		GDKfree(hash);
	return m ? NULL : map2histo(map);
bunins_failed:
	BBPreclaim(bn);
	if (hash && !m)
		GDKfree(hash);
	return NULL;
}
@c
int
tailtype(BAT *b, int str_trick)
{
	int tpe = ATOMstorage(b->ttype);	/* standard type remappings */

	/* more daring remappings possible under simple equality */
	if (tpe == TYPE_flt) {
		return TYPE_int;
	} else if (tpe == TYPE_dbl) {
		return TYPE_lng;
	} else if (tpe == TYPE_str && str_trick && GDK_ELIMDOUBLES((b->theap))) {
		return TYPE_var;	/* string offsets are identifying integers */
	}
	return tpe;
}

/* Generate both 'normal' CTgroup and clustered CTgroups */
@= wrappedgroupinner
@:groupAll(chr,tloc,simple,@1,@2)@
@:groupAll(sht,tloc,simple,@1,@2)@
@:groupAll(int,tloc,simple,@1,@2)@
@:groupAll(lng,tloc,simple,@1,@2)@
@:groupAll(any,tail,atom,@1,@2)@

/* Generate both 'normal' CTgroup and parameterized CTgroups */
@= wrappedgroupouter
@:wrappedgroupinner(unclustered,@1)@
@:wrappedgroupinner(clustered,@1)@

@c
@:wrappedgroupouter(STANDARD)@
@:wrappedgroupouter(CUSTOM)@

@= returnvalue
	@1 =
@c
#define declare_mask_STANDARD	/* fixed */
#define declare_mask_CUSTOM	hash_t mask = (1 << *N) - 1;

int
CTgroup(BAT **retval,		/* put pointer to BAT[oid,oid] record here. */
	BAT **hbat,		/* put histogram BAT here */
	BAT *b			/* pointer to BAT[oid,oid] record. */
)
{
	@:CTgroupbody(STANDARD)@
}

int
CTgroup_custom(BAT **retval,	/* put pointer to BAT[oid,oid] record here. */
   BAT **hbat,	/* put histogram BAT here */
   BAT *b,		/* pointer to BAT[oid,oid] record. */
   int *N,		/* number of bits for hashmask */
   int *rng		/* expected number of entries in map */
)
{
	@:CTgroupbody(CUSTOM)@
}

static int 
bits(size_t i)
{
	int sh;

	assert(i>0);
        for (sh = 0; i != 0; sh++) {
                i >>= 1;
        }
	return sh;
}


@= CTgroupbody
	BAT *histo = NULL, *bn = NULL;
	declare_mask_@1

	/* b->tkey, simply return mirror(0), and hist = project(reverse(bn),1) */
	if (b->tkey) {
		int one = 1;
		BAT *v = VIEWcombine(b);

		bn = v;
		if (b->batRestricted == BAT_WRITE) {
			bn = BATcopy(v, v->htype, v->ttype, FALSE);
			BBPreclaim(v);
		}
		histo = BATconst(BATmirror(bn), TYPE_int, &one);
	} else {
		bn = BATnew(b->htype, TYPE_oid, BATcount(b));
		if (bn == NULL) {
			return GDK_FAIL;
		}
		/* Poor man's clustered test: sorted & !keyed => clustered  */
		if ( ((b->tsorted)&1) && !(b->tkey) ) {
			@:choosegroup@1(tailtype(b,TRUE),bn,NULL,clustered,histo)@
		} else {
			@:choosegroup@1(tailtype(b,TRUE),bn,NULL,unclustered,histo)@
		}
		if (histo == NULL) {
			BBPreclaim(bn);
			return GDK_FAIL;
		}
		bn->tsorted = 0;
	}
	if (BATcount(histo) == BATcount(bn)) {
		BATkey(BATmirror(bn),TRUE);
		BATkey(BATmirror(histo),TRUE);
	}
	ALIGNsetH(bn, b);
	if (!(bn->batDirty&2)) bn = BATsetaccess(bn, BAT_READ);
	*retval = bn;
	*hbat = histo;
	return grp_new(bn, histo);

@= choosegroupSTANDARD
	/* Choose appropriate @4 CTgroup implementation */
	switch(@1) {
	case TYPE_chr:
		@?@5:returnvalue(@5)@ CTgroup_chr_@4_STANDARD(b,@2,@3);
		break;
	case TYPE_sht:
		@?@5:returnvalue(@5)@ CTgroup_sht_@4_STANDARD(b,@2,@3);
		break;
	case TYPE_int:
		@?@5:returnvalue(@5)@ CTgroup_int_@4_STANDARD(b,@2,@3);
		break;
	case TYPE_lng:
		@?@5:returnvalue(@5)@ CTgroup_lng_@4_STANDARD(b,@2,@3);
		break;
	default:
		@?@5:returnvalue(@5)@ CTgroup_any_@4_STANDARD(b,@2,@3);
		break;
	}

@= choosegroupCUSTOM
	/* Choose appropriate @4 CTgroup implementation */
	switch(@1) {
	case TYPE_chr:
		@?@5:returnvalue(@5)@ CTgroup_chr_@4_CUSTOM(mask,*rng,b,@2,@3);
		break;
	case TYPE_sht:
		@?@5:returnvalue(@5)@ CTgroup_sht_@4_CUSTOM(mask,*rng,b,@2,@3);
		break;
	case TYPE_int:
		@?@5:returnvalue(@5)@ CTgroup_int_@4_CUSTOM(mask,*rng,b,@2,@3);
		break;
	case TYPE_lng:
		@?@5:returnvalue(@5)@ CTgroup_lng_@4_CUSTOM(mask,*rng,b,@2,@3);
		break;
	default:
		@?@5:returnvalue(@5)@ CTgroup_any_@4_CUSTOM(mask,*rng,b,@2,@3);
		break;
	}

@= derive
BAT *
CTderive_@1_@2_@5(BAT* ct_histo, BAT *ct_map, BAT *b, BAT *bn, map_T *m)
{
	oid *dst = (oid*) BUNfirst(bn);
	size_t yy = BUNsize(ct_map), zz, mapsize;
	hash_t xx, *hash;
	BUN p, q, r, cp = BUNfirst(ct_map) - yy;
	mapentry_t entry, *e;
	BAT *map;
	int n = bits(BATcount(ct_histo)),*N = &n;
	declare_@4
	declare_mask_CUSTOM
	int custom_rng = BATcount(ct_histo); /* expected number of groups */
	hash_t custom_MASK = mask;

	map_init_CUSTOM(map,hash,mask,entry,mapsize);
	if (map == NULL)
		return NULL;

	/* core hash grouping algorithm */
	BATloopFast(b, p, q, xx) {
		ptr tcur = BUN@3(b,p);
		hash_t c;
		oid hcur;
		declare_@5

		/* find corresponding value in 'ct_map' */
		match_@1(ct_map, BUNhead(b,p), cp);
		hcur = *(oid*) BUNtloc(ct_map,cp);

		/* hash-lookup of [hcur,tcur] in map */
		c = (((hash_t) hcur) ^ HASH_@2(tcur));
		c = mix_int(c) & mask;
		chain_@5 {
			r = BUNptr(map,zz);
			e = (mapentry_t*) BUNhloc(map,r);
			if (tst_derive_@5(@4_EQ, BUN@3(map,r), @2)) {
				if (m == NULL)
					e->cnt++;
				goto found;
			}
		}
		/* not found-> insert new element in map (and hash) */
		if (m) {
			zz = mapsize;
		} else {
			entry.gid = *(oid*) BUNhead(b,p);
		}
		entry.hcur = hcur;
		entry.link =  hash[c];
		hash[c] = mapsize++;
		bunfastins(map, &entry, tcur);
		e = &entry;

found:		/* ultra-fast 'insert' of [oid,gid] into result ct */
		if (bn->htype)
			*dst++ = *(oid*) BUNhead(b,p);
		*dst++ = m?zz:e->gid;
	}
	bn->batBuns->free = ((BUN) dst) - bn->batBuns->base;
	BATsetcount(bn, bn->batBuns->free/BUNsize(bn));
	if (hash && !m)
		GDKfree(hash);
	if (!(bn->batDirty&2)) bn = BATsetaccess(bn, BAT_READ);
	return m?NULL:map2histo(map);
bunins_failed:
	if (hash && !m)
		GDKfree(hash);
	BBPreclaim(bn);
	return NULL;
}

@c

/* Generate both 'normal' CTderive and clustered CTderive */
@= wrappedderive
@:derive(sync,chr,tloc,simple,@1)@
@:derive(sync,sht,tloc,simple,@1)@
@:derive(sync,int,tloc,simple,@1)@
@:derive(sync,lng,tloc,simple,@1)@
@:derive(sync,any,tail,atom,@1)@
@:derive(hash,chr,tloc,simple,@1)@
@:derive(hash,sht,tloc,simple,@1)@
@:derive(hash,int,tloc,simple,@1)@
@:derive(hash,lng,tloc,simple,@1)@
@:derive(hash,any,tail,atom,@1)@
@c
@:wrappedderive(unclustered)@
@:wrappedderive(clustered)@

@= choosederive
	/* Choose appropriate (@1 && @2) CTderive implementation */
	switch(tt) {
	case TYPE_chr:
		histo = CTderive_@1_chr_@2(ct_histo,ct_map,b,bn,m);
		break;
	case TYPE_sht:
		histo = CTderive_@1_sht_@2(ct_histo,ct_map,b,bn,m);
		break;
	case TYPE_int:
		histo = CTderive_@1_int_@2(ct_histo,ct_map,b,bn,m);
		break;
	case TYPE_lng:
		histo = CTderive_@1_lng_@2(ct_histo,ct_map,b,bn,m);
		break;
	default:
		histo = CTderive_@1_any_@2(ct_histo,ct_map,b,bn,m);
		break;
	}
@c
int
derive(BAT **H, BAT **M, BAT *ct_histo, BAT *ct_map, BAT *b, int tt, map_T *m)
{
	BAT *histo = NULL, *bn = NULL;
	int synced = ALIGNsynced(ct_map, b);

	/* create the result bat 'bn' */
	int ht = (synced && BAThdense(b)) ? TYPE_void : TYPE_oid;

	if (!ct_map->tkey) { /* cannot derive more groups */
		bn = BATnew(ht, TYPE_oid, BATcount(b));
		if (bn == NULL) {
			return GDK_FAIL;
		}

		/* CTderive with correct lookup method (hash,synced) and type */
		if (synced) {
			if (((ct_map->tsorted) & 1)) {
				@:choosederive(sync,clustered)@
			} else {
				@:choosederive(sync,unclustered)@
			}
		} else {
			if (((ct_map->tsorted) & 1)) {
				@:choosederive(hash,clustered)@
			} else {
				@:choosederive(hash,unclustered)@
			}
		}
		if (histo == NULL) {
			assert(histo);
			BBPunfix(bn->batCacheid);
		}

		/* postprocess the result bat 'bn' */
		bn->tsorted = 0;
		if (BATcount(bn) == BATcount(b)) {
			ALIGNsetH(bn, b);
		} else {
			bn->hsorted = BAThordered(b);
			if (b->hkey)
				BATkey(bn, TRUE);
		}

	} else {
		bn = ct_map;
		histo = ct_histo;
		if (!synced) {
			bn = BATsemijoin(ct_map, b);
			histo = BATsemijoin(ct_histo, BATmirror(bn));
		} else {
			BBPfix(ct_map->batCacheid);
			BBPfix(ct_histo->batCacheid);
		}
	}
	*M = bn;
	*H = histo;
	return grp_new(bn, histo);
}

int
CTderive(BAT **M, BAT **H, BAT *ct_histo, BAT *ct_map, BAT *b)
{
	int ret;

	ret = derive(H, M, ct_histo, ct_map, b, tailtype(b, TRUE), NULL);
	return ret;
}

@-
The routine CThistosum takes an grouping and a histogram and produces
a new histogram by summing the old values within the same group.
@c
int
CThistosum(BAT **retval,	/* put pointer to BAT[oid,int] record here. */
	   BAT *b,		/* pointer to BAT[oid,oid] record. */
	   BAT *c		/* pointer to BAT[oid,int] record. */
)
{
	BAT *res = BATnew(TYPE_oid, TYPE_int, BATcount(b));
	BUN p, q, qb;
	int xx, i, *z;
	oid *ot, *oh;

	(void) c;
	if (res == NULL) {
		return GDK_FAIL;
	}
	BATloopFast(b, p, q, xx) {
		oh = (oid *) BUNhloc(b, p);
		i = *(int *) BUNtloc(b, p);

		BUNfndOID(qb, b, oh);
		if (qb == NULL) {
			GDKerror("CThistosum: Matching count entry not found\n");
			continue;
		}
		ot = (oid *) BUNtloc(b, qb);

		BUNfndOID(qb, res, ot);
		if (qb == NULL) {
			BUNins(res, ot, &i, FALSE);
		} else {
			z = (int *) BUNtloc(res, qb);
			*z += i;
		}
	}
	res->hsorted = res->tsorted = 0;
	if (!(res->batDirty&2)) res = BATsetaccess(res, BAT_READ);
	*retval = res;
	return GDK_SUCCEED;
}

int
CTsubhisto(BAT **ret, BAT *sel, BAT *grp, BAT *dom)
{
	bit *filter = (bit *) BUNtloc(sel, BUNfirst(sel));
	size_t size = BATcount(dom);
	int xx, zz;
	hash_t yy, mask, *hash = NULL;
	BUN r, p, q;
	BAT *bn = BATnew(TYPE_idxentry, TYPE_int, size);

	if (bn == NULL)
		return GDK_FAIL;

	/* we know the domain; go for perfect hashing */
	for (mask = 1; mask < size; mask <<= 1)
		;
	if (mask < 256)
		mask = 256;
	hash = (hash_t *) GDKmalloc(sizeof(hash_t) * mask);
	if (hash == NULL) {
		BBPreclaim(bn);
		return GDK_FAIL;
	}
	for (yy = 0; yy < mask; yy++) {
		hash[yy] = HASH_MAX;
	}
	mask--;

	/* insert all values in the hash table, and in bn with count zero */
	r = BUNfirst(bn);
	yy = 0;
	BATloopFast(dom, p, q, xx) {
		oid v = *(oid *) BUNhloc(dom, p);
		hash_t c = v & mask;

		((idxentry_t *) BUNhloc(bn, r))->hcur = v;
		((idxentry_t *) BUNhloc(bn, r))->link = hash[c];
		*(int *) BUNtloc(bn, r) = 0;
		r = BUNnext(bn, r);
		hash[c] = yy;
		yy++;
	}
	bn->batBuns->free = (char *) r - (char *) Bunbase(bn);
	BATsetcount(bn, bn->batBuns->free/BUNsize(bn));
	bn->tsorted = 0;
	bn->htype = BATmirror(bn)->ttype = TYPE_oid;
	/* assert(offsetof(idxentry_t,hcur) == 0);
	ALIGNsetH(bn, dom); */

	/* add the counts for this selection using the hash table */
	zz = BUNsize(sel);
	BATloopFast(grp, p, q, xx) {
		if (*filter == TRUE) {
			oid v = *(oid *) BUNtloc(grp, p);
			hash_t c = v & mask;

			for (yy = hash[c]; yy != HASH_MAX; yy = ((idxentry_t *) BUNhloc(bn, r))->link) {
				r = BUNptr(bn, yy);
				if (((idxentry_t *) BUNhloc(bn, r))->hcur == v) {
					*(int *) BUNtloc(bn, r) += 1;
					break;
				}
			}
		}
		filter += zz;

	}
	GDKfree(hash);
	if (!(bn->batDirty&2)) bn = BATsetaccess(bn, BAT_READ);
	*ret = bn;
	return GDK_SUCCEED;
}

@+ Support for Order-by
@c
#define DEFAULT_SIZE 10000

struct refine {
	var_t off;
	oid o;
};

static INLINE oid *
sort_flush(struct refine *buf, size_t size, int tpe, BUN base, oid *dst, oid *idp, int reverse)
{
	int (*cmp) (ptr, ptr) = BATatoms[tpe].atomCmp;
	struct refine *end = buf + size;
	oid id = *idp + 1;
	ptr cur, val;

	/* StM: we don't need to sort voids, do we??? */
	if (tpe != TYPE_void) {
		/* qsort works fine for small amount of tuples; with few duplicates */
		if (reverse) {
			GDKqsort_rev(buf, base, size, (int) sizeof(struct refine), tpe, offsetof(struct refine, off));
		} else {
			GDKqsort(buf, base, size, (int) sizeof(struct refine), tpe, offsetof(struct refine, off));
		}
	}

	cur = base + buf->off;
	while (buf < end) {
		val = base + buf->off;
		if ((*cmp) (cur, val)) {
			cur = val;
			id++;
		}
		*dst++ = buf->o;
		*dst++ = id;

		buf++;
	}
	*idp = id;

	return dst;
}

static int
refine(BAT **res, BAT *b, BAT *a, int rv)
{
	str rev = rv ? "_rev" : "";
	BAT *bn = NULL;

	if (BATcount(b) != BATcount(a)) {
		GDKerror("CTrefine%s: both BATs must have the same cardinality and their heads must form a 1-1 match.\n", rev);
		return GDK_FAIL;
	}
@(
	/* checking only the key property is too strict,
	 * as it might not be set although it does hold;
	 * exhaustively checking keyness is too expensive;
	 * hence, we just don't check, and keep our fingers crossed...
	 */
	if (!(b->hkey && a->hkey)) {
		if (a->hkey) {
			GDKerror("CTrefine%s: head of first BAT is not unique (key);", rev);
		} else if (b->hkey) {
			GDKerror("CTrefine%s: head of second BAT is not unique (key);", rev);
		} else {
			GDKerror("CTrefine%s: heads of both BATs are not unique (key);", rev);
		}
		GDKerror("CTrefine%s: heads of both BATs must be unique (key) to form a 1-1 match.\n", rev);
		return GDK_FAIL;
	}
@)
	if (b->tkey) {		/* if key, no further refinements can take place */
		bn = BATmark(b, 0);
	} else {
		int (*cmp) (ptr, ptr) = BATatoms[b->ttype].atomCmp;
		BUN p, q, r, last = BUNfirst(b), base = a->theap ? NULL : a->batBuns->base, this = NULL;
		struct refine *buf, *cur, *end;
		bit a_void = (a->ttype == TYPE_void);
		int xx, tpe = a_void ? TYPE_oid : a->ttype;
		size_t size = DEFAULT_SIZE;
		oid *dst, o, *op = &o, id = 0;

		/* create tmp BAT that holds one cluster; estimate required size using sampling */
		if (BATcount(b) > DEFAULT_SIZE) {
			BAT *histo = NULL, *sample = BATsample(b, DEFAULT_SIZE);

			if (sample) {
				histo = BAThistogram(sample);
				if (histo) {
					BATmax(histo, &xx);
					if (xx > 1)
						size = MAX(size, (size_t) (xx * (((float) BATcount(b)) / DEFAULT_SIZE)));
					BBPreclaim(histo);
				}
				BBPreclaim(sample);
			}
			if (histo == NULL)
				return GDK_FAIL;
		}
		/* create a temporary BAT of the estimated size holding pointers to the a tail atoms */
		buf = cur = (struct refine *) GDKmalloc(size * sizeof(struct refine));
		end = buf + size;
		if (buf == NULL)
			return GDK_FAIL;
		if (a_void) {
			base = this = (BUN) GDKmalloc(size * sizeof(oid));
			if (base == NULL) {
				GDKfree(buf);
				return GDK_FAIL;
			}
		}

		/* create result BAT */
		bn = BATnew(TYPE_oid, TYPE_oid, BATcount(b));
		if (bn == NULL) {
			GDKfree(buf);
			if (a_void)
				GDKfree(base);
			return GDK_FAIL;
		}
		bn->hsorted = bn->tsorted = FALSE;
		dst = (oid *) BUNfirst(bn);

		if (a_void) {
			@:refine_loop(@:refine_void_1@,@:refine_void_2@,GDKfree(base);,this = base;)@
		} else {
			@:refine_loop(r += a->tloc;)@
		}
@= refine_void_2
	off = (size_t) (this - base);
	base = (BUN) GDKrealloc(base, size * sizeof(oid));
	this = base + off;
@= refine_void_1
	/* TYPE_void: BUNtail(b,p) = (BUN)BUNtpos(b,p) */
	*(oid*)this = *(oid*)(BUN)BUNtpos(a, r);
	r = this;
@= refine_loop
		/* merge-scan tail of b, finding chunks with equal values; then sort each chunk on a */
		BATloopFast(b, p, q, xx) {
			if ((*cmp) (BUNtail(b, last), BUNtail(b, p))) {
				dst = sort_flush(buf, (size_t) (cur - buf), tpe, base ? base : a->theap->base, dst, &id, rv);

				last = p;
				cur = buf;
				@4
			}
			o = *(oid *) BUNhead(b, p);
			BUNfndOID(r, a, op);
			if (r == NULL) {
				GDKerror("CTrefine%s: value "SZFMT"@0 not found in head of second BAT;\n"
					 "CTrefine%s: heads of both BATs do not form a 1-1 match.\n", rev, o, rev);
				BBPreclaim(bn);
				GDKfree(buf);
				@3
				return GDK_FAIL;
			}
			if (cur >= end) {
				size_t off = (size_t) (cur - buf);
				buf = (struct refine *) GDKrealloc(buf, (size *= 2) * sizeof(struct refine));
				end = buf + size;
				cur = buf + off;
				@2
			}
			@1
			cur->off = base ? (var_t) (r - base) : *(var_t *) r;
			cur->o = o;
			cur++;
			this += sizeof(oid);
		}
@c
		dst = sort_flush(buf, (size_t) (cur - buf), tpe, base ? base : a->theap->base, dst, &id, rv);

		GDKfree(buf);
		if (a_void)
			GDKfree(base);
		bn->batBuns->free = ((BUN) dst) - bn->batBuns->base;
		BATsetcount(bn, bn->batBuns->free/BUNsize(bn));
		bn->tsorted = GDK_SORTED;
	}
	*res = bn;
	return GDK_SUCCEED;
}

int
CTrefine(BAT **res, BAT *b, BAT *a)
{
	return refine(res, b, a, FALSE);
}

int
CTrefine_rev(BAT **res, BAT *b, BAT *a)
{
	return refine(res, b, a, TRUE);
}

@- Wrapping
Wrapping the version 4 xtables code base
@c
#include "mal.h"
#include "mal_exception.h"
#include "mal_atom.h"

#ifdef WIN32
#ifndef LIBGROUP
#define group_export extern __declspec(dllimport)
#else
#define group_export extern __declspec(dllexport)
#endif
#else
#define group_export extern
#endif

@-
Recall that we only support void- and oid- typed heads.
This is captured as a runtime check in the implementation.
@= chkHeader
	if(@1->htype != TYPE_oid && @1->htype != TYPE_void)
		throw(MAL, "group.@2", "(v)oid head required\n");
@c
group_export str GRPprelude(void);
str
GRPprelude(void)
{
	/* printf("#init group\n"); */
	TYPE_mapentry = malAtomFixed(sizeof(mapentry_t), sizeof(oid), "mapentry");
	TYPE_idxentry = malAtomFixed(sizeof(idxentry_t), sizeof(oid), "idxentry");
	return MAL_SUCCEED;
}

group_export str GRPgroup0(int *ret, int *bid, int *start, int *incr, int *grpsize);
str
GRPgroup0(int *ret, int *bid, int *start, int *incr, int *grpsize)
{
	BAT *result, *b;

	if ((b = BATdescriptor(*bid)) == NULL) {
		throw(MAL, "group.group", "Cannot access descriptor");
	}

	result = BATgroup(b, *start, *incr, *grpsize);
	if (result == 0)
		throw(MAL, "GRPgroup0", "Failed to group");
	*ret = result->batCacheid;
	BBPkeepref(*ret);
	BBPreleaseref(b->batCacheid);
	return MAL_SUCCEED;
}

group_export str GRPgroup_custom(int *rethisto, int *retbid, int *bid, int *N, int *rng);
group_export str GRPgroup(int *rethisto, int *retbid, int *bid);
str
GRPgroup(int *rethisto, int *retbid, int *bid)
{
	BAT *histo = 0, *b, *bn = 0;

	if ((b = BATdescriptor(*bid)) == NULL) {
		throw(MAL, "group.group", "Cannot access descriptor");
	}
	if (BATcount(b) > 1024*1024 &&
	    (b->ttype == TYPE_int || b->ttype == TYPE_lng)) { 
		int N = BATcount(b), one = 1;
		assert(N);
		if (b->ttype == TYPE_int) {
			int h, l;
			BATmax(b,&h);
			BATmin(b,&l);
			if (h != int_nil && l != int_nil && h-l < N && h-l > 0) 
				N = h-l;
		} else if (b->ttype == TYPE_lng) {
			lng h, l;
			BATmax(b,&h);
			BATmin(b,&l);
			if (h != lng_nil && l != lng_nil && (int)(h-l) < N && (int)(h-l) > 0) 
				N = (int)(h-l);
		}
		N = bits(N);
		assert(N);
		BBPunfix(b->batCacheid);
		return GRPgroup_custom(rethisto, retbid, bid, &N, &one);
	}
	@:chkHeader(b,GRPgroup)@
	CTgroup(&bn, &histo, b);
	*rethisto = histo ? histo->batCacheid : 0;
	*retbid = bn->batCacheid;
	BBPreleaseref(b->batCacheid);
	return MAL_SUCCEED;
}

str
GRPgroup_custom(int *rethisto, int *retbid, int *bid, int *N, int *rng)
{
	BAT *histo = 0, *b, *bn = 0;

	if ((b = BATdescriptor(*bid)) == NULL) {
		throw(MAL, "group.group", "Cannot access descriptor");
	}
	@:chkHeader(b,GRPgroup)@
	CTgroup_custom(&bn, &histo, b, N, rng);
	*rethisto = histo ? histo->batCacheid : 0;
	*retbid = bn->batCacheid;
	BBPreleaseref(b->batCacheid);
	return MAL_SUCCEED;
}

group_export str GRPderive(int *hid, int *mid, int *ct_histoid, int *ct_mapid, int *bid);
str
GRPderive(int *hid, int *mid, int *ct_histoid, int *ct_mapid, int *bid)
{
	BAT *ct_map, *ct_histo, *b;
	BAT *bn = NULL, *histo = NULL;

	if ((ct_map = BATdescriptor(*ct_mapid)) == NULL) {
		throw(MAL, "group.derive", "Cannot access descriptor");
	}
	@:chkHeader(ct_map,GRPderive)@
	if ((ct_histo = BATdescriptor(*ct_histoid)) == NULL) {
		BBPreleaseref(ct_map->batCacheid);
		throw(MAL, "group.derive", "Cannot access descriptor");
	}
	@:chkHeader(ct_histo,GRPderive)@
	if ((b = BATdescriptor(*bid)) == NULL) {
		BBPreleaseref(ct_map->batCacheid);
		BBPreleaseref(ct_histo->batCacheid);
		throw(MAL, "group.derive", "Cannot access descriptor");
	}
	@:chkHeader(b,GRPderive)@
	if( derive(&histo, &bn, ct_histo, ct_map, b, tailtype(b, TRUE), NULL) == GDK_FAIL){
		BBPreleaseref(b->batCacheid);
		BBPreleaseref(ct_map->batCacheid);
		BBPreleaseref(ct_histo->batCacheid);
		throw(MAL, "group.derive","Could not derive group");
	}

	*mid = bn->batCacheid;
	*hid = histo->batCacheid;
	BBPreleaseref(b->batCacheid);
	BBPreleaseref(ct_map->batCacheid);
	BBPreleaseref(ct_histo->batCacheid);
	return MAL_SUCCEED;
}

group_export str GRPsubhisto(int *retid, int *selid, int *grpid, int *domid);
str
GRPsubhisto(int *retid, int *selid, int *grpid, int *domid)
{
	BAT *sel, *grp, *dom;
	BAT *bn;

	if ((sel = BATdescriptor(*selid)) == NULL) {
		throw(MAL, "group.subhisto", "Cannot access descriptor");
	}
	if ((grp = BATdescriptor(*grpid)) == NULL) {
		BBPreleaseref(sel->batCacheid);
		throw(MAL, "group.subhisto", "Cannot access descriptor");
	}
	@:chkHeader(grp,GRPsubhisto)@
	if ((dom = BATdescriptor(*domid)) == NULL) {
		throw(MAL, "group.subhisto", "Cannot access descriptor");
	}

	if ((dom = BATdescriptor(*domid)) == NULL) {
		BBPreleaseref(sel->batCacheid);
		BBPreleaseref(grp->batCacheid);
		throw(MAL, "group.subhisto", "Cannot access descriptor");
	}
	CTsubhisto(&bn, sel, grp, dom);
	*retid = bn->batCacheid;
	BBPkeepref(*retid);
	BBPreleaseref(sel->batCacheid);
	BBPreleaseref(grp->batCacheid);
	BBPreleaseref(dom->batCacheid);
	return MAL_SUCCEED;
}

group_export str GRPrefine(int *retid, int *bid, int *aid);
str
GRPrefine(int *retid, int *bid, int *aid)
{
	BAT *b, *a;
	BAT *bn;

	if ((b = BATdescriptor(*bid)) == NULL) {
		throw(MAL, "group.refine", "Cannot access descriptor");
	}
	@:chkHeader(b,GRPrefine)@
	if ((a = BATdescriptor(*aid)) == NULL) {
		BBPreleaseref(b->batCacheid);
		throw(MAL, "group.refine", "Cannot access descriptor");
	}
	@:chkHeader(a,GRPrefine)@

	CTrefine(&bn, b, a);
	*retid = bn->batCacheid;
	BBPkeepref(*retid);
	BBPreleaseref(b->batCacheid);
	BBPreleaseref(a->batCacheid);
	return MAL_SUCCEED;
}

group_export str GRPrefine_rev(int *retid, int *bid, int *aid);
str
GRPrefine_rev(int *retid, int *bid, int *aid)
{
	BAT *b, *a;
	BAT *bn;

	if ((b = BATdescriptor(*bid)) == NULL) {
		throw(MAL, "group.refine", "Cannot access descriptor");
	}
	@:chkHeader(b,GRPrefine_rev)@
	if ((a = BATdescriptor(*aid)) == NULL) {
		BBPreleaseref(b->batCacheid);
		throw(MAL, "group.refine", "Cannot access descriptor");
	}
	@:chkHeader(a,GRPrefine_rev)@

	CTrefine_rev(&bn, b, a);
	*retid = bn->batCacheid;
	BBPkeepref(*retid);
	BBPreleaseref(b->batCacheid);
	BBPreleaseref(a->batCacheid);
	return MAL_SUCCEED;
}

@-

These implementations need just one scan and a simple hash-maintained data
structure to compute a group of common aggregates.

With group OIDs spanning a range of less SMALL_AGGR_MAX (the actual number
of groups might be even less, in case there are "holes" in the group OID
range), we use a simple array as temporary sum/cnt table on order to benefit
from positional lookups; with size of sum <= 8 bytes and size of cnt == 4
bytes, we stay below 16 KBytes, i.e., within (almost) any L1 cache

@c
#define SMALL_AGGR_MAX 1024

@-
@= large_aggr_sum
		(void) BATprepareHash(bn);
		BATloopFast(b, p, q, xx) {
				oid *h = (oid*) BUNhead(b,p);
				@1 *t = (@1*) BUN@2(b,p);

				BUNfndOID(r, bn, h);
				if (r) {
						@1 *dst = (@1*) BUN@2(bn, r);
						if (*dst != @1_nil) {
								if (*t == @1_nil) {
										*dst = @1_nil;
								} else {
										*dst += *t;
								}
						}
				}
		}
@-
@= small_aggr_sum
		sums = (@1*) GDKmalloc(range*sizeof(@1));
		for (i = 0; i < range; i++) sums[i] = zero;
		BATloopFast(b, p, q, xx) {
				int h = (int)(*(oid*) BUNhead(b,p)) - min;
				@1 *t = (@1*) BUN@2(b,p);

				if (h >= 0 && h < range) {
						@1 *dst = sums + h;
						if (*dst != @1_nil) {
								if (*t == @1_nil) {
										*dst = @1_nil;
								} else {
										*dst += *t;
								}
						}
				}
		}
		BATloopFast(bn, p, q, xx) {
				int h = (int)(*(oid*) BUNhead(bn,p)) - min;
				*(@1*)BUN@2(bn, p) = sums[h];
		}
		GDKfree(sums);
@-
@= large_aggr_avg
		cnt  = (int*) GDKmalloc(BATcount(e)*sizeof(int));
		memset(cnt, 0, BATcount(e)*sizeof(int));
		(void) BATprepareHash(bn);
		BATloopFast(b, p, q, xx) {
				oid *h = (oid*) BUNhead(b,p);
				@1 *t = (@1*) BUN@2(b,p);

				BUNfndOID(r,bn,h);
				if (r) {
						@1 *dst = (@1*) BUN@2(bn, r);
						if (*dst != @1_nil) {
								if (*t == @1_nil) {
										*dst = @1_nil;
								} else {
										*dst += *t;
								}
								cnt[BUNindex(bn,r)-off]++;
						}
				}
		}
		/* postprocess by dividing sums by counts */
		BATloopFast(bn, p, q, xx) {
				@1 *dst = (@1*) BUN@2(bn, p);
				if (cnt[yy] == 0) {
						*dst = @1_nil;
				} else if (*dst != @1_nil) {
						*dst /= cnt[yy];
				} yy++;
		}
		GDKfree(cnt);

@-
@= small_aggr_avg
		sums = (@1*) GDKmalloc(range*sizeof(@1));
		cnt  = (int*) GDKmalloc(range*sizeof(int));
		for (i = 0; i < range; i++) sums[i] = zero;
		memset(cnt, 0, range*sizeof(int));
		BATloopFast(b, p, q, xx) {
				int h = (int)(*(oid*) BUNhead(b,p)) - min;
				@1 *t = (@1*) BUN@2(b,p);

				if (h >= 0 && h < range) {
						@1 *dst = sums + h;
						if (*dst != @1_nil) {
								if (*t == @1_nil) {
										*dst = @1_nil;
								} else {
										*dst += *t;
								}
								cnt[h]++;
						}
				}
		}
		/* postprocess by dividing sums by counts */
		BATloopFast(bn, p, q, xx) {
				int h = (int)(*(oid*) BUNhead(bn,p)) - min;
				@1 *dst = (@1*) BUN@2(bn, p);
				if (cnt[h] == 0 || sums[h] == @1_nil) {
						*dst = @1_nil;
				} else {
						*dst = sums[h]/cnt[h];
				}
		}
		GDKfree(sums);
		GDKfree(cnt);

@= arithpump
group_export str GRPsum_@1(int *retval, int *bid,int  *eid, bit *ignore_nils);
str GRPsum_@1(int *retval, int *bid,int  *eid, bit *ignore_nils){
		BAT *b = NULL, *e = NULL;
		BAT *bn = BATnew(e->htype, BATttype(b), BATcount(e));
		@1 zero = (@1) 0, *sums;
		BUN p, q, r;
		int xx,i,range,min,max;

		(void) ignore_nils; /* fool compiler */
		if( (b= BATdescriptor(*bid)) == NULL ){
			throw(MAL, "group.sum", "Cannot access descriptor");
		}

		@:chkHeader(b,GRPsum_@1)@
		if( (e= BATdescriptor(*eid)) == NULL ){
			BBPreleaseref(b->batCacheid);
			throw(MAL, "group.sum", "Cannot access descriptor");
		}
		@:chkHeader(e,GRPsum_@1)@
		/* init: set all sums to zero */
		bn->tsorted = bn->hsorted = 0;
		ALIGNsetH(bn, e);
		if (BAThordered(e)&1) {
				min = (int)(*(oid*)BUNhead(e, BUNfirst(e)));
				BATloopFast(e, p, q, xx) {
						BUNfastins(bn, BUNhead(e,p), &zero);
				}
				max = (int)(*(oid*)BUNhead(e, BUNlast(e)-BUNsize(e)));
		} else {
				min = max = (int)(*(oid*)BUNhead(e, BUNfirst(e)));
				BATloopFast(e, p, q, xx) {
						BUNfastins(bn, BUNhead(e,p), &zero);
						i = (int)(*(oid*)BUNhead(e, p));
						if (i < min) min = i;
						else
						if (i > max) max = i;
				}
		}
		range = max - min + 1;

		/* scan b, and add values to sums in-place */
		if (range > SMALL_AGGR_MAX) {
				ALGODEBUG THRprintf(GDKout, "#GRPsum_@1: range(=%d) > SMALL_AGGR_MAX(=%d)  =>  large_aggr_sum\n",range,SMALL_AGGR_MAX);
				@:large_aggr_sum(@1,@2)@
		} else {
				ALGODEBUG THRprintf(GDKout, "#GRPsum_@1: range(=%d) <= SMALL_AGGR_MAX(=%d)  =>  small_aggr_sum\n",range,SMALL_AGGR_MAX);
				@:small_aggr_sum(@1,@2)@
		}
		*retval= bn->batCacheid;
		BBPkeepref(*retval);
		BBPreleaseref(b->batCacheid);
		BBPreleaseref(e->batCacheid);
		return MAL_SUCCEED;
}

group_export str GRPavg_@1(int *retval, int *bid,int  *eid);
str GRPavg_@1(int *retval, int *bid,int  *eid){
		BAT *b = NULL, *e = NULL;
		BAT *bn = BATnew(e->htype, BATttype(b), BATcount(e));
		int xx, yy = 0, off = BUNindex(bn,BUNfirst(bn));
		int *cnt = (int*) GDKmalloc(BATcount(e)*sizeof(int));
		@1 zero = (@1) 0;
		BUN p, q, r;

		if( (b= BATdescriptor(*bid)) == NULL ){
			throw(MAL, "group.@1", "Cannot access descriptor");
		}
		@:chkHeader(b,GRPsum_@1)@
		if( (e= BATdescriptor(*eid)) == NULL ){
			BBPreleaseref(b->batCacheid);
			throw(MAL, "group.@1", "Cannot access descriptor");
		}
		@:chkHeader(e,GRPsum_@1)@
		/* init sums and counts to zero */
		bn->tsorted = bn->hsorted = 0;
		ALIGNsetH(bn, e);
		memset(cnt, 0, BATcount(e)*sizeof(int));
		BATloopFast(e, p, q, xx) {
				BUNfastins(bn, BUNhead(e,p), &zero);
		}
		/* scan b, adding sums, and incrementing counts */
		(void) BATprepareHash(bn);
		BATloopFast(b, p, q, xx) {
				oid *h = (oid*) BUNhead(b,p);
				@1 *t = (@1*) BUNtail(b,p);

				BUNfndOID(r,bn,h);
				if (r) {
						@1 *dst = (@1*) BUNtloc(bn, r);
						if (*dst != @1_nil) {
								if (*t == @1_nil) {
										*dst = @1_nil;
								} else {
										*dst += *t;
								}
								cnt[BUNindex(bn,r)-off]++;
						}
				}
		}
		/* postprocess by dividing sums by counts */
		BATloopFast(bn, p, q, xx) {
				@1 *dst = (@1*) BUNtail(bn, p);
				if (cnt[yy] == 0) {
						*dst = @1_nil;
				} else if (*dst != @1_nil) {
						*dst /= cnt[yy];
				} yy++;
		}
		GDKfree(cnt);
		*retval= bn->batCacheid;
		BBPkeepref(*retval);
		BBPreleaseref(b->batCacheid);
		BBPreleaseref(e->batCacheid);
		return MAL_SUCCEED;
}

@c
@:arithpump(sht,tloc)@
@:arithpump(int,tloc)@
@:arithpump(lng,tloc)@
@:arithpump(flt,tloc)@
@:arithpump(dbl,tloc)@

@= extreme
group_export str GRP@1(int *retval, int *bid,int  *eid);
str GRP@1(int *retval, int *bid,int  *eid){
		BAT *b = NULL, *e = NULL;
		BAT *bn;
		int (*cmp)(ptr,ptr);
		ptr nil;
		int xx, yy, off;
		ptr *extremes;
		BUN p, q, r;

		if( (b= BATdescriptor(*bid)) == NULL ){
			throw(MAL, "group.@1", "Cannot access descriptor");
		}

		@:chkHeader(b,GRP@1)@
		if( (e= BATdescriptor(*eid)) == NULL ){
			BBPreleaseref(b->batCacheid);
			throw(MAL, "group.@1", "Cannot access descriptor");
		}
		@:chkHeader(e,GRP@1)@

		bn = BATnew(e->htype, BATttype(b), BATcount(e));
		cmp = BATatoms[bn->ttype].atomCmp;
		nil = ATOMnilptr(bn->ttype);
		yy = 0; off = BUNindex(e,BUNfirst(e));
		extremes = (ptr*) GDKmalloc(BATcount(e)*sizeof(ptr));

		/* init: set all extremes to the zero pointer */
		memset(extremes, 0, BATcount(e)*sizeof(ptr));

		/* scan b and replace totals by the extreme value (just pointers to vals in b) */
		(void) BATprepareHash(e);
		BATloopFast(b, p, q, xx) {
				oid *h = (oid*) BUNhead(b,p);
				ptr t =  BUNtail(b,p);

				BUNfndOID(r,e,h);
				if (r) {
						ptr *val = extremes + (BUNindex(e,r) - off);
						if (*val != nil) {
								if ((*cmp)(t,nil) == 0) {
										*val = nil;
								} else if (*val == NULL || (*cmp)(t,*val) @2 0) {
										*val = t;
								}
						}
				}
		}
		/* insert the extreme values into the result */
		BATloopFast(e, p, q, xx) {
				ptr val = extremes[yy++];
				BUNfastins(bn, BUNhead(e,p), val?val:nil);
		}
		bn->tsorted = bn->hsorted = 0;
		ALIGNsetH(bn, e);
		GDKfree(extremes);
		*retval= bn->batCacheid;
		BBPkeepref(*retval);
		BBPreleaseref(b->batCacheid);
		BBPreleaseref(e->batCacheid);
		return MAL_SUCCEED;
}
@c
@:extreme(min,<)@
@:extreme(max,>)@
@-
The simple extreme operations exploit the grouping and order
properties to speed up the process.
@= xqMinMaxImpl
group_export str GRP@1_oid_@2(int *retval, int *bid);
str GRP@1_oid_@2(int *retval, int *bid){
		BAT *b;
		BAT *bn;
		oid grp= oid_nil;
		@2 *val= 0;
		int xx;
		BUN p, q;

		if( (b= BATdescriptor(*bid)) == NULL ){
			throw(MAL, "group.@1", "Cannot access descriptor");
		}
		/* use expensive operation when the BAT is not ordered on the head */
		if( !(b->hsorted&1) ){
			/* determine groups first */
			BBPreleaseref(b->batCacheid);
			throw(MAL, "group","not yet implemented");
		}

		@:chkHeader(b,GRP@1_oid_@2)@

		bn = BATnew(BAThtype(b), BATttype(b), BATcount(b));

		BATloopFast(b, p, q, xx) {
				oid h = *(oid*) BUNhead(b,p);
				@2 t =  *(@2*) BUNtail(b,p);

				if( h != grp){
					/* switch to a new group */
					BUNins(bn, &h, &t, FALSE);
					grp= h;
					val = (@2*) BUNtail(bn,BUNlast(bn)-xx);
				} else
				if( t @3 *val )
						*val = t;
		}
		bn->hsorted = b->hsorted ;
		bn->tsorted = b->tsorted ;
		BBPkeepref(*retval= bn->batCacheid);
		BBPreleaseref(b->batCacheid);
		return MAL_SUCCEED;
}
@c
 @:xqMinMaxImpl(min,oid,<)@
 @:xqMinMaxImpl(min,sht,<)@
 @:xqMinMaxImpl(min,int,<)@
 @:xqMinMaxImpl(min,lng,<)@
 @:xqMinMaxImpl(min,flt,<)@
 @:xqMinMaxImpl(min,dbl,<)@
 @:xqMinMaxImpl(max,oid,>)@
 @:xqMinMaxImpl(max,sht,>)@
 @:xqMinMaxImpl(max,int,>)@
 @:xqMinMaxImpl(max,lng,>)@
 @:xqMinMaxImpl(max,flt,>)@
 @:xqMinMaxImpl(max,dbl,>)@

@-
@= large_aggr_count
		(void) BATprepareHash(bn);
		BATloopFast(b, p, q, xx) {
				oid *h = (oid*) BUNhead(b,p);

				BUNfndOID(r, bn, h);
				if (r) {
						 ptr t = BUNtail(b,p);
						 (void) t ; /* fool compiler */
						  /*if (ATOMcmp(btt,t,bt_nil)) {*/
						@1 {
								int *dst = (int*) BUNtloc(bn, r);
								(*dst)++;
						}
				}
		}
@= small_aggr_count
		cnt  = (int*) GDKmalloc(range*sizeof(int));
		memset(cnt, 0, range*sizeof(int));
		BATloopFast(b, p, q, xx) {
				int h = (int)(*(oid*) BUNhead(b,p)) - min;

				if (h >= 0 && h < range) {
						 ptr t = BUNtail(b,p);
						(void)t; /* fool compiler */
						/* if (ATOMcmp(btt,t,bt_nil)) {*/
						@1 {
								cnt[h]++;
						}
				}
		}
		BATloopFast(bn, p, q, xx) {
				int h = (int)(*(oid*) BUNhead(bn,p)) - min;
				*(int*)BUNtloc(bn, p) = cnt[h];
		}
		GDKfree(cnt);

@c

group_export str GRPaggr_count(int *retval, int *bid, int *eid, bit *ignore_nils);
str
GRPaggr_count(int *retval, int *bid, int *eid, bit *ignore_nils)
{
	BAT *b = NULL, *e = NULL;
	BAT *bn;
	int zero = 0, *cnt;
	BUN p, q, r;
	int xx, i, range, min, max;
	int btt;
	ptr bt_nil;

	if ((b = BATdescriptor(*bid)) == NULL) {
		throw(MAL, "group.count", "Cannot access descriptor");
	}

	@:chkHeader(b,GRPaggr_count)@
	if ((e = BATdescriptor(*eid)) == NULL) {
		BBPreleaseref(b->batCacheid);
		throw(MAL, "group.count", "Cannot access descriptor");
	}
	@:chkHeader(e,GRPaggr_count)@

	bn = BATnew(e->htype, TYPE_int, BATcount(e));
	btt = b->ttype;
	bt_nil = ATOMnilptr(b->ttype);

	/* init: set all sums to zero */
	bn->tsorted = bn->hsorted = 0;
	ALIGNsetH(bn, e);
	if (BAThordered(e) & 1) {
		min = (int) (*(oid *) BUNhead(e, BUNfirst(e)));
		BATloopFast(e, p, q, xx) {
			BUNfastins(bn, BUNhead(e, p), &zero);
		}
		max = (int) (*(oid *) BUNhead(e, BUNlast(e) - BUNsize(e)));
	} else {
		min = max = (int) (*(oid *) BUNhead(e, BUNfirst(e)));
		BATloopFast(e, p, q, xx) {
			BUNfastins(bn, BUNhead(e, p), &zero);
			i = (int) (*(oid *) BUNhead(e, p));
			if (i < min)
				min = i;
			else if (i > max)
				max = i;
		}
	}
	range = max - min + 1;

	/* scan b, and add increment totals for true values */
	if (range > SMALL_AGGR_MAX) {
		if (*ignore_nils) {
			ALGODEBUG THRprintf(GDKout, "#CMDaggr_count: range(=%lu) > SMALL_AGGR_MAX(=%d)  =>  large_aggr_count(if (ATOMcmp(btt,t,bt_nil)))\n", (unsigned long) range, SMALL_AGGR_MAX);

			@:large_aggr_count(if (ATOMcmp(btt, t, bt_nil)))@
		} else {
			ALGODEBUG THRprintf(GDKout, "#CMDaggr_count: range(=%lu) > SMALL_AGGR_MAX(=%d)  =>  large_aggr_count()\n", (unsigned long) range, SMALL_AGGR_MAX);

			@:large_aggr_count()@
		}

	} else {
		if (*ignore_nils) {
			ALGODEBUG THRprintf(GDKout, "#CMDaggr_count: range(=%lu) <= SMALL_AGGR_MAX(=%d)  =>  small_aggr_count(if (ATOMcmp(btt,t,bt_nil)))\n", (unsigned long) range, SMALL_AGGR_MAX);

			@:small_aggr_count(if (ATOMcmp(btt, t, bt_nil)))@
		} else {
			ALGODEBUG THRprintf(GDKout, "#CMDaggr_count: range(=%lu) <= SMALL_AGGR_MAX(=%d)  =>  small_aggr_count()\n", (unsigned long) range, SMALL_AGGR_MAX);

			@:small_aggr_count()@
		}

	}

	*retval = bn->batCacheid;
	BBPkeepref(*retval);
	BBPreleaseref(b->batCacheid);
	BBPreleaseref(e->batCacheid);
	return MAL_SUCCEED;
}

group_export str GRPsize(int *retval, int *bid, int *eid);
str
GRPsize(int *retval, int *bid, int *eid)
{
	BAT *b = NULL, *e = NULL;
	BAT *bn;
	int zero = 0;
	BUN p, q, r;
	int xx;

	if ((b = BATdescriptor(*bid)) == NULL) {
		throw(MAL, "group.size", "Cannot access descriptor");
	}

	@:chkHeader(b,GRPsize)@
	if ((e = BATdescriptor(*eid)) == NULL) {
		BBPreleaseref(b->batCacheid);
		throw(MAL, "group.size", "Cannot access descriptor");
	}
	@:chkHeader(e,GRPsize)@

	bn = BATnew(e->htype, TYPE_int, BATcount(e));
	/* init: set all sums to zero */
	bn->tsorted = bn->hsorted = 0;
	ALIGNsetH(bn, e);
	BATloopFast(e, p, q, xx) {
		BUNfastins(bn, BUNhead(e, p), &zero);
	}
	/* scan b, and add increment totals for true values */
	(void) BATprepareHash(bn);
	BATloopFast(b, p, q, xx) {
		if (*(bit *) BUNtloc(b, p) == TRUE) {
			oid *h = (oid *) BUNhead(b, p);

			BUNfndOID(r, bn, h);
			if (r) {
				int *dst = (int *) BUNtloc(bn, r);

				(*dst)++;
			}
		}
	}
	*retval = bn->batCacheid;
	BBPkeepref(*retval);
	BBPreleaseref(b->batCacheid);
	BBPreleaseref(e->batCacheid);
	return MAL_SUCCEED;
}

@-
The window aggregate functions
@= windowsum
group_export str GRPslidingsum_@1(int *retval, int *bid, int  *size, int *shift);
str GRPslidingsum_@1(int *retval, int *bid, int  *size, int *shift){
		BAT *b, *bn;
		@2 sum;
		oid o= oid_nil;
		BUN p, q;
		int xx,i;

		if( *shift <=0){
			throw(MAL, "group.sum", "Illegal shift value");
		}
			
		if( (b= BATdescriptor(*bid)) == NULL ){
			throw(MAL, "group.sum", "Cannot access descriptor");
		}
		@:chkHeader(b,GRPwindowsum_@1)@

		/* init: set all sums to zero */
		bn= BATnew( TYPE_void, TYPE_@2, BATcount(b)/ *size +1);
		bn->tsorted = bn->hsorted = 0;
		BATseqbase(bn,0);

		i= *size;
		sum =0;
		BATloopFast(b, p, q, xx) {
				sum += *(@1*) BUNtail(b,p);
				if( --i == 0){
					BUNfastins(bn, &o, &sum);
					/* slide here */
					if( *size != *shift ){
						p-= (*size-*shift)*xx;
					}
					i= *size;
					sum =0;
				}
		}
		if(i != *size)
			BUNfastins(bn, &o, &sum);

		*retval= bn->batCacheid;
		BBPkeepref(*retval);
		BBPreleaseref(b->batCacheid);
		return MAL_SUCCEED;
}
group_export str GRPwindowsum_@1(int *retval, int *bid, int  *size);
str GRPwindowsum_@1(int *retval, int *bid, int  *size){
	return GRPslidingsum_@1(retval,bid,size,size);
}
@c
@:windowsum(sht,lng)@
@:windowsum(int,lng)@
@:windowsum(lng,lng)@
@:windowsum(flt,dbl)@
@:windowsum(dbl,dbl)@
@}
